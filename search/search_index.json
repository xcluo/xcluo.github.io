{"config":{"lang":["en","en"],"separator":"[\\s\\u200b\\-\\u3000\\u3001\\u3002\\uFF0C\\uFF0E\\uFF1F\\uFF01\\uFF1B]+","pipeline":["stemmer"]},"docs":[{"location":"index.html","title":"Home","text":""},{"location":"index.html#hello-world","title":"Hello World!","text":""},{"location":"todo.html","title":"Todo","text":"<ul> <li> RAG\u200b\u7684\u200b\u591a\u200b\u5b9e\u4f53\u200b\u95ee\u9898\u200b\u5982\u4f55\u200b\u89e3\u51b3\u200b\uff1a\u200b\u7231\u56e0\u65af\u5766\u200b\u548c\u200b\u725b\u987f\u200b\u5728\u200b\u7269\u7406\u5b66\u200b\u4e0a\u200b\u7684\u200b\u8d21\u732e\u200b\u6709\u4f55\u200b\u4e0d\u540c\u200b\uff1f</li> <li> \u200b\u591a\u4efb\u52a1\u200b\u5b66\u4e60\u200b\u4e2d\u200b\u4e92\u65a5\u200b\u4efb\u52a1\u200b\u5f71\u54cd\u200b\u524a\u51cf\u200b\uff1a1) model merging; 2) \u200b\u57fa\u4e8e\u200bprompt\u200b\u8bad\u7ec3\u200b</li> <li> \u200b\u4ece\u200b\u96f6\u200b\u6784\u5efa\u200bDS\uff1ahttps://avoid.overfit.cn/post/ac6d4be0a234412ea00032737365638c#</li> <li> MCP\uff1amodel context protocol</li> <li> function call</li> <li> gpt-oss, Open Source Software</li> <li> curl</li> <li> triton\u200b\u6846\u67b6\u200b</li> <li> ollama, tensorRT</li> <li> langchain (Language Chain)</li> <li> dify(do it for you)</li> <li> ragflow</li> <li> haystack</li> <li> \u200b\u963f\u91cc\u200b\u767e\u70bc\u200b</li> <li> docker</li> <li> kubernetes (k8s)</li> <li> \u200b\u8054\u90a6\u200b\u5b66\u4e60\u200b</li> <li> Fisher information matrix</li> <li> Hessian matrix</li> <li> QK-Norm, \u200b\u5728\u200bW_Q/K/V\u200b\u8f93\u5165\u200b\u524d\u200b\u8fdb\u884c\u200bLN\u200b\u64cd\u4f5c\u200b<ul> <li>Scaling vision transformers to 22 billion parameters</li> <li>Small-scale proxies for large-scale transformer training instabilities</li> </ul> </li> <li> bits-per-byte, BPB, The Pile: An 800GB Dataset of Diverse Text for Language Modeling</li> <li> scaling laws<ul> <li>Deep learning scaling is predictable, empirically</li> <li>Scaling laws for autoregressive generative modeling</li> <li>Training compute-optimal large language models, IsoFLOP\u200b\u56fa\u5b9a\u200b\u7b97\u529b\u200b</li> <li>Scaling laws for neural language models</li> </ul> </li> <li> DARE: Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch</li> <li> linear attention<ul> <li>Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention</li> <li>Linformer: Self-Attention with Linear Complexity</li> </ul> </li> <li> MRL paper: Matryoshka Representation Learning, \u200b\u4e00\u822c\u200bmrl \u2192 norm</li> <li> Slimmable Neural Networks</li> <li> Reducing activation recomputation in large transformer models.</li> <li> 3D parallel</li> <li> pipedream, pipedream-2bw</li> <li> Zero bubble pipeline parallelism</li> <li> Device Capacity Factor</li> <li> ROI Pooling, Region of Interest: 1) region proposal; 2) pooling sections; 3) max_pooling of sections<ul> <li>\u200b\u5c06\u200bfeature map\u200b\u5212\u5206\u200b\u4e3a\u200b H*W \u200b\u4e2a\u200b\u533a\u57df\u200b</li> <li>\u200b\u901a\u8fc7\u200bmax_pooling\u200b\u5f97\u5230\u200b H*W \u200b\u5927\u5c0f\u200b\u7684\u200b\u7279\u5f81\u200b\u56fe\u200b</li> </ul> </li> <li> Persona Hub\uff1aScaling Synthetic Data Creation with 1,000,000,000 Personas</li> <li> dashscope for alibaba; openai for openai; requests for glm4</li> <li> yolo\u200b\u5bb6\u65cf\u200b\uff0c SSD\uff08Single Shot MultiBox Detector\uff09\u200b\u591a\u200b\u5c3a\u5ea6\u200b\u7279\u5f81\u200b\u56fe\u200b\u9884\u6d4b\u200b\uff0cRetinaNet</li> <li> Faster R-CNN</li> <li> GoogleNet=Inception v1\uff0cInception\u200b\u5bb6\u65cf\u200b\uff0cInception-ResNet</li> <li> AlexNet: \u200b\u5f15\u5165\u200bdropout\u200b\u548c\u200bReLU\u200b\u6fc0\u6d3b\u200b\u51fd\u6570\u200b</li> <li> VGGNet\uff1a\u200b\u5168\u90e8\u200b\u4f7f\u7528\u200b3*3\u200b\u7684\u200bkernel\uff0c\u200b\u51cf\u5c11\u200b\u53c2\u6570\u200b\uff0c\u200b\u589e\u52a0\u200b\u975e\u7ebf\u6027\u200b</li> <li> ResNet-50\uff1a\u200b\u63d0\u51fa\u200b\u6b8b\u5dee\u200b\u8fde\u63a5\u200b</li> <li> FCN\uff08Fully Convolutional Network\uff09</li> <li> ConvNeXt\uff0cMobileNet\uff0cShuffleNet, EfficientNet\uff0c3D CNN\uff0cPointNet </li> <li> DETR</li> <li> openCV</li> <li> cv\u200b\u4e2d\u200b\u5e38\u89c1\u200b\u7684\u200b\u6570\u636e\u200b\u589e\u5f3a\u200b\u65b9\u6848\u200b\uff1acrop \u200b\u5bf9\u200b\u5355\u5f20\u200b\u8f93\u5165\u200b\u56fe\u50cf\u200b\u88c1\u526a\u200b</li> <li> xfyun for xunfei</li> <li> Universal transformers. \u200b\u7c7b\u4f3c\u200b RNN \u200b\u7684\u200b\u6743\u91cd\u200b\u5171\u4eab\u200b\uff0c\u200b\u6240\u6709\u200b\u65f6\u95f4\u200b\u6b65\u200b\u5171\u4eab\u200b\u540c\u200b\u4e00\u7ec4\u200b Self-Attention \u200b\u548c\u200b FFN \u200b\u53c2\u6570\u200b</li> <li> mGTE</li> <li> bge, bge-m3</li> <li> jina embedding\uff0cjina ai\u200b\u63a8\u51fa\u200b</li> <li> e5 embedding\uff0cintfloat\u200b\u56e2\u961f\u200b\u7814\u53d1\u200b</li> <li> xlm-roberta\uff0cfair\u200b\u7814\u53d1\u200b</li> <li> https://github.com/castorini/pyserini</li> <li> cot, cot-sc, tot, got, TCoT, PoT, ICoT</li> <li> transformers.optmization, transformers.Trainer</li> <li> q-learning DQN, DDPG\u200b\u4e0d\u7528\u200b\u91cd\u8981\u6027\u200b\u91c7\u6837\u200b</li> <li> DPO, PPO, GRPO, DAPO</li> <li> GLM-4.5, Kimi-K2, Qwen</li> <li> tf.metrics, torchmetrics</li> <li> \u200b\u6587\u6863\u200bchunk\u200b\u65b9\u6848\u200b         - Fixed-size window Chunking + overlapping, charatertextsplitter         - \u200b\u7ed3\u6784\u5316\u200b\u5206\u5757\u200b\uff1amarkdown\u3001html\u3001pdf\u200b\u7b49\u200b\u7ed3\u6784\u5316\u200b\u6587\u6863\u200b</li> <li> \u200b\u5bf9\u6bd4\u200b\u5b66\u4e60\u200b\u8d1f\u200b\u6837\u672c\u200b\u9009\u62e9\u200b\u65b9\u6848\u200b, improved infonce loss</li> <li> \u200b\u6587\u6863\u200b\u68c0\u7d22\u200btop-k\u200b\u540e\u200b\u8fd8\u8981\u200b\u8fdb\u884c\u200b\u91cd\u6392\u200breranking\uff0c\u200b\u53ef\u200b\u5728\u200b\u7ed3\u5408\u200b\u641c\u7d22\u200b\u63a8\u8350\u200b\u4e2d\u200b\u7684\u200b\u91cd\u6392\u200b\u6280\u672f\u200b</li> <li> sft roberta with multiple sequence concurrent with customized attention mask</li> <li> DeepSeek-2</li> <li> DeepSeek-3 https://zhuanlan.zhihu.com/p/16323685381</li> <li> \u200b\u514d\u8d39\u200b gpt-4: https://gpt.xfai.online/list/#/home</li> <li> instruct gpt: Training language models to follow instructions with human feedback</li> <li> GPTQ</li> <li> Atom: Low-bit quantization for efficient and accurate LLM serving</li> <li> MoE: https://zhuanlan.zhihu.com/p/669312652</li> <li> huggingface leaderboard</li> <li> code with paper leaderboard</li> <li> \u200b\u5927\u200b\u6a21\u578b\u200b\u9762\u8bd5\u200b</li> <li> NSA: natively trainable sparse Attention, hierarchical attention</li> <li> Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct</li> <li> Math-shepherd: Verify and reinforce llms step-by-step without human annotations</li> <li> vllm: Efficient Memory Management for Large Language Model Serving with PagedAttention</li> <li> HAI-LLM framework\uff08higher flyer\uff09</li> <li> Colossal-AI:  A Unified Deep Learning System For Large-Scale Parallel Training</li> <li> accelerate config</li> <li> \u200b\u6a21\u578b\u200b\u5e7b\u89c9\u200bhallucination</li> <li> \u200b\u6301\u7eed\u200b\u5b66\u4e60\u200b\uff0c\u200b\u907f\u514d\u200b\u707e\u96be\u6027\u200b\u9057\u5fd8\u200b<ul> <li>\u200b\u6b63\u5219\u200b\u5316\u200b\u3001\u200b\u6570\u636e\u200b\u653e\u200b\u56de\u200b\u3001\u200b\u589e\u91cf\u200b\u5b66\u4e60\u200b\u3001adapter\u200b\u7f51\u7edc\u200b\uff0c\u200b\u4f7f\u7528\u200bpre model\u200b\u8f6f\u200b\u6807\u7b7e\u200b\u6570\u636e\u200b\u53c2\u4e0e\u200b\u8bad\u7ec3\u200b\u7b49\u200b</li> </ul> </li> <li> gradient checkpointing, activation checkpointing: Training Deep Nets with Sublinear Memory Cost</li> <li> Gradient Checkpointing\uff0cgif, reduce the activation memory by approximately the square root of the total activations at the expense of 33% re-computation overhead</li> <li> length normalization</li> <li> lora with diffusion model </li> <li> LDA\u200b\u6f5c\u5728\u200b\u8fea\u5229\u514b\u96f7\u200b\u5206\u5e03\u200b\uff0cb\u200b\u7ad9\u200b\u89c6\u9891\u200b LDA\u200b\u4e3b\u9898\u200b\u6a21\u578b\u200b</li> <li> LSA/PLSA</li> <li> Cholesky\u200b\u5206\u89e3\u200b</li> <li> odds\uff0clogit\uff0cligitis</li> <li> GBDT + LR</li> <li> Restricted Boltzmann Machines (RBM)</li> <li> A/B test</li> <li> TF-IDF_j, MI_{a, b, c, d}</li> <li>tensorflow 1.x\u200b\u4e2d\u200b\u5728\u200b\u68af\u5ea6\u200b\u4e0b\u964d\u65f6\u200b\u5982\u4f55\u200b\u8bbe\u7f6e\u200bL1\uff0cL2\u200b\u6b63\u5219\u200b\u5316\u200b\u7ea6\u675f\u200b     <pre><code>with tf.variable_scope(\"layer1\", regularizer=l2_regularizer):\n    xxx\nreg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\ntotal_loss = cross_entropy_loss + sum(reg_losses)\n</code></pre></li> <li>\u200b\u63a8\u8350\u200b\u7cfb\u7edf\u200b\u653b\u51fb\u200b</li> <li>\u200b\u63a8\u8350\u200b\u7cfb\u7edf\u200b\u8bba\u6587\u200b\u7b14\u8bb0\u200b<ul> <li> \u200b\u63a8\u8350\u200b\u7cfb\u7edf\u200b\u8bba\u6587\u200b\u7cbe\u8bfb\u200b</li> <li> \u200b\u7ecf\u5178\u200b\u63a8\u8350\u200b\u7b97\u6cd5\u200b\u5b66\u4e60\u200b</li> <li> \u200b\u63a8\u8350\u200b\u7cfb\u7edf\u200b\u4e0e\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u8bba\u6587\u200b\u7b14\u8bb0\u200b</li> </ul> </li> <li>https://km.netease.com/v4/detail/blog/223053  </li> <li>https://readpaper.feishu.cn/docx/CrMGdSVPKow5d1x1XQMcJioRnQe</li> </ul>"},{"location":"AI/annotation.html","title":"\u4e13\u4e1a\u540d\u8bcd","text":""},{"location":"AI/annotation.html#a","title":"A","text":"<ul> <li>AE\uff1aAuto-Encoder\uff0c\u200b\u81ea\u200b\u7f16\u7801\u5668\u200b</li> <li>AGI\uff1aArtifical General Intelligence\uff0c\u200b\u901a\u7528\u200b\u4eba\u5de5\u667a\u80fd\u200b</li> <li>AIGC\uff1aArtificial Intelligence Generated Content\uff0c\u200b\u4eba\u5de5\u667a\u80fd\u200b\u751f\u6210\u200b\u5185\u5bb9\u200b</li> <li>AMP\uff1aAutomatic Mixed Precision\uff0c\u200b\u81ea\u52a8\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b</li> <li>AR\uff1aAuto Regressive\uff0c\u200b\u81ea\u200b\u56de\u5f52\u200b</li> <li>AR: Augmented Reality\uff0c\u200b\u589e\u5f3a\u200b\u73b0\u5b9e\u200b</li> <li>ASR\uff1aAutomatic Speech Recognition\uff0c\u200b\u81ea\u52a8\u200b\u8bed\u97f3\u200b\u8bc6\u522b\u200b\uff0c\u200b\u5c06\u200b\u8bed\u97f3\u200b\u8bcd\u6c47\u200b\u5185\u5bb9\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u8ba1\u7b97\u673a\u200b\u53ef\u8bfb\u200b\u7684\u200b\u8f93\u5165\u200b</li> <li>AUC\uff1aArea Under Curve\uff0c\u200b\u66f2\u7ebf\u200b\u4e0e\u200b\u5750\u6807\u8f74\u200b\u56f4\u6210\u200b\u7684\u200b\u9762\u79ef\u200b</li> </ul>"},{"location":"AI/annotation.html#b","title":"B","text":"<ul> <li>BERT\uff1aBidirectional Encoder Representations from Transformers  </li> <li>BLEU BiLingual Evaluation Understudy, \u200b\u53cc\u8bed\u200b\u8bc4\u4f30\u200b\u7814\u7a76\u200b</li> <li>BSR\uff1aBlind image Super-Resolution\uff0c\u200b\u56fe\u50cf\u200b\u76f2\u8d85\u200b\u5206\u8fa8\u7387\u200b</li> </ul>"},{"location":"AI/annotation.html#c","title":"C","text":"<ul> <li>CART\uff1aClassification And Regression Tree\uff0c\u200b\u5206\u7c7b\u200b\u548c\u200b\u56de\u5f52\u200b\u4e8c\u53c9\u6811\u200b\u51b3\u7b56\u6811\u200b\u3002</li> <li>CoT: Chain of  Think\uff0c\u200b\u94fe\u5f0f\u200b\u601d\u7ef4\u200b</li> <li>CPT\uff1aContrastive PreTraining model\uff0c\u200b\u5bf9\u6bd4\u200b\u5b66\u4e60\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b</li> <li>CRF: Conditional Random Field\uff0c\u200b\u6761\u4ef6\u200b\u968f\u200b\u673a\u573a\u200b\uff0c\u200b\u4e5f\u200b\u53eb\u505a\u200b\u9a6c\u5c14\u53ef\u592b\u200b\u968f\u200b\u673a\u573a\u200b</li> <li>CTR: Click-Throught Rate\u200b\u70b9\u51fb\u200b\u901a\u8fc7\u7387\u200b\uff0c\u200b\u6307\u200b\u4e00\u5b9a\u200b\u65f6\u95f4\u200b\u5185\u200b\u7528\u6237\u200b\u70b9\u51fb\u200b\u94fe\u63a5\u200b\u6b21\u6570\u200b\u4e0e\u200b\u5c55\u793a\u200b\u94fe\u63a5\u200b\u6b21\u6570\u200b\u7684\u200b\u6bd4\u4f8b\u200b</li> </ul>"},{"location":"AI/annotation.html#d","title":"D","text":"<ul> <li>DAE\uff1aDenoising Auto-Encoder\uff0c\u200b\u53bb\u200b\u566a\u81ea\u200b\u7f16\u7801\u5668\u200b</li> <li>DDIM\uff1aDenoising Diffusion Implicit Model\uff0c\u200b\u53bb\u200b\u566a\u200b\u6269\u6563\u200b\u9690\u5f0f\u200b\u6a21\u578b\u200b</li> <li>DDPM\uff1aDenoising Diffusion Probabilistic Model\uff0c\u200b\u53bb\u200b\u566a\u200b\u6269\u6563\u200b\u6982\u7387\u6a21\u578b\u200b</li> <li>DPO\uff1aDirect Preference Optimization</li> <li>DPU\uff1aDeep learning Processing Unit\uff0c\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u5904\u7406\u5668\u200b</li> </ul>"},{"location":"AI/annotation.html#e","title":"E","text":"<ul> <li>EDA\uff1aEasy Data Augmentation\uff0c\u200b\u7b80\u5355\u200b\u7684\u200b\u6570\u636e\u200b\u589e\u5f3a\u200b\u65b9\u6cd5\u200b</li> <li>EM\uff1aExact Match\uff0c\u200b\u7cbe\u786e\u200b\u5339\u914d\u200b</li> <li>EM\uff1aExpectation-Maximization algorithm\uff0c\u200b\u6700\u5927\u200b\u671f\u671b\u200b\u7b97\u6cd5\u200b\uff0cEM\u200b\u7b97\u6cd5\u200b</li> </ul>"},{"location":"AI/annotation.html#f","title":"F","text":"<ul> <li>FID\uff1aFrechet Inception Distance\uff0c\u200b\u4e00\u79cd\u200b\u662f\u200b\u901a\u8fc7\u200b\u8ba1\u7b97\u200b\u4e24\u4e2a\u200b\u56fe\u50cf\u200b\u96c6\u5728\u200bInception\u200b\u7f51\u7edc\u200b\u4e0a\u200b\u7684\u200b\u5e73\u5747\u200b\u6982\u7387\u8ddd\u79bb\u200b\u5f97\u51fa\u200b\u3001\u200b\u5e7f\u6cdb\u200b\u4f7f\u7528\u200b\u7684\u200b\u8861\u91cf\u200b\u4e24\u4e2a\u200b\u56fe\u50cf\u200b\u751f\u6210\u200b\u6a21\u578b\u200b\u751f\u6210\u200b\u7684\u200b\u56fe\u50cf\u200b\u5206\u5e03\u200b\u4e4b\u95f4\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\u7684\u200b\u5ea6\u91cf\u200b\u6307\u6807\u200b</li> <li>FPU\uff1aFloating Processing Unit\uff0c\u200b\u6d6e\u70b9\u200b\u8ba1\u7b97\u200b\u5355\u5143\u200b\u5904\u7406\u5668\u200b</li> </ul>"},{"location":"AI/annotation.html#g","title":"G","text":"<ul> <li>GAN\uff1aGenerative Aversarial Network\uff0c\u200b\u751f\u6210\u200b\u5bf9\u6297\u200b\u6a21\u578b\u200b</li> <li>GBDT\uff1aGradient Boosted Decision Trees\uff0c\u200b\u68af\u5ea6\u200b\u63d0\u5347\u200b\u51b3\u7b56\u6811\u200b\uff0cGBM\u200b\u7684\u200b\u4e00\u79cd\u200b\u7279\u6b8a\u200b\u5b9e\u73b0\u200b</li> <li>GBM\uff1aGradient Boosting Machines\uff0c\u200b\u68af\u5ea6\u200b\u63d0\u5347\u673a\u200b</li> <li>GEC\uff1aGrammatical Error Correction\uff0c\u200b\u8bed\u6cd5\u200b\u7ea0\u9519\u200b</li> <li>GeMM\uff1aGeneral Matrix Multiplication\uff0c\u200b\u901a\u7528\u200b\u77e9\u9635\u200b\u4e58\u6cd5\u200b</li> <li>GPT\uff1aGenerative Pre-trained Transformer</li> <li>GQA\uff1aGrouped Query Attention\uff0c\u200b\u5206\u7ec4\u200b\u67e5\u8be2\u200b\u6ce8\u610f\u529b\u200b</li> </ul>"},{"location":"AI/annotation.html#h","title":"H","text":"<ul> <li>HMM: Hidden Markov Model\uff0c\u200b\u9690\u5f0f\u200b\u9a6c\u5c14\u53ef\u592b\u200b\u6a21\u578b\u200b</li> </ul>"},{"location":"AI/annotation.html#i","title":"I","text":"<ul> <li>ID3: Iterative Dichotomiser 3\uff0c\u200b\u8fed\u4ee3\u200b\u4e8c\u5206\u200b\u7b97\u6cd5\u200b</li> <li>IR\uff1aInformation Retrieval\uff0c\u200b\u4fe1\u606f\u68c0\u7d22\u200b</li> </ul>"},{"location":"AI/annotation.html#j","title":"J","text":""},{"location":"AI/annotation.html#k","title":"K","text":""},{"location":"AI/annotation.html#l","title":"L","text":"<ul> <li>LLM\uff1aLarge Language Model\uff0c\u200b\u5927\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b</li> <li>LoRA\uff1aLow Rank Adaptation\uff0c\u200b\u4f4e\u200b\u79e9\u200b\u9002\u914d\u200b</li> <li>LSA\uff1aLatent Semantic Analysis\uff0c\u200b\u6f5c\u5728\u200b\u8bed\u4e49\u200b\u5206\u6790\u200b\uff0c\u200b\u4e5f\u200b\u79f0\u4e3a\u200b\u6f5c\u5728\u200b\u8bed\u4e49\u200b\u7d22\u5f15\u200bLSI(Latent Semantic Indexing)</li> </ul>"},{"location":"AI/annotation.html#m","title":"M","text":"<ul> <li>MHA\uff1aMulti-Head Attention\uff0c\u200b\u591a\u5934\u200b\u6ce8\u610f\u529b\u200b\uff0c\u200b\u5373\u200bvanilla Attention</li> <li>MLM\uff1aMasked Language Modeling\uff0c\u200b\u63a9\u7801\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff0c\u200b\u4e00\u79cd\u200b\u9884\u200b\u8bad\u7ec3\u4efb\u52a1\u200b</li> <li>MoE\uff1aMixture of Experts\uff0c\u200b\u4e13\u5bb6\u200b\u6df7\u5408\u200b</li> <li>MoLE\uff1aMixture of LoRA Experts\uff0cLoRA\u200b\u4e13\u5bb6\u200b\u6df7\u5408\u200b</li> <li>MQA\uff1aMulti-Query Attention\uff0c\u200b\u591a\u200b\u67e5\u8be2\u200b\u6ce8\u610f\u529b\u200b</li> <li>MRR\uff1aMean Reciprocal Rank\uff0c\u200b\u5e73\u5747\u200b\u5012\u6570\u200b\u6392\u540d\u200b</li> <li>MTEB: Massive Text Embedding Benchmark\uff0c\u200b\u6d77\u91cf\u200b\u6587\u672c\u200bembedding\u200b\u6d4b\u8bd5\u200b\u57fa\u51c6\u200b</li> <li>MTP\uff1aMulti-Token Prediction\uff0c\u200b\u8fde\u7eed\u200b\u591a\u200btoken\u200b\u9884\u6d4b\u200b\u4efb\u52a1\u200b</li> </ul>"},{"location":"AI/annotation.html#n","title":"N","text":"<ul> <li>NLG\uff1aNatural Language Generation\uff0c\u200b\u81ea\u7136\u8bed\u8a00\u200b\u751f\u6210\u200b</li> <li>NLP\uff1aNatural Language Processing\uff0c\u200b\u81ea\u7136\u8bed\u8a00\u200b\u5904\u7406\u200b</li> <li>NLU\uff1aNatural Language Understanding\uff0c\u200b\u81ea\u7136\u8bed\u8a00\u200b\u7406\u89e3\u200b</li> <li>NPU\uff1aNeural network Processing Unit\uff0c\u200b\u4e2d\u79d1\u9662\u8ba1\u7b97\u6240\u200b/\u200b\u5bd2\u6b66\u7eaa\u200b\u516c\u53f8\u51fa\u54c1\u200b\u7684\u200b\u795e\u7ecf\u7f51\u7edc\u200b\u5904\u7406\u5668\u200b</li> </ul>"},{"location":"AI/annotation.html#o","title":"O","text":"<ul> <li>OCR\uff1aOptical Character Recognition\uff0c\u200b\u5149\u5b66\u200b\u5b57\u7b26\u8bc6\u522b\u200b</li> <li>ONNX\uff1aOpen Neural Network Exchange\uff0c\u200b\u4e00\u79cd\u200b\u6a21\u578b\u200b\u7ed3\u6784\u200b\u4f18\u5316\u200b\u5f00\u6e90\u200b\u6570\u636e\u7c7b\u578b\u200b</li> <li>OOM\uff1aOout Of Memory\uff0c\u200b\u5185\u5b58\u200b\u6ea2\u51fa\u200b\u6216\u200b\u5185\u5b58\u4e0d\u8db3\u200b</li> <li>OOV: Out Of Vocabulary\uff0c\u200b\u4e0d\u200b\u5728\u200b\u8bcd\u8868\u200b\u5185\u200b</li> </ul>"},{"location":"AI/annotation.html#p","title":"P","text":"<ul> <li>PEFT: Parameter-Efficient Fine-Tuning\uff0c\u200b\u53c2\u6570\u200b\u9ad8\u6548\u200b\u5fae\u8c03\u200b</li> <li>PLM\uff1aPretrained Language Model\uff0c\u200b\u9884\u200b\u8bad\u7ec3\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b</li> <li>pLSA\uff1aProbabilistic Latent Semantic Analysis\uff0c\u200b\u6982\u7387\u200b\u6f5c\u5728\u200b\u8bed\u4e49\u200b\u5206\u6790\u200b\uff0c\u200b\u4e5f\u200b\u79f0\u4e3a\u200b\u6982\u7387\u200b\u6f5c\u5728\u200b\u8bed\u4e49\u200b\u7d22\u5f15\u200b\uff08PLSI\uff09</li> <li>PoS: Part of Speech, \u200b\u8bcd\u6027\u200b</li> <li>PPO\uff1aProximal Policy Optimization</li> <li>PTQ\uff1aPost-Training Quantization\uff0c\u200b\u8bad\u7ec3\u200b\u540e\u200b\u91cf\u5316\u200b\uff0c\u200b\u4e5f\u200b\u79f0\u4f5c\u200b\u79bb\u7ebf\u200b\u91cf\u5316\u200b</li> </ul>"},{"location":"AI/annotation.html#q","title":"Q","text":"<ul> <li>QAT\uff1aQuantization Aware Training\uff0c\u200b\u91cf\u5316\u200b\u611f\u77e5\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u91cf\u5316\u200b\uff0c\u200b\u4e5f\u200b\u79f0\u4f5c\u200b\u5728\u7ebf\u200b\u91cf\u5316\u200b</li> </ul>"},{"location":"AI/annotation.html#r","title":"R","text":"<ul> <li>RAG\uff1aRetrieval-Augmented Generation\uff0c\u200b\u68c0\u7d22\u200b\u589e\u5f3a\u200b\u751f\u6210\u200b</li> <li>RL(HF)\uff1aReinforcement Learning \uff08from Huamn Feedback\uff09\uff0c\uff08\u200b\u4eba\u7c7b\u200b\u53cd\u9988\u200b\uff09\u200b\u5f3a\u5316\u200b\u5b66\u4e60\u200b</li> <li>ROC\uff1aReceiver Operating Characteristic curve\uff0c\u200b\u53d7\u8bd5\u8005\u200b\u5de5\u4f5c\u200b\u7279\u5f81\u200b\u66f2\u7ebf\u200b</li> <li>ROUGE\uff1aRecall-Oriented Understudy for Gisting Evaluation</li> </ul>"},{"location":"AI/annotation.html#s","title":"S","text":"<ul> <li>SFT\uff1aSupervised Fine-Tuning\uff0c\u200b\u6709\u200b\u76d1\u7763\u200b\u5b66\u4e60\u200b  </li> </ul>"},{"location":"AI/annotation.html#t","title":"T","text":"<ul> <li>TPU\uff1aTensor Processing Unit\uff0cgoogle\u200b\u7684\u200b\u5f20\u91cf\u200b\u5904\u7406\u5668\u200b</li> <li>TTS\uff1aText To Speech\uff0c\u200b\u6587\u672c\u200b\u8f6c\u200b\u8bed\u97f3\u200b</li> </ul>"},{"location":"AI/annotation.html#u","title":"U","text":""},{"location":"AI/annotation.html#v","title":"V","text":"<ul> <li>VAE\uff1aVariational Auto-Encoder\uff0c\u200b\u53d8\u5206\u200b\u81ea\u200b\u7f16\u7801\u5668\u200b</li> <li>VQVAE</li> </ul>"},{"location":"AI/annotation.html#w","title":"W","text":""},{"location":"AI/annotation.html#x","title":"X","text":""},{"location":"AI/annotation.html#y","title":"Y","text":""},{"location":"AI/annotation.html#z","title":"Z","text":""},{"location":"AI/AI_Lab/AI_Lab.html","title":"AI_Lab","text":""},{"location":"AI/AI_Lab/AI_Lab.html#_1","title":"\u516c\u53f8\u200b &amp; \u200b\u673a\u6784","text":"<ol> <li>Open AI</li> <li>Facebook AI Research</li> <li>Google Research</li> <li>Google DeepMind<ol> <li>AlphoGo Zero  </li> </ol> </li> <li>Microsoft Research</li> </ol>"},{"location":"AI/AI_Lab/AI_Lab.html#_2","title":"\u5b66\u6821","text":"<ol> <li>University of Washington</li> </ol>"},{"location":"AI/AI_Lab/FAIR/FAIR.html","title":"FAIR","text":"<p>FAIR (Facebook AI Research)</p>"},{"location":"AI/AI_Lab/Google/DeepMind.html","title":"DeepMind","text":"<p>Google DeepMind</p>"},{"location":"AI/AI_Lab/Google/Research.html","title":"Research","text":"<p>Google Research</p>"},{"location":"AI/AI_Lab/Microsoft/MSR.html","title":"MSR","text":"<p>Microsoft Research (MSR)</p> <p>Microsoft Research Aisa (MSRA)</p>"},{"location":"AI/AI_Lab/OpenAI/OpenAI.html","title":"OpenAI","text":"<p>OpenAI</p>"},{"location":"AI/AI_Platform/index.html","title":"\u673a\u5668\u200b\u5b66\u4e60\u200b\u5e93","text":""},{"location":"AI/AI_Platform/index.html#_1","title":"\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6846\u67b6","text":"<ul> <li> SafeTensors</li> </ul>"},{"location":"AI/AI_Platform/index.html#tensorflow","title":"Tensorflow","text":"<ul> <li>Tensorflow</li> </ul>"},{"location":"AI/AI_Platform/index.html#pytorch","title":"Pytorch","text":"<ul> <li>PyTorch</li> <li>Transformers</li> </ul>"},{"location":"AI/AI_Platform/index.html#paddlepaddle","title":"PaddlePaddle","text":"<ul> <li>PaddlePaddle</li> <li>Nvidia</li> </ul>"},{"location":"AI/AI_Platform/index.html#_2","title":"\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u6846\u67b6","text":"<ul> <li>DeepSpeed</li> <li>Megatron-LM</li> <li>HAI-LLM</li> </ul>"},{"location":"AI/AI_Platform/index.html#_3","title":"\u8fd0\u884c\u200b\u90e8\u7f72\u200b\u6846\u67b6","text":""},{"location":"AI/AI_Platform/index.html#_4","title":"\u90e8\u7f72","text":"<ul> <li>vLLM</li> <li>TensorRT</li> <li>triton</li> </ul>"},{"location":"AI/AI_Platform/index.html#_5","title":"+\u200b\u5f00\u53d1","text":"<ul> <li>Ollama</li> <li>LangChain</li> <li>Dify</li> <li>RAGFlow</li> <li>Haystack</li> <li>\u200b\u963f\u91cc\u200b\u767e\u70bc\u200b</li> </ul>"},{"location":"AI/AI_Platform/index.html#_6","title":"\u6570\u636e\u200b\u9884\u5904\u7406","text":"<ol> <li><code>tf1_dataset_utils.py</code></li> <li> <p><code>torch_dataset_utils.py</code></p> </li> <li> <p>dataset generator</p> </li> <li>Transformers + datasets</li> </ol>"},{"location":"AI/AI_Platform/index.html#scheduler","title":"scheduler","text":""},{"location":"AI/AI_Platform/Dify/dify.html","title":"Dify","text":""},{"location":"AI/AI_Platform/Facebook/faiss.html","title":"Faiss","text":""},{"location":"AI/AI_Platform/LangChain/document_loader.html","title":"Document loader","text":""},{"location":"AI/AI_Platform/LangChain/document_loader.html#pdf","title":"PDF","text":"<pre><code>from langchain_community.document_loaders import PyPDFLoader\nfrom langchain_unstructured import UnstructuredLoader\n</code></pre> Agglomerate text boxes into lines, paragraphs, and other structures via heuristics or ML inference; Run OCR on images to detect text therein; Classify text as belonging to paragraphs, lists, tables, or other structures; Structure text into table rows and columns, or key-value pairs. <p>\u200b\u6574\u5408\u200b\u4e86\u200b\u4f17\u591a\u200b PDF parser</p>"},{"location":"AI/AI_Platform/LangChain/document_loader.html#text-extraction","title":"Text Extraction","text":"<p>\u200b\u7b80\u5355\u200b\u8bc6\u522b\u200b\u6b63\u6587\u200b\u4e2d\u200b\u7684\u200b\u6587\u672c\u200b\u5b57\u7b26\u200b</p> <p><code>pip install pypdf</code></p>"},{"location":"AI/AI_Platform/LangChain/document_loader.html#layout-analysis","title":"Layout Analysis","text":"<p><code>pip install langchain-unstructured</code></p> <pre><code>loader = UnstructuredLoader(\n    file_path=file_path,\n    strategy=\"hi_res\",\n    partition_via_api=True,\n    coordinates=True,\n)\ndocs = []\nfor doc in loader.lazy_load():\n    docs.append(doc)\n</code></pre>"},{"location":"AI/AI_Platform/LangChain/document_loader.html#image-ocr","title":"Image OCR","text":""},{"location":"AI/AI_Platform/LangChain/document_loader.html#web-pages","title":"Web Pages","text":""},{"location":"AI/AI_Platform/LangChain/document_loader.html#html","title":"HTML","text":""},{"location":"AI/AI_Platform/LangChain/document_loader.html#markdown","title":"Markdown","text":""},{"location":"AI/AI_Platform/LangChain/document_loader.html#office-data","title":"Office Data","text":""},{"location":"AI/AI_Platform/LangChain/document_loader.html#csv","title":"CSV","text":""},{"location":"AI/AI_Platform/LangChain/document_loader.html#json","title":"JSON","text":""},{"location":"AI/AI_Platform/LangChain/document_loader.html#customized-data","title":"Customized Data","text":""},{"location":"AI/AI_Platform/LangChain/langchain.html","title":"Langchain","text":"<p><code>pip install longchain</code></p> <ul> <li>https://python.langchain.com/docs/how_to/</li> </ul>"},{"location":"AI/AI_Platform/LangChain/langchain.html#_1","title":"\u6570\u636e\u5904\u7406","text":""},{"location":"AI/AI_Platform/LangChain/langchain.html#document-loader","title":"Document Loader","text":"<ol> <li>PDF files</li> <li>web pages</li> <li>CSV data</li> <li>data from a directory</li> <li>HTML data</li> <li>JSON data</li> <li>Markdown data</li> <li>Microsoft Office Data</li> <li>customized document loader</li> </ol>"},{"location":"AI/AI_Platform/LangChain/langchain.html#text-spliter","title":"Text Spliter","text":""},{"location":"AI/AI_Platform/LangChain/langchain.html#embedding","title":"Embedding\u200b\u76f8\u5173","text":"<pre><code>from langchain_core.vectorstores import InMemoryVectorStore\nfrom langchain_openai import OpenAIEmbeddings\n\nvector_store = InMemoryVectorStore.from_documents(pages, OpenAIEmbeddings())\ndocs = vector_store.similarity_search(\"What is LayoutParser?\", k=2)\nfor doc in docs:\n    print(f'Page {doc.metadata[\"page\"]}: {doc.page_content[:300]}\\n')\n</code></pre>"},{"location":"AI/AI_Platform/Microsoft/deepspeed.html","title":"Deepspeed","text":""},{"location":"AI/AI_Platform/Microsoft/deepspeed.html#zero","title":"ZeRO","text":"<p>\u200b\u8bba\u6587\u200b\uff1aZeRO: Memory Optimizations Toward Training Trillion Parameter Models ZeRO\uff1aZero Redundancy Optimizer Github\uff1aDeepSpeed Microsoft, 2019 Oct, SC2020</p>"},{"location":"AI/AI_Platform/Microsoft/deepspeed.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<p>DeepSpeed \u200b\u662f\u200b\u7531\u200b\u5fae\u8f6f\u200b\u5f00\u53d1\u200b\u7684\u200b\u4e00\u4e2a\u200b\u5f00\u6e90\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u4f18\u5316\u200b\u5e93\u200b\uff0c\u200b\u57fa\u4e8e\u200b \u200b\u5e76\u975e\u200b\u6240\u6709\u200b\u68af\u5ea6\u200b\u548c\u200b\u53c2\u6570\u200b\u7684\u200b\u72b6\u6001\u200b\u5728\u200b\u4efb\u4f55\u200b\u65f6\u5019\u200b\u90fd\u200b\u662f\u200b\u5fc5\u9700\u200b\u7684\u200b\u8fd9\u200b\u4e00\u200b\u89c1\u89e3\u200b \uff0c\u200b\u589e\u52a0\u200b\u53ef\u200b\u9ad8\u6548\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6a21\u578b\u200b\u89c4\u6a21\u200b\uff0c\u200b\u540c\u65f6\u200b\u4f18\u5316\u200b\u5185\u5b58\u200b\uff0c\u200b\u5927\u5e45\u63d0\u9ad8\u200b\u8bad\u7ec3\u200b\u901f\u5ea6\u200b\u3002</p>"},{"location":"AI/AI_Platform/Microsoft/deepspeed.html#zero-dp","title":"ZeRO-DP","text":"<p>\u200b\u4ee5\u200bAMP FP32/FP16\u200b\u8bad\u7ec3\u200b\u573a\u666f\u200b\u4e3a\u4f8b\u200b\uff0c\\(\\Psi\\) \u200b\u8868\u793a\u200b\u6a21\u578b\u200b\u603b\u53c2\u200b\u6570\u91cf\u200b</p> <ol> <li> <p>ZeRO-1 \\(P_{os}\\) \u200b\u5212\u5206\u200b Optimizer State (e.g., momentum and variances in Adam) \uff0c\\(3*4 = K\\)</p> </li> <li> <p>ZeRO-2 \\(P_{os + g}\\)\uff0c+ \u200b\u5212\u5206\u200b Gradient </p> <p>\u200b\u901a\u8fc7\u200b <code>one-reduce</code> \u200b\u64cd\u4f5c\u200b\u5206\u6876\u200b\u89c4\u7ea6\u200b\u5305\u542b\u200b\u6307\u5b9a\u200b\u5206\u7247\u200b\u7684\u200b\u68af\u5ea6\u200b</p> </li> <li> <p>ZeRO-3 \\(P_{os + g + p}\\)\uff0c+ \u200b\u5212\u5206\u200b Parameter Weight</p> <ul> <li>\u200b\u6267\u884c\u200b\u4e00\u6b21\u200b<code>all-gather</code>\u200b\u5b8c\u6210\u200bforward\uff0c\u200b\u5e76\u200b\u5728\u200b\u5f97\u5230\u200bactivation\u200b\u540e\u200b\u4fbf\u200b\u820d\u5f03\u200b\u76f8\u5e94\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b</li> <li>\u200b\u6267\u884c\u200b\u4e00\u6b21\u200b<code>all-gather</code>\u200b\u5b8c\u6210\u200bbackward\uff0c\u200b\u5e76\u200b\u5728\u200b\u5f97\u5230\u200bgradient\u200b\u540e\u200b\u4fbf\u200b\u820d\u5f03\u200b\u76f8\u5e94\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b</li> <li>\u200b\u8f83\u200bDP \u200b\u989d\u5916\u200b\u5f15\u5165\u200b\u4e86\u200b <code>all-gather</code>\u200b\u901a\u4fe1\u200b\u5f00\u9500\u200b\uff08 all-reduce \\(2\\Psi \\rightarrow\\) 2 all-gather + reduce-scatter gradient \\(3\\Psi\\)\uff09\uff0c\u200b\u4f46\u662f\u200b\u80fd\u200b\u5c06\u200b\u5b58\u50a8\u7a7a\u95f4\u200b\u51cf\u200b\u4e3a\u200b\\(\\frac{1}{N_d}\\)</li> </ul> </li> </ol>"},{"location":"AI/AI_Platform/Microsoft/deepspeed.html#zero-r","title":"ZeRO-R","text":"<ol> <li>Partitioned Activation Checkpointing \u200b\u642d\u914d\u200bactivation checkpoint\u200b\u4f7f\u7528\u200b<ul> <li>\\(P_a\\) \u200b\u53ea\u200b\u5b58\u50a8\u200b\u5206\u7247\u200b\u90e8\u5206\u200b\u4e2d\u200b\u7684\u200bactivation checkpointing <p>\u200b\u5728\u200bbackward\u200b\u4e2d\u200bactivation recomputation\u200b\u65f6\u200b\uff0c\u200b\u9700\u8981\u200b\u8fdb\u884c\u200b<code>all-gather</code>\u200b\u64cd\u4f5c\u200b</p> </li> <li>\\(P_{a + cpu}\\)\u200b\u5728\u200b\u6781\u7aef\u200b\u5b58\u50a8\u200b\u53d7\u9650\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u5c06\u200bactivation checkpointing\u200b\u5378\u8f7d\u200b\u81f3\u200bCPU <p>\u200b\u989d\u5916\u200b\u65b0\u589e\u200b\u4e86\u200bGPU\u27f7CPU\u200b\u7684\u200b\u6570\u636e\u200b\u79fb\u52a8\u200b\u5f00\u9500\u200b\uff0c\u200b\u5f53\u200bCPU\u200b\u5185\u5b58\u200b\u8db3\u591f\u200b\u5927\u65f6\u200b\uff0c\u200b\u53ea\u8981\u200bGPU\u27f7CPU\u200b\u7684\u200b\u6570\u636e\u200b\u79fb\u52a8\u200b\u5f00\u9500\u200b\u5c0f\u4e8e\u200bGPU\u200b\u95f4\u901a\u4fe1\u200b\u5f00\u9500\u200b\uff0c<code>batch_size</code>\u200b\u7406\u8bba\u200b\u4e0a\u200b\u53ef\u4ee5\u200b\u65e0\u9650\u5927\u200b</p> </li> </ul> </li> <li>Constant Size Buffers \\(C_B\\) \u200b\u4f7f\u7528\u6027\u80fd\u200b\u9ad8\u6548\u200b\u4e14\u200b\u5e38\u6570\u200b\u5927\u5c0f\u200b\u7684\u200b <code>fuzed buffer size</code></li> <li>Memory Defragmentation \u200b\u5f53\u200b\u65e0\u200b\u8db3\u591f\u200b\u7684\u200b\u8fde\u7eed\u200b\u5185\u5b58\u200b\u6765\u200b\u6ee1\u8db3\u200b\u5f20\u91cf\u200b\u7a7a\u95f4\u200b\u8bf7\u6c42\u200b\uff0c\u200b\u90a3\u4e48\u200b\u5373\u4f7f\u200b\u603b\u5171\u200b\u53ef\u7528\u200b\u7a7a\u95f4\u200b\u5927\u4e8e\u200b\u8bf7\u6c42\u200b\u7684\u200b\u7a7a\u95f4\u200b\uff0c\u200b\u53ef\u80fd\u200b\u4f1a\u200b 1)\u200b\u62a5\u9519\u200bOOM\uff1b2) \u200b\u641c\u7d22\u200b\u5206\u914d\u200b\u8fde\u7eed\u200b\u7a7a\u95f4\u200b\u6548\u7387\u200b\u4f4e\u4e0b\u200b\u3002<ul> <li>\\(M_D\\) \u200b\u5728\u200bactivation checkpointing\u200b\u548c\u200b\u68af\u5ea6\u200b\u8ba1\u7b97\u200b\u5b8c\u6210\u200b\u524d\u9884\u200b\u5206\u914d\u200b\u8fde\u7eed\u200b\u5185\u5b58\u200b\u5757\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u8ba1\u7b97\u200b\u540e\u200b\u5b58\u5165\u200b</li> </ul> </li> </ol>"},{"location":"AI/AI_Platform/Nvidia/index.html","title":"Index","text":"<ul> <li>cuda</li> </ul>"},{"location":"AI/AI_Platform/Nvidia/index.html#nvidia-gpu","title":"Nvidia GPU \u200b\u8ba1\u7b97\u200b\u67b6\u6784","text":"<ol> <li>Tesla</li> <li>Fermi</li> <li>Kepler</li> <li>Maxwell</li> <li>Pascal</li> <li>Volta</li> <li>Turing</li> <li>Ampere</li> <li>Ada Lovelace</li> <li>Hopper</li> <li> <p>Blackwell</p> </li> <li> <p>triton, CUTLASS(CUDA Templates for Linear Algebra Subroutines)</p> </li> <li>CUTLASS profiler tool</li> <li>Warp Matrix Multiply and Accumulate (WMMA) \u200b\u662f\u200b\u73b0\u4ee3\u200b NVIDIA GPU\uff08\u200b\u7279\u522b\u200b\u662f\u4ece\u200b Volta \u200b\u67b6\u6784\u200b\u5f00\u59cb\u200b\uff09\u200b\u4e0a\u200b\u5b9e\u73b0\u200b\u6781\u81f4\u200b\u8ba1\u7b97\u200b\u6027\u80fd\u200b\u7684\u200b\u6838\u5fc3\u6280\u672f\u200b\uff0c\u200b\u901a\u5e38\u200b\u6307\u200bWMMA api\uff0c\u200b\u5141\u8bb8\u200b\u5f00\u53d1\u8005\u200b\u4ee5\u200b Warp\uff0832\u200b\u4e2a\u200b\u5e76\u884c\u200b\u7ebf\u7a0b\u200b\u7684\u200b\u7ec4\u200b\uff09\u200b\u4e3a\u200b\u6267\u884c\u200b\u5355\u4f4d\u200b\uff0c\u200b\u76f4\u63a5\u200b\u5bf9\u200b\u5c0f\u578b\u200b\u77e9\u9635\u200b\uff08\u200b\u4f8b\u5982\u200b 16x16, 32x8 \u200b\u7b49\u200b\uff0c\u200b\u79f0\u4e3a\u200bTile\u200b\u6216\u200bFragment\uff09\u200b\u8fdb\u884c\u200b\u9ad8\u6548\u200b\u7684\u200b\u4e58\u52a0\u200b\u8fd0\u7b97\u200b\u3002</li> <li>thread-blocks, WARPs, and WMMA (Tensor cores)</li> <li>cuDNN</li> <li> <p>Megatron-AI\u200b\u5a01\u9707\u200b\u5929\u200b</p> </li> <li> <p>\u200b\u7b97\u529b\u200b\u5355\u4f4d\u200b</p> </li> <li>TFLOPs: 1e12\u200b\u6b21\u200b\u6d6e\u70b9\u200b \u200b\u8fd0\u7b97\u200b \u200b\u6b21\u6570\u200b</li> <li>TOPs\uff1a1e12\u200b\u6574\u6570\u200b\u8fd0\u7b97\u200b\u6b21\u6570\u200b</li> <li>Kernel Implementation</li> </ol>"},{"location":"AI/AI_Platform/Nvidia/megatron-lm.html","title":"Megatron lm","text":""},{"location":"AI/AI_Platform/Nvidia/megatron-lm.html#megatron-lm","title":"Megatron-LM","text":"<p>\u200b\u8bba\u6587\u200b\uff1aMegatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism Github\uff1aMegatron-LM Nvidia, 2019 Sep</p>"},{"location":"AI/AI_Platform/Nvidia/megatron-lm.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<p>Megatron-LM\u200b\u57fa\u4e8e\u200bPyTorch\u200b\u7684\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u6846\u67b6\u200b\uff0c\u200b\u53ea\u200b\u9700\u200b\u5728\u200bforward\u200b\u548c\u200bbackward\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u589e\u52a0\u200b\u5c11\u91cf\u200b\u989d\u5916\u200b\u7684\u200b<code>all-reduce</code> \u200b\u64cd\u4f5c\u200b\uff0c\u200b\u65e0\u9700\u200b\u5bf9\u200b\u7f16\u8bd1\u5668\u200b\u4fee\u6539\u200b\u3002</p>"},{"location":"AI/AI_Platform/Nvidia/megatron-lm.html#mlp-parallel","title":"MLP Parallel","text":"<p>\\(f\\) \u200b\u8868\u793a\u200bforward\u200b\u4e2d\u200b\u7684\u200b\u6052\u7b49\u200b\u7b97\u5b50\u200b\uff0cbackward\u200b\u4e2d\u200b\u7684\u200ball-reduce\u200b\u64cd\u4f5c\u200b\uff1b\\(g\\) \u200b\u5219\u200b\u76f8\u53cd\u200b</p> <ol> <li> <p>MLP 1st GEMM Column Parallelism \\(Y=\\text{GeLU}(XA)\\)\uff0c\u200b\u7531\u4e8e\u200b<code>GeLU</code>\u200b\u4e3a\u200b\u975e\u7ebf\u6027\u200b\u53d8\u6362\u200b\u4e14\u200b\\(\\text{GeLU}(a+b)\\)$ \\ne \\text{GeLU}(a) + \\text{GeLU}(b)$\uff0c\u200b\u56e0\u6b64\u200b\u5bf9\u200b1st Layer\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b \\(A\\) \u200b\u8fdb\u884c\u200b\u5217\u200b\u62c6\u5206\u200b\uff0c\u200b\u5373\u200b</p> \\[     [Y_1, Y_2] = \\text{GeLU}(X[A_1, A_2]) = \\text{GeLU}([XA_1, XA_2]) \\] </li> <li> <p>MLP 2nd GEMM Row Parallelism \u200b\u4e3a\u200b\u9002\u914d\u200b\u5bf9\u200b1st Layer\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b \\(A\\) \u200b\u8fdb\u884c\u200b\u5217\u200b\u62c6\u5206\u200b\uff0c\u200b\u5bf9\u200b2nd Layer\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b\u53c2\u6570\u200b \\(B\\) \u200b\u8fdb\u884c\u200b\u884c\u200b\u62c6\u5206\u200b\uff0c\u200b\u5373\u200b</p> \\[     Y=  [X_1, X_1][B_1; B_2] = [X_1B_1 + X_2B_2] \\] </li> </ol>"},{"location":"AI/AI_Platform/Nvidia/megatron-lm.html#self-attention-parallel","title":"Self-Attention Parallel","text":"<p>\\(f\\) \u200b\u8868\u793a\u200bforward\u200b\u4e2d\u200b\u7684\u200b\u6052\u7b49\u200b\u7b97\u5b50\u200b\uff0cbackward\u200b\u4e2d\u200b\u7684\u200ball-reduce\u200b\u64cd\u4f5c\u200b\uff1b\\(g\\) \u200b\u5219\u200b\u76f8\u53cd\u200b</p> <ol> <li> <p>Q, K, V  Column Parallelism, O  Row Parallelism \u200b\u5bf9\u200b\u6295\u5f71\u200b\u51fd\u6570\u200b\\(W_Q, W_K, W_V\\)\u200b\u8fdb\u884c\u200b\u5217\u200b\u62c6\u5206\u200b\uff0c\u200b\u4ee5\u200b\u4fdd\u8bc1\u200b\u5404\u200bhead\u200b\u7684\u200bSelf-Attention\u200b\u8fd0\u7b97\u200b\u5728\u200b\u4e0d\u540c\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u4e3a\u200b\u9002\u914d\u200bSelf-Attention\u200b\u7ed3\u679c\u200b\uff0c\u200b\u5bf9\u200b\u8f93\u51fa\u200b\u51fd\u6570\u200b \\(W_O\\) \u200b\u8fdb\u884c\u200b\u884c\u200b\u62c6\u5206\u200b\uff0c\u200b\u5373\u200b</p> \\[ \\begin{aligned}     Q_i =&amp; Q[(i-1)\\times d_k:i\\times d_{k}] \\\\     K_i =&amp; K[(i-1)\\times d_k:i\\times d_{k}] \\\\     V_i =&amp; V[(i-1)\\times d_k:i\\times d_{k}] \\\\     A_i =&amp; \\text{Softmax}\\left(\\frac{Q_iK_i^T}{\\sqrt{d_k}}\\right)V_i \\\\     O =&amp; [A_1, A_2, \\dots, A_h][W_{O, 1}; W_{O, 2}, \\dots, W_{O, h}] \\\\     =&amp; [A_1W_{O, 1} + A_2W_{O, 2} + \\cdots + A_hW_{O, h}] \\end{aligned} \\] </li> </ol>"},{"location":"AI/AI_Platform/Nvidia/megatron-lm.html#embedding-parallelism","title":"Embedding Parallelism","text":"<p>\u200b\u5728\u200b\u751f\u6210\u200b\u6a21\u578b\u200b\u4e2d\u200b\uff0c<code>next_token_prediction</code> \u200b\u901a\u8fc7\u200b\u5c06\u200b\u9690\u5c42\u200b\u5411\u91cf\u200b\u4e0e\u200b<code>input_embedding</code> \\(E \\in \\mathbb{R}^{d \\times \\vert V \\vert}\\) \u200b\u8fdb\u884c\u200bGEMM\u200b\u8ba1\u7b97\u200b\u5f97\u5230\u200blogits</p> <ol> <li> <p>Embedding Weight Column Parallelism</p> \\[ [Y_1, Y_2] = X[E_1, E_2] = [XE_1, XE_2]\\\\ \\] </li> </ol> <p>Success</p> <p>\u200b\u4e3a\u200b\u907f\u514d\u200b<code>all-gather</code>\u200b\u64cd\u4f5c\u200b\u7684\u200b\u901a\u4fe1\u200b\u5f00\u9500\u200b\uff0c\u200b\u53ef\u200b\u5c06\u200blogits\u200b\u7ed3\u679c\u200b\\([Y_1, Y_2]\\) \u200b\u4e0e\u200bcross-entropy\u200b\u878d\u5408\u200b\u5728\u200b\u4e00\u8d77\u200b\uff0c\u200b\u4ece\u800c\u200b\u5c06\u200b\u590d\u6742\u5ea6\u200b\u4ece\u200b\\(bs \\times l \\times \\vert V \\vert\\)\u200b\u7684\u200b\u51cf\u5c11\u200b\u4e3a\u200b\\(bs \\times l\\)</p> <ul> <li>15.1*1000/(39*512)=75.6%</li> <li>BERT-style \u200b\u7684\u200blarger model\u200b\u8bad\u7ec3\u200b\u4f7f\u7528\u200bpre-Norm\u200b\u8f83\u200bpost-Norm\u200b\u66f4\u52a0\u200b\u6709\u6548\u200b, the placement of layer normalization in BERT-like models is critical to achieving increased performance as the model size grows</li> <li>To synchronize residual connection dropout across model parallel workers we seed the random number generators at the beginning of training with the same seed. \u200b\u76f8\u540c\u200b\u7684\u200bdropout random seed</li> <li>To achieve each worker to achieve randomness across the entire operation, we maintain a separate random number generator for dropout within model parallel regions. This random number generator is uniquely seeded for each model parallel worker.</li> </ul>"},{"location":"AI/AI_Platform/Nvidia/megatron-lm.html#llm-using-megatron-lm","title":"LLM using Megatron-LM","text":"<p>\u200b\u8bba\u6587\u200b\uff1aEfficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM Nvidia &amp; Stanford University &amp; MSR, 2021 Apr, SC 2021</p>"},{"location":"AI/AI_Platform/Nvidia/megatron-lm.html#_2","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/AI_Platform/Nvidia/megatron-lm.html#megatron-deepspeed","title":"Megatron-DeepSpeed","text":""},{"location":"AI/AI_Platform/Nvidia/tensorrt.html","title":"Tensorrt","text":""},{"location":"AI/AI_Platform/Nvidia/tensorrt.html#tensorrt","title":"TensorRT","text":"<p>TensorRT \u200b\u662f\u200b NVIDIA \u200b\u63a8\u51fa\u200b\u7684\u200b\u9ad8\u6027\u80fd\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u63a8\u7406\u200b\uff08Inference\uff09\u200b\u4f18\u5316\u200b\u5668\u200b\u548c\u200b\u8fd0\u884c\u200b\u65f6\u5e93\u200b\uff0c\u200b\u4e13\u95e8\u200b\u7528\u4e8e\u200b\u5728\u200b\u751f\u4ea7\u200b\u73af\u5883\u200b\u4e2d\u200b\u9ad8\u6548\u200b\u90e8\u7f72\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6a21\u578b\u200b\u3002\u200b\u8be5\u5e93\u200b\u6838\u5fc3\u200b\u76ee\u6807\u200b\u662f\u200b\u901a\u8fc7\u200b\u4e00\u7cfb\u5217\u200b\u4f18\u5316\u200b\u6280\u672f\u200b\uff0c\u200b\u4e0e\u200bNvidia GPU\u200b\u7ed3\u5408\u200b\uff0c\u200b\u6700\u5927\u200b\u9650\u5ea6\u200b\u5730\u200b\u63d0\u9ad8\u200b\u57fa\u4e8e\u200b Tensorflow\u3001Caffe\u3001Mxnet\u200b\u548c\u200bPytorch \u200b\u7b49\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6846\u67b6\u200b\u7684\u200b\u6a21\u578b\u200b\u63a8\u7406\u200b\u6027\u80fd\u200b\u3002</p>"},{"location":"AI/AI_Platform/Nvidia/tensorrt.html#_1","title":"\u5b89\u88c5","text":"<p>https://zhuanlan.zhihu.com/p/706873079</p>"},{"location":"AI/AI_Platform/Nvidia/tensorrt.html#_2","title":"\u4e3b\u8981\u200b\u7279\u6027","text":""},{"location":"AI/AI_Platform/Nvidia/tensorrt.html#layer-fusion","title":"Layer Fusion","text":"<p>\u200b\u5c42\u95f4\u200b\u878d\u5408\u200b\uff1a\u200b\u5408\u5e76\u200b\u591a\u4e2a\u200b\u64cd\u4f5c\u200b\u8f83\u200b\u5c11\u200b\u5185\u6838\u200b\u8c03\u7528\u200b</p>"},{"location":"AI/AI_Platform/Nvidia/tensorrt.html#precision-calibration","title":"Precision Calibration","text":"<p>\u200b\u6570\u636e\u200b\u7cbe\u5ea6\u200b\u6821\u51c6\u200b\uff1a\u200b\u5bf9\u200b\u91cf\u5316\u200b\u6a21\u578b\u200b\u8fdb\u4e00\u6b65\u200b\u6821\u51c6\u200b</p>"},{"location":"AI/AI_Platform/Nvidia/tensorrt.html#kernel-auto-tuning","title":"Kernel Auto-Tuning","text":"<p>\u200b\u5185\u6838\u200b\u81ea\u52a8\u200b\u8c03\u4f18\u200b\uff1a\u200b\u9009\u62e9\u200b\u6700\u4f18\u200b\u5185\u6838\u200b\u5b9e\u73b0\u200b</p>"},{"location":"AI/AI_Platform/Nvidia/tensorrt.html#dynamic-tensor-memory","title":"Dynamic Tensor Memory","text":"<p>\u200b\u52a8\u6001\u200b\u5f20\u91cf\u200b\u5185\u5b58\u200b\uff1a\u200b\u6700\u5c0f\u5316\u200b\u5185\u5b58\u200b\u5360\u7528\u200b</p>"},{"location":"AI/AI_Platform/Nvidia/tensorrt.html#graph-optimization","title":"Graph Optimization","text":"<p>\u200b\u56fe\u200b\u4f18\u5316\u200b\uff1a\u200b\u6d88\u9664\u200b\u5197\u4f59\u200b\u8ba1\u7b97\u200b</p>"},{"location":"AI/AI_Platform/Ollama/ollama.html","title":"Ollama","text":""},{"location":"AI/AI_Platform/PaddlePaddle/index.html","title":"Index","text":""},{"location":"AI/AI_Platform/PyTorch/index.html","title":"Index","text":""},{"location":"AI/AI_Platform/PyTorch/index.html#_1","title":"Index","text":"<p>Dataset </p><pre><code>from torch.utils.data import Dataset, DataLoader\n</code></pre><p></p>"},{"location":"AI/AI_Platform/PyTorch/index.html#torch","title":"torch\u200b\u751f\u6001\u200b\u5e93","text":""},{"location":"AI/AI_Platform/PyTorch/index.html#torchtext","title":"torchtext","text":"<p><code>pip install torchtext</code></p>"},{"location":"AI/AI_Platform/PyTorch/index.html#torchvision","title":"torchvision","text":"<p><code>pip install torchvision</code></p> <pre><code>from torchvision.utils import save_image, transforms\n\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.5, ),  # 3 for RGB channels\n                         std=(0.5, ))])\n\ndef denorm(x):\n    out = (x + 1) / 2\n    return out.clamp(0, 1)\n\nfake_images = generate_image.view(generate_image.size(0), 1, 28, 28)\nsave_image(denorm(fake_images.data), 'samples/test.png')\n</code></pre>"},{"location":"AI/AI_Platform/PyTorch/index.html#torchaudio","title":"torchaudio","text":"<p><code>pip install torchaudio</code></p>"},{"location":"AI/AI_Platform/PyTorch/index.html#torchmetrics","title":"torchmetrics","text":"<p><code>pip install torchmetrics</code></p> Precision/RecallF1ScoreAccuracy <pre><code>class Precision/Recall(StatScores):\n    def __init__(\n        self,\n        num_classes: Optional[int] = None,\n        threshold: float = 0.5,\n        average: str = \"micro\",\n        mdmc_average: Optional[str] = None,\n        ignore_index: Optional[int] = None,\n        top_k: Optional[int] = None,\n        multiclass: Optional[bool] = None,\n        compute_on_step: Optional[bool] = None,\n        **kwargs: Dict[str, Any],\n    )\n</code></pre> <pre><code>class F1Score(FBetaScore):\n    def __init__(\n        self,\n        num_classes: Optional[int] = None,          # num_of_classes\n        threshold: float = 0.5,                     # prob \u2265 threshold \u2192 True\n        average: str = \"micro\",                     # micro: \u200b\u5168\u5c40\u200b\u5e73\u5747\u200b\n                                                    # macro: \u200b\u52a0\u6743\u200b\u5e73\u5747\u200b\n                                                    # ...\n        mdmc_average: Optional[str] = None,\n        ignore_index: Optional[int] = None,         # \u200b\u8ba1\u7b97\u200b\u65f6\u200b\u5ffd\u7565\u200b\u6307\u5b9a\u200b\u7684\u200b\u6807\u7b7e\u200b\u503c\u200b\n        top_k: Optional[int] = None,                # \u200b\u8fd4\u56de\u200b\u76ee\u6807\u200b\u7c7b\u200b\u7f6e\u4fe1\u5ea6\u200b\u6700\u9ad8\u200b\u7684\u200btop-k\u200b\u4e2a\u200b\n        multiclass: Optional[bool] = None,\n        compute_on_step: Optional[bool] = None,\n        **kwargs: Dict[str, Any],\n    )\n</code></pre> <pre><code>class Accuracy(StatScores):\n    def __init__(\n        self,\n        threshold: float = 0.5,                     # prob \u2265 threshold \u2192 True\n        num_classes: Optional[int] = None,          # num_of_classes\n        average: str = \"micro\",                     # micro: \u200b\u5168\u5c40\u200b\u5e73\u5747\u200b\n                                                    # macro: \u200b\u52a0\u6743\u200b\u5e73\u5747\u200b\n                                                    # ...\n        mdmc_average: Optional[str] = \"global\", \n        ignore_index: Optional[int] = None,         # \u200b\u8ba1\u7b97\u200b\u65f6\u200b\u5ffd\u7565\u200b\u6307\u5b9a\u200b\u7684\u200b\u6807\u7b7e\u200b\u503c\u200b\n        top_k: Optional[int] = None,                # \u200b\u8fd4\u56de\u200b\u76ee\u6807\u200b\u7c7b\u200b\u7f6e\u4fe1\u5ea6\u200b\u6700\u9ad8\u200b\u7684\u200btop-k\u200b\u4e2a\u200b\n        multiclass: Optional[bool] = None,\n        subset_accuracy: bool = False,\n        compute_on_step: Optional[bool] = None,\n        **kwargs: Dict[str, Any],\n    )\n</code></pre> <pre><code>from torchmetrics import Accuracy, F1Score, Precision, Recall\n\n\n# \u200b\u521d\u59cb\u5316\u200b\u6307\u6807\u200b\uff08\u200b\u652f\u6301\u200b\u591a\u200b\u5206\u7c7b\u200b\u3001\u200b\u591a\u200b\u6807\u7b7e\u200b\uff09\naccuracy = Accuracy(num_classes=2)\nprecision = Precision(num_classes=2)\nrecall = Recall(task=\"multiclass\", num_classes=10, average='macro')\n\n# \u200b\u8ba1\u7b97\u200b\u6279\u6b21\u200b\u6307\u6807\u200b\nlogits = torch.randn(32, 10)  # batch_size=32, 10\u200b\u7c7b\u200b\nlabels = torch.randint(0, 10, (32,))\npreds = torch.argmax(logits, dim=1).to(\"cpu\")\n\n# accuracy.update(preds, labels)\n# precision.update(preds, labels)\n# recall.update(preds, labels)\n\n# \u200b\u83b7\u53d6\u200b\u7d2f\u79ef\u200b\u7ed3\u679c\u200b\nprint(f\"Accuracy: {accuracy.compute():.4f}\")\nprint(f\"Precision: {precision.compute():.4f}\")\nprint(f\"Recall: {recall.compute():.4f}\")\n\n# \u200b\u91cd\u7f6e\u200b\u6307\u6807\u200b\naccuracy.reset()\n\n\ntorchmetrics.functional.accuracy(preds, target)\n\nfor s in batch_s:\n    accuracy(preds, target)     # batch accuracy\naccuracy.compute()              # total accuracy\n</code></pre>"},{"location":"AI/AI_Platform/RAGFlow/ragflow.html","title":"Ragflow","text":""},{"location":"AI/AI_Platform/Tensorflow/index.html","title":"Index","text":"<p>Tensorflow\u200b\u7684\u200b\u529f\u80fd\u200b\u662f\u200b\u5b9a\u4e49\u200b\u4e00\u4e2a\u200b\u8ba1\u7b97\u200b\u56fe\u200bGraph\uff0c\u200b\u901a\u8fc7\u200b<code>sess.run()</code>\u200b\u6765\u200b\u542f\u52a8\u200b\u8ba1\u7b97\u200b\u56fe\u200b\u5f97\u5230\u200b\u7ed3\u679c\u200b\u3002</p> <p>\u200b\u8ba1\u7b97\u200b\u63a5\u8fc7\u200b\u524d\u200b\u9700\u8981\u200b\u5148\u200b\u63d0\u524d\u200b\u5bf9\u200b\u8ba1\u7b97\u200b\u56fe\u200b\u53c2\u6570\u200b\u8fdb\u884c\u200b\u521d\u59cb\u5316\u200b\u64cd\u4f5c\u200b </p><pre><code>sess.run(tf.global_variables_initializer())\nsess.run(tf.local_variables_initializer())\n</code></pre><p></p>"},{"location":"AI/AI_Platform/Tensorflow/index.html#_1","title":"\u56fe\u200b\u76f8\u5173","text":"<ul> <li>\u200b\u8ba1\u7b97\u200b\u56fe\u200b\uff1aGraph<ul> <li>\u200b\u8fb9\u200b\uff1aTensor</li> <li>\u200b\u8282\u70b9\u200b\uff1aOperation</li> </ul> </li> <li>\u200b\u4f1a\u8bdd\u200b\uff1aSession</li> </ul>"},{"location":"AI/AI_Platform/Tensorflow/index.html#_2","title":"\u6570\u636e\u200b\u83b7\u53d6","text":"<ul> <li>\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u751f\u6210\u200b\uff1aDataset</li> <li>\u200b\u5207\u7247\u200b\uff1agather, where</li> <li>\u200b\u578b\u200b\u64cd\u4f5c\u200b\uff1asqueeze, expand_dims\uff1bsplit, concat</li> </ul> <p>\u3010\u200b\u6709\u9053\u200b\u4e91\u200b\u7b14\u8bb0\u200b\uff1a\u200b\u7d22\u5f15\u200b\u4e0e\u200b\u5207\u7247\u200b\u3011split, gather, where</p>"},{"location":"AI/AI_Platform/Tensorflow/index.html#_3","title":"\u5f20\u91cf\u200b\u58f0\u660e","text":"<ul> <li>\u200b\u53d8\u91cf\u200b\u58f0\u660e\u200b\uff1aplaceholder\u3001get_variable\u3001Variable</li> <li>embedding\u200b\u76f8\u5173\u200b\uff1aembedding</li> <li>\u200b\u521d\u59cb\u5316\u200b\uff1ainitializer</li> </ul>"},{"location":"AI/AI_Platform/Tensorflow/index.html#_4","title":"\u53c2\u6570\u200b\u8c03\u5ea6\u200b\u7b56\u7565","text":"<ul> <li>\u200b\u68af\u5ea6\u200b\u66f4\u65b0\u200b\uff1agradient_update\u3001gradient clipping</li> <li>\u200b\u5b66\u4e60\u200b\u7387\u200b\u8c03\u5ea6\u200b\uff1alr_schedule\u3001warm_up</li> <li>\u200b\u4f18\u5316\u200b\u5668\u200b\uff1aoptimizer</li> <li>\u200b\u6269\u6563\u200b\u6a21\u578b\u200b\u03b2\u200b\u8c03\u5ea6\u200b\uff1abeta_schedule</li> </ul>"},{"location":"AI/AI_Platform/Tensorflow/index.html#_5","title":"\u7f51\u7edc\u5c42\u200b\u76f8\u5173","text":""},{"location":"AI/AI_Platform/Tensorflow/data_fetch/Dataset.html","title":"Dataset","text":""},{"location":"AI/AI_Platform/Tensorflow/data_fetch/Dataset.html#_1","title":"\u4ee3\u7801\u200b\u8f6e\u5b50","text":""},{"location":"AI/AI_Platform/Tensorflow/data_fetch/Dataset.html#data_utils","title":"<code>data_utils</code>","text":"data_utils.py<pre><code># coding=utf-8\nimport tensorflow as tf\nimport json\nfrom data_example import ExampleBuilder\n\nclass DataResourece:\n    def __init__(self, \n                input_file, \n                shuffle, \n                epochs,\n                drop_reainder,\n                tokenizer_type,\n                vocab_file,\n                replace_file,\n                max_seq_length,\n                do_lower_case, \n                t2s,\n                uni_white,\n                truncate_direct):\n\n        self.input_file = input_file\n        self.shuffle = shuffle\n        self.epochs = epochs\n        self.drop_reainder = drop_reainder\n        self.line_num = _count()\n\n        self.builder = ExampleBuilder(tokenizer_type, vocab_file, \n                                      replace_file, max_seq_length, \n                                      do_lower_case, t2s, uni_white, \n                                      truncate_direct)\n\n    # \u200b\u7531\u4e8e\u200b\u4f7f\u7528\u200b\u751f\u6210\u5668\u200b\u8868\u8fbe\u5f0f\u200b\uff0c\u200b\u5355\u6b21\u200b\u904d\u5386\u200b\u7edf\u8ba1\u200b\u6837\u672c\u6570\u200b\n    def _count(self):\n        f = open(self.input_file, \"r\", encoding=\"utf-8\")\n        line_num = 0\n        for line in f:\n            try:\n                json.loads(line)\n            except json.decoder.JSONDecodeError:\n                print(line)\n                raise ValueError(f'line {line_num} is not a json sample')\n            line_num += 1\n        f.close()\n        return line_num\n\n\n    def generator(self):\n        f = open(self.input_file, \"r\", encoding=\"utf-8\")\n        for line in f:\n            try:\n                line = json.loads(line)\n            except json.decoder.JSONDecodeError:\n                raise ValueError(f'line {i} is not a json sample')\n            if \"Content\" in line.keys():\n                content = line[\"Content\"]\n            elif \"content\" in line.keys():\n                content = line[\"content\"]\n            elif \"c\" in line.keys():\n                content = line[\"c\"]\n            else:\n                raise ValueError\n\n            if \"Label\" in line.keys():\n                label = line[\"Label\"]\n            elif \"label\" in line.keys():\n                label = line[\"label\"]\n            else:\n                label = \"\"\n\n            example = self.builder.build_example(text_a=content, text_b=None, \n                                                 text_label=label)\n\n            # \u200b\u5bf9\u5e94\u200bdataset\u200b\u7684\u200b`output_types`\n            # todo: \u200b\u8f6f\u200b\u6807\u7b7e\u200b\u84b8\u998f\u200b\u65f6\u200b\u9700\u8981\u200b`str(label)`\n            yield [content], [label], example.features[\"input_ids\"], \n                  example.features[\"input_mask\"], example.features[\"segment_ids\"],\n                  example.features[\"label_ids\"]\n\n    def next_batch(self, batch_size):\n        dataset = tf.data.Dataset.from_generator(\n            # \u200b\u6570\u636e\u200b\u751f\u6210\u200b\u51fd\u6570\u200b\n            self.generator, \n            # \u200b\u5bf9\u5e94\u200bgenerator\u200b\u8fd4\u56de\u200b\u7684\u200b\u6570\u636e\u7c7b\u578b\u200b\n            output_types=(tf.string, tf.string, \n                          f.int32, tf.int32, tf.int32, tf.int32)\n            )\n        # repeat\u200b\u5bf9\u5e94\u200bepochs\uff0c\u200b\u56e0\u6b64\u200b\u53ef\u200b\u57fa\u4e8e\u200b\u5168\u5c40\u200b\n        dataset = dataset.repeat(self.epochs)\n        # \u200b\u8bad\u7ec3\u200b\u65f6\u200b\u6270\u52a8\u200b\u3001\u200b\u6d4b\u8bd5\u200b\u65f6\u200b\u987a\u5e8f\u200b\u53d6\u503c\u200b\uff0c\u200b\u8bbe\u7f6e\u200b\u6270\u52a8\u200b\u6c60\u200b\u5927\u5c0f\u200b\n        if self.shuffle:\n            dataset = dataset.shuffle(buffer_size=100 * batch_size)\n        # \u200b\u8bbe\u7f6e\u200b\u968f\u673a\u200b\u53d6\u503c\u200b\u6c60\u200b\u5927\u5c0f\u200b\n        dataset = dataset.prefetch(buffer_size=100 * batch_size)\n\n        dataset = dataset.padded_batch(\n            batch_size,             # \u200b\u6bcf\u6b21\u200b\u53d6\u503c\u200b `batch_size` \u200b\u6837\u672c\u200b\n            padded_shapes=([None], [None], [None], [None], [None], [None]), \n                                    # `None` \u200b\u8868\u793a\u200b `pad_to_longest` \uff0c[] \u200b\u8868\u793a\u200b\u4e0d\u200b\u586b\u5145\u200b\n                                    # shape.length\u200b\u4e0e\u200bgenerate\u200b\u65b9\u6cd5\u200b\u8fd4\u56de\u503c\u200b\u4e00\u81f4\u200b\n            drop_remainder=welf.drop_remainder,\n                                    # \u200b\u5bf9\u4e8e\u200bbatch_size\u200b\u53d6\u6574\u200b\u7684\u200b\u4f59\u6570\u200b\u90e8\u5206\u200b\u5904\u7406\u200b\u65b9\u5f0f\u200b\n            padding_values=None     # \u200b\u6307\u5b9a\u200bpadding_values\uff0c\u200b\u7f3a\u7701\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u6570\u503c\u200b\u8865\u200b0\uff0c\u200b\u5e03\u5c14\u503c\u200b\u8865\u200bFalse\uff0c\u200b\u5b57\u7b26\u4e32\u200b\u8865\u200b\"\"\n                                    # \u200b\u53ef\u4ee5\u200b\u4e3a\u200b\u6570\u503c\u200b\u6216\u200b\u5143\u7ec4\u200b\uff0c\u200b\u4f46\u200bshape\u200b\u548c\u200b\u7c7b\u578b\u200b\u5e94\u8be5\u200b\u4e0e\u200bgenerate\u200b\u65b9\u6cd5\u200b\u8fd4\u56de\u503c\u200b\u4e00\u81f4\u200b\n        )\n\n        iterator = dataset.make_initializable_iterator()\n        return iterator.get_next(), iterator.initializer\n</code></pre> <p>Info</p> <ul> <li><code>padded_batch</code> \u200b\u4e2d\u200b\u5982\u679c\u200b\u91c7\u7528\u200b\u4e86\u200b <code>pad_to_longest</code> \u200b\u5bf9\u4e8e\u200b\u5904\u4e8e\u200b\u4e0d\u540c\u200b <code>batch_size</code> \u200b\u4e2d\u200b\u7684\u200b\u540c\u4e00\u200b\u6837\u672c\u200b\uff0c<code>longest_length</code> \u200b\u7684\u200b\u4e0d\u540c\u200b\u4f1a\u200b\u5bfc\u81f4\u200b \u200b\u7ed3\u679c\u200b\u4e0d\u4f1a\u200b\u4e00\u81f4\u200b \uff0c\u200b\u4f46\u200b\u6700\u7ec8\u200b\u9020\u6210\u200b\u7684\u200b\u533a\u522b\u200b\u5f71\u54cd\u200b\u53ef\u4ee5\u200b\u5ffd\u7565\u200b\u4e0d\u8bb0\u200b\uff0c\u200b\u4e14\u200b\u4e0d\u540c\u200b\u6570\u76ee\u200b\u7684\u200b[PAD]\u200b\u80fd\u591f\u200b\u66f4\u597d\u200b\u5730\u4f7f\u200b\u6a21\u578b\u200b\u5b66\u4e60\u200b\u5230\u200b\u8fd9\u4e2a\u200b\u7b26\u53f7\u200b\u7684\u200b\u8bed\u4e49\u200b\u548c\u200b\u4f5c\u7528\u200b\u3002</li> </ul>"},{"location":"AI/AI_Platform/Tensorflow/data_fetch/Dataset.html#data_example","title":"<code>data_example</code>","text":"data_example.py<pre><code># coding=utf-8\nimport collections\nimport tokenization         # \u200b\u81ea\u5b9a\u4e49\u200b\u7684\u200b\u4e00\u7cfb\u5217\u200btokenization\nimport ahocorasick\nfrom opencc import OpenCC\nimport re\n\nclass Example(object):\n    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n        input_len = len(input_ids)\n        if not (input_len == len(input_mask) and input_len == len(segment_ids)):\n            raise ValueError('All feature lists should have the same length ({})'.format(input_len))\n\n        self.features = collections.OrderedDict([(\"input_ids\", input_ids),\n                                                 (\"input_mask\", input_mask),\n                                                 (\"segment_ids\", segment_ids),\n                                                 (\"label_ids\", label_ids)])\n\n\nclass ExampleBuilder(object):\n    def __init__(self,\n                 tokenizer_type,\n                 vocab_file,\n                 replace_file,\n                 max_seq_length,\n                 do_lower_case,\n                 t2s=False,\n                 uni_white=False,\n                 truncate_direct='first'):\n\n        if tokenizer_type == 'BPE':           # using BPE tokenizer\n            self._tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case=do_lower_case)\n        elif tokenizer_type == 'char-level':  # using char-level tokenizer\n            self._tokenizer = tokenization.CharTokenizer(vocab_file, do_lower_case=do_lower_case)\n        # todo: \u200b\u65b0\u589e\u200btokenizer\n        else:\n            raise ValueError(f'{tokenizer_type} is not a specialized tokenizer')\n\n        self._pad_id = self._get_pad_id()\n\n        self.trie = ahocorasick.Trie(allow_overlaps=False)  # AC\u200b\u7b97\u6cd5\u200b\u6267\u884c\u200b\u5b57\u200b\u6bb5\u200b\u66ff\u6362\u200b\n        self.replace_map = {}\n        self._load_replace_file(replace_file)\n\n        self.t2s = t2s\n        self.cc = OpenCC(\"t2s\")  # \u200b\u4e2d\u6587\u200b\u7e41\u7b80\u4f53\u200b\u8f6c\u6362\u200b\n\n        self._max_seq_length = max_seq_length\n        self.uni_white = uni_white\n        self.truncate_direct = truncate_direct\n\n        # todo: \u200b\u65b0\u589e\u200b\u7a7a\u767d\u200b\u5b57\u7b26\u200b\n        self.white_space_pattern = re.compile(\n            \"[\\u0000-\\u001f\\u007f\\ufff0-\\ufff8\\\\s\\u3000\\u00a0\\u2002-\\u200a\\u202f\\u205f]+\")\n\n        # todo: \u200b\u624b\u52a8\u200b\u8bbe\u7f6e\u200b `special_tokens`\n        self.special_tokens = [\n            'unified_emojis',\n            # \"unified_white_chars\"\n        ]\n        # todo: \u200b\u4e3a\u200b\u88ab\u200btokenizer\u200b\u5b8c\u6574\u200b\u8bc6\u522b\u200b\uff0c\u200b\u8bbe\u7f6e\u200b`special toekn`\u200b\u7684\u200b\u4e2d\u8f6c\u200btoken\n        self.special_token_map = {\n            token: chr(ord('\u2460') + i) for i, token in enumerate(self.special_tokens)\n        }\n        # todo: \u200b\u8bbe\u7f6e\u200b`specia_token`\u200b\u7684\u200b\u6700\u7ec8\u200btoken\n        self.special_token_result = {self.special_token_map[token]: f'[unused{i}]' for i, token in enumerate(self.special_tokens, 1)}\n\n    def _truncate_first_list(self, x):\n        return x[:self._max_seq_length - 2]\n\n    def _truncate_last_list(self, x):\n        begin = max(0, len(x) - self._max_seq_length + 2)\n        return x[begin:]\n\n    def _truncate_seq_pair(self, tokens_a, tokens_b):\n        while True:\n            total_length = len(tokens_a) + len(tokens_b)\n            if total_length &lt;= (self._max_seq_length - 3):\n                break\n            if len(tokens_a) &gt; len(tokens_b):\n                tokens_a.pop()\n            else:\n                tokens_b.pop()\n\n    def _get_pad_id(self):\n        try:\n            return self._tokenizer.convert_tokens_to_ids(['[PAD]'])[0]\n        except KeyError:\n            return 0\n\n    def _load_replace_file(self, replace_file):\n        if replace_file is None:\n            print(\"don't use replace file.\")\n            return\n        with open(replace_file, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n\n                line = line.strip()\n                if len(line) == 0:\n                    continue\n                line_split = line.split(\"\\t\", maxsplit=1)\n                assert len(line_split) == 2\n                if line_split[0] in self.replace_map:\n                    print('---' * 10, f'duplicate: {line_split[0]}', '---' * 10)\n                self.replace_map[line_split[0]] = line_split[1]\n\n            self.trie.build_trie(self.replace_map.keys())\n        print(\"load %d replace token\" % len(self.replace_map))\n\n    # todo: \u200b\u4e3a\u200b\u5b8c\u6574\u200b\u4fdd\u7559\u200b\u539f\u59cb\u200b\u7279\u5f81\u200b\uff0c\u200b\u672a\u200b\u63d0\u524d\u200b\u6267\u884c\u200b `str.lower()`, replace_file\u200b\u987b\u200b\u540c\u65f6\u200b\u5305\u542b\u200b\u5927\u5c0f\u5199\u200b\u683c\u5f0f\u200b\n    def replace_span(self, text):\n        intervals = self.trie.parse_text(text)\n        text_new = \"\"\n        idx = 0\n        for interval in intervals:\n            text_new += text[idx:interval.start]\n            token = text[interval.start:interval.end + 1]\n            replace_token = self.replace_map[token]\n            text_new += replace_token\n            idx = interval.end + 1\n        text_new += text[idx:]\n        return text_new\n\n    def uni_white_space(self, text):\n        return re.sub(self.white_space_pattern, ' ', text.strip())\n\n    # tokenize\u200b\u524d\u200b\u4e2d\u8f6c\u200b\u7279\u6b8a\u200b\u7a7a\u767d\u200b\u5b57\u7b26\u200b &amp;&amp; tokenize\u200b\u540e\u200b\u6620\u5c04\u200b\u7279\u6b8a\u5b57\u7b26\u200b\n    def preprocess(self, text):\n        text = self.replace_span(text)\n        if self.t2s:\n            text = self.cc.convert(text)\n        if self.uni_white:\n            text = self.uni_white_space(text)\n            if 'unified_white_chars' in self.special_tokens:\n                text = re.sub(' ', self.special_token_map.get(\"unified_white_chars\", ' '), text)\n        # \u200b\u907f\u514d\u200b ##special_token \u200b\u73b0\u8c61\u200b\n        text = self.encode_special_tokens(text)\n        return text\n\n    def encode_special_tokens(self, text):        \n        for key in self.special_token_map:\n            text = text.replace(self.special_token_map[key], f' {self.special_token_map[key]} ')\n        return text\n\n    def decode_special_tokens(self, tokens):\n        final_tokens = []\n        for token in tokens:\n            final_tokens.append(self.special_token_result.get(token, token))\n        return final_tokens\n\n    def build_example(self, text_a, text_b=None, text_label=None):\n        text_a = self.preprocess(text_a)\n        tokens_a = self._tokenizer.tokenize(text_a)\n\n        tokens_b = None\n        if text_b:\n            text_b = self.preprocess(text_b)\n            tokens_b = self._tokenizer.tokenize(text_b)\n            tokens_b = self.decode_special_tokens(tokens_b)\n\n        if self._max_seq_length:\n            if tokens_b:\n                self._truncate_seq_pair(tokens_a, tokens_b)\n            else:\n                if self.truncate_direct == 'first':\n                    tokens_a = self._truncate_list(tokens_a)\n                elif self.truncate_direct == 'last':\n                    tokens_a = self._truncate_last_list(tokens_a)\n                else:\n                    raise ValueError(f'{self.truncate_direct} is not a specialized truncate direction')\n            tokens_a = self.decode_special_tokens(tokens_a)\n\n        tokens = []\n        segment_ids = []\n        tokens.append(\"[CLS]\")\n        segment_ids.append(0)\n        for token in tokens_a:\n            tokens.append(token)\n            segment_ids.append(0)\n        tokens.append(\"[SEP]\")\n        segment_ids.append(0)\n\n        if tokens_b:\n            for token in tokens_b:\n                tokens.append(token)\n                segment_ids.append(1)\n            tokens.append(\"[SEP]\")\n            segment_ids.append(1)\n\n        input_ids = self._tokenizer.convert_tokens_to_ids(tokens)\n        input_mask = [1] * len(input_ids)\n\n        # padding\n        for _ in range(len(tokens), self._max_seq_length):\n            input_ids.append(self._get_pad_id())\n            input_mask.append(0)\n            segment_ids.append(0)\n\n        # todo: customize label definition\n        if text_label:\n            text_label_split = text_label.split(\",\")\n            label_ids = [0]\n            if \"advertise\" in text_label_split:\n                label_ids[0] = 1\n        else:\n            label_ids = [0]\n\n        example = Example(input_ids=input_ids,\n                          input_mask=input_mask,\n                          segment_ids=segment_ids,\n                          label_ids=label_ids)\n        return example\n</code></pre>"},{"location":"AI/AI_Platform/Tensorflow/data_fetch/gather.html","title":"Gather","text":"<p><code>tf.gather</code> \u200b\u57fa\u4e8e\u200b\u7ed9\u5b9a\u200b\u7684\u200b\u7d22\u5f15\u200b\u5750\u6807\u200b <code>indices</code> \u200b\u4ece\u200b\u7684\u200b\u5f20\u91cf\u200b <code>param</code> \u200b\u7684\u200b<code>axis</code> \u200b\u7ef4\u5ea6\u200b\u83b7\u53d6\u200b \u200b\u5207\u7247\u200b\u5e76\u200b\u6574\u5408\u200b \u200b\u540e\u200b\u7684\u200b\u5f20\u91cf\u200b </p><pre><code>def gather(\n    param,\n    indices,                # isinstance(indices, ndaddry or list or tensor)\n                            # ndims(indices) in {0, 1}\n    validate_indices=None,  # pass\u200b\u5f62\u53c2\u200b\uff0c\u200b\u65e0\u6548\u200b\u7528\u200b\n    name=None,\n    axis=None,              # \u200b\u6307\u5b9a\u200b\u5207\u7247\u200b\u7684\u200b\u8f74\u200b\n    batch_dims=0\n)\n</code></pre><p></p>"},{"location":"AI/AI_Platform/Tensorflow/data_fetch/where.html","title":"Where","text":"<p><code>tf.where</code> \u200b\u5177\u6709\u200b\u4ee5\u4e0b\u200b\u4e24\u79cd\u200b\u6548\u679c\u200b\uff1a</p> <ol> <li>\u200b\u5982\u679c\u200b<code>x</code>\u200b\u548c\u200b<code>y</code>\u200b\u90fd\u200b\u4e3a\u200bNone\uff0c\u200b\u5219\u200b\u8be5\u200b\u64cd\u4f5c\u200b\u5c06\u200b\u8fd4\u56de\u200b<code>condition</code>\u200b\u4e2d\u200b\u6240\u6709\u200btrue\u200b\u5143\u7d20\u200b\u7684\u200b\u7d22\u5f15\u200bidx</li> <li>\u200b\u5982\u679c\u200bx\u200b\u548c\u200by\u200b\u90fd\u200b\u4e0d\u200b\u4e3a\u200bNone\uff0c\u200b\u5219\u200b\u8981\u6c42\u200b <code>shape(x) == shape(y)</code> \u200b\u4e14\u200b <code>shape(x) == shape(condition) or shape(x)[0] = shape(condition)</code> <pre><code>def where(\n    condition,      # condition.dtype == tf.bool\n    x=None,\n    y=None,\n    name=None\n)\n</code></pre></li> </ol>"},{"location":"AI/AI_Platform/Tensorflow/graph_related/session.html","title":"Session","text":""},{"location":"AI/AI_Platform/Tensorflow/graph_related/session.html#tfsession","title":"tf.Session","text":"<p>\u200b\u4e3b\u8981\u200b\u7528\u4e8e\u200b\u6267\u884c\u200b\u7f51\u7edc\u200b\u3002\u200b\u6240\u6709\u200b\u5173\u4e8e\u200b\u795e\u7ecf\u7f51\u7edc\u200b\u7684\u200b\u8ba1\u7b97\u200b\u90fd\u200b\u5728\u200b\u8fd9\u91cc\u200b\u8fdb\u884c\u200b\uff0c\u200b\u5b83\u200b\u6267\u884c\u200b\u7684\u200b\u4f9d\u636e\u200b\u662f\u200b\u8ba1\u7b97\u200b\u56fe\u200b\u6216\u8005\u200b\u8ba1\u7b97\u200b\u56fe\u200b\u7684\u200b\u4e00\u90e8\u5206\u200b\uff0c\u200b\u540c\u65f6\u200b\uff0c\u200b\u4f1a\u8bdd\u200b\u4e5f\u200b\u4f1a\u200b\u8d1f\u8d23\u200b\u5206\u914d\u200b\u8ba1\u7b97\u8d44\u6e90\u200b\u548c\u200b\u53d8\u91cf\u200b\u5b58\u653e\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u7ef4\u62a4\u200b\u6267\u884c\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u7684\u200b\u53d8\u91cf\u200b\u3002 </p><pre><code>def __init__(self,\n    target='',\n    graph=None,             # tf.Graph\uff0c\n    config=None):           # tf.ConfigProto\uff0c\u200b\u8bbe\u7f6e\u200bsession\u200b\u7684\u200b\u5404\u79cd\u200b\u914d\u7f6e\u200b\u9009\u9879\u200b\n</code></pre><p></p>"},{"location":"AI/AI_Platform/Tensorflow/graph_related/session.html#tfconfigproto","title":"tf.ConfigProto","text":"<p>https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto </p><pre><code># \u200b\u76f4\u63a5\u200b\u521d\u59cb\u5316\u200b\ndef session_config = tf.ConfigProto(\n        log_device_placement=True,          # \u200b\u65e5\u5fd7\u200b\u6253\u5370\u200b\u51fa\u200bTensoFlow\u200b\u4f7f\u7528\u200b\u4e86\u200b\u54ea\u79cd\u200b\u64cd\u4f5c\u200b\n        allow_soft_placement=True,          # \u200b\u6839\u636e\u200b\u8bbe\u5907\u200b\u53ef\u7528\u200b\u60c5\u51b5\u200b\uff0c\u200b\u81ea\u52a8\u200b\u5206\u914d\u200bGPU\u200b\u6216\u200bCPU\n        inter_op_parallelism_threads=0,     # \u200b\u5206\u914d\u200b\u7684\u200b\u7b97\u5b50\u200b\u95f4\u200b\u7ebf\u7a0b\u200b\u6570\u200b\uff0c0\u200b\u8868\u793a\u200b\u5355\u6838\u200b\u5355\u7ebf\u7a0b\u200b\n        intra_op_parallelism_threads=0)     # \u200b\u5206\u914d\u200b\u7684\u200b\u7b97\u5b50\u200b\u5185\u7ebf\u200b\u7a0b\u6570\u200b\uff0c0\u200b\u8868\u793a\u200b\u5355\u6838\u200b\u5355\u7ebf\u7a0b\u200b\n\n# \u200b\u5355\u72ec\u200b\u8d4b\u503c\u200b\ncofnig.log_device_placement=True\nconfig.allow_soft_placement=True\nconfig.inter_op_parallelism_threads=1\nconfig.intra_op_parallelism_threads=1\nconfig.gpu_options.per_process_gpu_memory_fraction=0.1      # \u200b\u6307\u5b9a\u200b\u6700\u5927\u200b\u7684\u200bgpu\u200b\u4f7f\u7528\u200b\u767e\u5206\u6bd4\u200b\nconfig.gpu_options.allow_growth=True                        # \u200b\u52a8\u6001\u5206\u914d\u200bgpu\uff0c\u200b\u7528\u200b\u591a\u5c11\u200b\u53d6\u200b\u591a\u5c11\u200b\n</code></pre><p></p> <p>\u200b\u9ed8\u8ba4\u200b\u4f7f\u7528\u200b\u5168\u90e8\u200bgpu\uff0c\u200b\u5373\u200b<code>config.gpu_options.per_process_gpu_memory_fraction=1</code></p>"},{"location":"AI/AI_Platform/Tensorflow/graph_related/session.html#sessionrun-tensoreval","title":"Session.run &amp; Tensor.eval","text":""},{"location":"AI/AI_Platform/Tensorflow/graph_related/ops/graph.html","title":"Graph","text":"<p>tensorflow/python/frameworkd/ops</p>"},{"location":"AI/AI_Platform/Tensorflow/graph_related/ops/graph.html#tfgraph","title":"tf.Graph","text":"<p>\u200b\u7531\u200b\u8282\u70b9\u200b\u548c\u200b\u6709\u200b\u5411\u200b\u8fb9\u200b\u63cf\u8ff0\u200b\u6570\u5b66\u200b\u8fd0\u7b97\u200b\u7684\u200b\u6709\u200b\u5411\u200b\u65e0\u73af\u200b\u8ba1\u7b97\u200b\u56fe\u200b\uff0c\u200b\u4e3b\u8981\u200b\u7528\u4e8e\u200b\u6784\u5efa\u200b\u7f51\u7edc\u200b\uff08\u200b\u8bbe\u8ba1\u200b\u542f\u53d1\u200b\u662f\u200b\u9ad8\u7b49\u6570\u5b66\u200b\u91cc\u9762\u200b\u7684\u200b\u94fe\u5f0f\u200b\u6c42\u5bfc\u200b\u6cd5\u5219\u200b\u7684\u200b\u56fe\u200b\uff09\uff0c\u200b\u672c\u8eab\u200b\u4e0d\u200b\u8fdb\u884c\u200b\u4efb\u4f55\u200b\u5b9e\u9645\u200b\u7684\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u8ba1\u7b97\u200b\u56fe\u200b\u7406\u89e3\u200b\u4e3a\u200b\u662f\u200b\u4e00\u4e2a\u200b\u8ba1\u7b97\u200b\u6a21\u677f\u200b\u6216\u8005\u200b\u8ba1\u5212\u4e66\u200b\u3002</p>"},{"location":"AI/AI_Platform/Tensorflow/graph_related/ops/graph.html#graph","title":"graph","text":"<ol> <li> <p><code>graph.as_default()</code> \u200b\u5c06\u200b\u5f53\u524d\u200bgraph\u200b\u8bbe\u200b\u4e3a\u200b\u7f3a\u7701\u200bgraph</p> </li> <li> <p><code>tf.get_default_graph()</code> \u200b\u7c7b\u4f3c\u200b\u4e8e\u200b<code>get_variable</code>\uff0c\u200b\u672a\u200b\u521b\u5efa\u200b\u4fbf\u200b\u521b\u5efa\u200b\u56fe\u200b\u5e76\u200b\u8bbe\u4e3a\u200b\u7f3a\u7701\u200bgraph\uff0c\u200b\u5df2\u200b\u521b\u5efa\u200b\u5c31\u200b\u76f4\u63a5\u200b\u83b7\u53d6\u200b\u7f3a\u7701\u200bgraph</p> </li> </ol>"},{"location":"AI/AI_Platform/Tensorflow/graph_related/ops/graph.html#_collections","title":"_collections","text":"<ol> <li> <p><code>graph._collections: defaultdict(list)</code> \u200b\u4ee5\u200b\u96c6\u5408\u200b\u7684\u200b\u5f62\u5f0f\u200b\u5b58\u653e\u200b\u56fe\u4e2d\u200b\u7684\u200b\u53d8\u91cf\u200b\uff0c\u200b\u6bcf\u6b21\u200b\u521b\u5efa\u200b\u53d8\u91cf\u200b\u65f6\u200b\u8c03\u7528\u200b<code>tf.add_to_collection(s)</code>\u200b\u8fdb\u884c\u200b\u5b58\u50a8\u200b</p> </li> <li> <p><code>graph.collections</code> \u200b\u4ee5\u200blist\u200b\u5f62\u5f0f\u200b\u8fd4\u56de\u200b<code>_collections</code>\u200b\u7684\u200bkey</p> </li> <li> <p><code>tf.GraphKeys</code> \u200b\u679a\u4e3e\u200b\u7c7b\u200b\uff0c\u200b\u5305\u542b\u200b<code>_collections</code>\u200b\u4e2d\u200b\u5e38\u89c1\u200b\u7684\u200bkey </p><pre><code>LOCAL_VARIABLES = \"local_variables\"             # local variables\uff0c\u200b\u58f0\u660e\u200b\u65f6\u200b\u6307\u5b9a\u200b`collections=[tf.GraphKeys.LOCAL_VARIABLES]` \u200b\u7684\u200b\u53d8\u91cf\u200b\nGLOBAL_VARIABLES = \"variables\"                  # global variables\nTRAINABLE_VARIABLES = \"trainable_variables\"     # trainable variables\n</code></pre><p></p> </li> </ol> <li>\u200b\u7f3a\u7701\u200b\u72b6\u6001\u200b\u4e0b\u200b<code>collections=[tf.GraphKeys.GLOBAL_VARIABLES]</code></li> <li>\u200b\u5f62\u53c2\u200b<code>trainable</code>\u200b\u63a7\u5236\u200b\u662f\u5426\u200bappend <code>tf.GraphKeys.TRAINABLE_VARIABLES</code>(\u200b\u624b\u52a8\u200bappend\u200b\u4f1a\u200b\u8986\u76d6\u200b<code>trainable</code>\u200b\u4f5c\u7528\u200b)</li> <li>variable\u200b\u6240\u200b\u5904\u200bcollecttions\u200b\u4e0d\u200b\u4e92\u76f8\u200b\u72ec\u7acb\u200b\uff0c\u200b\u56e0\u6b64\u200b\u53ef\u200b\u540c\u65f6\u200b\u5904\u4e8e\u200b\u591a\u4e2a\u200bcollection</li> <ol> <li> <p><code>tf.trainable_variables()</code> \u200b\u4ee5\u200blist\u200b\u5f62\u5f0f\u200b\u8fd4\u56de\u200btrainable\u200b\u53d8\u91cf\u200b </p><pre><code># \u200b\u7b49\u4ef7\u200b\u7684\u200b\u8868\u8ff0\u200b\u65b9\u5f0f\u200b\ntf.trainable_variables(scope=None)\ntf.get_collection(ops.GraphKeys.TRAINABLE_VARIABLES, scope=None)\n</code></pre><p></p> </li> <li> <p><code>tf.all/global_variables()</code> \u200b\u4ee5\u200blist\u200b\u5f62\u5f0f\u200b\u83b7\u53d6\u200b\u6240\u6709\u200b\u53d8\u91cf\u200b </p><pre><code># \u200b\u7b49\u4ef7\u200b\u7684\u200b\u8868\u8ff0\u200b\u65b9\u5f0f\u200b\ntf.all/global_variables()\ntf.get_collection(ops.GraphKeys.GLOBAL_VARIABLES, scope=None)\n</code></pre><p></p> </li> <li> <p><code>tf.local_variables()</code> \u200b\u4ee5\u200blist\u200b\u5f62\u5f0f\u200b\u83b7\u53d6\u200b\u5c40\u90e8\u53d8\u91cf\u200b </p><pre><code># \u200b\u7b49\u4ef7\u200b\u7684\u200b\u8868\u8ff0\u200b\u65b9\u5f0f\u200b\ntf.local_variables()\ntf.get_collection(ops.GraphKeys.LOCAL_VARIABLES, scope=None)\n</code></pre><p></p> </li> </ol>"},{"location":"AI/AI_Platform/Tensorflow/graph_related/ops/operation.html","title":"Operation","text":""},{"location":"AI/AI_Platform/Tensorflow/graph_related/ops/operation.html#tfoperation","title":"tf.Operation","text":"<p>\u200b\u8282\u70b9\u200bOperation: name + op + input + attrs \u200b\u8fb9\u200bTensor\uff1a</p> <p>session=run operation + eval tensor</p> <p>TensorBoard </p><pre><code>tf.summary.FileWriter(logdir, graph=None, max_queue=10, flush_secs=120, graph_def=None, filename_suffix=None, session=None) \nlogdir\uff0c\u200b\u65e5\u5fd7\u200b\u8def\u5f84\u200b \ngraph\uff0c \nfilename_suffix\uff0c\u200b\u65e5\u5fd7\u200b\u6587\u4ef6\u200b\u540e\u7f00\u200b \n</code></pre><p></p>"},{"location":"AI/AI_Platform/Tensorflow/graph_related/ops/tensor.html","title":"Tensor","text":""},{"location":"AI/AI_Platform/Tensorflow/graph_related/ops/tensor.html#tftensor","title":"tf.Tensor","text":""},{"location":"AI/AI_Platform/Tensorflow/graph_related/ops/tensor.html#tensorshape","title":"TensorShape","text":"<pre><code>var.shape.as_list()     # list[int], list values of each dimension\nvar.shape.ndims         # list[Dimensions]\nvar.shape.dims          # int, number of dims, equals to `var.shape.rank`\n</code></pre>"},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html","title":"Gradient update","text":"<ol> <li>(\u200b\u53ef\u9009\u9879\u200b) learning rate schedule</li> <li>(\u200b\u53ef\u9009\u9879\u200b) warmup</li> <li>\u200b\u8ba1\u7b97\u200b\u53c2\u6570\u200b\u7684\u200b\u53cd\u5411\u200b\u68af\u5ea6\u200b</li> <li>(\u200b\u53ef\u9009\u9879\u200b) gradient clipping</li> <li>\u200b\u9009\u5b9a\u200boptimizer</li> <li>\u200b\u5e94\u7528\u200boptimizer\u200b\u5b9e\u73b0\u200bgradient update</li> <li>execute operation graph one time</li> </ol> TF 1.x <pre><code>tvars = tf.trainable_variables()\n# calculate trainable_variables bp gradients\ngrads = tf.gradients(loss, tvars)\n# gradients clip\n(grads, _) = tf.clip_by_global_norm(grads, clip_norm=1.0)\n# choose optimizer\noptimizer = tf.train.AdamOptimizer(learning_rate)\n# update using (trainable_variable, gradient) pairwise\ntrain_op = optimizer.apply_gradients(zip(grads, tvars), global_step=global_step)\n    # global_step: IntegerTensor\uff0c\u200b\u6bcf\u6b21\u200b\u6267\u884c\u200b\u4f1a\u200b\u5bf9\u200b\u8be5\u200btensor\u200b\u8fdb\u884c\u200b\u52a0\u200b1\u200b\u64cd\u4f5c\u200b\n# execute operation graph one time\nsess.run(train_op)\n</code></pre>"},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#lr_schedule","title":"lr_schedule","text":""},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#exponential_decay","title":"exponential_decay","text":"<p>learning rate\u200b\u6307\u6570\u200b\u8870\u51cf\u200b</p> \\[\\text{decayed_lr} = init\\_lr * \\text{pow}(decay\\_rate, \\frac{global\\_step}{decay\\_steps})\\] TF 1.x <pre><code>def exponential_decay(\n        learning_rate,              # init_lr\n        global_step,                # \u200b\u5f53\u524d\u200b\u8bad\u7ec3\u200b\u7684\u200bstep\u200b\u8ba1\u6570\u200b\n        decay_steps,                # \u200b\u7528\u4e8e\u200b\u8ba1\u7b97\u200b\u8870\u51cf\u200b\u6307\u6570\u200b\n        decay_rate,                 # \u200b\u5e42\u51fd\u6570\u200b\u5e95\u200b\uff0c\u200b\u4e00\u822c\u200b&lt;1\uff0c\u200b\u8d8a\u5c0f\u200b\u8870\u51cf\u200b\u8d8a\u200b\u5feb\u200b\n        staircase=False,            # lr\u200b\u662f\u5426\u200b\u79bb\u6563\u200b\u8870\u51cf\u200b\n                                    # staircase=False, \u200b\u8fde\u7eed\u200b\u8870\u51cf\u200b\uff0c\u200b\u6bcf\u6b65\u200b\u8870\u51cf\u200b\u4e00\u6b21\u200b\n                                    # staircase=True, \u200b\u79bb\u6563\u200b\u8870\u51cf\u200b\uff0c\u200b\u6bcf\u200bdecay_rate\u200b\u6b65\u200b\u8870\u51cf\u200b\u4e00\u6b21\u200b\n        name=None):\n</code></pre>"},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#polynomial_decay","title":"polynomial_decay","text":"<p>learning rate\u200b\u591a\u9879\u5f0f\u200b\u8870\u51cf\u200b</p> \\[\\text{decayed_lr} = (init\\_lr - end\\_lr) * \\text{pow}(1-\\frac{global\\_step}{decay\\_steps}, {power}) + end\\_lr \\] TF 1.x <pre><code>def polynomial_decay(\n        learning_rate,              # init_lr\n        global_step,                # \u200b\u5f53\u524d\u200b\u8bad\u7ec3\u200b\u7684\u200bstep\u200b\u8ba1\u6570\u200b\n        decay_steps,                # \u200b\u7528\u4e8e\u200b\u8ba1\u7b97\u200b\u8870\u51cf\u200b\u5e95\u6570\u200b\n        end_learning_rate=0.0001,   # end_lr, \u200b\u5141\u8bb8\u200b\u8870\u51cf\u200b\u81f3\u200b\u7684\u200b\u6700\u5c0f\u200blr\n        power=1.0,                  # \u200b\u591a\u9879\u5f0f\u200b\u5e42\u51fd\u6570\u200b\u6307\u6570\u200b\uff0c\u200b\u4e00\u822c\u200b\u22651\uff0c\u200b\u8d8a\u5927\u200b\u8870\u51cf\u200b\u8d8a\u200b\u5feb\u200b\n        cycle=False,                # \u200b\u53d7\u5426\u200b\u5468\u671f\u200b\u8870\u51cf\u200b\n                                    # cycle=False\uff0ccal_global_step=min(global_step, decay_steps)\n                                    # \u200b\u5e95\u6570\u200b -&gt; `(1 - cal_global_step/decay_steps)`\n                                    # cycle=True, cal_decay_steps=decay_steps * ceil(global_step/decay_steps)\n                                    # \u200b\u5e95\u6570\u200b -&gt; `(1 - global_step/cal_decay_steps)`\n        name=None):\n</code></pre>"},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#natural_exp_decay","title":"natural_exp_decay","text":""},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#inverse_time_decay","title":"inverse_time_decay","text":""},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#consine_decay","title":"consine_decay","text":""},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#linear_consine_decay","title":"linear_consine_decay","text":""},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#noise_linear_consine_decay","title":"noise_linear_consine_decay","text":""},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#warmup","title":"warmup","text":"<p>\u200b\u5728\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u521d\u671f\u200b\u5bf9\u200b(\u200b\u8870\u51cf\u200b\u540e\u200b\u7684\u200b)learning rate\u200b\u6267\u884c\u200bwarmup\u200b\u64cd\u4f5c\u200b</p> TF 1.x <pre><code>''' step \u200b\u5904\u4e8e\u200b [0, num_warmup_steps] \u200b\u533a\u95f4\u200b\u6267\u884c\u200bwarmup\u200b\u64cd\u4f5c\u200b '''\nglobal_steps_int = tf.cast(global_step, tf.int32)\nwarmup_steps_int = tf.constant(num_warmup_steps, dtype=tf.int32)\n\nglobal_steps_float = tf.cast(global_steps_int, tf.float32)\nwarmup_steps_float = tf.cast(warmup_steps_int, tf.float32)\n\nwarmup_percent_done = global_steps_float / warmup_steps_float\nwarmup_learning_rate = init_lr * warmup_percent_done\n# \u200b\u901a\u8fc7\u200b\u6bd4\u8f83\u200b global_step \u200b\u548c\u200b num_warmup_steps \u200b\u51b3\u5b9a\u200b\u662f\u5426\u200b\u9700\u8981\u200b\u5e94\u7528\u200bwarmup\u200b\u64cd\u4f5c\u200b\nis_warmup = tf.cast(global_steps_int &lt; warmup_steps_int, tf.float32)\n# \u200b\u9664\u200b\u7ebf\u6027\u200bwarmup\u200b\u5916\u200b\uff0c\u200b\u8fd8\u200b\u53ef\u200b\u81ea\u5b9a\u4e49\u200b\u5176\u5b83\u200bwarmup\u200b\u7b56\u7565\u200b\nlearning_rate = ((1.0 - is_warmup) * learning_rate + is_warmup * warmup_learning_rate)\n</code></pre>"},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#calculate-bp-gradients","title":"calculate bp gradients","text":""},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#using-function","title":"using function","text":"TF 1.x <pre><code>''' tf.gradients(loss, tf.trainable_variables()) '''\ndef gradients(\n        ys,\n        xs,\n        grad_ys=None,\n        name=\"gradients\",\n        colocate_gradients_with_ops=False,\n        gate_gradients=False,\n        aggregation_method=None,\n        stop_gradients=None,\n        unconnected_gradients=UnconnectedGradients.NONE):\n</code></pre>"},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#using-optimizer","title":"using optimizer","text":"TF 1.x <pre><code>''' optmizer.compute_gradients(loss, tf.trainable_variables()) '''\ndef compute_gradients(self, \n        loss, \n        var_list=None,\n        gate_gradients=GATE_OP,\n        aggregation_method=None,\n        colocate_gradients_with_ops=False,\n        grad_loss=None):\n</code></pre>"},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#gradient-clipping","title":"gradient clipping","text":"<p>\u200b\u68af\u5ea6\u200b\u88c1\u526a\u200b\u4e00\u822c\u200b\u7528\u4e8e\u200b\u89e3\u51b3\u200b \u200b\u68af\u5ea6\u200b\u7206\u70b8\u200b(gradient explosion) \u200b\u95ee\u9898\u200b</p>"},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#clip_by_value","title":"clip_by_value","text":"<p>\u200b\u5c06\u200b\u68af\u5ea6\u200b\u76f4\u63a5\u200b\u4fee\u526a\u200b\u4e3a\u200b\u6307\u5b9a\u200b\u533a\u95f4\u200b <code>[clip_value_min, clip_value_max]</code> \u200b\u5185\u200b\u7684\u200b\u503c\u200b</p> TF 1.x <pre><code>def clip_by_value(\n        t, \n        clip_value_min, \n        clip_value_max,\n        name=None):\n</code></pre>"},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#clip_by_norm","title":"clip_by_norm","text":"<p>\u200b\u901a\u8fc7\u200b\u63a7\u5236\u200b\u68af\u5ea6\u200b\u7684\u200b\u6700\u5927\u200b\u8303\u5f0f\u200b<code>t * clip_norm / max(clip_norm, l2norm(t))</code>\u200b\u5bf9\u200b\u68af\u5ea6\u200b\u8fdb\u884c\u200b\u7ea6\u675f\u200b\u88c1\u526a\u200b</p> TF 1.x <pre><code>def clip_by_norm(\n        t, \n        clip_norm, \n        axes=None, \n        name=None):\n</code></pre>"},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#optimizer","title":"optimizer","text":""},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#compute_gradients","title":"compute_gradients","text":"<p>\u200b\u4f7f\u7528\u200boptimizer\u200b\u8ba1\u7b97\u200b\u68af\u5ea6\u200b\uff0c\u200b\u89c1\u200busing optimizer</p>"},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#apply_gradients","title":"apply_gradients","text":"<p>\u200b\u5b9e\u73b0\u200btrainable_variables\u200b\u7684\u200b\u68af\u5ea6\u200b\u66f4\u65b0\u200b</p> TF 1.x <pre><code>def apply_gradients(self, \n    grads_and_vars,         # list[(gradient, variable)]\n    global_step=None,       # \u200b\u8bb0\u5f55\u200b\u8bad\u7ec3\u200b\u7684\u200bstep\u200b\u8ba1\u6570\u200b\u5f20\u91cf\u200b\uff0c\u200b\u6bcf\u6b21\u200b\u6267\u884c\u200b\u4f1a\u200b\u8fdb\u884c\u200b+1\u200b\u64cd\u4f5c\u200b\n    name=None)\n</code></pre> <p>\u200b\u81ea\u884c\u200b\u58f0\u660e\u200b\uff1a<code>global_step=tf.Variable(0, trainable=False)</code> \u200b\u5185\u7f6e\u200b\u65b9\u6cd5\u200b\u58f0\u660e\u200b\uff1a<code>global_step=tf.train.get_or_create_global_step()</code></p>"},{"location":"AI/AI_Platform/Tensorflow/schedule/gradient_update.html#minimize","title":"minimize","text":"<p><code>minimize = compute_gradients + apply_gradients</code></p>"},{"location":"AI/AI_Platform/Tensorflow/shape_operate/split_concat.html","title":"Split concat","text":""},{"location":"AI/AI_Platform/Tensorflow/shape_operate/split_concat.html#split","title":"split","text":"<p>\u200b\u4e24\u79cd\u200b\u7528\u6cd5\u200b\uff1a</p> <ol> <li><code>isinstance(num_or_size_splits, list)</code>\uff1a\u200b\u6307\u5b9a\u200b\u6bcf\u90e8\u200b\u5b50\u200b\u5f20\u91cf\u200b\u5728\u200b<code>axis</code>\u200b\u8f74\u4e0a\u200b\u5212\u5206\u200b\u7684\u200b\u6570\u91cf\u200b</li> <li><code>isinstance(num_or_size_splits, int)</code>\uff1a\u200b\u6bcf\u90e8\u200b\u5206\u5b50\u200b\u5f20\u91cf\u200b\u5728\u200b<code>axis</code>\u200b\u8f74\u4e0a\u200b\u7b49\u91cf\u200b\u5212\u5206\u200b\uff0c\u200b\u4e0d\u8db3\u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u53ea\u53d6\u200b\u5269\u4f59\u200b\u7684\u200b\u90e8\u5206\u200b <pre><code># \u200b\u6cbf\u200b\u6307\u5b9a\u200b\u8f74\u200b`axis`\u200b\u5c06\u200b\u4e00\u4e2a\u200b\u5f20\u91cf\u200b`value`\u200b\u5212\u5206\u200b\u4e3a\u200b\u591a\u4e2a\u200b\u5f20\u91cf\u200b\ndef split(\n    value,\n    num_or_size_splits,     # Union[int, list[int]]\n    axis=0,                 # int, \u200b\u548c\u200bpython\u200b\u7c7b\u4f3c\u200b\uff0c\u200b\u652f\u6301\u200b\u8d1f\u6570\u200b\u53cd\u5411\u200b\u7d22\u5f15\u200b\n    num=None,\n    name=\"split\"\n)\n</code></pre></li> </ol>"},{"location":"AI/AI_Platform/Tensorflow/shape_operate/split_concat.html#concat","title":"concat","text":"<pre><code># \u200b\u6cbf\u200b\u6307\u5b9a\u200b\u8f74\u200b`axis`\u200b\u5c06\u200b\u591a\u4e2a\u200b\u5f20\u91cf\u200b`values`\u200b\u6574\u5408\u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u5f20\u91cf\u200b\ndef concat(\n    values,                 # list[tf.Tensor]\n    axis,                   # int, \u200b\u548c\u200bpython\u200b\u7c7b\u4f3c\u200b\uff0c\u200b\u652f\u6301\u200b\u8d1f\u6570\u200b\u53cd\u5411\u200b\u7d22\u5f15\u200b\n    name=\"concat\"\n)\n</code></pre>"},{"location":"AI/AI_Platform/Tensorflow/shape_operate/squeeze.html","title":"Squeeze","text":""},{"location":"AI/AI_Platform/Tensorflow/shape_operate/squeeze.html#squeeze","title":"squeeze","text":"<pre><code># \u200b\u5c06\u200b\u5f20\u91cf\u200b `input` \u200b\u4e2d\u200b\u7684\u200b\u7ef4\u5ea6\u200b\u4e3a\u200b1\u200b\u7684\u200b\u8f74\u200b\uff08\u200b\u82e5\u200b\u6307\u5b9a\u200b\u4e86\u200b\u8f74\u200b\u53ea\u200b\u5904\u7406\u200b\u5bf9\u5e94\u200b\u7684\u200b\u8f74\u200b\uff09\u200b\u5220\u9664\u200b\ndef squeeze(\n    input,\n    axis=None,          # Union[int, list[int]]\n    name=None, \n    squeeze_dims=None   # `axis`\n)\n</code></pre>"},{"location":"AI/AI_Platform/Tensorflow/shape_operate/squeeze.html#unsqueeze","title":"unsqueeze","text":"<p>\u200b\u901a\u8fc7\u200b <code>tf.expand_dims</code> \u200b\u6765\u200b\u5b9e\u73b0\u200bunsqueeze\u200b\u6548\u679c\u200b </p><pre><code># \u200b\u5411\u200b\u5f20\u91cf\u200b `input` \u200b\u63d2\u5165\u200b\u4e00\u4e2a\u200b\u7ef4\u5ea6\u200b\u4e3a\u200b1\u200b\u7684\u200b\u8f74\u200b\ndef expand_dims(\n    input,\n    axis=None,      # int, \u200b\u548c\u200bpython\u200b\u7c7b\u4f3c\u200b\uff0c\u200b\u652f\u6301\u200b\u8d1f\u6570\u200b\u53cd\u5411\u200b\u7d22\u5f15\u200b\n    name=None,\n    dim=None        # `axis`\n)\n</code></pre><p></p>"},{"location":"AI/AI_Platform/Tensorflow/tensor_related/declaration.html","title":"Declaration","text":""},{"location":"AI/AI_Platform/Tensorflow/tensor_related/declaration.html#declaration","title":"declaration","text":""},{"location":"AI/AI_Platform/Tensorflow/tensor_related/declaration.html#placeholder","title":"placeholder","text":"<p>\u200b\u4e3a\u200b\u9700\u8981\u200b\u8f93\u5165\u200b\u7684\u200b\u5f20\u91cf\u200b\u63d2\u5165\u200b\u4e00\u4e2a\u200b\u5360\u4f4d\u200b\u7b26\u200b\uff0c\u200b\u5bf9\u5e94\u200b<code>sess.run</code>\u200b\u4e2d\u200b\u7684\u200b<code>feed_dict</code> </p><pre><code>def placeholder(\n    dtype,\n    shape=None,                 \n    name=None)\n</code></pre><p></p>"},{"location":"AI/AI_Platform/Tensorflow/tensor_related/declaration.html#get_variable","title":"get_variable","text":"<pre><code>tf.get_variable(\n    name,                       # variable_name\n    shape=None,                 # variable_shape\n    dtype=None,                 # data type\n    initializer=None,           # \u200b\u4f7f\u7528\u200b\u4e86\u200b\u5177\u4f53\u200b\u6570\u503c\u200b\u8fdb\u884c\u200b\u521d\u59cb\u5316\u200b\u65f6\u200b\u4e0d\u80fd\u200b\u6307\u5b9a\u200bshape\n    trainable=None)\n</code></pre> <ol> <li>\u200b\u4f7f\u7528\u200b<code>initializer</code>\u200b\u521d\u59cb\u5316\u200b <pre><code>tf.get_variable(\n    name,\n    shape=[dim_1, ..., dim_n],\n    initializer=tf.truncated_normal_initializer(mean, stddev),\n    dtype=tf.float32\n)\n</code></pre></li> <li> <p>\u200b\u6307\u5b9a\u200b\u6570\u503c\u200b\u521d\u59cb\u5316\u200b </p><pre><code>tf.get_variable(\n    name,\n    initializer=pkl.load(open(value_file_path, 'rb'))\n    dtype=tf.float32\n)\n</code></pre><p></p> <p>\u200b\u4f7f\u7528\u200b\u6307\u5b9a\u200b\u503c\u200b\u521d\u59cb\u5316\u200b\u65f6\u200b\u4e0d\u80fd\u200b\u6307\u5b9a\u200b<code>shape</code>\uff0c\u200b\u6539\u4e3a\u200b\u4f7f\u7528\u200bconstant_initalizer\u200b\u521d\u59cb\u5316\u200b\u65f6\u200b\u53ef\u4ee5\u200b\u6307\u5b9a\u200b</p> </li> <li> <p>\u200b\u642d\u914d\u200b<code>variable_scope</code>\u200b\u5b9e\u73b0\u200b\u53d8\u91cf\u200b\u5171\u4eab\u200b </p><pre><code>with tf.variable_scope(scope_name, reuse=tf.AUTO_REUSE) as scope:\n    tf.get_variable(var_name)   # true_var_name=f'{scope_name}/{var_name}'\n                                # scope_name=\"\", var_name=true_var_name\u200b\u7b49\u4ef7\u200b\u4e8e\u200b\u2191\n    # reuse: 1/True/tf.AUTO_REUSE\uff0c\u200b\u672a\u5b9a\u4e49\u200b\u5219\u200b\u521b\u5efa\u200b\uff0c\u200b\u5df2\u200b\u5b9a\u4e49\u200b\u5219\u200b\u83b7\u53d6\u200b\u8be5\u200b\u53d8\u91cf\u200b\n    # reuse: 0/False/None\uff0c\u200b\u672a\u5b9a\u4e49\u200b\u5219\u200b\u521b\u5efa\u200b\uff0c\u200b\u5df2\u200b\u5b9a\u4e49\u200b\u62a5\u9519\u200b`ValueError`\u200b\u5e76\u200b\u63d0\u793a\u200b\u53d8\u91cf\u200b\u5df2\u200b\u5b58\u5728\u200b\n</code></pre><p></p> </li> </ol> <p><code>variable_scope</code>\u200b\u5d4c\u5957\u200b\u4f7f\u7528\u200b\u65f6\u200b\uff0cscope\u200b\u4f1a\u200b\u81ea\u52a8\u200b\u4f9d\u6b21\u200b\u53e0\u52a0\u200b</p>"},{"location":"AI/AI_Platform/Tensorflow/tensor_related/declaration.html#variable","title":"Variable","text":"<p>\u200b\u6bcf\u6b21\u200b\u8c03\u7528\u200b\u90fd\u200b\u662f\u200b\u521b\u5efa\u200b\u65b0\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u4e14\u200b\u68c0\u6d4b\u200b\u5230\u200b\u547d\u540d\u200b\u51b2\u7a81\u200b\u65f6\u200b\uff0c\u200b\u8be5\u200b\u51fd\u6570\u200b\u4f1a\u200b\u81ea\u52a8\u200b\u5904\u7406\u200b\u51b2\u7a81\u200b(\u200b\u6539\u540d\u200b)\u200b\u5e76\u200b\u5b8c\u6210\u200b\u5bf9\u8c61\u200b\u521b\u5efa\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5373\u4f7f\u200b <code>reuse=True</code> \u200b\u65f6\u8be5\u200b\u65b9\u6cd5\u200b\u4e5f\u200b\u65e0\u6cd5\u200b\u5b9e\u73b0\u200b\u5171\u4eab\u200b\u53d8\u91cf\u200b\uff0c\u200b\u5176\u4f59\u200b\u6548\u679c\u200b\u4e0e\u200b get_variable \u200b\u5b8c\u5168\u4e00\u81f4\u200b </p> <p>\u200b\u4f7f\u7528\u200b<code>tf.Variable</code>\u200b\u58f0\u660e\u200b\uff0c\u200b\u800c\u540e\u200b\u7528\u200b<code>tf.get_variable</code>\u200b\u83b7\u53d6\u200b\u5bf9\u5e94\u200b\u540d\u5b57\u200b\u7684\u200b\u53d8\u91cf\u200b\u4e5f\u200b\u65e0\u6cd5\u200b\u5b9e\u73b0\u200b\u53d8\u91cf\u200b\u5171\u4eab\u200b\u3002</p>"},{"location":"AI/AI_Platform/Tensorflow/tensor_related/declaration.html#embedding","title":"embedding","text":"<p>embedding\u200b\u4e00\u822c\u200b\u4e3a\u200b\u4e00\u4e2a\u200b<code>[vocab_size, dim]</code> \u200b\u7684\u200b\u4e8c\u7ef4\u200b\u77e9\u9635\u200b\u5f20\u91cf\u200b</p> <ol> <li>\u200b\u5728\u200b\u77e9\u9635\u200bembedding\u200b\u4e2d\u200b\u63d0\u53d6\u200b\u4e00\u7ec4\u200b\u7d22\u5f15\u200b\u5bf9\u5e94\u200b\u7684\u200b\u5b50\u96c6\u200b <pre><code># params([vocab_size, dim]) + ids([seq_len]) \u2192 representation([seq_len, dim])\ntf.nn.embedding_lookup(\n    params,\n    ids,\n    partition_strategy=\"mod\"\n    name=None    \n)\n</code></pre></li> </ol> <p>\u200b\u529f\u80fd\u200b\u7b49\u540c\u4e8e\u200bgather\uff0c\u200b\u4f46\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u66f4\u4e3a\u200b\u9ad8\u6548\u200b\uff0c\u200b\u901a\u8fc7\u200b\u5c06\u200b\u89c4\u6a21\u200b\u8f83\u5927\u200b\u7684\u200bparams\u200b\u5206\u5757\u200b\u5b58\u50a8\u200b\uff0c\u200b\u518d\u200b\u6839\u636e\u200bids\u200b\u548c\u200b\u6bcf\u5757\u200b\u7684\u200b\u4f4d\u7f6e\u200b\u8fdb\u884c\u200b\u7d22\u5f15\u200b\u5b9e\u73b0\u200b\u53d6\u503c\u200b https://www.zhihu.com/question/52250059</p>"},{"location":"AI/AI_Platform/Tensorflow/tensor_related/declaration.html#initializer","title":"initializer","text":""},{"location":"AI/AI_Platform/Tensorflow/tensor_related/declaration.html#zerosonesconstant_initializer","title":"zeros/ones/constant_initializer","text":"<p>\u200b\u5168\u200b\u4f7f\u7528\u200b <code>0/1/value</code> \u200b\u8fdb\u884c\u200b\u5168\u90e8\u200b\u521d\u59cb\u5316\u200b </p><pre><code>''' tf.zeros/ones_initializer(dtype=tf.float32) '''\ndef __init__(self, dtype=dtypes.float32):\n''' tf.constant_initializer(2, dtype=tf.float32) '''\ndef __init__(self, value=0, dtype=dtypes.float32, verify_shape=False):\n</code></pre><p></p>"},{"location":"AI/AI_Platform/Tensorflow/tensor_related/declaration.html#random_uniform_initializer","title":"random_uniform_initializer","text":"<p>\u200b\u6bcf\u4e2a\u200b\u503c\u200b\u90fd\u200b\u4ece\u200b <code>[min_val, max_val]</code> \u200b\u533a\u95f4\u200b\u5185\u200b\u5747\u5300\u200b\u91c7\u6837\u200b\u8fdb\u884c\u200b\u521d\u59cb\u5316\u200b </p><pre><code>def __init__(self, minval=0, maxval=None, seed=None, dtype=dtypes.float32):\n# if maxval == None; maxval=1\n# minval, maxval = min(minval, maxval), max(minval, maxval)\n</code></pre><p></p>"},{"location":"AI/AI_Platform/Tensorflow/tensor_related/declaration.html#randomtruncated_normal_initializer","title":"random/truncated_normal_initializer","text":"<ul> <li><code>random</code>\uff1a\u200b\u6bcf\u4e2a\u200b\u503c\u200b\u90fd\u200b\u4ece\u200b\u5206\u5e03\u200b \\(N~(\\mu, \\sigma^2)\\) \u200b\u4e2d\u200b\u91c7\u6837\u200b\u8fdb\u884c\u200b\u521d\u59cb\u5316\u200b</li> <li><code>truncated</code>\uff1a\u200b\u5c06\u200b\u4fdd\u7559\u200b\u91c7\u6837\u200b\u4e2d\u200b\u5904\u4e8e\u200b <code>[\u03bc-2*\u03c3, u+2*\u03c3]</code> \u200b\u533a\u95f4\u200b\u5185\u200b\u7684\u200b\u503c\u200b\uff0c\u200b\u672a\u200b\u5904\u4e8e\u200b\u533a\u95f4\u200b\u5185\u200b\u7684\u200b\u503c\u200b\u91cd\u65b0\u200b\u8fdb\u884c\u200b\u91c7\u6837\u200b\u76f4\u81f3\u200b\u5904\u4e8e\u200b\u8be5\u200b\u76ee\u6807\u200b\u533a\u95f4\u200b\uff08\u200b\u4e00\u822c\u200b<code>stddev=0.02</code>\uff09</li> </ul> <pre><code>def __init__(self, mean=0.0, stddev=1.0, seed=None, dtype=dtypes.float32):\n</code></pre>"},{"location":"AI/AI_Platform/Tensorflow/tensor_related/declaration.html#glorot_uniformnormal_initializer","title":"glorot_uniform/normal_initializer","text":"<p><code>glorot</code> \u200b\u5728\u200b2010\u200b\u5e74\u200b\u7531\u200bXavier glorot\u200b\u53d1\u660e\u200b\uff0c\u200b\u6240\u4ee5\u200b\u4e5f\u200b\u53eb\u505a\u200b<code>Xavier</code>\uff0c\u200b\u7528\u4e8e\u200b\u5bf9\u200b\u7ebf\u6027\u53d8\u6362\u200b\u5c42\u200b\u7684\u200b\u5f20\u91cf\u200b(d_in, d_out)\u200b\u521d\u59cb\u5316\u200b  </p> <ul> <li><code>uniform</code>\uff0c\\(\\text{lim}=\\sqrt{\\frac{6}{d\\_in + d\\_out}}\\)\uff0c\u200b\u533a\u95f4\u200b\u4e3a\u200b <code>[-lim, lim]</code></li> <li><code>normal</code>\uff0c\\(\\text{stddev}=\\sqrt{\\frac{2}{d\\_in + d\\_out}}\\)\uff0c\u200b\u7b49\u4ef7\u200b\u4e8e\u200b<code>truncated_normal_initializer(mean=0, stddev=stddev)</code></li> </ul> <pre><code>def __init__(self, seed=None, dtype=dtypes.float32):\n</code></pre>"},{"location":"AI/AI_Platform/Transformers/transformers.html","title":"Transformers","text":"<p>transformers\u200b\u7248\u672c\u200b\u8d8a\u65b0\u8d8a\u200b\u597d\u200b\uff0c\u200b\u6700\u597d\u200bpython&gt;=3.9</p> <ul> <li> transformers.optimization</li> <li> pipeline</li> </ul> <pre><code>from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\nfrom datasets import load_dataset\nfrom sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\nimport numpy as np\nfrom opencc import OpenCC\nfrom functools import partial\nfrom wheel_utils.char_alpha_numeric import *\nfrom wheel_utils.general_dataset_utils import *\n\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return {\n        \"accuracy\": accuracy_score(labels, predictions),\n        \"f1\": f1_score(labels, predictions, average=\"macro\"),\n        \"recall\": recall_score(labels, predictions),\n        \"precision\": precision_score(labels, predictions),\n    }\n\n\ndef tokenize_function(examples, max_seq_length):\n    return tokenizer(\n        examples[\"content\"],\n        padding=\"longest\",\n        truncation=True,\n        max_length=max_seq_length,\n        # return_tensors=\"pt\"\n    )\n\n\ndef split_dataset(data_files, process_func, tokenize_func, train_percent=.99):\n    dataset_dict = load_dataset(\"json\", data_files=data_files)\n    if len(dataset_dict) == 1:\n        dataset = dataset_dict[\"train\"].shuffle()\n        train_dataset = dataset.select(range(int(train_percent * len(dataset))))\n        valid_dataset = dataset.select(range(int(train_percent * len(dataset)), len(dataset)))\n    else:\n        train_dataset = dataset_dict[\"train\"]\n        valid_dataset = dataset_dict[\"valid\"]\n    train_dataset = train_dataset.map(process_func, desc=\"preprocessing train dataset\")\n    valid_dataset = valid_dataset.map(process_func, desc=\"preprocessing valid dataset\")\n    tokenized_train_dataset = train_dataset.map(tokenize_func, batched=True, desc=\"tokenizing train dataset\")\n    tokenized_valid_dataset = valid_dataset.map(tokenize_func, batched=True, desc=\"tokenizing valid dataset\")\n\n    return tokenized_train_dataset, tokenized_valid_dataset\n\n\nif __name__ ==\"__main__\":\n    data_path = {\"train\": \"../data/data.json\"}\n    model_path = \"../../pre_trains/roberta/\"\n    save_steps = 1000\n    gradient_accumulation_steps = 1\n    train_batch_size = 64\n    eval_batch_size = 64\n    max_seq_length = 512\n    epochs = 1\n    lr=2e-5\n\n    trie = StringUtils.SpanReplacement(\"../data/replace_map.txt\")\n    t2s = OpenCC(\"t2s\")\n    case_sensitive=False\n\n    # init model\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n\n    # prepare dataset\n    process_func = partial(pre_process, trie=trie, t2s=t2s, case_sensitive=case_sensitive)\n    tokenize_func = partial(tokenize_function, max_seq_lenght=max_seq_length)\n    tokenized_train_dataset, tokenized_valid_dataset = split_dataset(data_path, process_func, tokenize_func)\n\n\n    # trainer arguments\n    training_args = TrainingArguments(\n        # dataset part\n        remove_unused_columns=True,\n        # seed=42,\n        # group_by_length=False,\n        # dataloader_num_workers=4,\n\n        # train part\n        learning_rate=lr,\n        lr_scheduler_type=\"linear\",\n        warmup_ratio=0.1,\n        # warmup_steps=100,\n        optim=\"adamw_hf\",\n        num_train_epochs=epochs,\n        per_device_train_batch_size=train_batch_size,\n                                        # \u200b\u7b49\u4ef7\u200b\u4e8e\u200b`per_device_train_batch_size`\uff0c\u200b\u63a8\u8350\u200b\u4f7f\u7528\u200b\u524d\u8005\u200b\n                                        # \u200b\u56e0\u6b64\u200b\u771f\u5b9e\u200bbatch_size=num_gpu * per_device_train_batch_size\n        gradient_accumulation_steps=gradient_accumulation_steps,\n        # gradient_checkpointing=True,\n\n        # eval part\n        per_device_eval_batch_size=eval_batch_size,\n        evaluation_strategy=\"steps\",\n        eval_steps=save_steps,\n        metric_for_best_model=\"f1\",\n        greater_is_better=True,         # \u200b\u4e0a\u8ff0\u200bmetric\u200b\u6307\u6807\u200b\u662f\u5426\u200b\u8d8a\u5927\u8d8a\u200b\u597d\u200b\n\n        # dump part\n        save_strategy=\"steps\",\n        save_steps=save_steps,\n        save_total_limit=2,             # \u200b\u76ee\u6807\u200b\u6587\u4ef6\u5939\u200b\u6700\u200b\u591a\u200bdump_model\u200b\u6570\u200b\uff08\u200b\u5305\u62ec\u200b\u5386\u53f2\u200b\u8bad\u7ec3\u200b\u7ed3\u679c\u200b\uff09\n        output_dir=\"./ckpts/\",\n        load_best_model_at_end=False,   # \u200b\u9632\u6b62\u200b\u65e0\u6cd5\u200bsave_at_end\n        # save_at_end=True              # Transfomrer\u22654.36.0\u200b\u624d\u200b\u5e94\u7528\u200b\n\n        # log part\n        logging_dir=\"./logs/\",\n        logging_steps=100,\n    )\n\n    trainer = Trainer(\n        model,\n        training_args,\n        train_dataset=tokenized_train_dataset,\n        eval_dataset=tokenized_valid_dataset,\n        compute_metrics=compute_metrics,\n        tokenizer=tokenizer\n    )\n\n    trainer.train()\n    trainer.save_model(\"./ckpts/final_model/\")  # \u200b\u8bad\u7ec3\u200b\u7ed3\u675f\u200b\u540e\u200b\u8c03\u7528\u200b\n</code></pre>"},{"location":"AI/Metrics/index.html","title":"\u6570\u636e\u200b\u6307\u6807","text":"<ul> <li>\u200b\u7279\u5f81\u503c\u200b</li> <li>\u200b\u76f8\u5173\u7cfb\u6570\u200b</li> <li>\u200b\u8bc4\u5224\u200b\u6307\u6807\u200b</li> <li>\u200b\u5e73\u6ed1\u200b\u7cfb\u6570\u200b</li> </ul>"},{"location":"AI/Metrics/correlation_metrics.html","title":"Correlation metrics","text":""},{"location":"AI/Metrics/correlation_metrics.html#cosine-similarity","title":"Cosine Similarity","text":"<p>\u200b\u4f59\u5f26\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\uff0c\u200b\u5373\u200b\u4e24\u4e2a\u200b\u5411\u91cf\u200b\u5939\u89d2\u200b\u7684\u200bcos\u200b\u503c\u200b\uff0c\u200b\u53d6\u503c\u200b\u4e3a\u200b[-1, 1]</p> <ol> <li> <p>Cosiine Similarity</p> \\[ \\text{cos_sim}(x, y) = \\frac{x\\cdot y}{\\vert x \\vert * \\vert y \\vert} \\] </li> <li> <p>Adjusted Cosine Similarity\uff0c\u200b\u8fdb\u4e00\u6b65\u200b\u8003\u8651\u200b\u4e86\u200b\u5411\u91cf\u200b\u5747\u503c\u200b\u7684\u200b\u5dee\u5f02\u200b</p> \\[ \\text{adj_cos_sim}(x, y) = \\frac{(x-\\bar{x})\\cdot(y-\\bar{y})}{\\vert x-\\bar{x}\\vert * \\vert y-\\bar{y} \\vert} \\] <p>\\(\\bar{\\cdot}\\) \u200b\u4e3a\u200b\u5411\u91cf\u200b\u5747\u503c\u200b</p> </li> </ol>"},{"location":"AI/Metrics/correlation_metrics.html#pearson-correlation-coefficient","title":"Pearson Correlation Coefficient","text":"<p>\u200b\u76ae\u5c14\u68ee\u200b\u76f8\u5173\u7cfb\u6570\u200bPCC\uff0c\u200b\u4e5f\u200b\u79f0\u4e3a\u200b\u76ae\u5c14\u68ee\u200b\u79ef\u77e9\u200b\u76f8\u5173\u7cfb\u6570\u200b\uff08Pearson Product-Moment Correlation Coefficient\uff0cPPMCC\uff09\uff0c\u200b\u7528\u6765\u200b\u8861\u91cf\u200b\u4e24\u4e2a\u200b\u53d8\u91cf\u200b\u95f4\u200b\u7ebf\u6027\u5173\u7cfb\u200b\u5f3a\u5ea6\u200b\uff0c\u200b\u53d6\u503c\u200b\u4e3a\u200b[-1, 1]\u200b\u8868\u793a\u200b<code>\u200b\u5b8c\u5168\u200b\u8d1f\u76f8\u5173\u200b \u2192 \u200b\u4e0d\u200b\u76f8\u5173\u200b \u2192 \u200b\u5b8c\u5168\u200b\u6b63\u200b\u76f8\u5173\u200b</code>\uff0c\uff08\u200b\u5047\u8bbe\u200b\u6570\u636e\u670d\u52a1\u200b\u6b63\u6001\u5206\u5e03\u200b\uff09\u200b\u672c\u8d28\u200b\u4e3a\u200b\u4e24\u4e2a\u200b\u5411\u91cf\u200b\u4e2d\u5fc3\u5316\u200b\u540e\u200b\u7684\u200bcosine similarity\uff1a</p> \\[ r(x, y) = \\frac{\\text{Cov}(x, y)}{\\sigma_x \\sigma_y} = \\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum_{i=1}^n(x_i - \\bar{x})^2}\\sqrt{\\sum_{i=1}^n(y_i - \\bar{y})^2}} \\]"},{"location":"AI/Metrics/correlation_metrics.html#lp-distance","title":"Lp Distance","text":"<p>\u200b\u4e5f\u200b\u79f0\u4f5c\u200b\u95f5\u53ef\u200b\u592b\u65af\u57fa\u200b\u8ddd\u79bb\u200bMinkowski Distance\uff0c\u200b\u7528\u4e8e\u200b\u8861\u91cf\u200b\u4e24\u4e2a\u200b\u5411\u91cf\u200b\u95f4\u200b\u8ddd\u79bb\u200b\uff0c\u200b\u8ba1\u7b97\u200b\u65b9\u5f0f\u200b\u4e3a\u200b</p> \\[ L_p(x, y) = \\bigg(\\sum_{i=1}^n \\vert x_i - y_i\\vert^p\\bigg)^{\\frac{1}{p}} \\] <ul> <li> <p>\\(L_0\\) Distance\uff0c\u200b\u4e5f\u200b\u53eb\u200b\u6c49\u660e\u200b\u8ddd\u79bb\u200bHamming Distance\uff0c\u200b\u8868\u793a\u200b\u5404\u200b\u7ef4\u5ea6\u200b\u4e0a\u200b\u5143\u7d20\u200b\u503c\u200b\u4e0d\u540c\u200b\u7684\u200b\u6570\u91cf\u200b</p> \\[ L_0(x, y) = \\sum_{i=1}^n \\mathbb{I}(x_i \\ne y_i) \\] </li> <li> <p>\\(L_1\\) Distance\uff0c\u200b\u4e5f\u200b\u53eb\u200b\u66fc\u54c8\u987f\u200b\u8ddd\u79bb\u200bManhattan Distance</p> \\[ L_1(x, y) = \\sum_{i=1}^n \\vert x_i - y_i\\vert \\] </li> <li> <p>\\(L_2\\) Distance\uff0c\u200b\u4e5f\u200b\u53eb\u200b\u6b27\u51e0\u91cc\u5f97\u200b\u8ddd\u79bb\u200bEuclidean Distance</p> \\[ L_2(x, y) =\\sqrt{\\sum_{i=1}^n (x_i - y_i)^2} \\] </li> <li> <p>\\(L_\\infty\\) Distance\uff0c\u200b\u4e5f\u200b\u53eb\u5207\u200b\u6bd4\u96ea\u592b\u200b\u8ddd\u79bb\u200bChebyshev Distance\uff0c\u200b\u8868\u793a\u200b\u6240\u6709\u200b\u7ef4\u5ea6\u200b\u4e0a\u200b\u7684\u200b\u6700\u5927\u200b\u7edd\u5bf9\u503c\u200b\u5dee\u200b</p> \\[ L_\\infty(x, y) = \\max (\\vert x_1 - y_1 \\vert, \\vert x_2 - y_2 \\vert, \\dots, \\vert x_n - y_n \\vert) \\] </li> </ul> <ul> <li>\u200b\u8ba1\u7b97\u200b\u8303\u6570\u200b \\(L_n\\) Norm\u200b\u65f6\u200b\uff0c\\(y\\) \u200b\u503c\u8bbe\u200b\u4e3a\u200b\u5168\u200b0</li> <li>Frobenius Norm\u200b\u4e3a\u200b\u77e9\u9635\u200b\u5f62\u5f0f\u200b\u7684\u200b\\(L_2\\) Norm\uff0c\u200b\u5373\u200b \\(\\Vert A \\Vert_\\text{F} = \\sqrt{\\sum_{i}\\sum_j \\vert a_{i, j} \\vert ^2}\\)</li> </ul>"},{"location":"AI/Metrics/correlation_metrics.html#kullback-leibler-divergence","title":"Kullback-Leibler Divergence","text":"<p>KL\u200b\u6563\u5ea6\u200b\uff0c\u200b\u4e5f\u200b\u53eb\u505a\u200b\u76f8\u5bf9\u200b\u71b5\u200bRelative Entropy\u200b\u6216\u200b\u4fe1\u606f\u200b\u6563\u5ea6\u200bInformation Divergence\uff0c\u200b\u63cf\u8ff0\u200b\u4e24\u4e2a\u200b\u6982\u7387\u5206\u5e03\u200b\u95f4\u200b\u5dee\u5f02\u200b\u7684\u200b\u975e\u200b\u5bf9\u79f0\u6027\u200b\u5ea6\u91cf\u200b\uff0c\\(D_{KL}(P\\Vert Q)\\ge 0\\)\uff0c\u200b\u503c\u8d8a\u200b\u5927\u200b\u8868\u793a\u200b\u5dee\u5f02\u6027\u200b\u8d8a\u5927\u200b\u3002</p> <ul> <li> <p>\u200b\u79bb\u6563\u200b\u6982\u7387\u5206\u5e03\u200b \\(P\\) \u200b\u548c\u200b \\(Q\\) \u200b\u7684\u200bKL\u200b\u6563\u5ea6\u200b\uff1a</p> \\[ D_{KL}(P\\Vert Q) = \\sum_{i=1}^n P(x_i)\\log \\frac{P(x_i)}{Q(x_i)} = \\sum_{i=1}^n \\big(-P(x_i)\\log {Q(x_i)} \\text{+} P(x_i)\\log P(x_ix)\\big) \\] </li> <li> <p>\u200b\u8fde\u7eed\u200b\u6982\u7387\u5206\u5e03\u200b \\(P\\) \u200b\u548c\u200b \\(Q\\) \u200b\u7684\u200bKL\u200b\u6563\u5ea6\u200b\uff1a</p> \\[ D_{KL}(P\\Vert Q) = \\int_{-\\infty}^{\\infty} P(x)\\log \\frac{P(x)}{Q(x)} \\] </li> </ul>"},{"location":"AI/Metrics/correlation_metrics.html#spearmans-rank-correlation-coefficient","title":"Spearman's Rank Correlation Coefficient","text":"<p>\u200b\u65af\u76ae\u5c14\u66fc\u200b\u7b49\u7ea7\u200b\u76f8\u5173\u7cfb\u6570\u200b\uff0c\u200b\u901a\u5e38\u200b\u7b80\u79f0\u200b\u4e3a\u200b\u65af\u76ae\u5c14\u66fc\u200b\u76f8\u5173\u7cfb\u6570\u200b\uff0c\u200b\u7528\u4e8e\u200b\u8861\u91cf\u200b\u4e24\u4e2a\u200b\u53d8\u91cf\u200b\u4e4b\u95f4\u200b\u7684\u200b\u5355\u8c03\u200b\u5173\u7cfb\u200b\u800c\u200b\u975e\u200b\u7cbe\u786e\u200b\u7684\u200b\u7ebf\u6027\u5173\u7cfb\u200b</p> \\[ \\rho(x , y) = 1 - \\frac{6\\sum_{i=1}^n d_i^2}{n(n^2-1)} = 1 - \\frac{6\\sum_{i=1}^n (r_{x_i} - r_{y_i})^2}{n(n^2-1)} \\] <p>\\(d_i\\) \u200b\u8868\u793a\u200b\u5411\u91cf\u200b \\(x\\) \u200b\u548c\u200b \\(y\\) \u200b\u4e2d\u200b \\(i\\text{-}th\\) \u200b\u5143\u7d20\u200b\u5728\u200b\u5404\u81ea\u200b\u5411\u91cf\u200b\u5185\u200bargsort\u200b\u6392\u5e8f\u200b\u540e\u200b\u7684\u200b\u4f4d\u6b21\u200b\u5dee\u503c\u200b</p>"},{"location":"AI/Metrics/correlation_metrics.html#bm25","title":"BM25","text":"<p>BM25 (Best Matching 25)\uff0c\u200b\u662f\u200b\u4e00\u79cd\u200bTF-IDF\u200b\u6539\u8fdb\u200b\u7248\u672c\u200b\u7684\u200b\u4fe1\u606f\u68c0\u7d22\u200b\u7b97\u6cd5\u200b\uff0c\u200b\u7528\u4e8e\u200b\u8ba1\u7b97\u200b\u67e5\u8be2\u200b\uff08Query\uff09\u200b\u548c\u200b\u6587\u6863\u200b\uff08Document\uff09\u200b\u4e4b\u95f4\u200b\u7684\u200b\u76f8\u5173\u6027\u200b\u5206\u6570\u200b\uff0c\u200b\u5e7f\u6cdb\u5e94\u7528\u200b\u4e8e\u200b\u641c\u7d22\u5f15\u64ce\u200b\u3001\u200b\u6587\u6863\u200b\u68c0\u7d22\u200b\u548c\u200b\u95ee\u7b54\u200b\u7cfb\u7edf\u200b\u7b49\u200b\u9886\u57df\u200b\u3002</p> \\[ \\text{BM25}(q, d) = \\sum_{i=1}^n \\text{IDF}(q_i)\\frac{f(q_i, d)\\times(k_1 + 1)}{f(q_i, d) + k_1(1-b + b\\frac{\\vert d \\vert}{\\text{avg dl}})} \\] <ul> <li>\\(q\\) \u200b\u8868\u793a\u200b\u67e5\u8be2\u200b\u5185\u5bb9\u200b\uff0c\u200b\u7531\u200b\u4e00\u7ec4\u200b\u8bcd\u200b \\(q_1, q_2, \\dots, q_n\\) \u200b\u7ec4\u6210\u200b</li> <li>\\(d\\) \u200b\u8868\u793a\u200b\u4e00\u4e2a\u200b\u6587\u672c\u6587\u6863\u200b\uff0c\\(\\vert d \\vert\\) \u200b\u5219\u200b\u8868\u793a\u200b\u8be5\u200b\u6587\u6863\u200b\u4e2d\u200b\u7684\u200b\u8bcd\u6570\u200b</li> <li>\\(f(q_i, d)\\) \u200b\u8868\u793a\u200b\u8bcd\u200b \\(q_i\\) \u200b\u5728\u200b\u6587\u6863\u200b \\(d\\) \u200b\u4e2d\u200b\u7684\u200b\u8bcd\u9891\u200b</li> <li>\\(\\text{IDF}(q_i)\\) \u200b\u8868\u793a\u200b\u8bcd\u200b \\(q_i\\) \u200b\u7684\u200b\u9006\u200b\u6587\u6863\u200b\u9891\u7387\u200b</li> <li>\\(\\text{avg dl}\\) \u200b\u8868\u793a\u200b\u6240\u6709\u200b\u6587\u6863\u200b\u7684\u200b\u5e73\u5747\u200b\u8bcd\u6570\u200b</li> <li>\\(k_1\\) \u200b\u548c\u200b \\(b\\) \u200b\u4e3a\u200b\u53ef\u8c03\u200b\u53c2\u6570\u200b\uff0c\u200b\u901a\u5e38\u200b\u53d6\u503c\u200b\\(k_1 \\in [1.2, 2.0]\\)\uff0c\\(b \\in [0.5, 0.8]\\)</li> </ul> <p>\u200b\u7f3a\u9677\u200b</p> <ul> <li>\u200b\u8bcd\u6c47\u200b\u4e0d\u200b\u5339\u914d\u200b(vocabulary mismatch)\uff1a\u200b\u5982\u200bcat\u200b\u548c\u200bkitty\u200b\u5747\u200b\u8868\u793a\u200b\u732b\u200b</li> <li>\u200b\u8bed\u4e49\u200b\u4e0d\u200b\u5339\u914d\u200b(semantic mismatch)\uff1a\u200b\u5728\u200b\u4e0d\u540c\u200b\u573a\u666f\u200b\u4e2d\u4e00\u8bcd\u200b\u591a\u4e49\u200b\uff0c\u200b\u5982\u200bbank of river \u200b\u548c\u200b bank in finance</li> <li>\u200b\u8bcd\u888b\u200b\u6a21\u578b\u200b\u672a\u200b\u8003\u8651\u200b\u8bcd\u8ddd\u200b\uff1aq={\u200b\u4e9a\u9a6c\u900a\u200b\uff0c\u200b\u96e8\u6797\u200b}\uff1bd={\u200b\u6211\u200b\u5728\u200b\u4e9a\u9a6c\u900a\u200b\u4e0a\u7f51\u200b\u8d2d\u200b\u4e86\u200b\u4e00\u200b\u672c\u4e66\u200b\uff0c\u200b\u4ecb\u7ecd\u200b\u4e1c\u5357\u4e9a\u200b\u70ed\u5e26\u96e8\u6797\u200b\u7684\u200b\u690d\u7269\u7fa4\u843d\u200b\u2026}</li> </ul>"},{"location":"AI/Metrics/correlation_metrics.html#jaccard-similarity","title":"Jaccard Similarity","text":"<p>Jaccard Similarity\u200b\u6770\u200b\u5361\u5fb7\u200b\u76f8\u4f3c\u200b\u7cfb\u6570\u200b\u7528\u4e8e\u200b\u8861\u91cf\u200b\u4e24\u4e2a\u200b\u96c6\u5408\u200b\u4e4b\u95f4\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\u3002</p> \\[ J(A, B) = \\frac{\\vert A \\cap  B \\vert}{\\vert A \\cup B \\vert} = \\frac{\\vert A \\cap  B \\vert}{\\vert A \\vert + \\vert B \\vert - \\vert A \\cap B \\vert} \\]"},{"location":"AI/Metrics/evaluation_metrics.html","title":"Evaluation metrics","text":"<p>macro\uff1a\u200b\u5206\u522b\u200b\u8ba1\u7b97\u200b\u53d6\u200b\u5e73\u5747\u200b micro\uff1a\u200b\u52a0\u6743\u200b</p>"},{"location":"AI/Metrics/evaluation_metrics.html#decision-tree","title":"Decision Tree","text":""},{"location":"AI/Metrics/evaluation_metrics.html#id3","title":"ID3\u200b\u7b97\u6cd5","text":"<ol> <li> <p>Entropy</p> \\[ \\begin{aligned}     H(X)=E(X) =&amp; -\\sum_{k=1}^K p(k)\\log p(k) \\\\     =&amp; -\\sum_{k=1}^K \\frac{\\vert X^k \\vert}{\\vert X \\vert}\\log \\frac{\\vert X^k \\vert}{\\vert X\\vert} \\end{aligned} \\] <p>\\(K\\) \u200b\u8868\u793a\u200b\u5206\u7c7b\u200b\u4efb\u52a1\u200b\u7c7b\u522b\u200b\u6570\u200b \\(X\\) \u200b\u8868\u793a\u200b\u6240\u6709\u200b\u6837\u672c\u200b\u96c6\u5408\u200b\uff0c\\(X^k\\) \u200b\u8868\u793a\u200b\u6240\u6709\u200b\u6837\u672c\u200b\u4e2d\u200b\u5c5e\u4e8e\u200b k-th \u200b\u7c7b\u522b\u200b\u7684\u200b\u6837\u672c\u200b\u96c6\u5408\u200b</p> </li> <li> <p>Information Gain\uff0c\u200b\u4fe1\u606f\u200b\u589e\u76ca\u200b\u6307\u200b\u9009\u62e9\u200b\u67d0\u4e2a\u200b\u7279\u5f81\u200b\u8fdb\u884c\u200b\u5206\u5272\u200b\u80fd\u591f\u200b\u51cf\u5c11\u200b\u7684\u200b\u71b5\u200b\u7684\u200b\u7a0b\u5ea6\u200b</p> \\[ \\begin{aligned}         IG(X, m) =&amp;  E(X) - H(X\\vert X_{m, v}) \\\\         =&amp; E(X) - \\sum_{v \\in V}\\frac{\\vert X_{m, v} \\vert}{\\vert X\\vert}E(X_{m, v}) \\\\         =&amp; E(X) - \\sum_{v \\in V}\\frac{\\vert X_{m, v} \\vert}{\\vert X\\vert}*\\bigg(-\\sum_{k=1}^k \\frac{\\vert X_{m, v}^k \\vert}{\\vert X_{m, v}\\vert}\\log \\frac{\\vert X_{m, v}^k \\vert}{\\vert X_{m, v}\\vert}\\bigg) \\\\         = &amp; E(X) -\\sum_{v \\in V}\\sum_{k=1}^K\\frac{\\vert X_{m, v}^k \\vert}{\\vert X \\vert}\\log \\frac{\\vert X_{m, v}^k \\vert}{\\vert X_{m, v}\\vert} \\\\          = &amp; E(X) -\\sum_{v \\in V}\\sum_{k=1}^Kp(k, m=v)\\log p(k\\vert m=v) \\end{aligned} \\] </li> </ol>"},{"location":"AI/Metrics/evaluation_metrics.html#c45","title":"C4.5\u200b\u7b97\u6cd5","text":"<p>ID3\u200b\u7b97\u6cd5\u200b\u7684\u200b\u6539\u8fdb\u200b\u7248\u672c\u200b</p> <ol> <li> <p>Split Information\uff0c\u200b\u6839\u636e\u200b\u5c5e\u6027\u200b\u7279\u5f81\u200bm\u200b\u5206\u88c2\u200b\u6570\u636e\u200b\u96c6\u6240\u200b\u4ea7\u751f\u200b\u7684\u200b\u71b5\u200b\uff0c\u200b\u7528\u4e8e\u200b\u60e9\u7f5a\u200b\u5177\u6709\u200b\u66f4\u200b\u591a\u200b\u53d6\u503c\u200b\u7684\u200b\u5c5e\u6027\u200b\u7279\u5f81\u200b\uff0c\u200b\u9632\u6b62\u200b\u5b83\u4eec\u200b\u88ab\u200b\u8fc7\u5ea6\u200b\u5212\u5206\u200b\u3002</p> \\[ SI(X, m) = -\\sum_{v \\in V}\\frac{\\vert X_{m, v} \\vert}{\\vert X \\vert}\\log_2 \\frac{\\vert X_{m, v} \\vert}{\\vert X \\vert} \\] </li> <li> <p>Information Gain Ratio\uff0c\u200b\u4fe1\u606f\u200b\u589e\u76ca\u200b\u7387\u200b</p> \\[ GR(X, m) = \\frac{IG(X, m)}{SI(X, m)} \\] </li> </ol>"},{"location":"AI/Metrics/evaluation_metrics.html#cart","title":"CART\u200b\u7b97\u6cd5","text":"<ol> <li> <p>Gini Index\uff0c\u200b\u57fa\u5c3c\u200b\u6307\u6570\u200b\u7528\u4e8e\u200b\u5ea6\u91cf\u200b\u6570\u636e\u200b\u96c6\u200b\u4e0d\u200b\u7eaf\u5ea6\u200b\uff08Gini Impurity\uff09\uff0c\u200b\u5373\u200b\u8861\u91cf\u200b\u6837\u672c\u200b\u88ab\u200b\u9519\u8bef\u200b\u5206\u7c7b\u200b\u7684\u200b\u6982\u7387\u200b\uff0c\u200b\u53d6\u503c\u200b\u8303\u56f4\u200b\u4e3a\u200b[0, 1]\uff0c\u200b\u6570\u503c\u200b\u8d8a\u5927\u8d8a\u200b\u4e0d\u7eaf\u200b</p> \\[ Gini(X) = 1 - \\sum_{k=1}^{K} p(k)^2 = 1 - \\sum_{k=1}^{K} \\bigg(\\frac{\\vert X^k \\vert}{\\vert X \\vert}\\bigg)^2 \\] </li> <li> <p>Gini Gain\uff0c\u200b\u57fa\u5c3c\u200b\u589e\u76ca\u200b\u7528\u6765\u200b\u9009\u62e9\u200b\u6700\u4f73\u200b\u7684\u200b\u5206\u88c2\u200b\u5c5e\u6027\u200b\uff0c\u200b\u4e3a\u200b\u5c5e\u6027\u200bm\u200b\u5206\u88c2\u200b\u540e\u200b\u7684\u200b\u57fa\u5c3c\u200b\u6307\u6570\u200b\u51cf\u5c11\u200b\u7a0b\u5ea6\u200b\uff0c\u200b\u8be5\u503c\u200b\u8d8a\u5927\u8d8a\u200b\u597d\u200b\uff0c\u200b\u8868\u793a\u200b\u5206\u88c2\u200b\u540e\u200b\u6570\u636e\u200b\u7684\u200b\u4e0d\u200b\u7eaf\u5ea6\u200b\u964d\u4f4e\u200b\u7a0b\u5ea6\u200b\u8d8a\u5927\u200b\u3002</p> \\[ GiniGain(X, m) = Gini(X) - \\sum_{v \\in V} \\frac{\\vert X_{m, v} \\vert}{\\vert X \\vert}Gini(X_{m, v}) \\] <p>\\(m\\) \u200b\u8868\u793a\u200b m-th \u200b\u7279\u5f81\u200b\uff0c\\(V=Set(X_m)\\) \u200b\u8868\u793a\u200b\u6240\u6709\u200b\u6837\u672c\u200b\u96c6\u5408\u200b\u4e2d\u200b m-th \u200b\u7279\u5f81\u200b\u6240\u6709\u200b\u53d6\u503c\u200b\u7ed3\u5408\u200b \\(X_{m, v}\\) \u200b\u8868\u793a\u200b\u6240\u6709\u200b\u6837\u672c\u200b\u4e2d\u200b m-th \u200b\u7279\u5f81\u200b\u7b49\u4e8e\u200bv\u200b\u7684\u200b\u6837\u672c\u200b\u96c6\u5408\u200b \\(X_{m, v}^k\\) \u200b\u8868\u793a\u200b\u6240\u6709\u200b\u6837\u672c\u200b\u4e2d\u200b m-th \u200b\u7279\u5f81\u200b\u7b49\u4e8e\u200bv\u200b\u4e14\u200b\u6837\u672c\u200b\u5c5e\u4e8e\u200b k-th \u200b\u7c7b\u522b\u200b\u7684\u200b\u6837\u672c\u200b\u96c6\u5408\u200b</p> </li> </ol>"},{"location":"AI/Metrics/evaluation_metrics.html#classification","title":"Classification","text":"\u9884\u6d4b\u503c\u200b\\\u200b\u771f\u5b9e\u200b\u503c\u200b \u200b\u6b63\u200b\u6807\u7b7e\u200b \u200b\u8d1f\u200b\u6807\u7b7e\u200b \u200b\u6b63\u200b\u6807\u7b7e\u200b TP FP \u200b\u8d1f\u200b\u6807\u7b7e\u200b FN TN"},{"location":"AI/Metrics/evaluation_metrics.html#prf1accuracy","title":"P\u3001R\u3001F1\u3001Accuracy","text":"PrecisionRecallAccuracyF1-scoreFn-score <p>\u200b\u7cbe\u786e\u200b\u7387\u200b\uff0c\u200b\u9884\u6d4b\u200b\u4e3a\u200b\u6b63\u4f8b\u200b\u6837\u672c\u200b\u4e2d\u200b\u771f\u5b9e\u200b\u6b63\u4f8b\u200b\u7684\u200b\u767e\u5206\u6bd4\u200b</p> \\[ P=\\frac{\\text{TP}}{\\text{TP} + \\text{FP}} \\] <p>\u200b\u53ec\u56de\u200b\u7387\u200b\uff0c\u200b\u771f\u5b9e\u200b\u6b63\u4f8b\u200b\u88ab\u200b\u9884\u6d4b\u200b\u4e3a\u200b\u6b63\u4f8b\u200b\u7684\u200b\u767e\u5206\u6bd4\u200b</p> \\[ R=\\frac{\\text{TP}}{\\text{TP} + \\text{FN}} \\] <p>\u200b\u51c6\u786e\u7387\u200b\uff0c\u200b\u6837\u672c\u200b\u603b\u6570\u200b\u4e2d\u200b\u88ab\u200b\u6b63\u786e\u200b\u9884\u6d4b\u200b\uff08\u200b\u5305\u62ec\u200b\u8d1f\u4f8b\u200b\uff09\u200b\u7684\u200b\u767e\u5206\u6bd4\u200b</p> \\[ Accuracy=\\frac{TP+TN}{TP+TN+FP+FN} \\] \\[ \\begin{aligned} P &amp;= \\frac{\\text{TP}_1 + \\text{TP}_2 + ... + \\text{TP}_k}{\\text{TP}_1 + \\text{TP}_2 + ... + \\text{TP}_k + \\text{FP}_1 + \\text{FP}_2 + ... + \\text{FP}_k} \\\\ R &amp;= \\frac{\\text{TP}_1 + \\text{TP}_2 + ... + \\text{TP}_k}{\\text{TP}_1 + \\text{TP}_2 + ... + \\text{TP}_k + \\text{FN}_1 + \\text{FN}_2 + ... + \\text{FN}_k} \\\\ &amp; \\text{micro-F1} = \\frac{2*P*R}{P+R} \\\\ &amp; \\frac{2}{\\text{micro-F1}} = \\frac{1}{P} + \\frac{1}{R} \\\\ &amp; \\text{macro-F1} = \\frac{\\sum_1^k F1_k}{k} \\end{aligned} \\] <p>Info</p> <ul> <li>\u200b\u591a\u200b(\u200b\u5927\u4e8e\u200b2)\u200b\u5206\u7c7b\u200b\u4e2d\u200b\uff0c\u200b\u5bf9\u4e8e\u200bmicro-average\uff0c\u200b\u7cbe\u786e\u200b\u7387\u200bP\u3001\u200b\u53ec\u56de\u200b\u7387\u200bR\u3001\u200b\u51c6\u786e\u7387\u200bAccuracy\u200b\u548c\u200bF1\u200b\u662f\u200b\u76f8\u7b49\u200b\u7684\u200b  </li> <li>micro\u200b\u66f4\u200b\u5173\u6ce8\u200b\u6574\u4f53\u200b\u6548\u679c\u200b\uff0c\u200b\u9002\u7528\u200b\u4e8e\u200b\u7c7b\u522b\u200b\u76f8\u5bf9\u200b\u5e73\u8861\u200b\u7684\u200b\u60c5\u51b5\u200b\uff1b  </li> <li>macro\u200b\u66f4\u200b\u5173\u6ce8\u200b\u6bcf\u4e2a\u200b\u7c7b\u522b\u200b\u7684\u200b\u6548\u679c\u200b\uff0c\u200b\u9002\u7528\u200b\u4e8e\u200b\u7c7b\u522b\u200b\u4e0d\u200b\u5e73\u8861\u200b\u7684\u200b\u60c5\u51b5\u200b\u6216\u200b\u9700\u8981\u200b\u8bc4\u4f30\u200b\u6bcf\u4e2a\u200b\u7c7b\u522b\u200b\u7684\u200b\u6548\u679c\u200b\u7684\u200b\u60c5\u666f\u200b\uff1b</li> </ul> \\[ \\begin{aligned} \\text{F}n=&amp;\\frac{(n^2+1)*P*R}{n^2*P+R} \\\\     \\frac{1+n^2}{\\text{F}n} =&amp; \\frac{1}{P} + \\frac{n^2}{R}  \\end{aligned} \\] <p>Info</p> <p>\\(n\\) \u200b\u503c\u8d8a\u200b\u5927\u200b\uff0c\\(R\\)\u200b\u7684\u200b\u6743\u91cd\u200b\u8d8a\u9ad8\u200b  </p> <ul> <li>\\(n \\gt 1\\)\uff0c\\(R\\)\u200b\u7684\u200b\u6743\u200b\u91cd\u5927\u200b\u4e8e\u200b\\(P\\)</li> <li>\\(n \\lt 1\\)\uff0c\\(P\\)\u200b\u7684\u200b\u6743\u200b\u91cd\u5927\u200b\u4e8e\u200b\\(R\\)</li> </ul>"},{"location":"AI/Metrics/evaluation_metrics.html#rocauc","title":"ROC\u3001AUC","text":"ROCAUC <p>Receiver Operating Characteristic Curve\uff0c\u200b\u53d7\u8bd5\u8005\u200b\u5de5\u4f5c\u200b\u7279\u5f81\u200b\u66f2\u7ebf\u200b\uff0c\u200b\u8868\u793a\u200b\u6536\u76ca\u200b\u548c\u200b\u6210\u672c\u200b\u4e4b\u95f4\u200b\u7684\u200b\u6743\u8861\u200b\u5173\u7cfb\u200b\uff1a</p> <ul> <li>\u200b\u6210\u672c\u200b\u6a2a\u5750\u6807\u200b\u4e3a\u200b\\(FPR=FP/N=FP/(FP+TN)\\)\uff0c\u200b\u5373\u200b\u771f\u5b9e\u200b\u8d1f\u4f8b\u200b\u4e2d\u200b\u88ab\u200b\u9884\u6d4b\u200b\u4e3a\u200b\u6b63\u4f8b\u200b\u7684\u200b\u6bd4\u4f8b\u200b\uff1b</li> <li>\u200b\u6536\u76ca\u200b\u7eb5\u5750\u6807\u200b\u4e3a\u200b\\(TPR=TP/P=TP/(TP+FN)\\)\uff0c\u200b\u5373\u200b\u771f\u5b9e\u200b\u6b63\u4f8b\u200b\u4e2d\u200b\u88ab\u200b\u9884\u6d4b\u200b\u4e3a\u200b\u6b63\u4f8b\u200b\u7684\u200b\u6bd4\u4f8b\u200b\uff1b</li> </ul> <p>\u200b\u66f2\u7ebf\u200b\u7ed8\u5236\u200b\uff08\u200b\u79bb\u6563\u200b\u7684\u200bplot\u200b\u56fe\u200b\uff09\u200b\u4e0e\u200b\u9762\u79ef\u200b\u8ba1\u7b97\u200b\uff1a</p> <ol> <li>\u200b\u5c06\u200bP+N\u200b\u4e2a\u200b\u6837\u672c\u200b\u7684\u200b\u6309\u200b\u76ee\u6807\u200b\u7c7b\u200b\u9884\u6d4b\u200b\u7f6e\u4fe1\u200b\u503c\u200b\u964d\u5e8f\u200b\u6392\u5217\u200b\uff0c\u200b\u521d\u59cb\u200b\u70b9\u200b\u4f4d\u4e8e\u200b(0, 0)\uff1b</li> <li>\u200b\u904d\u5386\u200b\u6837\u672c\u200b\u5e8f\u5217\u200b\uff0c\u200b\u4ee5\u8be5\u200b\u70b9\u200b\u7f6e\u4fe1\u200b\u503c\u4e3a\u200b\u9608\u503c\u200bt\uff0c\u200b\u8ba1\u7b97\u200btpr\u200b\u548c\u200bfpr\u200b\u5e76\u200b\u63cf\u70b9\u200b\u8fde\u7ebf\u200b\uff08\u200b\u5b9e\u9645\u200b\u53ea\u200b\u63cf\u7ed8\u200b\u8f6c\u5411\u200b\u7684\u200b\u70b9\u200b\uff09\uff1b</li> <li>\u200b\u7ed8\u5236\u200b\u66f2\u7ebf\u200b\u5373\u200b\u4e3a\u200bROC\uff0c\u200b\u66f2\u7ebf\u200b\u4e0e\u200b\u6a2a\u5750\u6807\u8f74\u200b\u56f4\u6210\u200b\u7684\u200b\uff08\u200b\u5206\u6bb5\u200b\u77e9\u5f62\u200b\uff09\u200b\u533a\u57df\u200b\u9762\u79ef\u200b\u4e3a\u200bAUC\uff1b</li> </ol> <ul> <li>\u200b\u7b49\u4ef7\u200b\u4e8e\u200b\u4ece\u200b(0, 0)\u200b\u5f00\u59cb\u200b\uff0c\u200b\u987a\u5e8f\u200b\u904d\u5386\u200b\u9047\u89c1\u200b\u6b63\u4f8b\u200b\u2b06\ufe0f\u200b\u79fb\u52a8\u200b\\(1/P\\)\uff0c\u200b\u9047\u89c1\u200b\u8d1f\u4f8b\u200b\u27a1\ufe0f\u200b\u79fb\u52a8\u200b\\(1/N\\)\uff0c\u200b\u76f4\u81f3\u200b\u79fb\u52a8\u200b\u81f3\u200b(1, 1)\u3002</li> <li>micro-ROC\uff1a\u200b\u5bf9\u4e8e\u200b\\(n\\)\u200b\u4e2a\u200b\u6837\u672c\u200b\uff0c\\(k\\)\u200b\u4e2a\u7c7b\u200b\uff0c\u200b\u5171\u200b\\(n*k\\)\u200b\u4e2a\u200b\u7f6e\u4fe1\u200b\u503c\u200b\u964d\u5e8f\u200b\u6392\u5e8f\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u9608\u503c\u200b\u8ba1\u7b97\u200btpr, fpr</li> <li>macro-ROC\u200b\u7ed8\u5236\u200b<ol> <li>\u200b\u5f97\u5230\u200b\u5404\u7c7b\u200b\u7684\u200b\\((fpr_i, tpr_i)\\)\u200b\u70b9\u96c6\u200b\u5e76\u200b\u5bf9\u200b\u6a2a\u5750\u6807\u200b\u53bb\u200b\u91cd\u200b\u5f97\u5230\u200b\\(fpr\\)\uff1b</li> <li>\u200b\u904d\u5386\u200b\u5404\u7c7b\u200b\u7684\u200b\\((fpr_i, tpr_i)\\)\u200b\u83b7\u5f97\u200b\\(fpr\\)\u200b\u70b9\u96c6\u200b\u5bf9\u5e94\u200b\u7684\u200b\\(tpr\\)\u200b\u5747\u503c\u200b\uff08\u200b\u5404\u7c7b\u200b[a, b)\u200b\u8303\u56f4\u200b\u5185\u200b\u7684\u200b\\(tpr_i\\)\u200b\u4e3a\u200b\\(frp_a\\)\u200b\u5bf9\u5e94\u200b\u7684\u200b\\(tpr_i\\)\uff09</li> <li>\u200b\u83b7\u5f97\u200b\\((frp, tpr)\\)\u200b\u540e\u200b\u5373\u53ef\u200b\u8fdb\u884c\u200bROC\u200b\u66f2\u7ebf\u200b\u7ed8\u5236\u200b</li> </ol> </li> <li>micro-ROC\u200b\u66f4\u200b\u6ce8\u91cd\u200b\u6574\u4f53\u200b\u5206\u7c7b\u200b\u6548\u679c\u200b\uff1b</li> <li>macro-ROC\u200b\u5728\u200b\u5904\u7406\u200b\u4e0d\u200b\u5e73\u8861\u200b\u6570\u636e\u200b\u96c6\u65f6\u200b\uff0c\u200b\u66f4\u80fd\u200b\u53cd\u5e94\u200b\u5c11\u6570\u200b\u7c7b\u522b\u200b\u7684\u200b\u5206\u7c7b\u200b\u6027\u80fd\u200b\uff08micro\u200b\u5728\u200b\u6392\u5e8f\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u7a00\u91ca\u200b\u4e86\u200b\u5c11\u6570\u200b\u6837\u672c\u200b\u7c7b\u200b\uff09\uff1b</li> </ul> <p>Area Under Curve\uff0c\u200b\u66f2\u7ebf\u200b\u4e0b\u200b\u9762\u79ef\u200b\uff0c\u200b\u5373\u200bROC\u200b\u66f2\u7ebf\u200b\u4e0e\u200b\u5750\u6807\u8f74\u200b\u56f4\u6210\u200b\u7684\u200b\u9762\u79ef\u200b\uff0c\u200b\u53d6\u503c\u200b\u8303\u56f4\u200b\u5904\u4e8e\u200b[0, 1]\uff0c\u200b\u503c\u8d8a\u200b\u5927\u200b\u8868\u793a\u200b\u8868\u793a\u200b\u6548\u679c\u200b\u8d8a\u200b\u597d\u200b\u3002</p> <pre><code>from sklearn.metrics import roc_curve, auc\n# label_i: ROC + AUC\nfpr[i], tpr[i], thresholds = roc_curve(y[:, i], y_score[:, i])  # thresholds\u200b\u4e3a\u200b\u964d\u5e8f\u200b\u6392\u5217\u200b\u7684\u200b\n                                                                # \u200b\u8f6c\u6298\u70b9\u200b\uff08\u200b\u4e0e\u200b\u4e0a\u200b\u4e00\u200b\u72b6\u6001\u200b\u76f8\u6bd4\u200b\u53d8\u200b\u5411\u200b\uff09\u200b\u9608\u503c\u200b\nroc_auc[i] = auc(fpr[i], tpr[i])\n\n# micro-ROC + AUC\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y.flatten(), y_score.flatten())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n# macro-ROC + AUC\nfpr[\"macro\"] = np.unique(np.concatenate([fpr[i] for i in range(n_classes)])) # np.unique\u200b\u5347\u5e8f\u200b\u8fd4\u56de\u200b\u7ed3\u679c\u200b\n''' \n    \u200b\u83b7\u53d6\u200b `fpr[\"macro\"]` \u200b\u5bf9\u5e94\u200b\u7684\u200b `tpr[\"macro\"]=mean_tpr` \n    - \u200b\u5404\u7c7b\u200b[a, b)\u200b\u8303\u56f4\u200b\u5185\u200b\u7684\u200b`tpr_i`\u200b\u4e3a\u200b\u5de6\u200b\u8fb9\u754c\u200b`frp_a`\u200b\u5bf9\u5e94\u200b\u7684\u200b`tpr_i``\n'''\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n</code></pre>"},{"location":"AI/Metrics/evaluation_metrics.html#generation","title":"Generation","text":"<p>\\(S\\)\u200b\u8868\u793a\u200b\u53e5\u5b50\u200b\u5e8f\u5217\u200b\uff0c\\(W\\)\u200b\u8868\u793a\u200b\u8bcd\u200b\u6216\u200btoken</p>"},{"location":"AI/Metrics/evaluation_metrics.html#ppl","title":"PPL","text":"<p>Perplexity\uff0c\u200b\u6307\u200b\u6a21\u578b\u200b\u5728\u200b\u751f\u6210\u200b\u4e00\u6bb5\u200b\u5185\u5bb9\u200b\u65f6\u200b\u7684\u200b\u56f0\u60d1\u200b\u7a0b\u5ea6\u200b\uff0c\u200b\u503c\u8d8a\u200b\u9ad8\u200b\uff0c\u200b\u6a21\u578b\u200b\u56f0\u60d1\u200b\u5ea6\u8d8a\u200b\u5927\u200b\uff0c\u200b\u53cd\u4e4b\u200b\u8d8a\u5c0f\u8d8a\u200b\u81ea\u4fe1\u200b\u3002</p> \\[ \\begin{aligned} PPL &amp;= \\frac{1}{p_{\\theta}(w_1w_2...w_n)^n} = \\sqrt[-n]{p_{\\theta}(w_1w_2...w_n)} \\\\ &amp;=\\sqrt[-n]{\\prod_{t=1}^np_{\\theta}(w_t|w_{\\lt t})} \\\\ \\log{PPL} &amp;= -\\frac{\\sum_{i=t}^n\\log{p_{\\theta}(w_t|w_{\\lt t})}}{n} \\\\ PPL &amp;= \\exp\\Bigg(-\\frac{\\sum_{i=t}^n\\log{p_{\\theta}(w_t|w_{\\lt t})}}{n}\\Bigg)  \\end{aligned} \\] <p>\u200b\u5728\u200b\u751f\u6210\u200b\u6a21\u578b\u200b\u4e2d\u200b\uff0c<code>ppl = nll.exp()</code>\uff0c\u200b\u5373\u200b\u3010\u200b\u8d1f\u200b\u5bf9\u6570\u200b\u4f3c\u7136\u200b\u548c\u200b\u7684\u200b\u5747\u503c\u200b\u3011\u200b\u4f5c\u4e3a\u200b\u6307\u6570\u200b</p>"},{"location":"AI/Metrics/evaluation_metrics.html#question-answering","title":"Question Answering","text":""},{"location":"AI/Metrics/evaluation_metrics.html#extract-match","title":"Extract Match","text":"\\[ EM=\\begin{cases} 1, &amp; \\text{if}\\ S_{pred}\\ =\\ S_{ref} \\\\ 0, &amp; \\text{if}\\ S_{pred}\\ \\neq \\ S_{ref} \\\\ \\end{cases} \\]"},{"location":"AI/Metrics/evaluation_metrics.html#maxmatch-score","title":"MaxMatch Score","text":"<p>\u200b\u4e5f\u200b\u79f0\u4f5c\u200b \\(M^2\\) score\uff0c\u200b\u901a\u8fc7\u200b\u6bd4\u8f83\u200b\u7cfb\u7edf\u200b\u8f93\u51fa\u200b\u548c\u200b\u53c2\u8003\u7b54\u6848\u200b\u76f8\u5bf9\u200b\u4e8e\u6e90\u200b\u53e5\u5b50\u200b\u7684\u200b\u6700\u5c0f\u200b\u7f16\u8f91\u200b\u5e8f\u5217\u200b\uff0c\u200b\u5e76\u200b\u8ba1\u7b97\u200b\u76f8\u5e94\u200b\u7684\u200b F1 \u200b\u503c\u200b\uff0c\u200b\u6765\u200b\u7efc\u5408\u200b\u8bc4\u4ef7\u200bGEC\u200b\u7cfb\u7edf\u200b\u7684\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u3002\u200b\u5176\u200b\u6838\u5fc3\u200b\u4f18\u52bf\u200b\u5728\u4e8e\u200b\u57fa\u4e8e\u200b\u7f16\u8f91\u200b\u7684\u200b\u5bf9\u9f50\u200b\u4e0e\u200b\u5339\u914d\u200b\u7684\u200b\u8bc4\u4f30\u200b\u601d\u60f3\u200b\uff0c\u200b\u6bd4\u200b\u7cbe\u786e\u200b\u5339\u914d\u200b\u66f4\u200b\u5408\u7406\u200b\uff0c\u200b\u6bd4\u200b\u5355\u7eaf\u200b\u7684\u200b\u7f16\u8f91\u200b\u8ddd\u79bb\u200b\u66f4\u200b\u6709\u200b\u89e3\u91ca\u6027\u200b\u3002</p> <ol> <li>\u200b\u7f16\u8f91\u200b\u683c\u5f0f\u200b \u200b\u4e3a\u200b<code>(start, end, cat, cor)</code>\uff0c\u200b\u533a\u95f4\u200b\u4e3a\u200b<code>[start, end)</code>\uff0c\u200b\u5f53\u200b<code>start=end</code>\u200b\u65f6\u200b\uff0c\u200b\u8868\u793a\u200b\u63d2\u5165\u200b\u64cd\u4f5c\u200b</li> <li>\u200b\u6700\u4f18\u200b\u7f16\u8f91\u200b\u8ddd\u79bb\u200b\u96c6\u5408\u200b \u200b\u901a\u8fc7\u200b\u52a8\u6001\u200b\u89c4\u5212\u200b\u7b97\u6cd5\u200b\u5b9e\u73b0\u200b\u5c06\u6e90\u200b\u5e8f\u5217\u200bS\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u76ee\u6807\u200b\u5e8f\u5217\u200bT\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u6700\u4f18\u200b\u7f16\u8f91\u200b\u96c6\u5408\u200b\uff08\u200b\u53c2\u8003\u200b\u7ea0\u6b63\u200b\u7f16\u8f91\u200b\u96c6\u5408\u200b\u4e3a\u200b\\(G\\)\uff0c\u200b\u7cfb\u7edf\u200b\u8f93\u51fa\u200b\u7f16\u8f91\u200b\u96c6\u5408\u200b\u4e3a\u200b\\(H\\)\uff09\uff0c\u200b\u8981\u6c42\u200b\u6ee1\u8db3\u200b<ul> <li>\u200b\u6700\u5c0f\u5316\u200b\uff08Minimality\uff09\uff0c\u200b\u7f16\u8f91\u200b\u64cd\u4f5c\u200b\u5c3d\u53ef\u80fd\u5c11\u200b</li> <li>\u200b\u4e0d\u200b\u76f8\u4ea4\u200b\uff08Disjoint\uff09\uff0c\u200b\u540c\u4e00\u200b\u5e8f\u5217\u200b\u7684\u200b\u6240\u6709\u200b\u7f16\u8f91\u200b\u533a\u95f4\u200b\u4e0d\u200b\u76f8\u4ea4\u200b</li> </ul> </li> <li>\u200b\u57fa\u4e8e\u200b\u7f16\u8f91\u200b\u7684\u200b\u5bf9\u9f50\u200b\u4e0e\u200b\u5339\u914d\u200b \u200b\u5f53\u4e14\u200b\u4ec5\u200b\u5f53\u200b\u4e0b\u5217\u200b\u6761\u4ef6\u200b\u5747\u200b\u5339\u914d\u200b\u65f6\u200b\uff0c<code>g_i</code>\u200b\u548c\u200b<code>h_j</code>\u200b\u5339\u914d\u200b\uff0c\u200b\u56e0\u6b64\u200b\\(TP=\\vert G \\cap H \\vert\\)\uff09<ul> <li><code>g_i.start == h_j.start</code></li> <li><code>g_i.end == h_j.end</code></li> <li><code>g_i.cor == h_j.cor</code></li> </ul> </li> </ol> <p>\u200b\u6709\u200b\u591a\u6761\u200b\u53c2\u8003\u200b\u7ea0\u6b63\u200b\u65f6\u200b\uff0c\u200b\u9009\u62e9\u200b\u5206\u6570\u200b\u6700\u9ad8\u200b\u7684\u200b\u4f5c\u4e3a\u200b\u6700\u4f73\u200b\u5339\u914d\u200b\u53c2\u8003\u200b</p> MaxMatch Score Code <pre><code>def get_edits(source, target):\n    \"\"\"\n    \u200b\u4f7f\u7528\u200b\u52a8\u6001\u200b\u89c4\u5212\u200b\u8ba1\u7b97\u200b\u5c06\u200bsource\u200b\u8f6c\u6362\u200b\u4e3a\u200btarget\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u6700\u5c0f\u200b\u7f16\u8f91\u200b\u5e8f\u5217\u200b\u3002\n    \u200b\u8fd9\u662f\u200b\u4e00\u4e2a\u200b\u7b80\u5316\u200b\u5b9e\u73b0\u200b\uff0c\u200b\u8fd4\u56de\u200b\u7f16\u8f91\u200b\u5217\u8868\u200b[(start, end, cor)]\u3002\n    \"\"\"\n    n, m = len(source), len(target)\n    # dp[i][j] \u200b\u8868\u793a\u200bsource\u200b\u524d\u200bi\u200b\u4e2a\u200b\u8bcd\u5230\u200btarget\u200b\u524d\u200bj\u200b\u4e2a\u200b\u8bcd\u200b\u7684\u200b\u6700\u5c0f\u200b\u7f16\u8f91\u200b\u8ddd\u79bb\u200b\n    dp = [[0] * (m + 1) for _ in range(n + 1)]\n\n    # \u200b\u521d\u59cb\u5316\u200b\u8fb9\u754c\u6761\u4ef6\u200b\n    for i in range(n + 1):\n        dp[i][0] = i  # \u200b\u5220\u9664\u200b\u6240\u6709\u200bsource\u200b\u8bcd\u200b\n    for j in range(m + 1):\n        dp[0][j] = j  # \u200b\u63d2\u5165\u200b\u6240\u6709\u200btarget\u200b\u8bcd\u200b\n\n    # \u200b\u586b\u5145\u200bdp\u200b\u8868\u200b\n    for i in range(1, n + 1):\n        for j in range(1, m + 1):\n            if source[i - 1] == target[j - 1]:\n                dp[i][j] = dp[i - 1][j - 1]  # \u200b\u8bcd\u200b\u5339\u914d\u200b\uff0c\u200b\u65e0\u9700\u200b\u7f16\u8f91\u200b\n            else:\n                dp[i][j] = min(dp[i - 1][j] + 1,  # \u200b\u5220\u9664\u200bsource[i-1]\n                            dp[i][j - 1] + 1,  # \u200b\u63d2\u5165\u200btarget[j-1]\n                            dp[i - 1][j - 1] + 1)  # \u200b\u66ff\u6362\u200b\n\n    # \u200b\u56de\u6eaf\u200b\u63d0\u53d6\u200b\u7f16\u8f91\u200b\u5e8f\u5217\u200b\n    edits = []\n    i, j = n, m\n    while i &gt; 0 or j &gt; 0:\n        if i &gt; 0 and j &gt; 0 and source[i - 1] == target[j - 1]:\n            i -= 1\n            j -= 1  # \u200b\u5339\u914d\u200b\uff0c\u200b\u5411\u524d\u200b\u79fb\u52a8\u200b\n        else:\n            if j &gt; 0 and (i == 0 or dp[i][j - 1] + 1 == dp[i][j]):\n                # \u200b\u63d2\u5165\u200b\u64cd\u4f5c\u200b: \u200b\u5728\u200b\u4f4d\u7f6e\u200bi\u200b\u63d2\u5165\u200btarget[j-1]\n                edits.append((i, i, target[j - 1]))\n                j -= 1\n            elif i &gt; 0 and (j == 0 or dp[i - 1][j] + 1 == dp[i][j]):\n                # \u200b\u5220\u9664\u200b\u64cd\u4f5c\u200b: \u200b\u5220\u9664\u200b\u4f4d\u7f6e\u200bi-1\u200b\u7684\u200b\u8bcd\u200b\n                edits.append((i - 1, i, ''))\n                i -= 1\n            else:\n                # \u200b\u66ff\u6362\u200b\u64cd\u4f5c\u200b: \u200b\u5c06\u200bsource[i-1]\u200b\u66ff\u6362\u200b\u4e3a\u200btarget[j-1]\n                edits.append((i - 1, i, target[j - 1]))\n                i -= 1\n                j -= 1\n\n    # \u200b\u53cd\u8f6c\u200b\u7f16\u8f91\u200b\u5e8f\u5217\u200b\u5e76\u200b\u6309\u200b\u8d77\u59cb\u200b\u4f4d\u7f6e\u200b\u6392\u5e8f\u200b\n    edits.reverse()\n    return edits\n\n\ndef edits_match(edit1, edit2):\n    \"\"\"\u200b\u68c0\u67e5\u200b\u4e24\u4e2a\u200b\u7f16\u8f91\u200b\u662f\u5426\u200b\u5339\u914d\u200b\uff08\u200b\u8fb9\u754c\u200b\u548c\u200b\u5185\u5bb9\u200b\u90fd\u200b\u76f8\u540c\u200b\uff09\"\"\"\n    start1, end1, cor1 = edit1\n    start2, end2, cor2 = edit2\n    return start1 == start2 and end1 == end2 and cor1 == cor2\n\n\ndef calculate_m2(source, gold, hypothesis):\n    \"\"\"\n    \u200b\u8ba1\u7b97\u200bM\u00b2 Score (Precision, Recall, F1)\n    \u200b\u53c2\u6570\u200b:\n        source: \u200b\u6e90\u200b\u53e5\u5b50\u200b\uff08\u200b\u5206\u8bcd\u200b\u5217\u8868\u200b\uff09\uff0c\u200b\u5982\u200b ['I', 'have', 'a', 'apple', '.']\n        gold: \u200b\u53c2\u8003\u200b\u4fee\u6b63\u200b\uff08\u200b\u5206\u8bcd\u200b\u5217\u8868\u200b\uff09\n        hypothesis: \u200b\u7cfb\u7edf\u200b\u8f93\u51fa\u200b\uff08\u200b\u5206\u8bcd\u200b\u5217\u8868\u200b\uff09\n    \u200b\u8fd4\u56de\u200b:\n        precision, recall, f1\n    \"\"\"\n    # 1. \u200b\u63d0\u53d6\u200b\u7f16\u8f91\u200b\u96c6\u5408\u200b\n    gold_edits = get_edits(source, gold)\n    hyp_edits = get_edits(source, hypothesis)\n\n    # 2. \u200b\u8ba1\u7b97\u200b\u5339\u914d\u200b\u60c5\u51b5\u200b\n    tp = 0  # True Positive\n    fp = 0  # False Positive\n    fn = 0  # False Negative\n\n    # \u200b\u68c0\u67e5\u200b\u7cfb\u7edf\u200b\u7f16\u8f91\u200b\u662f\u5426\u200b\u4e0e\u200b\u4efb\u4f55\u200b\u53c2\u8003\u200b\u7f16\u8f91\u200b\u5339\u914d\u200b\n    matched_gold_indices = set()\n\n    # |H \u2229 G| = TP, |H| - TP = FP\n    for h_edit in hyp_edits:\n        found_match = False\n        for g_idx, g_edit in enumerate(gold_edits):\n            if edits_match(h_edit, g_edit):\n                tp += 1\n                matched_gold_indices.add(g_idx)\n                found_match = True\n                break\n        if not found_match:\n            fp += 1\n\n    # \u200b\u672a\u200b\u5339\u914d\u200b\u7684\u200b\u53c2\u8003\u200b\u7f16\u8f91\u200b\u5c31\u662f\u200bFN\n    fn = len(gold_edits) - len(matched_gold_indices)\n\n    # 3. \u200b\u8ba1\u7b97\u200b\u6307\u6807\u200b\n    precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0.0\n    recall = tp / (tp + fn) if (tp + fn) &gt; 0 else 0.0\n    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) &gt; 0 else 0.0\n\n    return precision, recall, f1\n\nif __name__ == \"__main__\":\n    # \u200b\u5e94\u200b\u8003\u8651\u200b\u5206\u8bcd\u200b\u65b9\u5f0f\u200b\uff0c{token-level, char-level, ...}\n    source = ['I', 'have', 'a', 'apple', '.']\n    gold = ['They', 'have', 'an', 'apple', '.']\n    hypothesis = ['I', 'have', 'a', 'red', 'apple', '.']\n\n    # \u200b\u5bf9\u4e8e\u200b\u591a\u4e2a\u200b\u7ea0\u6b63\u200b\u5019\u9009\u200b\uff0c\u200b\u53ef\u901a\u200b\u67e5\u770b\u200b`m2scorer-master.scripts.maxmatch_gold_pick`\u200b\u6587\u4ef6\u200b\n    p, r, f1 = calculate_m2(source, gold, hypothesis)\n    print(f\"Precision: {p:.4f}\")\n    print(f\"Recall: {r:.4f}\")\n    print(f\"M\u00b2 F1 Score: {f1:.4f}\")\n\n    # \u200b\u6253\u5370\u200b\u7f16\u8f91\u200b\u7ec6\u8282\u200b\u4ee5\u4fbf\u200b\u7406\u89e3\u200b\n    print(f\"\\n\u200b\u53c2\u8003\u200b\u7f16\u8f91\u200b: {get_edits(source, gold)}\")\n    print(f\"\u200b\u7cfb\u7edf\u200b\u7f16\u8f91\u200b: {get_edits(source, hypothesis)}\")\n</code></pre>"},{"location":"AI/Metrics/evaluation_metrics.html#f1","title":"F1","text":"\\[ \\begin{aligned} W_{match} &amp;= W_{pred}\\cap W_{ref} \\\\ P &amp;= \\frac{|W_{match}|}{|W_{pred}|} \\\\ R &amp;= \\frac{|W_{match}|}{|W_{ref}|} \\\\ F1 &amp;= \\frac{2*P*R}{P+R} \\end{aligned} \\] <p>\\(W_{match}\\)\u200b\u53d6\u200b\u7684\u200b\u662f\u200b<code>Counter(pred_tokens) &amp; Counter(ref_tokens)</code> \u200b\u7684\u200b\u5c31\u200b\u4f4e\u200btoken\u200b\u4ea4\u96c6\u200b</p>"},{"location":"AI/Metrics/evaluation_metrics.html#translation-summary","title":"Translation &amp; Summary","text":""},{"location":"AI/Metrics/evaluation_metrics.html#bleu","title":"BLEU","text":"<p>Bilingual Evaluation Understudy\uff0c\u200b\u662f\u200b\u7528\u4e8e\u200b\u8bc4\u4f30\u200b\u81ea\u7136\u8bed\u8a00\u200b\u7684\u200b\u5b57\u53e5\u200b\u7528\u200b\u673a\u5668\u7ffb\u8bd1\u200b\u51fa\u6765\u200b\u7684\u200b\u54c1\u8d28\u200b\uff08\u200b\u7cbe\u5ea6\u200b\uff09\u200b\u7684\u200b\u4e00\u79cd\u200b\u6307\u6807\u200b\u3002</p> BLEU+ clip+ N-gram+ BP \\[ BLEU = \\frac{\\sum_{token \\in C, S} Counter(token)}{len(C)} \\] <p>\u200b\u65e0\u200b\u6b21\u6570\u200b\u5c31\u200b\u4f4e\u200b\u7ea6\u675f\u200b\uff0c<code>C=\"the the the\", S=\"the dog\"</code>\u200b\u7ed3\u679c\u200b\u4e3a\u200b<code>3/3=1</code></p> \\[ BLEU = \\frac{\\sum_{token \\in C, S} Counter_{match}(token)}{len(C)} \\] <p>\u200b\u589e\u52a0\u200b\u5c31\u200b\u4f4e\u200b\u7ea6\u675f\u200b\uff0c<code>C=\"the the the\", S=\"the dog\"</code>\u200b\u7ed3\u679c\u200b\u4e3a\u200b<code>1/3=0.33</code></p> \\[ \\begin{aligned} BLEU_N &amp;= \\frac{\\sum_{gram_N \\in C, S} Counter_{match}(gram_N)}{\\sum_{gram_N \\in C}Counter(gram_N)} \\\\ BLEU &amp;= \\sum_{n=1}^N w_n\\log BLEU_n \\end{aligned} \\] <p>brevity penalty\uff0c\u200b\u589e\u52a0\u200b\u7b80\u6d01\u6027\u200b\u7ea6\u675f\u200b\uff0c\u200b\u60e9\u7f5a\u200b\u8bad\u7ec3\u200b\u7ed3\u679c\u200b\u503e\u5411\u200b\u77ed\u53e5\u200b\u7684\u200b\u73b0\u8c61\u200b\uff08\u200b\u7f29\u5c0f\u200b\u77ed\u53e5\u200b\u7684\u200bBLEU\u200b\u503c\u200b\uff09\u3002</p> \\[ \\begin{aligned} BP&amp;=\\begin{cases} 1, &amp; \\text{if}\\ c \\gt r \\\\ e^{1-r/c}, &amp; \\text{if}\\ c \\le r \\\\ \\end{cases} \\\\ BLEU &amp;= BP*\\exp\\Bigg(\\sum_{n=1}^N w_n\\log BLEU_n\\Bigg) \\\\ \\log BLEU &amp;= 1-\\frac{r}{c} + \\sum_{n=1}^N w_n\\log BLEU_n \\end{aligned} \\] <ul> <li>\\(w_n\\)\u200b\u4e3a\u200b\u6743\u91cd\u200b\uff0c\u200b\u4e00\u822c\u200b\u4e3a\u200b\u5747\u5300\u200b\u52a0\u6743\u200b\uff0c\u200b\u5373\u200b\\(w_n=\\frac{1}{N}\\)\uff0c\\(N\\)\u200b\u7684\u200b\u4e0a\u9650\u200b\u53d6\u503c\u200b\u4e3a\u200b4\u3002</li> <li>\u200b\u591a\u4e2a\u200b\u53e5\u5b50\u200b\u7684\u200bBLEU\u200b\u8ba1\u7b97\u200b\u65f6\u200b\u7b80\u5355\u200b\u5730\u200b\u901a\u8fc7\u200b\u7d2f\u52a0\u200b\u64cd\u4f5c\u200b\u589e\u52a0\u200b\u76f8\u5e94\u200b\u7684\u200b\u5206\u5b50\u200b\u5206\u6bcd\u200b</li> </ul>"},{"location":"AI/Metrics/evaluation_metrics.html#rouge","title":"ROUGE","text":"<p>Recall-Oriented Understudy for Gisting Evaluation\uff0c\u200b\u662f\u200b\u8bc4\u4f30\u200b\u6458\u8981\u200b\u603b\u7ed3\u200b\u4ee5\u53ca\u200b\u673a\u5668\u7ffb\u8bd1\u200b\u6548\u679c\u200b\uff08\u200b\u53ec\u56de\u200b\uff09\u200b\u7684\u200b\u4e00\u7ec4\u200b\u6307\u6807\u200b</p> ROUGE-NROUGE-LROUGE-WROUGE-S \\[ \\text{RG-N} = \\frac{\\sum_{S\\in Refer} \\sum_{gram_N\\in S} Counter_{match}(gram_N)}{\\sum_{S\\in Refer} \\sum_{gram_N\\in S} Counter(gram_N)} \\] \\[ \\begin{aligned} P_{lcs} &amp;= \\frac{LCS(C, S)}{len(C)} \\\\ R_{lcs} &amp;= \\frac{LCS(C, S)}{len(S)}\\\\ \\text{RG-L} &amp;= F_{lcs} = \\frac{(1+\\beta^2)P_{lcs}R_{lcs}}{\\beta^2 P_{lcs} + R_{lcs}} \\end{aligned} \\] <p>sss https://blog.csdn.net/BIT_666/article/details/132347794</p> <p>sss</p> <ul> <li>ROUGE\u200b\u53d6\u503c\u200b\u8303\u56f4\u200b\u4e3a\u200b[0, 1]\uff1b</li> <li>\\(Refer\\)\u200b\u4e3a\u200b\u53c2\u8003\u200b\u6587\u672c\u200b\u5e8f\u5217\u200b\u96c6\u5408\u200b\uff1b</li> <li>N\u200b\u8868\u793a\u200bN-gram\uff0c\u200b\u4e00\u822c\u200b\u53d6\u503c\u200b\u4e3a\u200b1\uff0c2\uff0c3\uff0c\\(Counter_{match}\\)\u200b\u4e3a\u200b\u5c31\u200b\u4f4e\u200b\u64cd\u4f5c\u200b\uff1b</li> <li>\\(C\\)\u200b\u8868\u793a\u200b\u751f\u6210\u200b\u6587\u672c\u200b\u5e8f\u5217\u200b\uff0c\\(S\\)\u200b\u4e3a\u200b\u53c2\u8003\u200b\u6587\u672c\u200b\u5e8f\u5217\u200b\uff0c\\(len()\\)\u200b\u8fd4\u56de\u200b\u5e8f\u5217\u200btoken\u200b\u6570\u200b\uff1b</li> <li>L\u200b\u8868\u793a\u200b\u6700\u957f\u200b\u516c\u5171\u200b\u5b50\u200b\u5e8f\u5217\u200bLongest common subsequence\uff08\u200b\u6ce8\u610f\u200b\u4e0d\u662f\u200b\u6700\u957f\u200b\u8fde\u7eed\u200b\u516c\u5171\u200b\u5b50\u200b\u5e8f\u5217\u200b\uff09\uff1b</li> </ul>"},{"location":"AI/Metrics/evaluation_metrics.html#llm-throughput","title":"LLM Throughput","text":""},{"location":"AI/Metrics/evaluation_metrics.html#generation-throughput","title":"Generation Throughput","text":"\\[ \\text{Generation Throghtput} = \\frac{\\text{Total Generated Tokens}}{\\text{Total Time}} \\]"},{"location":"AI/Metrics/evaluation_metrics.html#prompt-input-throughput","title":"Prompt Input Throughput","text":"\\[ \\text{Prompt Input Throghtput} = \\frac{\\text{Total Input Tokens}}{\\text{Total Time}} \\]"},{"location":"AI/Metrics/evaluation_metrics.html#search-recommendation","title":"Search Recommendation","text":""},{"location":"AI/Metrics/evaluation_metrics.html#map","title":"MAP","text":"<p>Mean Average Precision\u200b\u5e73\u5747\u200b\u5e73\u5747\u200b\u7cbe\u5ea6\u200b\uff0c\u200b\u7528\u4e8e\u200b\u8861\u91cf\u200b\u6a21\u578b\u200b\u5728\u200b\u6240\u6709\u200b\u67e5\u8be2\u200b\uff08\u200b\u6216\u200b\u7528\u6237\u200b\u8bf7\u6c42\u200b\uff09\u200b\u68c0\u7d22\u200b\u5230\u200b\u6392\u540d\u200b\u9760\u200b\u524d\u200b\u7684\u200b\u76f8\u5173\u200b\u6587\u6863\u200b\u7684\u200b\u7cbe\u5ea6\u200b\u3002</p> <ol> <li> <p>Agerage Precision (AP)\uff0c\u200b\u5bf9\u200b\u5355\u4e2a\u200b\u67e5\u8be2\u200b\uff0c\u200b\u4f9d\u6b21\u200b\u8ba1\u7b97\u200b\u5404\u200b\u771f\u5b9e\u200b\u76f8\u5173\u200b\u6587\u6863\u200b\u5728\u200b\u68c0\u7d22\u200b\u6587\u6863\u200b\u6392\u540d\u200b\u5904\u53ca\u200b\u4e4b\u524d\u200b\u6392\u540d\u200b\u7ed3\u679c\u200b\u4e2d\u200b\u7684\u200b\u5e73\u5747\u200b\u7cbe\u5ea6\u200b</p> <pre><code>R_q = {d_2, d_4}    # R_q \u200b\u8868\u793a\u200b\u67e5\u8be2\u200b q \u200b\u5bf9\u5e94\u200b\u7684\u200b\u771f\u5b9e\u200b\u76f8\u5173\u200b\u6587\u6863\u200b\u96c6\u5408\u200b\nrank = [d_2, d_3, d_4, d_1, d_7]\nP(\u2265r(d_2)) = 1/1    # \u200b\u524d\u200b1\u200b\u6709\u200bd_2\u200b\u662f\u200bTP\nP(\u2265r(d_4)) = 2/3    # \u200b\u524d\u200b3\u200b\u6709\u200bd_2\u200b\u548c\u200bd_4\u200b\u662f\u200bTP\nAP(q) = (1/1 + 2/3)/2 \u2248 0.835\n</code></pre> \\[ AP(q) = \\frac{1}{\\vert R_q \\vert} \\sum_{d \\in R_q} P\\big(\\ge r(d)\\big) \\] </li> <li> <p>Mean AP\uff0c\u200b\u5bf9\u200b\u6240\u6709\u200b\u67e5\u8be2\u200b\u7684\u200bAP\u200b\u503c\u53d6\u200b\u5e73\u5747\u200b</p> \\[ MAP = \\frac{1}{\\vert Q\\vert} \\sum_{q\\in Q} AP(q) \\] </li> </ol>"},{"location":"AI/Metrics/evaluation_metrics.html#mrr","title":"MRR","text":"<p>\u200b\u5e73\u5747\u200b\u5012\u6570\u200b\u6392\u540d\u200bMean Reciprocal Rank\uff0c\u200b\u65e8\u5728\u200b\u8861\u91cf\u200b\u6392\u5e8f\u200b\u7ed3\u679c\u200b\u7684\u200b\u8d28\u91cf\u200b\uff0c\u200b\u662f\u200b\u6307\u200b\u591a\u4e2a\u200b\u67e5\u8be2\u200b\u8bed\u53e5\u200b\u7684\u200b\u7b2c\u4e00\u4e2a\u200b\u6b63\u786e\u200b\u7ed3\u679c\u200b\u6392\u540d\u200b\u7684\u200b\u5012\u6570\u200b\u5747\u503c\u200b</p> <ol> <li> <p>MRR</p> \\[ MRR = \\frac{1}{|Q|}\\sum_{i=1}^{|Q|}\\frac{1}{r_i} \\] <p>\\(r_i\\) \u200b\u8868\u793a\u200b\\(i\\text{-}th\\) \u200b\u67e5\u8be2\u200b\u5bf9\u5e94\u200b\u7684\u200b\u7b2c\u4e00\u4e2a\u200b\u6b63\u786e\u200b\u7b54\u6848\u200b\u6392\u540d\u200b\u540d\u6b21\u200b\uff1b \\(Q\\) \u200b\u8868\u793a\u200b\u53c2\u4e0e\u200b\u6d4b\u8bd5\u200b\u7684\u200b\u67e5\u8be2\u200b\u96c6\u200b</p> </li> <li> <p>MRR@K\uff0c\u200b\u548c\u200bMRR\u200b\u7c7b\u4f3c\u200b\uff0c\u200b\u4f46\u662f\u200b\u53ea\u6709\u200b\u5728\u200b\u6392\u540d\u200b\u524d\u200bK\u200b\u4e2a\u200b\u65f6\u200b\u624d\u200b\u6709\u200b\u5206\u6570\u200b\uff0c\u200b\u5426\u5219\u200b\u4e3a\u200b0</p> </li> </ol>"},{"location":"AI/Metrics/evaluation_metrics.html#hr","title":"HR","text":"<p>\u200b\u547d\u4e2d\u7387\u200bHit Ratio\uff0c\u200b\u662f\u200b\u8861\u91cf\u200b\u63a8\u8350\u200b\u7cfb\u7edf\u200b\u51c6\u786e\u6027\u200b\u7684\u200b\u4e00\u4e2a\u200b\u6307\u6807\u200b\uff0c\u200b\u8868\u793a\u200b\u63a8\u8350\u200b\u5217\u8868\u200b\u4e2d\u200b\u7528\u6237\u200b\u5b9e\u9645\u200b\u611f\u5174\u8da3\u200b\uff08\u200b\u5982\u200b\u70b9\u51fb\u200b\u6216\u200b\u8d2d\u4e70\u200b\u7b49\u200b\uff09\u200b\u7684\u200b\u9879\u76ee\u200b\u6240\u200b\u5360\u200b\u6bd4\u4f8b\u200b\u3002\\(HR@k\\)\u200b\u8ba1\u7b97\u200b\u65b9\u5f0f\u200b\u5982\u4e0b\u200b\uff1a</p> \\[ HR@k = \\frac{\\sum_{u \\in U} \\mathbb{I}(\\text{user }u\\text{ has a hit in top-k})}{\\vert U\\vert} \\] <p>\\(U\\) \u200b\u8868\u793a\u200b\u7528\u6237\u200b\u96c6\u200b</p>"},{"location":"AI/Metrics/evaluation_metrics.html#ndcg","title":"NDCG","text":"<p>\u200b\u5f52\u4e00\u5316\u200b\u6298\u6263\u200b\u7d2f\u79ef\u200b\u6536\u76ca\u200bNormalized Discounted Cumulative Gain\uff0c\u200b\u65e8\u5728\u200b\u8861\u91cf\u200b\u6392\u5e8f\u200b\u7ed3\u679c\u200b\u7684\u200b\u8d28\u91cf\u200b\uff0c\u200b\u5373\u200b\u901a\u8fc7\u200b\u8003\u8651\u200b\u63a8\u8350\u200b\u6216\u200b\u68c0\u7d22\u200b\u7ed3\u679c\u200b\u4e2d\u200b\u76f8\u5173\u200b\u9879\u76ee\u200b\u7684\u200b\u6392\u540d\u200b\u4f4d\u7f6e\u200b\u6765\u200b\u8bc4\u4f30\u200b\u6392\u5e8f\u200b\u8d28\u91cf\u200b\uff0c\u200b\u5e76\u4e14\u200b\u5bf9\u200b\u7ed3\u679c\u200b\u8fdb\u884c\u200b\u4e86\u200b\u5f52\u4e00\u5316\u200b\u5904\u7406\u200b\uff0c\u200b\u4e0d\u4ec5\u200b\u5173\u6ce8\u200b\u63a8\u8350\u200b\u7ed3\u679c\u200b\u7684\u200b\u76f8\u5173\u6027\u200b\uff0c\u200b\u8fd8\u200b\u91cd\u89c6\u200b\u9879\u76ee\u200b\u7684\u200b\u5177\u4f53\u200b\u6392\u5e8f\u200b\u4f4d\u6b21\u200b\u3002</p> <ol> <li> <p>\u200b\u7d2f\u8ba1\u200b\u6536\u76ca\u200bCommulative Gain (CG)\uff0c\u200b\u5355\u7eaf\u200b\u7d2f\u52a0\u200b\uff0c\u200b\u4e0d\u200b\u8003\u8651\u200b\u4f4d\u6b21\u200b\u4fe1\u606f\u200b</p> \\[ CG@k = \\sum_{i=1}^k rel_i \\] </li> <li> <p>\u200b\u6298\u6263\u200b\u7d2f\u8ba1\u200b\u6536\u76ca\u200bDiscounted Comulative Gain (DCG)\uff0c\u200b\u6392\u540d\u200b\u4f4d\u6b21\u200b\u8d8a\u4f4e\u200b\u6298\u6263\u200b\u60e9\u7f5a\u200b\u8d8a\u5927\u200b</p> \\[ DCG@k = \\sum_{i=1}^k \\frac{2^{rel_i}-1}{\\log_2(i+1)} \\] <p>\\(rel_i\\) \u200b\u8868\u793a\u200b\u63a8\u8350\u200b\u5217\u8868\u200b\u4e2d\u200b \\(i\\text{-}th\\) \u200b\u6392\u540d\u200b\u9879\u200b\u7684\u200b\u76f8\u5173\u6027\u200b\u5f97\u5206\u200b</p> </li> <li> <p>\u200b\u7406\u60f3\u200b\u6298\u6263\u200b\u7d2f\u8ba1\u200b\u6536\u76ca\u200bIdeal DCG (IDCG)\uff0c\u200b\u6309\u7167\u200b\u63a8\u8350\u200b\u5217\u8868\u200b\u4e2d\u200b\u76f8\u5173\u6027\u200b\u5f97\u5206\u200b\u964d\u5e8f\u200b\u6392\u5e8f\u200b\u540e\u200b\u6c42\u5f97\u200b\u7684\u200bDCG\uff0c\u200b\u5373\u200b\u76f8\u5173\u6027\u200b\u5f97\u5206\u200b\u8d8a\u9ad8\u200b\u5728\u200b\u7406\u60f3\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u6392\u540d\u200b\u5e94\u8be5\u200b\u8d8a\u9ad8\u200b</p> </li> <li> <p>NDCG\uff0c\u200b\u53d6\u503c\u200b\u8303\u56f4\u200b[0, 1]\uff0c\u200b\u8fdb\u4e00\u6b65\u200b\u8003\u8651\u200b\u5230\u200b\u4e86\u200b\u63a8\u8350\u200b\u5217\u8868\u200b\u548c\u200b\u6bcf\u4e2a\u200b\u68c0\u7d22\u200b\u4e2d\u200b\u771f\u6b63\u200b\u6709\u6548\u200b\u7684\u200b\u7ed3\u679c\u200b\u4e2a\u6570\u200b\uff0c\u200b\u6570\u503c\u200b\u8d8a\u5927\u200b\u8868\u793a\u200b\u8d8a\u200b\u7b26\u5408\u200b\u7406\u60f3\u200b\u6392\u5e8f\u200b\u7ed3\u679c\u200b</p> \\[ NDCG@k = \\frac{DCG@k}{IDCG@k} \\] </li> </ol>"},{"location":"AI/Metrics/features.html","title":"Features","text":""},{"location":"AI/Metrics/features.html#features","title":"Features","text":""},{"location":"AI/Metrics/features.html#tf-idf","title":"TF-IDF","text":"<p>\u200b\u8bcd\u9891\u200b\u9006\u200b\u6587\u6863\u200b\u9891\u7387\u200bTerm Frequency-Inverse Document Frequency\uff0c\u200b\u7528\u4e8e\u200b\u8bc4\u4f30\u200b\u4e00\u4e2a\u200b\u8bcd\u200b\u5728\u200b\u6587\u6863\u200b\u6216\u200b\u8bed\u6599\u5e93\u200b\u4e2d\u200b\u7684\u200b\u91cd\u8981\u200b\u7a0b\u5ea6\u200b\uff0c\u200b\u8fd9\u4e2a\u200b\u6570\u503c\u200b\u7684\u200b\u91cd\u8981\u6027\u200b\u968f\u7740\u200b\u5b83\u200b\u5728\u200b\u4e00\u4e2a\u200b\u6587\u6863\u200b\u4e2d\u200b\u51fa\u73b0\u200b\u7684\u200b\u6b21\u6570\u200b\u6210\u6b63\u6bd4\u200b\u589e\u52a0\u200b\uff0c\u200b\u4f46\u200b\u540c\u65f6\u200b\u4f1a\u200b\u968f\u7740\u200b\u5b83\u200b\u5728\u200b\u6574\u4e2a\u200b\u6587\u6863\u200b\u96c6\u5408\u200b\u4e2d\u200b\u7684\u200b\u666e\u904d\u6027\u200b\u6210\u53cd\u6bd4\u200b\u51cf\u5c11\u200b\u3002</p> \\[ \\begin{aligned}     &amp;\\text{TF}_{i, j} = \\frac{\\#word_{j}}{\\#word\\_in\\_doc_i} \\\\     &amp;\\text{IDF}_j =\\log\\bigg(\\frac{\\#doc + 1}{\\#doc\\_has\\_word_j + 1}\\bigg) \\\\     &amp;\\text{TF-IDF}_{i, j} = \\text{TF}_{i, j} \\times \\text{IDF}_{j}  \\end{aligned}  \\] <ul> <li>\\(TF_{i, j}\\) \u200b\u4e3a\u200b \\(word_j\\) \u200b\u5728\u200b \\(doc_i\\) \u200b\u4e2d\u200b\u51fa\u73b0\u200b\u7684\u200b\u9891\u7387\u200b  </li> <li>\\(IDF_{j}\\) \u200b\u4e3a\u200b \\(word_j\\) \u200b\u5728\u200b\u6240\u6709\u200b\u6587\u6863\u200b\u4e2d\u200b\u51fa\u73b0\u200b\u9891\u7387\u200b\u7684\u200b\u5012\u6570\u200b\u53d6\u5bf9\u200b\u6570\u503c\u200b(1\u200b\u7528\u4e8e\u200b\u9632\u6b62\u200b0\u200b\u503c\u200b\u73b0\u8c61\u200b)\uff0c\u200b\u7528\u4e8e\u200b\u964d\u4f4e\u200b\u5728\u200b\u591a\u4e2a\u200b\u6587\u6863\u200b\u4e2d\u200b\u51fa\u73b0\u200b\u7684\u200b\u8bcd\u200b\uff08\u200b\u5982\u200bstop words\uff09\u200b\u7684\u200b\u6743\u91cd\u200b\uff0c\u200b\u63d0\u5347\u200b\u975e\u5e38\u200b\u7528\u8bcd\u200b\u7684\u200b\u6743\u91cd\u200b\u3002</li> <li>\\(\\text{TF-IDF}_{j}\\) ?</li> </ul>"},{"location":"AI/Metrics/features.html#mi","title":"MI","text":"<p>\u200b\u4e92\u4fe1\u606f\u200bMutual Information\uff0c\u200b\u662f\u200b\u5ea6\u91cf\u200b\u4e24\u4e2a\u200b\u968f\u673a\u53d8\u91cf\u200b\u4e4b\u95f4\u200b\u76f8\u4e92\u200b\u4f9d\u8d56\u6027\u200b(\u200b\u4fe1\u606f\u200b\u5171\u4eab\u200b\u7a0b\u5ea6\u200b)\u200b\u7684\u200b\u7edf\u8ba1\u200b\u91cf\u200b\u3002</p> \\[ \\text{mi} =\\sum_{x \\in X}\\sum_{y \\in Y} p(x,y)\\log\\frac{p(x,y)}{p(x)p(y)} \\] <ul> <li>\u200b\u62c6\u200b\u5206\u4e3a\u200b \\(\\text{mi}_{a}, \\text{mi}_{b}, \\text{mi}_{c}, \\text{mi}_{d}\\) 4\u200b\u90e8\u5206\u200b</li> </ul>"},{"location":"AI/Metrics/features.html#chi-square-statistic","title":"Chi-square statistic","text":"<p>\u200b\u5361\u65b9\u200b\u7edf\u8ba1\u200b\u91cf\u200b \\(\\chi^2\\) Chi-square statistic\uff0c\u200b\u7528\u4e8e\u200b\u8861\u91cf\u200b\u4e00\u4e2a\u200b\u7279\u5f81\u200b\u4e0e\u200b\u7c7b\u522b\u200b\u6807\u7b7e\u200b\u4e4b\u95f4\u200b\u7684\u200b\u76f8\u5173\u6027\u200b\u5f3a\u5ea6\u200b\uff0c\u200b\u503c\u8d8a\u200b\u5927\u200b\u8868\u660e\u200b\u76f8\u5173\u6027\u200b\u8d8a\u9ad8\u200b\uff0c0\u200b\u5219\u200b\u8868\u793a\u200b\u65e0\u200b\u76f8\u5173\u6027\u200b\u3002</p> \\[ \\chi^2 = \\frac{n\\times(ad - bc)^2}{(a+b)(c+d)(a+c)(b+d)} \\] <ul> <li>N11: a, \u200b\u8868\u793a\u200b\u540c\u65f6\u200b\u5177\u6709\u200b\u4e24\u79cd\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b</li> <li>N10: b, \u200b\u8868\u793a\u200b\u5177\u6709\u200b\u7b2c\u4e00\u4e2a\u200b\u5c5e\u6027\u200b\u4f46\u200b\u4e0d\u200b\u5177\u6709\u200b\u7b2c\u4e8c\u4e2a\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b</li> <li>N01: c, \u200b\u8868\u793a\u200b\u4e0d\u200b\u5177\u6709\u200b\u7b2c\u4e00\u4e2a\u200b\u5c5e\u6027\u200b\u4f46\u200b\u5177\u6709\u200b\u7b2c\u4e8c\u4e2a\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b</li> <li>N00: d, \u200b\u8868\u793a\u200b\u540c\u65f6\u200b\u4e0d\u200b\u5177\u6709\u200b\u8fd9\u200b\u4e24\u79cd\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b</li> </ul>"},{"location":"AI/Metrics/smoothing_metrics.html","title":"Smoothing metrics","text":""},{"location":"AI/Metrics/smoothing_metrics.html#add-one-smoothinglaplace-smoothing","title":"Add-One Smoothing/Laplace Smoothing","text":"<p>\u200b\u52a0\u4e00\u200b\u5e73\u6ed1\u200b\uff08\u200b\u53c8\u79f0\u200b\u62c9\u666e\u62c9\u65af\u200b\u5e73\u6ed1\u200b\uff09\uff0c\u200b\u7528\u4e8e\u200b\u89e3\u51b3\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u4e2d\u96f6\u200b\u6982\u7387\u200b\u95ee\u9898\u200b\uff08\u200b\u5373\u200b\u672a\u200b\u767b\u5f55\u200b\u8bcd\u200b\u6216\u200b\u4f4e\u9891\u8bcd\u200b\u7684\u200b\u6982\u7387\u200b\u4f30\u8ba1\u200b\uff09\uff0c\u200b\u5176\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\uff1a\u200b\u5bf9\u200b\u6240\u6709\u200b\u53ef\u80fd\u200b\u7684\u200b\u8bcd\u9891\u200b\u52a0\u200b1\uff0c\u200b\u786e\u4fdd\u200b\u6ca1\u6709\u200b\u8bcd\u200b\u7684\u200b\u6982\u7387\u200b\u4e3a\u200b\u96f6\u200b\u3002</p> \\[ P_{\\text{Add-1}}(w\\vert d) = \\frac{c(w, d) + 1}{\\vert d \\vert + \\vert V \\vert } \\] <ul> <li>\\(c(w,d)\\) \u200b\u8868\u793a\u200b\u8bcd\u200b \\(w\\)  \u200b\u5728\u200b\u6587\u6863\u200b \\(d\\) \u200b\u4e2d\u200b\u7684\u200b\u51fa\u73b0\u200b\u6b21\u6570\u200b\uff08\u200b\u8bcd\u9891\u200b\uff09</li> <li>\\(\\vert d\\vert\\) \u200b\u8868\u793a\u200b\u6587\u6863\u200b \\(d\\) \u200b\u7684\u200b\u957f\u5ea6\u200b\uff08\u200b\u603b\u200b\u8bcd\u6570\u200b\uff09</li> <li>\\(\\vert V \\vert\\) \u200b\u8868\u793a\u200b\u8bcd\u6c47\u8868\u200b\u5927\u5c0f\u200b\uff08\u200b\u603b\u200b\u5355\u8bcd\u200b\u6570\u200b\uff09</li> </ul> <ol> <li> <p>Add-k Smoothing\uff0c\u200b\u76f8\u5bf9\u200b\u4e8e\u200bAdd-1\u200b\u589e\u5927\u200b\u5e73\u6ed1\u200b\u5ea6\u200b\uff0c\\(k \\gt 1\\)</p> \\[ P_{\\text{Add-k}}(w\\vert d) = \\frac{c(w, d) + k}{\\vert d \\vert + k\\vert V \\vert } \\] </li> <li> <p>Lidstone Smoothing\uff0c\u200b\u76f8\u5bf9\u200b\u4e8e\u200bAdd-1\u200b\u51cf\u5c0f\u200b\u5e73\u6ed1\u200b\u5ea6\u200b\uff0c\\(0 \\lt k \\lt 1\\)\uff0c\u200b\u9002\u7528\u200b\u4e8e\u200b\u5c0f\u89c4\u6a21\u200b\u6570\u636e\u200b\u96c6\u200b</p> </li> </ol>"},{"location":"AI/Metrics/smoothing_metrics.html#jelinek-mercer-smoothing","title":"Jelinek-Mercer Smoothing","text":"<p>Jelinek-Mercer\u200b\u5e73\u6ed1\u200b\u662f\u200b\u4fe1\u606f\u68c0\u7d22\u200b\u548c\u200b\u81ea\u7136\u8bed\u8a00\u200b\u5904\u7406\u200b\u4e2d\u200b\u5e7f\u6cdb\u200b\u4f7f\u7528\u200b\u7684\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u5e73\u6ed1\u200b\u6280\u672f\u200b\uff0c\u200b\u901a\u8fc7\u200b\u7ebf\u6027\u63d2\u503c\u200b\uff08Linear Interpolation\uff09\u200b\u5c06\u200b\u6587\u6863\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u4e0e\u200b\u80cc\u666f\u200b\u8bed\u6599\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u7ed3\u5408\u200b\uff0c\u200b\u89e3\u51b3\u200b\u6570\u636e\u200b\u7a00\u758f\u200b\u95ee\u9898\u200b\u3002\u200b\u5176\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\uff1a\u200b\u4fe1\u4efb\u200b\u6587\u6863\u200b\u4e2d\u200b\u7684\u200b\u8bcd\u9891\u200b\u7edf\u8ba1\u200b\uff0c\u200b\u4f46\u200b\u5bf9\u200b\u4f4e\u9891\u200b\u6216\u200b\u672a\u200b\u51fa\u73b0\u200b\u8bcd\u200b\uff0c\u200b\u56de\u9000\u200b\u5230\u200b\u5168\u5c40\u200b\u80cc\u666f\u200b\u6a21\u578b\u200b\u3002</p> \\[ P_{\\text{JM}}(w\\vert d) = \\lambda \\frac{c(w, d)}{\\vert d \\vert} + (1-\\lambda)P(w\\vert D) \\] <ul> <li>\\(P(w\\vert D)\\) \u200b\u8868\u793a\u200b\u8bcd\u200b \\(w\\) \u200b\u5728\u200b\u6240\u6709\u200b\u6587\u6863\u200b\u96c6\u5408\u200b \\(D\\) \u200b\u4e2d\u200b\u7684\u200b\u80cc\u666f\u200b\u6982\u7387\u200b\uff08\u200b\u5373\u8bcd\u200b \\(w\\) \u200b\u5728\u200b\u6240\u6709\u200b\u6587\u6863\u200b\u4e2d\u200b\u7684\u200b\u5e73\u5747\u200b\u5f53\u521d\u200b\u5355\u4f4d\u200b\u5185\u200b\u51fa\u73b0\u200b\u6b21\u6570\u200b\uff09\uff0c\u200b\u901a\u5e38\u200b\u8ba1\u7b97\u200b\u4e3a\u200b \\(P(w\\vert D) = \\frac{\\sum_{d \\in D} c(w,d)}{\\sum_{d\\in D} \\vert d \\vert}\\)</li> <li>\\(0 \\le \\lambda \\le 1\\) \u200b\u4e3a\u200b\u63d2\u503c\u200b\u7cfb\u6570\u200b\uff0c\u200b\u63a7\u5236\u200b\u6587\u6863\u200b\u6a21\u578b\u200b\u548c\u200b\u80cc\u666f\u200b\u6a21\u578b\u200b\u7684\u200b\u6743\u91cd\u200b\uff0c\u200b\u7ecf\u9a8c\u200b\u53d6\u503c\u200b[0.1, 0.7]</li> </ul>"},{"location":"AI/Metrics/smoothing_metrics.html#dirichlet-prior-smoothing","title":"Dirichlet Prior Smoothing","text":"<p>\u200b\u8fea\u5229\u514b\u96f7\u200b\u5148\u9a8c\u200b\u5e73\u6ed1\u200b\u4e3b\u8981\u200b\u7528\u4e8e\u200b\u89e3\u51b3\u200b\u6570\u636e\u200b\u7a00\u758f\u200b\u95ee\u9898\u200b\uff08\u200b\u5373\u200b\u67d0\u4e9b\u200b\u8bcd\u200b\u5728\u200b\u6587\u6863\u200b\u4e2d\u672a\u200b\u51fa\u73b0\u200b\u5bfc\u81f4\u200b\u6982\u7387\u200b\u4e3a\u200b\u96f6\u200b\u7684\u200b\u60c5\u51b5\u200b\uff09\uff0c\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\u5f15\u5165\u200b\u6574\u4e2a\u200b\u6587\u6863\u200b\u96c6\u5408\u200b\u80cc\u666f\u200b\u8bed\u6599\u200b\u7684\u200b\u8bcd\u200b\u5206\u5e03\u200b\u4f5c\u4e3a\u200b\u5148\u9a8c\u200b\u77e5\u8bc6\u200b\uff0c\u200b\u5bf9\u200b\u6587\u6863\u200b\u4e2d\u200b\u7684\u200b\u8bcd\u200b\u6982\u7387\u200b\u8fdb\u884c\u200b\u5e73\u6ed1\u200b\u8c03\u6574\u200b\uff0c\u200b\u5e73\u6ed1\u200b\u540e\u200b\u503c\u57df\u200b\u8303\u56f4\u200b(0, 1]\u3002</p> \\[ P_{\\text{Dir}}(w\\vert d) = \\frac{c(w, d) + \\mu P(w|D)}{\\vert d \\vert + \\mu} \\] <ul> <li>\\(\\mu\\) \u200b\u4e3a\u200b\u5148\u9a8c\u200b\u5e73\u6ed1\u200b\u53c2\u6570\u200b\uff0c\u200b\u63a7\u5236\u200b\u80cc\u666f\u200b\u6a21\u578b\u200b\u7684\u200b\u6743\u91cd\u200b\uff0c\u200b\u901a\u5e38\u200b\u53d6\u503c\u200b[1000, 2000]</li> </ul> <p>\u200b\u7531\u200b\u8ba1\u7b97\u516c\u5f0f\u200b\u5206\u6bcd\u200b\u90e8\u5206\u200b\u53ef\u77e5\u200b \\(\\sum_{w \\in V} P_{\\text{Dir}}(w\\vert d) =1\\)\uff0c\u200b\u8be5\u200b\u5e73\u6ed1\u200b\u65b9\u6cd5\u200b\u5177\u6709\u200b\u81ea\u200b\u9002\u5e94\u200b\u7279\u6027\u200b\uff0c\u200b\u5373\u957f\u200b\u6587\u6863\u200b\u4f9d\u8d56\u200b\u6570\u636e\u200b\uff08\\(\\vert d \\vert \\gg \\mu\\)\uff09\uff0c\u200b\u77ed\u200b\u6587\u6863\u200b\u4f9d\u8d56\u200b\u5148\u9a8c\u200b\uff08\\(\\vert d \\vert \\ll \\mu\\)\uff09</p>"},{"location":"AI/Paper_Reading/Component/Activation/activation.html","title":"Activation","text":""},{"location":"AI/Paper_Reading/Component/Activation/activation.html#_1","title":"\u5355\u6b65\u200b\u6fc0\u6d3b\u200b\u51fd\u6570","text":""},{"location":"AI/Paper_Reading/Component/Activation/activation.html#sigmoid","title":"Sigmoid","text":"\\[ \\text{Sigmoid}(x)=\\sigma(x) = \\frac{1}{1+e^{-x}} \\]"},{"location":"AI/Paper_Reading/Component/Activation/activation.html#tanh","title":"Tanh","text":"\\[ \\text{Tanh}(x)=\\frac{e^x - e^{-x} }{e^x + e^{-x} }=\\frac{2}{1+e^{-2x}} -1 \\]"},{"location":"AI/Paper_Reading/Component/Activation/activation.html#relu","title":"ReLU","text":"<ol> <li> <p>ReLU(Rectified-Linear Units)</p> \\[ \\text{ReLU}(x)=\\max(0, x) \\] </li> <li> <p>LReLU\uff0cLeaky ReLU</p> \\[ \\text{LReLU}(x, \\alpha)=\\max(0, x) + \\alpha\\min(0, x) \\] </li> <li> <p>PReLU\uff0cParametric ReLU\uff0cLReLU\u200b\u53d8\u79cd\u200b\uff0c\u200b\u4f7f\u7528\u200b\u53ef\u200b\u5b66\u4e60\u200b\u7684\u200b\u53c2\u6570\u200b \\(w\\) \u200b\u800c\u200b\u4e0d\u200b\u56fa\u5b9a\u200b\\(\\alpha\\)</p> \\[ \\text{PReLU}(x)=\\max(0, x) + w\\min(0, x) \\] </li> </ol>"},{"location":"AI/Paper_Reading/Component/Activation/activation.html#_2","title":"\u95e8\u9650\u200b\u6fc0\u6d3b\u200b\u51fd\u6570","text":""},{"location":"AI/Paper_Reading/Component/Activation/activation.html#mish","title":"Mish","text":"\\[ \\text{Mish}(x)=x*\\text{Tanh}\\big(\\ln(1+e^x)\\big) \\]"},{"location":"AI/Paper_Reading/Component/Activation/activation.html#gelu","title":"GELU","text":"<p>Gaussian Error Linear Units\uff0cReLU\u200b\u7684\u200b\u4e00\u79cd\u200b\u5e73\u6ed1\u200b\u7248\u672c\u200b</p> \\[ \\begin{aligned} \\text{GELU}(x)=xP(X\\le x)=x\\Phi(x) &amp;= 0.5x[1+\\text{erf}({x}/{\\sqrt{2}})] \\\\ &amp; \\approx x\\sigma(1.702x) \\\\ &amp; \\approx 0.5x\\Big[ 1 + \\text{Tanh}(\\sqrt{\\frac{2}{\\pi}} \\big(x+ 0.044715x^3)\\big) \\Big]  \\end{aligned} \\] <p>sigmoid\u200b\u8fd1\u4f3c\u200b\u7cbe\u5ea6\u200b\u4f4e\u200b\uff0c\u200b\u8ba1\u7b97\u200b\u5feb\u200b\uff1btanh\u200b\u8fd1\u4f3c\u200b\u7cbe\u5ea6\u9ad8\u200b\uff0c\u200b\u8ba1\u7b97\u200b\u6162\u200b\u3002</p>"},{"location":"AI/Paper_Reading/Component/Activation/activation.html#swish","title":"Swish","text":"\\[ \\text{Swish}_\\beta(x, \\beta)=x\\sigma(\\beta x) \\]"},{"location":"AI/Paper_Reading/Component/Activation/activation.html#glu","title":"GLU","text":"<p>Gated Linear Units</p> \\[ \\text{GLU}(x, W, V, b, c)=\\sigma(xW+b)\\otimes(xV+c) \\]"},{"location":"AI/Paper_Reading/Component/Activation/activation.html#bilinear","title":"Bilinear","text":"\\[ \\text{Biliniear}(x, W, V, b, c)=(xW+b)\\otimes(xV+c) \\]"},{"location":"AI/Paper_Reading/Component/Activation/activation.html#reglu","title":"ReGLU","text":"\\[ \\text{ReGLU}(x, W, V, b, c)=\\max(0, xW+b)\\otimes(xV+c) \\]"},{"location":"AI/Paper_Reading/Component/Activation/activation.html#geglu","title":"GeGLU","text":"\\[ \\text{GeGLU}(x, W, V, b, c)=\\text{GELU}(xW+b)\\otimes(xV+c) \\]"},{"location":"AI/Paper_Reading/Component/Activation/activation.html#swiglu","title":"SwiGLU","text":"\\[ \\text{SwiGLU}(x, W, V, b, c)=\\text{Swish}_\\beta(xW+b)\\otimes(xV+c) \\] <ul> <li>\u200b\u95e8\u9650\u200b\u6fc0\u6d3b\u200b\u51fd\u6570\u200b\u8fdb\u4e00\u6b65\u200b\u7ec6\u5206\u200b\u6fc0\u6d3b\u200b\u6b65\u9aa4\u200b\uff0c\u200b\u4e00\u90e8\u5206\u200b\u8d1f\u8d23\u200b\u63a7\u5236\u200b\u95e8\u200b\uff0c\u200b\u53e6\u200b\u4e00\u90e8\u5206\u200b\u5219\u200b\u8d1f\u8d23\u200b\u751f\u6210\u200b\u95e8\u200b\u7684\u200b\u8f93\u5165\u200b\u503c\u200b\u3002</li> <li>Google\u200b\u5de5\u4f5c\u200bGLU Variants Improve Transformer\u200b\u901a\u8fc7\u200b\u5bf9\u6bd4\u200b\u5b9e\u9a8c\u200b\u5c55\u793a\u200b\u95e8\u9650\u200b\u6fc0\u6d3b\u200b\u51fd\u6570\u200b\u7684\u200b\u4f18\u8d8a\u200b\u8868\u73b0\u200b\u3002</li> </ul>"},{"location":"AI/Paper_Reading/Component/CNN/cnn.html","title":"Cnn","text":"<ul> <li>CNN\uff08Convolution\uff09</li> <li>\u200b\u53cd\u200b\u5377\u79ef\u200bDeconvolution \u200b\u901a\u8fc7\u200b\u9006\u5411\u200b\u64cd\u4f5c\u200b\u6a21\u62df\u200b\u5377\u79ef\u200b\u7684\u200b\u9006\u200b\u8fc7\u7a0b\u200b\uff08\u200b\u4f46\u200b\u5e76\u975e\u200b\u6570\u5b66\u200b\u4e0a\u200b\u7684\u200b\u4e25\u683c\u200b\u9006\u8fd0\u7b97\u200b\uff09\uff0c\u200b\u662f\u200b\u7528\u4e8e\u200b\u4e0a\u200b\u91c7\u7528\u200bupsampling\u200b\u7684\u200b\u5173\u952e\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u5176\u200b\u6838\u5fc3\u200b\u662f\u200b\u901a\u8fc7\u200b\u586b\u5145\u200b\uff08padding\uff09\u200b\u548c\u200b\u6b65\u957f\u200b\uff08stride\uff09\u200b\u7684\u200b\u8c03\u6574\u200b\u5b9e\u73b0\u200b\u5c3a\u5bf8\u200b\u653e\u5927\u200b\u3002  </li> <li>\u200b\u8f6c\u7f6e\u200b\u5377\u79ef\u200b\uff08Transposed Convolution\uff09\u200b\u6216\u200b\u5206\u6570\u200b\u6b65\u957f\u200b\u5377\u79ef\u200b\uff08Fractionally-Strided Convolution\uff09</li> <li>\u200b\u7a7a\u6d1e\u200b\u5377\u79ef\u200bDilated Convolution</li> <li>\u200b\u5b50\u200b\u50cf\u7d20\u200b\u5377\u79ef\u200bSub-Pixel Convolution</li> <li>pooling: mean, avg, max</li> <li>upooling: Max Unpooling, Average Unpooling</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/embedding.html","title":"Embedding","text":""},{"location":"AI/Paper_Reading/Component/Embedding/embedding.html#token-embedding","title":"Token Embedding","text":"<ul> <li>Token Embedding</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/embedding.html#sentence-embedding","title":"Sentence Embedding","text":"<ul> <li>Sentence Embedding</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/embedding.html#position-embedding","title":"Position Embedding","text":"<ul> <li>Position Embedding</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/position_embedding.html","title":"Position embedding","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/position_embedding.html#absolute-position-embedding","title":"Absolute Position Embedding","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/position_embedding.html#relative-position-embedding","title":"Relative Position Embedding","text":"<ul> <li>\u200b\u65cb\u8f6c\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200bRoPE</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/position_embedding.html#position-embedding-patches","title":"Position Embedding Patches","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/position_embedding.html#extend-context-window","title":"\u6a21\u578b\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b\u62d3\u5c55\u200b Extend Context Window","text":"<ol> <li>\u200b\u5916\u200b\u63a8\u200b(Extrapolation)\uff1a\u200b\u77ed\u6587\u200b\u672c\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u957f\u200b\u6587\u672c\u200b\u5e94\u7528\u200b<ul> <li>ALiBi</li> <li>LeX</li> </ul> </li> <li>\u200b\u5185\u200b\u63d2\u200b(Interpolation)\uff1a\u200b\u957f\u200b\u6587\u672c\u200b\u4e8c\u6b21\u200b\u8bad\u7ec3\u200b\u6216\u200b\u76f4\u63a5\u200b\u5e94\u7528\u200b<ul> <li>\u200b\u4f4d\u7f6e\u200b\u7ef4\u5ea6\u200b\u7ebf\u6027\u200b\u7f29\u653e\u200b\uff1aPosition Interpolation</li> <li>\u200b\u7279\u5f81\u9891\u7387\u200b\u7ef4\u5ea6\u200b\u975e\u200b\u5747\u5300\u200b\u7f29\u653e\u200b\uff1aNTK-Aware\uff0cYaRN</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/ALiBi.html","title":"ALiBi","text":"<p>ALiBi (Attention with Linear Biases) \u200b\u65e0\u9700\u200b\u5728\u200bembedding\u200b\u5c42\u200b\u5bf9\u200b\u52a0\u5165\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b\uff0c\u200b\u800c\u662f\u200b\u5728\u200bSoftmax\u200b\u4e4b\u524d\u200b\uff0c\u200b\u5c06\u200bAttention\u200b\u7684\u200b\u8ba1\u7b97\u200b\\(q_m^Tk_n\\)\u200b\u52a0\u4e0a\u200b\u4e00\u4e2a\u200b\u4e0e\u200b\u76f8\u5bf9\u200b\u4f4d\u7f6e\u200b\u8ddd\u79bb\u200b\u6210\u200b\u6bd4\u4f8b\u200b\u7684\u200b\u8d1f\u200b\u5e38\u6570\u200b\u504f\u7f6e\u200bbia\u200b\u5b9e\u73b0\u200b\u76f8\u5bf9\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b</p> <ul> <li> train short, test long: context_window\u200b\u7531\u200b1024\u200b\u76f4\u63a5\u200b\u5916\u200b\u63a8\u81f3\u200b2048</li> <li> context_window=1024 + ALiBi \u200b\u76f4\u63a5\u200b\u5916\u200b\u63a8\u81f3\u200b2048\u200b\u6548\u679c\u200b\u7b49\u4ef7\u200b\u4e8e\u200b context_window=2048 + \u200b\u6b63\u5f26\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b\uff0c\u200b\u524d\u8005\u200b\u6bd4\u200b\u540e\u8005\u200b\u5feb\u200b11%\u200b\u4e14\u200bgpu\u200b\u5360\u7528\u200b\u5c11\u200b11%</li> </ul> <ul> <li>\u200b\u673a\u6784\u200b\uff1aFAIR\u3001Allen AI\u3001UW</li> <li>Paper</li> <li>Github</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/ALiBi.html#_1","title":"\u65b9\u6cd5\u200b\u4ecb\u7ecd","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/ALiBi.html#_2","title":"\u57fa\u672c\u539f\u7406","text":"<p>\u200b\u4e0e\u200b\u76f4\u63a5\u200b\u5728\u200bembedding\u200b\u5c42\u200b\u589e\u52a0\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b\u4e0d\u540c\u200b\uff0cALiBi\u200b\u5728\u200bAttention (\u200b\u975e\u200bRoPE) \u200b\u4e2d\u200b\u589e\u52a0\u200b\u4e0e\u200btoken\u200b\u95f4\u200b\u76f8\u5bf9\u200b\u8ddd\u79bb\u200b\u6210\u6b63\u6bd4\u200b\u7684\u200b\u504f\u5dee\u200b\u4ee5\u200b\u6ce8\u5165\u200btoken\u200b\u4f4d\u7f6e\u200b\u4fe1\u606f\u200b\uff0c\u200b\u5373\u200b  </p> \\[\\text{softmax}(q_iK^T - m[i-1, \\dots,2, 1, 0])\\] <p>\u200b\u5176\u4e2d\u200b\\(m\\)\u200b\u662f\u200b\u4e00\u4e2a\u200b\u548c\u200battention head\u200b\u76f8\u5173\u200b\u3001\u200b\u591a\u5c42\u200b\u5171\u4eab\u200b\u7684\u200b\u6807\u91cf\u200b\uff0c\u200b\u6bcf\u4e2a\u200bhead\u200b\u5bf9\u5e94\u200b\u7b26\u5408\u200b\u516c\u5f0f\u200b</p> \\[m_k={2^{-\\frac{8}{k}}}\\] <p> </p> ALiBi\u200b\u5355\u4e2a\u200battention head\u200b\u5206\u6570\u200b\u8ba1\u7b97\u200b\u793a\u610f\u56fe\u200b <ul> <li>\u200b\u4f5c\u8005\u200b\u6bd4\u200b\u5bf9\u200b\u8fc7\u200btrainable \\(m\\)\u200b\u7684\u200b\u7ed3\u679c\u200b\uff0c\u200b\u53d1\u73b0\u200b\u6548\u679c\u200b\u6ca1\u4ec0\u4e48\u200b\u660e\u663e\u200b\u589e\u76ca\u200b\uff0c\u200b\u4e14\u200b\u8bad\u7ec3\u200b\u7684\u200b\u65f6\u95f4\u200b\u6027\u80fd\u200b\u4f1a\u200b\u4e0b\u964d\u200b</li> <li>\u200b\u672a\u200b\u5c55\u793a\u200b\u7684\u200b\u5b9e\u73b0\u200b\u8865\u5145\u200b\uff0c\u200b\u5bf9\u200b\\(q_iK^T\\)\u200b\u7f29\u653e\u200b\u4f1a\u200b\u635f\u4f24\u200b\u6a21\u578b\u200b\u6548\u679c\u200b</li> <li>ALiBi\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u89c6\u4f5c\u200b\u5c40\u90e8\u200bAttention\u200b\u65b9\u6848\u200b\uff0c\u200b\u76f8\u5bf9\u200b\u4f4d\u7f6e\u200b\u5927\u200b\u7684\u200b\u5730\u65b9\u200b\u60e9\u7f5a\u200b\u7cfb\u6570\u200b\u5927\u200b\uff0c\u200b\u8d8b\u8fd1\u200b\u4e8e\u200bMASK\u200b\u4e2d\u200b\u7684\u200b-INF</li> </ul> <p></p>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/ALiBi.html#_3","title":"\u5b9e\u9a8c\u200b\u7ed3\u679c","text":"<ul> <li>\u200b\u5916\u200b\u63a8\u6027\u200b\u8868\u73b0\u200b\uff1a\u200b\u6b63\u5f26\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b &lt; ROPE &lt; T5 bias (\u200b\u57fa\u4e8e\u200b\u5206\u6876\u200b\u7684\u200b\"\u200b\u7c97\u200b\"\u200b\u76f8\u5bf9\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b) &lt; ALiBi</li> </ul> <ul> <li>ALiBi\u200b\u5728\u200b\\(L^{'}\\approx 2*L\\)\u200b\u80fd\u200b\u6709\u200b\u6700\u597d\u200b\u7684\u200b\u5916\u200b\u63a8\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</li> </ul> <ul> <li>\\(L=512\\)\u200b\u5916\u200b\u63a8\u81f3\u200b\\(L^{'}=3072\\)\u200b\u7684\u200b\u6548\u679c\u200b\u4e0e\u200b\u76f4\u63a5\u200b\u8bad\u7ec3\u200b\u5fae\u8c03\u200b\u7684\u200b\u5176\u4ed6\u200bPE\u200b\u65b9\u6848\u200b\u6548\u679c\u200b\u76f8\u5f53\u200b</li> <li>\u200b\u76f8\u540c\u200b\\(L\\)\u200b\u4e0b\u200bALiBi\u200b\u8f83\u200b\u5176\u5b83\u200bPE\u200b\u65b9\u6848\u200b\u4e5f\u200b\u80fd\u200b\u53d6\u5f97\u200b\u6700\u4f73\u200b\u6027\u80fd\u200b\u8868\u73b0\u200b</li> </ul> <ul> <li>ALiBi\u200b\u4ee5\u200b\u66f4\u200b\u5c11\u200b\u7684\u200b\u8d44\u6e90\u200b\u548c\u200b\u66f4\u200b\u9ad8\u200b\u65f6\u95f4\u200b\u6027\u80fd\u200b\uff0c\u200b\u5916\u200b\u63a8\u200b\u4e00\u500d\u200b\u957f\u5ea6\u200b\u7684\u200b\u6548\u679c\u200b\u4e0e\u200b\u5e94\u7528\u200b\u6b63\u5f26\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u65b9\u6cd5\u200b\u5fae\u8c03\u200b\u7684\u200b\u6548\u679c\u200b\u76f8\u5f53\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/LeX.html","title":"LeX","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/LeX.html#lex","title":"LeX","text":"<p>\u200b\u8bba\u6587\u200b\uff1aA Length-Extrapolatable Transformer LeX\uff1aLength-eXtrapolatable Github\uff1atorchscale Microsoft, 2020 Dec, ACL 2023</p>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/LeX.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li> train short, test long</li> <li> XPos (Extrapolatable Position Embedding)\u200b\u5728\u200bRoPE\u200b\u7684\u200b\u57fa\u7840\u200b\u4e0a\u200b\uff0c\u200b\u589e\u8fdb\u200b\u4e86\u200b\u957f\u8ddd\u79bb\u200b\u4f9d\u8d56\u200b\u7684\u200b\u8868\u73b0\u200b</li> <li> \u200b\u5229\u7528\u200b\u5c40\u90e8\u200b\u6ce8\u610f\u529b\u200b\u673a\u5236\u200bBCA (Blockwise Causal Attention) \u200b\u589e\u8fdb\u200b\u6a21\u578b\u200b\u5916\u200b\u63a8\u200b\u6548\u679c\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/LeX.html#_2","title":"\u57fa\u672c\u539f\u7406","text":"<p>RoPE\u200b\u5bf9\u200b\\(q\\)\u200b\u548c\u200b\\(k\\)\u200b\u5206\u522b\u200b\u6ce8\u5165\u200b\u7edd\u5bf9\u200b\u4f4d\u7f6e\u200b\u4fe1\u606f\u200b\\(p_q\\)\u200b\u548c\u200b\\(p_k\\)\uff0c\u200b\u901a\u8fc7\u200b\u4e58\u6027\u200b\u53d8\u6362\u200b\u6700\u7ec8\u200b\u83b7\u5f97\u200b\u5173\u4e8e\u200b\u76f8\u5bf9\u200b\u4f4d\u7f6e\u200b\\(p_q-p_k\\)\u200b\u7684\u200b\u53d8\u6362\u200b\uff0c\u200b\u5373\u200b</p> \\[ \\begin{equation}  \u27e8f_q(q,p_q),f_k(k,p_k) \u27e9=\u27e8 f_q(q, p_q-p_k), f_k(k, 0)\u27e9 \\end{equation} \\] <p>\u200b\u4f20\u7edf\u200b\u7684\u200bRoPE\u200b\u4e8c\u7ef4\u200b\u65cb\u8f6c\u53d8\u6362\u200b\u4e3a\u200b</p> \\[f_q(q, n)=qe^{i\\theta m}\\] <p>\u200b\u800c\u200bXPoS\u200b\u7684\u200b\u4e8c\u7ef4\u200b\u65cb\u8f6c\u53d8\u6362\u200b\u5bf9\u200b\u65cb\u8f6c\u200b\u7ed3\u679c\u200b\u989d\u5916\u200b\u7f29\u653e\u200b\u53d8\u6362\u200b\uff0c\u200b\u5373\u200b</p> \\[f_q(q, m)=A_qqe^{i\\theta m}=e^{\\xi * m}qe^{i\\theta m}\\] \\[ f_k(k, n)=A_kke^{i\\theta n}=e^{-\\xi * n}ke^{i\\theta n} \\] \\[ \u27e8f_q(q,m),f_k(k,n)\u27e9=e^{(m-n)\\xi}\\text{RoPE(q, m, k, n)}=\\tilde{\\xi}^{(m-n)}\\text{RoPE(q, m, k, n)} \\\\ \\] \\[ \\tilde{\\xi}_i = \\frac{i/(d/2)+\\gamma}{1+\\gamma} \\in [0, 1] \\\\\\] <ul> <li>\u200b\u5176\u4e2d\u200b\\(\\theta=10000^{-\\frac{2*i}{d}}\\)\u200b\u5728\u200b\u51fd\u6570\u200b\u5468\u671f\u200b\u5185\u200b\u968f\u7740\u200b\\(i\\)\u200b\u589e\u5927\u200b\u800c\u200b\u51cf\u5c0f\u200b\uff0c\u200b\u4f46\u200b\u968f\u7740\u200b\u76f8\u5bf9\u200b\u4f4d\u7f6e\u200b\\(m-n\\)\u200b\u589e\u5927\u200b\uff0c\\((m-n)\\theta\\)\u200b\u4f1a\u200b\u8d85\u51fa\u200b\u5468\u671f\u200b\\(\\pi\\)\uff0c\u200b\u4e09\u89d2\u51fd\u6570\u200b\u8868\u73b0\u200b\u4e3a\u200b\u9707\u8361\u200b\uff1b</li> <li>\\(\\xi_i\\)\u200b\u968f\u7740\u200b\u589e\u5927\u200b\u800c\u200b\u589e\u5927\u200b\uff0c\u200b\u4f46\u200b\u968f\u7740\u200b\u76f8\u5bf9\u200b\u4f4d\u7f6e\u200b\\(m-n\\)\u200b\u589e\u5927\u200b\uff0c\u200b\u5e42\u6307\u6570\u200b\\(\\xi^{(m-n)}\\)\u200b\u51cf\u5c0f\u200b\uff0c\u200b\u7f29\u653e\u200b\u64cd\u4f5c\u200b\u56e0\u6b64\u200b\u80fd\u591f\u200b\u7f13\u89e3\u200b\u5916\u200b\u63a8\u65f6\u200bAttention\u200b\u9707\u8361\u200b <p>[0, 1]\u200b\u5185\u503c\u200b\u7684\u200b\u6307\u6570\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u4f7f\u7528\u200b\u65f6\u200b\u6ce8\u610f\u200b\u4e0b\u6ea2\u200b\u73b0\u8c61\u200b</p> </li> <li>\\(\\lambda\\)\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5e38\u6570\u200b\u6807\u91cf\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/LeX.html#_3","title":"\u5b9e\u9a8c\u200b\u7ed3\u679c","text":"<ul> <li>\\(\\tilde{\\xi}_i\\)\u200b\u7684\u200b\u5f15\u5165\u200b\u80fd\u200b\u4e00\u5b9a\u200b\u7a0b\u5ea6\u200b\u4e0a\u200b\u589e\u52a0\u200bRoPE\u200b\u7684\u200b\u7a33\u5b9a\u6027\u200b</li> </ul> <ul> <li>LeX\u200b\u65b9\u6848\u200b\u5728\u200bcontext windows \\([0, L]\\)\u200b\u548c\u200b\u5916\u200b\u63a8\u200b\\([L, l^{'}]\\)\u200b\u573a\u666f\u200b\u4e0b\u200b\uff0c\u200b\u6548\u679c\u200b\u5747\u200b\u8868\u73b0\u200b\u6700\u597d\u200b</li> </ul> <ul> <li>Attention MASK\uff1a\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u4e0b\u200b\u4e09\u89d2\u200bMASK\u3001\u200b\u6d4b\u8bd5\u200b\u65f6\u200bBCA (Block Causal Attention\uff0c\u200b\u6bcf\u4e2a\u200bblock\u200b\u957f\u5ea6\u200b\u4e3a\u200b\\(L/2\\))</li> <li>\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b\u5176\u4ed6\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u4f7f\u7528\u200b\u5c40\u90e8\u200bAttention\u200b\u63d0\u5347\u200bLong Dependency\u200b\u7684\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u9884\u6d4b\u200b\u8bd5\u200b\u5229\u7528\u200b\u5c40\u90e8\u200bAttention\u200b\u80fd\u591f\u200b\u63d0\u5347\u200b\u6a21\u578b\u200b\u5916\u200b\u63a8\u6027\u200b\uff0c\u200b\u63d0\u5347\u200bLong Dependency\u200b\u6548\u679c\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/YaRN.html","title":"YaRN","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/YaRN.html#yarn","title":"YaRN","text":"<p>\u200b\u8bba\u6587\u200b\uff1aYaRN: Efficient ContextWindow Extension of Large Language Models YaRN: Yet another RoPE extensioN method Github: yarn Nous Research &amp; EleutherAI &amp; University of Geneva, 2023 Aug, ICLR 2024</p>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/YaRN.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>YARN = NTK-by-parts + attention scaling</li> <li>\\(f^{'}(x,m, \\theta_i)\\)</li> <li>\u200b\u5bf9\u200bAttention\u200b\u5206\u6bcd\u200b\u4e58\u4ee5\u200b\u4e86\u200b\\(t\\)\uff0c\u200b\u53ef\u200b\u7406\u89e3\u200b\u4e3a\u200b\u5bf9\u200b\\(q\\)\u200b\u548c\u200b\\(k\\)\u200b\u5747\u200b\u8fdb\u884c\u200b\u6e29\u5ea6\u200b\u56e0\u5b50\u200b \\(\\frac{1}{\\sqrt{t}} = 1 + 0.1 \\ln s\\) \u200b\u7684\u200b\u7f29\u653e\u200b\uff0c\\(s = \\max(1, l/L_{train})\\)</li> <li>\u200b\u56e0\u4e3a\u200bRoPE\u200b\u5177\u6709\u200b\u957f\u5ea6\u200b\u8870\u51cf\u200b\u7279\u6027\u200b\uff0c\u200b\u5f53\u200b\u63d2\u503c\u200b\u540e\u200b\u76f8\u5bf9\u200b\u8ddd\u79bb\u200b\u4f1a\u200b\u51cf\u5c0f\u200b\uff08\u200b\u63d2\u503c\u200b\u540e\u200b\\(/s\\)\u200b\u503c\u4f1a\u200b\u53d8\u5927\u200b\uff0c\u200b\u76f8\u5173\u6027\u200b\u589e\u5927\u200b\uff09\uff0c\u200b\u56e0\u6b64\u200b\u9700\u8981\u200b\u901a\u8fc7\u200b\u4e58\u4ee5\u200b \\(\\frac{1}{\\sqrt{t}}\\)\u200b\u8fdb\u884c\u200b\u5e73\u6ed1\u200b\u8fd8\u539f\u200b\u7f29\u653e\u200b</li> <li>\u200b\u4e0d\u200b\u6539\u53d8\u200b\u5411\u91cf\u200b\u6a21\u957f\u200b\uff0c\u200b\u4f46\u662f\u200b\u6539\u53d8\u200b\u5411\u91cf\u200b\u5939\u89d2\u200b\uff0c\u200b\u5373\u200b \\(q^Tk\\approx d\\cos(q, k)\\)</li> <li>\u200b\u5728\u200b\u5fae\u8c03\u200b\u548c\u200b\u975e\u200b\u5fae\u8c03\u200b\u573a\u666f\u200b\u4e0b\u5747\u200b\u8d85\u8fc7\u200b\u4ee5\u5f80\u200b\u6240\u6709\u200b\u65b9\u6cd5\u200b</li> <li>\u200b\u53ea\u200b\u9700\u8981\u200b\u5bf9\u200b\u4e0d\u5230\u200b\u539f\u59cb\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u7684\u200b0.1%\u200b\u8fdb\u884c\u200b\u5fae\u8c03\u200b\uff0cYaRN\u200b\u7684\u200b\u4e0a\u4e0b\u200b\u7a97\u53e3\u200b\u62d3\u5c55\u200b\u5230\u200b\u6700\u200b\u5148\u8fdb\u200b\u7684\u200b\u6027\u80fd\u200b</li> </ul> <p>YaRN\u200b\u901a\u8fc7\u200b\u4e09\u4e2a\u200b\u5173\u952e\u200b\u673a\u5236\u200b\u89e3\u51b3\u200b\u4f4d\u7f6e\u200b\u5916\u200b\u63a8\u200b\u95ee\u9898\u200b</p> <ol> <li>dynamic-NTK \u200b\u63d2\u503c\u200b\uff0c\u200b\u52a8\u6001\u200b\u8c03\u6574\u200bRoPE\u200b\u57fa\u9891\u200b\uff0c\u200b\u5e73\u8861\u200b\u9ad8\u9891\u200b\uff08\\(l \\gt L_{train}\\)\uff09\u3001\u200b\u4f4e\u9891\u200b\u4fe1\u606f\u200b\uff08\\(l \\lt L_{train}\\)\uff09\uff0c\u200b\u7b26\u5408\u200b\u52a8\u6001\u200b\u8c03\u6574\u200b\u7279\u6027\u200b  </li> <li>\u200b\u52a8\u6001\u200b\u6e29\u5ea6\u200b\u7f29\u653e\u200b\uff0c\u200b\u81ea\u200b\u9002\u5e94\u200b\u8c03\u6574\u200b\u6ce8\u610f\u529b\u200b\u5206\u6570\u200blogits\uff0c \\(\\frac{1}{\\sqrt{t}} = 1 +\\frac{\\log \\alpha}{d} \\ln s\\)</li> <li> <p>\u200b\u8870\u51cf\u200b\u8865\u507f\u200b\uff0c\u200b\u4fdd\u62a4\u200b\u5c40\u90e8\u200b\u6ce8\u610f\u529b\u200b\u6a21\u5f0f\u200b\uff0c\u200b\u5373\u200b\u5bf9\u200b\u4f4e\u7ef4\u200b\u9ad8\u9891\u200b\u90e8\u5206\u200b\u9010\u6e10\u200b\u5f00\u653e\u200b\uff0c\u200b\u4f7f\u5f97\u200b\u968f\u200b\u7ef4\u5ea6\u200b\u589e\u52a0\u200b\uff0c\u200b\u9010\u6b65\u200b\u6291\u5236\u200b\u9ad8\u9891\u200b\uff0c\u200b\u9632\u6b62\u200b\u7531\u4e8e\u200b\u65cb\u8f6c\u200b\u8fc7\u5feb\u200b\u5bfc\u81f4\u200b\u76f8\u90bb\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b\u76f8\u4f3c\u200b\u5ea6\u8fc7\u200b\u5c0f\u200b</p> \\[ \\begin{aligned}     \\lambda_i =&amp; 1 - \\gamma \\frac{i}{d/2}, 0 \\le i \\lt d/2 \\\\     \\theta_i^{'} =&amp; \\lambda_i\\cdot \\theta_i \\end{aligned} \\] <p>\u200b\u5efa\u8bae\u200b\u53d6\u503c\u200b\uff0c\u200b\u5c0f\u200b\u6a21\u578b\u200b<code>d &lt;= 2556</code>\uff0c\u03b3=0.05<sub>0.1\uff1b\u200b\u5927\u200b\u6a21\u578b\u200b<code>d &gt; 256</code>\uff0c\u03b3=0.1</sub>0.15</p> </li> <li> <p> Attention softmax\u200b\u540e\u200b\u9664\u4ee5\u200b\\(\\sqrt{d_h}\\)\u200b\u662f\u56e0\u4e3a\u200b\u6743\u91cd\u200b\u77e9\u9635\u200b\u4e2d\u200b\u6bcf\u4e2a\u200b\u5143\u7d20\u200b\u90fd\u200b\u662f\u200b\u901a\u8fc7\u200b\u4e24\u4e2a\u200b(d_h, 1)\u200b\u5404\u200b\u7ef4\u5ea6\u200b\u4e3a\u200b\u72ec\u7acb\u200b\u540c\u200b\u5206\u5e03\u200b\u7684\u200b\u5747\u503c\u200b\u4e3a\u200b0\u200b\u65b9\u5dee\u200b\u4e3a\u200b1\u200b\u7684\u200b\u5411\u91cf\u200b\u76f8\u4e58\u200b\u5f97\u5230\u200b\u7684\u200b\uff0c\u200b\u57fa\u4e8e\u200b\u6b63\u6001\u5206\u5e03\u200b\u7d2f\u52a0\u200b\u540e\u200b\u7684\u200b\u6807\u51c6\u5dee\u200b\u516c\u5f0f\u200b\u53ef\u77e5\u200b\u8be5\u503c\u200b\u65b9\u5dee\u200b\u53d8\u4e3a\u200b\\(\\sqrt{d_h}\\)\uff0c\u200b\u56e0\u6b64\u200b\u6267\u884c\u200b\u8be5\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u82e5\u200b\u4e0d\u200b\u9664\u4ee5\u200b\\(\\sqrt{d_h}\\)\uff0c\u200b\u6839\u636e\u200bsoftmax\u200b\u51fd\u6570\u200b\u66f2\u7ebf\u200b\uff0csoftmax\u200b\u7ed3\u679c\u200b\u8868\u73b0\u200b\u66f4\u200b\u503e\u5411\u200b\u4e8e\u200bone-hot\u200b\u5206\u5e03\u200b\uff0c\u200b\u4f1a\u200b\u5e26\u6765\u200b\u68af\u5ea6\u200b\u6d88\u5931\u200b\u95ee\u9898\u200b</p> </li> <li> <p>truncated normal\u200b\u7684\u200b\u57fa\u4e8e\u200b\u6b63\u6001\u5206\u5e03\u200b \\(\\mathcal{N}(\\mu, \\sigma^2)\\)\uff0c\u200b\u5bf9\u4e8e\u200b\u5728\u200b\\([u-2\\sigma, u+2\\sigma]\\)\u200b\u8303\u56f4\u200b\u5185\u200b\u91c7\u6837\u200b\u7ed3\u679c\u200b\u4fdd\u7559\u200b\uff0c\u200b\u5176\u200b\u5747\u503c\u200b\u4e3a\u200b\\(\\mu\\)\uff0c\u200b\u65b9\u5dee\u200b\u4e3a\u200b</p> \\[ \\gamma = \\frac{\\int_{-2}^2 e^{-x^2/2}x^2 dx}{\\int_{-2}^2 e^{-x^2/2} dx} = 0.7737413 \\] </li> <li> <p>\u200b\u82e5\u200b\u8981\u200b\u5f97\u5230\u200b\u65b9\u5dee\u200b\u4e3a\u200b\\(\\sigma^2\\) \u200b\u91c7\u6837\u200b\u7ed3\u679c\u200b\uff0c\u200b\u9700\u8981\u200b\u5bf9\u200b\u4f20\u5165\u200b\u7684\u200b\u6807\u51c6\u5dee\u200b\u6267\u884c\u200b \\(\\sigma *= \\frac{1}{\\sqrt{\\gamma}} = 1.1368472\\sigma\\)</p> </li> <li>https://spaces.ac.cn/archives/8620</li> <li>https://spaces.ac.cn/archives/8823</li> <li>https://spaces.ac.cn/archives/9948</li> <li>https://spaces.ac.cn/archives/9859</li> </ol> <p>Attention\u200b\u673a\u5236\u200b</p> \\[ \\begin{aligned}     o_i = \\sum_{j=1}^n a_{i, j} v_j \\\\     a_{i,j} = \\frac{e^{\\lambda q_i^T k_j}}{\\sum_{j=1}^n e^{\\lambda q_i^T k_j}} \\end{aligned} \\] <ul> <li>\u200b\u6b63\u5e38\u200b\u60c5\u51b5\u200b\u4e0b\u200b \\(\\lambda = \\frac{1}{\\sqrt{d_h}}\\)</li> <li>\u200b\u4e3a\u4e86\u200b\u4f7f\u5f97\u200b\u6a21\u578b\u200b\u7ed3\u679c\u200b\u80fd\u591f\u200b\u66f4\u597d\u200b\u5730\u200b\u6cdb\u5316\u200b\u5230\u200b\u66f4\u200b\u5927\u200b\u957f\u5ea6\u200b\uff0cAttention\u200b\u673a\u5236\u200b\u5728\u200b\u62d3\u5c55\u200b\u65f6\u200b\u5e94\u8be5\u200b\u4f7f\u5f97\u200b\\(a_{i,j}\\) \u200b\u5c3d\u91cf\u200b\u5177\u5907\u200b\u71b5\u200b\u4e0d\u53d8\u6027\u200b\uff08\u200b\u5bf9\u200b\u957f\u5ea6\u200bn\u200b\u4e0d\u200b\u654f\u611f\u200b\uff09\uff0c\u200b\u5373\u200b \\(H_i = -\\sum a_{i, j} \\log a_{i, j}\\)</li> <li>\u200b\u6240\u6709\u200b\u6ce8\u610f\u529b\u200b\u90fd\u200b\u96c6\u4e2d\u200b\u5728\u200b\u4e00\u4e2a\u200btoken\u200b\u71b5\u200b \\(H_i = 0\\)\uff0c\u200b\u6ce8\u610f\u529b\u200b\u5747\u5300\u5206\u5e03\u200b\u5728\u200b\u6240\u6709\u200btoken\u200b\u4e0a\u200b \\(H_i = -\\frac{1}{n}\\log \\frac{1}{n} = \\log n\\)</li> <li>\u200b\u8fdb\u4e00\u6b65\u200b\u62c6\u89e3\u200b\\(H_i\\)</li> </ul> \\[ \\begin{aligned}     H_i =&amp; -\\sum_{j=1}^n a_{i, j} \\log a_{i, j} \\\\     =&amp; -\\sum_{j=1}^n  \\frac{e^{\\lambda q_i^T k_j}}{\\sum_{j=1}^n e^{\\lambda q_i^T k_j}} \\log \\frac{e^{\\lambda q_i^T k_j}}{\\sum_{j=1}^n e^{\\lambda q_i^T k_j}} \\\\     =&amp; \\frac{\\sum \u200b\u5b50\u200b \\log \u200b\u6bcd\u200b}{\u200b\u6bcd\u200b} - \\frac{\\sum \u200b\u5b50\u200b \\log \u200b\u5b50\u200b}{\u200b\u6bcd\u200b}= \\log \u200b\u6bcd\u200b - \\frac{\\sum \u200b\u5b50\u200b \\log \u200b\u5b50\u200b}{\u200b\u6bcd\u200b} \\\\     =&amp; \\log \\sum_{j=1}^n e^{\\lambda q_i^T k_j} - \\frac{\\sum_{j=1}^n e^{\\lambda q_i^T k_j}(\\lambda q_i^T k_j)}{\\sum_{j=1}^n e^{\\lambda q_i^T k_j}} \\end{aligned} \\] <ul> <li>\u200b\u5bf9\u4e8e\u200b \\(\\sum_{j=1}^n e^{\\lambda q_i^T k_j} = n\\times \\frac{1}{n} \\sum_{j=1}^n e^{\\lambda q_i^T k_j} \\approx n \\mathbb{E}_j[e^{\\lambda q_i^T k_j}]\\)</li> </ul> \\[ H_i \\approx \\log n \\mathbb{E}_j[e^{\\lambda q_i^T k_j}] - \\frac{\\lambda \\mathbb{E}_j[e^{\\lambda q_i^T k_j}(q_i^Tk_j)]}{\\mathbb{E}_j[e^{\\lambda q_i^T k_j}]} \\] <ul> <li>\u200b\u4e00\u822c\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\\(q_i, k_j\\) \u200b\u90fd\u200b\u662f\u200b\u7ecf\u8fc7\u200bLN + Dense\u200b\u5c42\u200b\u5f97\u6765\u200b\uff0c\u200b\u800c\u200b\u540e\u8005\u200b\u63a5\u8fd1\u200b\u6b63\u4ea4\u53d8\u6362\u200b\uff0c\u200b\u56e0\u6b64\u200b\u53ef\u4ee5\u200b\u8fd1\u4f3c\u200b\u5047\u8bbe\u200b \\(q_i, k_j\\) \u200b\u90fd\u200b\u662f\u200b\u6a21\u957f\u200b\u4e3a\u200b \\(\\sqrt{d_h}\\) \u200b\u7684\u200b\u5411\u91cf\u200b\uff0c\u200b\u6240\u4ee5\u200b \\(q_i^Tk_j = d\\cos(q_i, k_j)\\)\uff0c\u200b\u5047\u8bbe\u200b\\(k_j\\)\u200b\u5747\u5300\u5206\u5e03\u200b\u5728\u200b\u5411\u91cf\u200b\u7a7a\u95f4\u200b\u5185\u200b\uff0c\u200b\u90a3\u4e48\u200b\u5bf9\u200b\\(k_j\\)\u200b\u7684\u200b\u671f\u671b\u200b\u53ef\u4ee5\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u5bf9\u200b \\(q_i, k_j\\) \u200b\u5939\u89d2\u200b\u4f59\u5f26\u200b\u503c\u200b\u7684\u200b\u671f\u671b\u200b</li> </ul> \\[ H_i \\approx \\log n + \\log \\mathbb{E}_{\\theta} e^{\\lambda d\\cos \\theta} - \\frac{\\lambda d \\mathbb{E}_{\\theta}[e^{\\lambda d\\cos \\theta}\\cos \\theta]}{\\mathbb{E}_{\\theta}[e^{\\lambda d\\cos \\theta}]} \\] <p>\u200b\u62c9\u666e\u62c9\u65af\u200b\u8fd1\u4f3c\u200b\u53ef\u200b\u5f97\u200b, https://spaces.ac.cn/archives/7695#%E7%BB%93%E6%9E%9C%E5%AF%B9%E6%AF%94</p> \\[ H_i \\approx \\log n - \\frac{1}{2}\\ln \\frac{\\sqrt{5} + 1}{2} = \\log n -0.24\\lambda d \\] <ul> <li>\u200b\u4e3a\u4e86\u200b\u62b5\u6d88\u200b\u957f\u5ea6\u200b\\(n\\)\u200b\u7684\u200b\u5f71\u54cd\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u8ba9\u200b \\(\\log n - 0.24\\lambda d  =0\\)\uff0c\u200b\u5373\u200b\\(\\lambda \\approx \\frac{\\log n}{0.24 d} =  \\frac{\\log s + \\log L}{0.24 d}\\)\uff0c\u200b\u53ef\u4ee5\u200b\u5f15\u7533\u4e3a\u200b \\(\\lambda = \\frac{k}{d} \\log n\\) </li> <li> <p>\u200b\u6b64\u65f6\u200b\u53ef\u200b\u8868\u793a\u200b\u4e3a\u200b \\(\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{k \\log n}{d} QK^T\\right)\\)\uff0c\u200b\u5bf9\u4e8e\u200b\u539f\u59cb\u200b\u957f\u5ea6\u200b\\(L\\)\uff0c\u200b\u5373\u200b \\(\\frac{k\\log L}{d} = \\frac{1}{\\sqrt{d}}\\)\uff0c\\(k=\\frac{\\sqrt{d}}{\\log L}\\)\uff0c\u200b\u91cd\u65b0\u200b\u5e26\u5165\u200b\u516c\u5f0f\u200b\u5f97\u6b64\u200b\\(\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{\\log_L n}{\\sqrt{d}} QK^T\\right)\\)\uff0c\u200b\u5bf9\u4e8e\u200bcontext window\u200b\u62d3\u5c55\u200b\\(L'=sL\\)\uff0c\\(\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{\\log_L sL'}{\\sqrt{d}} QK^T\\right) = \\left(\\frac{\\log_L s + 1}{\\sqrt{d}} QK^T\\right)\\)</p> </li> <li> <p>yarn\u200b\u4e2d\u200b \\(\\frac{1}{t}=(0.1\\log s + 1)^2 \\approx 0.2\\log s + 1\\) </p> </li> <li>\u200b\u63a8\u5bfc\u200b\u503c\u200b \\(\\log_L s +1 = \\frac{\\ln s}{\\ln L} + 1\\)</li> <li>\u200b\u5f53\u200bL\u200b\u4e3a\u200b2K\u200b\u65f6\u200b\uff0c\u200b\u63a8\u5bfc\u200b\u503c\u200b\\(\\approx 0.13\\ln s + 1\\)\uff1b\u200b\u5f53\u200bL\u200b\u4e3a\u200b4K\u200b\u65f6\u200b\uff0c\u200b\u63a8\u5bfc\u200b\u503c\u200b\\(\\approx 0.12\\ln s + 1\\)</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/ntk-aware.html","title":"Ntk aware","text":"<ul> <li>https://spaces.ac.cn/archives/9948</li> <li>https://www.cnblogs.com/mudou/p/18309199#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86%E4%BB%8E%E8%BF%9B%E5%88%B6%E8%A1%A8%E7%A4%BA%E8%B0%88%E5%88%B0%E7%9B%B4%E6%8E%A5%E5%A4%96%E6%8E%A8%E7%BA%BF%E6%80%A7%E5%86%85%E6%8F%92%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2</li> <li>https://spaces.ac.cn/archives/9948#%E8%BD%AC%E5%9C%88%E8%A7%86%E8%A7%92</li> <li>https://blog.csdn.net/v_JULY_v/article/details/135072211  </li> <li>https://www.cnblogs.com/mudou/p/18309199#%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86-%E4%BB%8Entk-awarentk-by-parts%E5%88%B0dynamic-ntk%E6%8F%92%E5%80%BC  </li> <li>https://blog.csdn.net/z551646/article/details/140494221</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/ntk-aware.html#ntk-aware-scaled-rope","title":"NTK-aware Scaled RoPE","text":"<p>NTK-aware\u200b\u662f\u200b\u4e00\u79cd\u200b\u53d7\u200b\u795e\u7ecf\u200b\u6b63\u5207\u200b\u6838\u200b (Neural Tangent Kernel) \u200b\u7406\u8bba\u200b\u542f\u53d1\u200b\u7684\u200b\u52a8\u6001\u200b\u63d2\u503c\u200b\u65b9\u6848\u200b\uff0c\u200b\u901a\u8fc7\u200b\u975e\u200b\u5747\u5300\u200b\u7ef4\u5ea6\u200b\u7f29\u653e\u200b\uff08\u200b\u8f6c\u6362\u200b\u8868\u8fbe\u200b\u8fdb\u5236\u200b\uff09\uff0c\u200b\u907f\u514d\u200b\u76f4\u63a5\u200b\u7ebf\u6027\u200b\u5185\u200b\u63d2\u200b\u65f6\u200b\u9ad8\u9891\u200b\u7ef4\u5ea6\u200b\uff08e.g., \\(m' = m/k\\)\uff09\u200b\u7684\u200b\u65cb\u8f6c\u200b\u89d2\u5ea6\u200b\u53d8\u5316\u200b\u8fc7\u5927\u200b\uff08\u200b\u7c92\u5ea6\u200b\u8fc7\u200b\u5c0f\u200b\uff0c\u200b\u63d2\u5165\u200b\u96be\u5ea6\u200b\u9ad8\u200b\uff09\uff0c\u200b\u7834\u574f\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b\u4fe1\u606f\u200b\u7684\u200b\u6709\u6548\u200b\u63d2\u5165\u200b\u3002</p>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/ntk-aware.html#_1","title":"\u539f\u7406\u200b\uff1a\u200b\u8fdb\u5236\u200b\u8868\u8fbe\u200b\u8f6c\u6362","text":"\\[ \\begin{aligned}     f'(x, m, \\theta_i) =&amp; f\\left(x, m, h\\left(\\theta_i\\right)\\right) \\\\     h(\\theta_i) =&amp; (b\\lambda)^{-2*i/d} \\\\     \\lambda =&amp; k ^{\\frac{d}{d-2}} \\\\     k =&amp; \\frac{L^{'}}{L} \\end{aligned} \\] <ol> <li> <p>\u200b\u8f6c\u6362\u200b\u8868\u8fbe\u200b\u8fdb\u5236\u200b\uff1a3\u200b\u4f4d\u200b\u5341\u8fdb\u5236\u200b\u6700\u200b\u591a\u200b\u53ef\u4ee5\u200b\u8868\u793a\u200b0~999\uff0c\u200b\u82e5\u200b\u4ecd\u200b\u60f3\u200b\u4f7f\u7528\u200b\u76f8\u540c\u200b\u4f4d\u200b\u8868\u8fbe\u200b\u66f4\u5927\u200b\u6570\u503c\u200b\u8303\u56f4\u200b\uff0c\u200b\u53ef\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u66f4\u200b\u5927\u200b\u8fdb\u5236\u200b\u8868\u793a\u200b\uff0ce.g. <code>749==0x2ED</code>\uff0c\u200b\u6b64\u65f6\u200b\u9ad8\u4f4d\u200b\u81f3\u200b\u4f4e\u4f4d\u200b\u8fed\u4ee3\u200b\u5bf9\u200b\u4f59\u6570\u200b\u6267\u884c\u200b\u4e86\u200b \\(\\frac{m}{\\lfloor b^{i-1}\\rfloor}\\) \u200b\u64cd\u4f5c\u200b</p> <p>\u200b\u4ee3\u4ef7\u200b\u662f\u200b\u6bcf\u4e2a\u200b\u6570\u503c\u200b\u4f4d\u200b\u8868\u793a\u200b\u8303\u56f4\u200b\u589e\u5927\u200b\uff0c\u200b\u7c7b\u63a8\u200b\u81f3\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b\u5373\u200b\u5404\u200b\u7ef4\u5ea6\u200b\u9700\u200b\u805a\u5408\u200b\u7684\u200b\u4fe1\u606f\u200b\u8981\u6c42\u200b\u66f4\u200b\u591a\u200b</p> </li> <li> <p>RoPE\u200b\u4e0e\u200b\u8fdb\u5236\u200b\u8868\u8fbe\u200b\uff0c\u200b\u5728\u200bRoPE\u200b\u4e2d\u200b\u4f4d\u7f6e\u200b\\(m\\)\u200b\u7f16\u7801\u200b\u5982\u4e0b\u200b\uff0c\u200b\u7531\u4e8e\u200b <code>sin/cos</code> \u200b\u4e3a\u200b\u5468\u671f\u51fd\u6570\u200b\uff0c\u200b\u5176\u200b\u9ad8\u4f4d\u200b\u81f3\u200b\u4f4e\u4f4d\u200b\u53ef\u200b\u89c6\u4f5c\u200b\u5bf9\u200b\u4f4d\u7f6e\u200b \\(m\\) \u200b\u7684\u200b\\(\\frac{d}{2}\\)\u200b\u4f4d\u200b\\(\\beta\\)\u200b\u8fdb\u5236\u200b\u5316\u200b\u8868\u793a\u200b</p> \\[ \\left[ \\cos\\left(\\frac{m}{\\beta^{0}}\\right), \\sin\\left(\\frac{m}{\\beta^0}\\right), \\cos\\left(\\frac{m}{\\beta^{1}}\\right), \\sin\\left(\\frac{m}{\\beta^1}\\right), \\cdots, \\cos\\left(\\frac{m}{\\beta^{d/2-1}}\\right), \\sin\\left(\\frac{m}{\\beta^{d/2-1}}\\right) \\right] \\] </li> <li> <p>RoPE\u200b\u4e0e\u200b\u8fdb\u5236\u200b\u8f6c\u6362\u200b\uff0c\u200b\u5b9e\u9645\u200bRoPE\u200b\u4e2d\u200b \\(\\theta_{m, i} = \\frac{m}{b^{2*i/d}}, i \\in \\{0, 1, \\dots, d/2-1\\}\\)\uff0c\u200b\u8f6c\u6362\u200b\u8868\u8fbe\u200b\u8fdb\u5236\u200b\u540e\u200b\u4f4d\u7f6e\u200b \\(m\\) \u200b\u7f16\u7801\u200b \\(\\theta_{m, i}' = \\frac{m}{(b \\lambda )^{2*i/d}}\\)\u200b\u7684\u200b\u4f4e\u200b\u3001\u200b\u9ad8\u9891\u200b\u90e8\u5206\u200b\u6709\u200b\u4e0d\u540c\u200b\u8868\u73b0\u200b\uff1a</p> <ul> <li>\u200b\u4f4e\u9891\u200b\uff08\u200b\u9ad8\u4f4d\u200b\uff09\uff1a\\(\\theta'_{m, d/2-1} = \\frac{m/\\lambda^{(d-2)/d}}{b^{(d-2)/d}}= \\frac{m/k}{b^{(d-2)/d}}\\)\uff0c\u200b\u5bf9\u200b \\(m\\) \u200b\u4f4e\u9891\u200b\u90e8\u5206\u200b\u8fdb\u884c\u200b\u4e86\u200b\u5185\u200b\u63d2\u200b\u64cd\u4f5c\u200b</li> <li>\u200b\u9ad8\u9891\u200b\uff08\u200b\u4f4e\u4f4d\u200b\uff09\uff1a\\(\\theta'_{m, 0} = \\frac{m}{1}=m\\)\uff0c\u200b\u5bf9\u200b \\(m\\) \u200b\u9ad8\u9891\u200b\u90e8\u5206\u200b\u8fdb\u884c\u200b\u4e86\u200b\u76f4\u63a5\u200b\u5916\u200b\u63a8\u200b\u64cd\u4f5c\u200b</li> </ul> <ul> <li>\u200b\u4f4e\u200b\u3001\u200b\u9ad8\u9891\u200b\u90e8\u5206\u200b\u51fa\u73b0\u200b\u4e86\u200b\u5dee\u5f02\u5316\u200b\u975e\u200b\u5747\u5300\u200b\u7f29\u653e\u200b\u73b0\u8c61\u200b\uff0c\u200b\u5177\u4f53\u200b\u503e\u5411\u200b\u4e3a\u200b\u9ad8\u9891\u200b\u5916\u200b\u63a8\u200b\uff0c\u200b\u4f4e\u9891\u200b\u5185\u200b\u63d2\u200b\uff0c\u200b\u5373\u200b\u4f4e\u9891\u200b\u90e8\u5206\u200b\u8f83\u4e3a\u200b\u5bbd\u677e\u200b\uff0c\u200b\u9002\u5408\u200b\u63d2\u503c\u200b\uff0c\u200b\u9ad8\u9891\u200b\u8f83\u4e3a\u200b\u5bc6\u96c6\u200b\uff0c\u200b\u4f4d\u7f6e\u200b\u4fe1\u606f\u200b\u63d2\u5165\u200b\u540e\u200b\u8fc7\u4e8e\u200b\u62e5\u6324\u200b\uff0c\u200b\u963b\u788d\u200b\u89e3\u7801\u200b</li> <li><code>context_window</code> \u200b\u62d3\u5c55\u200b\u500d\u6570\u200b \\(k=\\lambda^{(d-2)/d}\\)\uff0c\u200b\u56e0\u6b64\u200b\u5b9e\u9645\u200b\u5e94\u7528\u200b\u4e2d\u5e38\u200b\u901a\u8fc7\u200b\u9884\u5b9a\u200b\u4e49\u200b\u62d3\u5c55\u200b\u500d\u6570\u200b\u8ba1\u7b97\u200b \\(\\lambda = k^{d/(d-2)}\\)</li> <li>\u200b\u8f6c\u6362\u200b\u540e\u200b\u7684\u200b\u8fdb\u5236\u200b \\(b' = b\\lambda^{d/(d-2)}\\)</li> </ul> </li> <li> <p>\u200b\u4ee3\u7801\u200b\u5b9e\u73b0\u200b\uff1antk_scaled_init </p><pre><code>import transformers\n\nold_init = transformers.models.llama.modeling_llama.LlamaRotaryEmbedding.__init__\ndef ntk_scaled_init(self, dim, max_position_embeddings=2048, base=10000, device=None):\n     # \u200b\u62d3\u5c55\u200b\u500d\u6570\u200b k\n     a = 8\n     # m' = k*m\n     max_position_embeddings = 16384\n     # \u200b\u57fa\u4e8e\u200b\u62d3\u5c55\u200b\u500d\u6570\u200b\u8f6c\u6362\u200b\u8fdb\u5236\u200b\u8868\u8fbe\u200b lambda = k^{d/(d-2)}\n     base = base * a ** (dim / (dim-2)) #Base change formula\n\n     old_init(self, dim, max_position_embeddings, base, device)\n</code></pre><p></p> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/ntk-aware.html#dynamic-ntk","title":"Dynamic NTK","text":"<p>Dynamic NTK\u200b\u662f\u200bNTK-aware Scaled RoPE\u200b\u7684\u200b\u6539\u8fdb\u200b\u7248\u672c\u200b\uff0c\u200b\u57fa\u4e8e\u200b\u5f53\u524d\u200b\u8f93\u5165\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b\u52a8\u6001\u200b\u8c03\u6574\u200bRoPE\u200b\u7684\u200b\u9891\u7387\u200b\u57fa\u200b\uff0c\u200b\u907f\u514d\u200b\u56fa\u5b9a\u200b\u7f29\u653e\u200b\u6bd4\u4f8b\u200b\u5e26\u6765\u200b\u7684\u200b\u6f5c\u5728\u200b\u95ee\u9898\u200b\uff0c\u200b\u4ece\u800c\u200b\u5728\u200b\u77ed\u6587\u200b\u672c\u4e0a\u200b\u4fdd\u6301\u200b\u539f\u59cb\u200b\u6027\u80fd\u200b\uff0c\u200b\u5728\u200b\u957f\u200b\u6587\u672c\u200b\u4e0a\u200b\u5b9e\u73b0\u200b\u7a33\u5b9a\u200b\u62d3\u5c55\u200b\u3002</p>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/ntk-aware.html#_2","title":"\u80cc\u666f\u200b\u4e0e\u200b\u52a8\u673a","text":"<ol> <li>NTK-aware Scaled RoPE\u200b\u5c40\u9650\u6027\u200b \u200b\u901a\u8fc7\u200b\u56fa\u5b9a\u200b\u7f29\u653e\u200b\u500d\u6570\u200b\uff08e.g., \\(k = L_\\text{test} / L_\\text{train}\\)\uff09\u200b\u8c03\u6574\u200bRoPE\u200b\u7684\u200b\u9891\u7387\u200b\u57fa\u200b\\(b\\lambda\\)\uff0c\u200b\u4f7f\u5f97\u200b\u6a21\u578b\u200b\u5728\u200b\u66f4\u957f\u200b<code>context_window</code>\u200b\u4e0a\u200b\u4fdd\u6301\u200b\u8f83\u200b\u597d\u200b\u7684\u200b\u6027\u80fd\u200b\uff0c\u200b\u4f46\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u5b58\u5728\u200b\u4ee5\u4e0b\u200b\u4e24\u4e2a\u200b\u95ee\u9898\u200b<ul> <li> \u200b\u77ed\u6587\u200b\u672c\u200b\u6027\u80fd\u200b\u4e0b\u964d\u200b\uff0c\u200b\u5982\u200b\u56fa\u5b9a\u200b\u7f29\u653e\u200b\u500d\u6570\u200b \\(k\\) \u200b\u8fc7\u5927\u200b\uff0c\u200b\u5728\u200b\u5904\u7406\u200b\u77ed\u6587\u200b\u672c\u65f6\u200b\u65cb\u8f6c\u200b\u89d2\u200b\u53ef\u80fd\u200b\u8fc7\u5ea6\u200b\u538b\u7f29\u200b\uff0c\u200b\u5f71\u54cd\u200b\u6a21\u578b\u200b\u5bf9\u200b\u5c40\u90e8\u200b\u4f4d\u7f6e\u200b\u611f\u77e5\u200b\u80fd\u529b\u200b</li> <li> \u200b\u62d3\u5c55\u200b\u957f\u200b\u6587\u672c\u200b\u540e\u200b\u6548\u679c\u200b\u7a81\u7136\u200b\u8870\u51cf\u200b</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/ntk-aware.html#_3","title":"\u6539\u8fdb","text":"\\[ \\begin{aligned}     f'(x, m, \\theta_i) =&amp; f\\left(x, m, h\\left(\\theta_i\\right)\\right) \\\\     h(\\theta_i) =&amp; (b\\lambda)^{-2*i/d} \\\\     \\lambda =&amp; s ^{\\frac{d}{d-2}} \\\\     s =&amp; \\max(1, l_\\text{seq}/L_\\text{train}) \\end{aligned} \\] <ol> <li>\u200b\u52a8\u6001\u200b\u8c03\u6574\u200b\u7f29\u653e\u200b\u500d\u6570\u200b\uff0c\u200b\u57fa\u4e8e\u200b\u6bcf\u6b21\u200b\u8f93\u5165\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b\u52a8\u6001\u200b\u66f4\u65b0\u200b\u7f29\u653e\u200b\u500d\u6570\u200b \\(k=\\max(1, l_\\text{seq}/L_\\text{train})\\)\uff0c\u200b\u9632\u6b62\u200b\u6a21\u578b\u200b\u5728\u200b\u77ed\u6587\u200b\u672c\u200b\u573a\u666f\u200b\u4e0b\u200b\\(l_\\text{seq} \\le L_\\text{train}\\)\u200b\u51fa\u73b0\u200b\u6027\u80fd\u200b\u6298\u6263\u200b\uff0c\u200b\u957f\u200b\u6587\u672c\u200b\u573a\u666f\u200b\u4e0b\u200b\\(l_\\text{seq} \\ge L_\\text{train}\\)\u200b\u6548\u679c\u200b\u7a81\u7136\u200b\u8870\u51cf\u200b<ul> <li>\\(l \\le L_{train}\\)\uff0c\u200b\u4fdd\u6301\u200b\u539f\u6709\u200bRoPE\u200b\u4e0d\u53d8\u200b</li> <li>\\(l \\ge L_{train}\\)\uff0c\u200b\u4f7f\u7528\u200bNTK-aware Scaled RoPE \u200b\u8fdb\u884c\u200b <code>context_window</code> \u200b\u62d3\u5c55\u200b</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/ntk-aware.html#ntk-by-parts","title":"NTK-by-parts","text":"<p>NTK-by-Parts \u200b\u662f\u200b NTK-aware Scaled RoPE \u200b\u7684\u200b\u8fdb\u4e00\u6b65\u200b\u4f18\u5316\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u901a\u8fc7\u200b\u5bf9\u200b\u4e0d\u540c\u200b\u9891\u7387\u200b\u533a\u95f4\u200b\u5dee\u5f02\u5316\u200b\u7f29\u653e\u200b\uff08\u200b\u7c7b\u4f3c\u200b\u4e8e\u200bNTK-RoPE-fixed\uff09\uff0c\u200b\u89e3\u51b3\u200b\u957f\u200b\u5e8f\u5217\u200b\u62d3\u5c55\u200b\u65f6\u200b\u7684\u200b\u9ad8\u9891\u200b\u9707\u8361\u200b\u95ee\u9898\u200b\u3002</p>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/ntk-aware.html#_4","title":"\u80cc\u666f\u200b\u4e0e\u200b\u52a8\u673a","text":"<ol> <li>NTK-aware \u200b\u5c40\u9650\u6027\u200b\uff0c\u200b\u5bf9\u200b\u6240\u6709\u200b\u9891\u7387\u200b\u7ef4\u5ea6\u200b\u91c7\u7528\u200b\u7edf\u4e00\u200b\u7f29\u653e\u200b\u7b56\u7565\u200b\uff0c\u200b\u53ef\u80fd\u200b\u5bfc\u81f4\u200b<ul> <li>\u200b\u9ad8\u9891\u200b\u4fe1\u606f\u200b\u8fc7\u5ea6\u200b\u538b\u7f29\u200b\uff0c\u200b\u65cb\u8f6c\u200b\u89d2\u5ea6\u200b\u53d8\u5316\u200b\u8fc7\u5feb\u200b</li> <li>\u200b\u4f4e\u9891\u200b\u4fe1\u606f\u200b\u7f29\u653e\u200b\u4e0d\u8db3\u200b\uff0c\u200b\u96be\u4ee5\u200b\u6355\u83b7\u200b\u8d85\u957f\u200b\u7a0b\u200b\u4ee5\u6765\u200b</li> </ul> </li> <li> <p>Dynamic NTK\u200b\u5c40\u9650\u6027\u200b\uff0c\u200b\u672a\u200b\u533a\u5206\u200b\u4e0d\u540c\u200b\u9891\u7387\u200b\u533a\u95f4\u200b\uff0c\u200b\u53ef\u80fd\u200b\u65e0\u6cd5\u200b\u6700\u4f18\u200b\u5904\u7406\u200b\u8d85\u957f\u200b\u5e8f\u5217\u200b\u3002</p> </li> <li> <p>RoPE\u200b\u89d2\u901f\u5ea6\u200b\u4e0e\u200b\u6ce2\u957f\u200b\uff0c\u200b\u5728\u200bRoPE\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b\u4e2d\u200b\uff0c\u200b\u7279\u5f81\u200b\u7ef4\u5ea6\u200b \\(i\\) \u200b\u7684\u200b\u89d2\u901f\u5ea6\u200b \\(\\theta_i = \\frac{1}{b^{2*i/d}}\\)\uff0c\u200b\u6b64\u65f6\u200b\u8be5\u200b\u89d2\u901f\u5ea6\u200b\u4e0b\u200b\u53ef\u200b\u88ab\u200b\u8bad\u7ec3\u200b\u7684\u200b\u70b9\u6570\u200b\uff08\u200b\u5373\u200b\u6ce2\u957f\u200b\uff09\u200b\u4e3a\u200b\\(\\lambda_i = \\frac{2\\pi}{\\theta_i} = 2\\pi {b^{2*i/d}}\\)\uff0c\u200b\u4e0d\u540c\u200b\u7279\u5f81\u200b\u7ef4\u5ea6\u200b\u6ce2\u957f\u200b\u7279\u6027\u200b\u4e0d\u540c\u200b\uff1a</p> <ul> <li>\u200b\u4f4e\u7ef4\u200b\u7279\u5f81\u200b\u6ce2\u957f\u200b\u8f83\u200b\u5c0f\u200b\uff0c\u200b\u5145\u5206\u200b\u8bad\u7ec3\u200b\u5bf9\u5e94\u200b\u6240\u200b\u9700\u200b\u6700\u5c0f\u200b\u76f8\u5bf9\u200b\u957f\u5ea6\u200b\u8f83\u200b\u5c0f\u200b</li> <li>\u200b\u9ad8\u7ef4\u200b\u7279\u5f81\u200b\u6ce2\u957f\u200b\u8f83\u5927\u200b\uff0c\u200b\u5145\u5206\u200b\u8bad\u7ec3\u200b\u5bf9\u5e94\u200b\u6240\u200b\u9700\u200b\u6700\u5c0f\u200b\u76f8\u5bf9\u200b\u957f\u5ea6\u200b\u8f83\u5927\u200b</li> </ul> <ul> <li>\u200b\u76f8\u5bf9\u200b\u957f\u5ea6\u200b\u6781\u7aef\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u4e3a\u200b\\(L_\\text{train}-1\\)</li> <li>\u200b\u5e94\u7528\u200bPI\u200b\u7ebf\u6027\u63d2\u503c\u200b\u540e\u200b\uff0c\u200b\u6700\u5c0f\u200b\u76f8\u5bf9\u200b\u957f\u5ea6\u200b\u589e\u200b\u4e3a\u200b \\(k=L'/L\\) \u200b\u500d\u200b</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/ntk-aware.html#_5","title":"\u6539\u8fdb","text":"<p>\u200b\u57fa\u4e8e\u200b\u4e0a\u8ff0\u200b\u4e0d\u540c\u200b\u7279\u5f81\u200b\u7ef4\u5ea6\u200b\u6ce2\u957f\u200b\u548c\u200b\u5145\u5206\u200b\u8bad\u7ec3\u200b\u6240\u200b\u9700\u200b\u6700\u5c0f\u200b\u76f8\u5bf9\u200b\u957f\u5ea6\u200b\u7684\u200b\u5dee\u5f02\u6027\u200b\uff0c\u200b\u4ece\u200b\u4ee5\u4e0b\u200b\u8fdb\u884c\u200b\u4e86\u200b\u6539\u8fdb\u200b\uff1a</p> <ol> <li>\u200b\u5c06\u200bRoPE\u200b\u7684\u200b\u9891\u7387\u200b\u7ef4\u5ea6\u200b\u5212\u5206\u200b\u4e3a\u200b\u591a\u4e2a\u200b\u533a\u95f4\u200b\uff0c\u200b\u5982\u200b\u4f4e\u9891\u200b\u3001\u200b\u4e2d\u9891\u200b\u3001\u200b\u9ad8\u9891\u200b</li> <li>\u200b\u5bf9\u200b\u4e0d\u540c\u200b\u9891\u7387\u200b\u533a\u95f4\u200b\u5dee\u5f02\u5316\u200b\u7f29\u653e\u200b\uff0c\u200b\u91cd\u7f6e\u200b\u5404\u200b\u7ef4\u5ea6\u200b\u89d2\u901f\u5ea6\u200b \\(h(\\theta_i)\\)<ul> <li>\u200b\u9ad8\u9891\u200b-\u200b\u5927\u200b\u89d2\u901f\u5ea6\u200b-\u200b\u5c0f\u200b\u6ce2\u957f\u200b\uff0c\u200b\u5df2\u200b\u5145\u5206\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u5f31\u200b\u7f29\u653e\u200b\u6216\u200b\u4fdd\u6301\u200b\u539f\u6837\u200b\u76f4\u63a5\u200b\u5916\u200b\u63a8\u200b</li> <li>\u200b\u4f4e\u9891\u200b-\u200b\u5c0f\u200b\u89d2\u901f\u5ea6\u200b-\u200b\u5927\u200b\u6ce2\u957f\u200b\uff0c\u200b\u90e8\u5206\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u5185\u200b\u63d2\u5f3a\u200b\u7f29\u653e\u200b</li> <li>\u200b\u4e2d\u9891\u200b-\u200b\u4e2d\u200b\u89d2\u901f\u5ea6\u200b-\u200b\u4e2d\u6ce2\u957f\u200b\uff0ctrade-off</li> </ul> </li> <li> <p>\u200b\u907f\u514d\u200b\u9891\u7387\u200b\u533a\u95f4\u200b\u51b2\u7a81\u200b\uff0c\u200b\u4fdd\u6301\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b\u7684\u200b\u8fde\u7eed\u6027\u200b\uff0c\u200b\u907f\u514d\u200b\u7f29\u653e\u200b\u540e\u200b\u5dee\u5f02\u200b\u8fc7\u5927\u200b</p> \\[ \\begin{aligned}     f'(x, m, \\theta_i) =&amp; f\\left(x, m, h\\left(\\theta_i\\right)\\right) \\\\     \\gamma(r) =&amp; \\begin{cases}         0 &amp; \\text{if } r \\lt \\alpha \\\\         1 &amp; \\text{if } r \\gt \\beta \\\\         \\frac{r-\\alpha}{\\beta - \\alpha} &amp; \\text{otherwise} \\\\     \\end{cases} \\\\     h(\\theta_i) =&amp; \\left(1 - \\gamma\\left(r_i \\right)\\right)\\frac{\\theta_i}{k} + \\gamma\\left(r_i \\right) \\theta_i \\\\     r_i =&amp; \\frac{L_\\text{train}}{\\lambda_i} = \\frac{L_\\text{train}}{2\\pi {b^{2*i/d}}} \\end{aligned} \\] <ul> <li>\\(r_i\\) \u200b\u8868\u793a\u200b\u8bad\u7ec3\u200b\u957f\u5ea6\u200b\u4e0e\u200b\u7279\u5f81\u200b\u7ef4\u5ea6\u200b \\(i\\) \u200b\u7684\u200b\u6bd4\u7387\u200b</li> <li>\\(k=L'/L\\) \u200b\u4e3a\u200b\u62d3\u5c55\u200b\u500d\u6570\u200b\uff0c\u200b\u8868\u73b0\u200b\u4e3a\u200b\u7ebf\u6027\u63d2\u503c\u200b\u6bd4\u4f8b\u200b\uff0c\u200b\u4e5f\u200b\u5e38\u7528\u200b scale factor \\(s\\) \u200b\u8868\u793a\u200b</li> <li>\\(\\alpha=1, \\beta=32\\)</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/ntk-aware.html#yarn","title":"YaRN","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/pi.html","title":"Pi","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/pi.html#position-interpolation","title":"Position Interpolation","text":"<p>\u200b\u8bba\u6587\u200b\uff1aExtending Context Window Of Large Language Models Via Position Interpolation Github\uff1aExtend_Context_Window_Position_Interpolation Meta Platforms Inc., 2023 Jun, ACL 2024</p>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/pi.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<p>PI\u200b\u901a\u8fc7\u200b\u63d2\u503c\u200b\u65b9\u6cd5\u200b\u4e8c\u6b21\u200b\u8bad\u7ec3\u200bPLM\uff0c\u200b\u589e\u5927\u200b\u6a21\u578b\u200b\u7684\u200b<code>context_window</code>\u200b\u5904\u7406\u200b\u80fd\u529b\u200b</p> <ul> <li> \u200b\u53ea\u200b\u9700\u8981\u200b1000 steps\uff0c\u200b\u5373\u53ef\u200b\u5b9e\u73b0\u200b<code>context_window</code> \\(L^{'}\\) \u200b\u62d3\u5c55\u200b\uff0ce.g., LLaMA 2K -&gt; 32K</li> <li> PI\u200b\u6a21\u578b\u200b\u5728\u200b<code>original_context_window</code> \\(L\\) \u200b\u5185\u200b\u7684\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u548c\u200b\u5fae\u8c03\u200b\u524d\u200b\u6548\u679c\u200b\u76f8\u5f53\u200b</li> </ul> <p>\u200b\u7531\u4e8e\u200b\u7ebf\u6027\u63d2\u503c\u200b\u540e\u200b\u589e\u52a0\u200b\u4e86\u200b\u65b0\u200b\u7684\u200b\u5c0f\u6570\u200b\u7a7a\u95f4\u200b\uff0c\u200b\u800c\u200b\u6a21\u578b\u200b\u672a\u200b\u83b7\u53d6\u200b\u5c0f\u6570\u200b\u7a7a\u95f4\u200b\u7684\u200b\u76f8\u5bf9\u200b\u5927\u5c0f\u200b\uff0c\u200b\u56e0\u6b64\u200b\u9700\u8981\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u5fae\u8c03\u200b\u77eb\u6b63\u200b</p>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/pi.html#_2","title":"\u57fa\u672c\u539f\u7406","text":"\\[   f^{'}(x,m, \\theta_i)=f\\left( x, m/k, \\theta_i \\right) \\] <ul> <li>RoPE\u200b\u53ea\u200b\u5229\u7528\u200b\u4e86\u200b\u6574\u6570\u200b\u7c92\u5ea6\u200b\uff08e.g., 1 &lt; 2\uff09\uff0cPI\u200b\u8fdb\u4e00\u6b65\u200b\u4f7f\u7528\u200b\u4e86\u200b\u5c0f\u6570\u200b\u7c92\u5ea6\u200b\uff08e.g., 1 &lt; 1.5 &lt; 2\uff09  </li> <li>\u200b\u5185\u200b\u63d2\u200b\u500d\u6570\u200b \\(k=\\frac{L^{'}}{L}\\)</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/PE_patch/pi.html#evaluation","title":"Evaluation","text":"<ol> <li> <p>PI-FT\u200b\u5bf9\u6bd4\u200b\uff1aPI\u200b\u65b9\u6848\u200b(1000 steps) \u200b\u8f83\u200bFine-tune\u200b\u65b9\u6848\u200b(10000 steps)\u200b\u6548\u7387\u200b\u66f4\u9ad8\u200b\uff0c\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u66f4\u597d\u200b     </p> <p></p> <p></p> <p></p> </li> <li> <p>PI\u200b\u6a21\u578b\u200b\u5728\u200b<code>original_context_window</code>\u200b\u8868\u73b0\u200b\uff1aPI\u200b\u65b9\u6848\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u4e0e\u200b\u5fae\u8c03\u200b\u524d\u200b\u6548\u679c\u200b\u76f8\u5f53\u200b\uff0c\u200b\u4e14\u200bPI\u200b\u65b9\u6848\u200b\u5bf9\u200bSFT\u200b\u6837\u672c\u200b\u654f\u611f\u5ea6\u200b\u4e0d\u9ad8\u200b\uff08Row 2 on Pipe v.s. Row 5 RedPajama\uff09     </p> <p></p> </li> <li> <p>PI\u200b\u6a21\u578b\u200b\u6548\u679c\u200b\u4e0e\u200b\u8bad\u7ec3\u200bstep\u200b\u7684\u200b\u5173\u7cfb\u200b\uff1a\u200b\u53ea\u200b\u9700\u8981\u200b1000 steps\uff0c\u200b\u5373\u53ef\u200b\u5b9e\u73b0\u200b<code>context_window</code> \\(L^{'}\\) \u200b\u62d3\u5c55\u200b     </p> <p></p> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/RelativePE/RoPE.html","title":"RoPE","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/RelativePE/RoPE.html#rope","title":"RoPE","text":"<ul> <li>\u200b\u8bba\u6587\u200b\uff1aRoFormer: Enhanced Transformer with Rotary Position Embedding </li> <li>Github\uff1aroformer</li> <li>\u200b\u82cf\u5251\u6797\u200b 2021, Neurocomputing 2024</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/RelativePE/RoPE.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ol> <li> <p>Attentino\u200b\u673a\u5236\u200b\u4e2d\u200b\uff1a\u200b\u5728\u200b\u8ba1\u7b97\u200b\u6ce8\u610f\u529b\u200b\u5206\u6570\u200b\u4e4b\u524d\u200b\uff0c\u200b\u9700\u200b\u6839\u636e\u200bQuery\u200b\u548c\u200bKey\u200b\u5411\u91cf\u200b\u5bf9\u200bQuery\u200b\u6267\u884c\u200b\u76f8\u5bf9\u200b\u4f4d\u7f6e\u200b\u65cb\u8f6c\u200b </p> <p>RoPE\u200b\u4e0e\u200bValue\u200b\u5411\u91cf\u200b\u65e0\u5173\u200b</p> </li> <li> <p>\u200b\u8fdc\u8ddd\u79bb\u200b\u8870\u51cf\u200b\uff0c\u200b\u76f8\u5bf9\u200b\u8ddd\u79bb\u200b\u8d8a\u5927\u200b\u6ce8\u610f\u529b\u200b\u5206\u6570\u200b\u76f8\u5bf9\u200b\u8d8a\u5c0f\u200b</p> </li> <li> \u200b\u52a0\u5feb\u200b\u6a21\u578b\u200b\u7684\u200b\u8bad\u7ec3\u200b\u6536\u655b\u200b\u901f\u5ea6\u200b</li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/RelativePE/RoPE.html#rope_1","title":"RoPE","text":"<ol> <li> <p>\u200b\u4f4d\u7f6e\u200b\u5411\u91cf\u200b\u95f4\u200b\u4fdd\u6301\u200b\u4e58\u6027\u200b\u76f8\u5bf9\u200b\u5173\u7cfb\u200b\uff0c\u200b\u5373\u200b\\(\\langle f_q(x_m, m), f_k(x_n, n) \\rangle =g(x_m, x_n, n-m)\\)\uff0c RoPE\u200b\u8bbe\u8ba1\u200b\u4e86\u200b\u4ee5\u4e0b\u200b\u6ee1\u8db3\u200b\u4e0a\u8ff0\u200b\u5173\u7cfb\u200b\u7684\u200b \\(f\\) \u200b\u548c\u200b \\(g\\)</p> <ul> <li>\\(d=2\\) \u200b\u5f62\u5f0f\u200b</li> </ul> \\[ \\begin{aligned}     f_q(x_m, m) =&amp; e^{im\\theta}q_m =  \\begin{pmatrix}         \\cos m\\theta &amp; -\\sin m\\theta \\\\         \\sin m\\theta &amp; \\cos m\\theta      \\end{pmatrix}W^Q\\begin{pmatrix}         x_m^{(1)} \\\\         x_m^{(2)}     \\end{pmatrix}  \\\\     f_k(x_n, n) =&amp; e^{in\\theta}k_n= \\begin{pmatrix}         \\cos n\\theta &amp; -\\sin n\\theta \\\\         \\sin n\\theta &amp; \\cos n\\theta      \\end{pmatrix}W^K\\begin{pmatrix}         x_n^{(1)} \\\\         x_n^{(2)}     \\end{pmatrix} \\\\     g(x_m, x_n, n-m) =&amp; f_q(x_m, m)^Tf_k(x_n, n) \\\\     =&amp; q_m^T \\begin{pmatrix}         \\cos m\\theta &amp; \\sin m\\theta \\\\         -\\sin m\\theta &amp; \\cos m\\theta      \\end{pmatrix} \\begin{pmatrix}         \\cos n\\theta &amp; -\\sin n\\theta \\\\         \\sin n\\theta &amp; \\cos n\\theta      \\end{pmatrix} k_n \\\\     =&amp; q_m^T \\begin{pmatrix}         \\cos (n-m)\\theta &amp; -\\sin (n-m)\\theta \\\\         \\sin (n-m)\\theta &amp; \\cos (n-m)\\theta      \\end{pmatrix}  k_n \\\\     = &amp; q_m^T e^{i(n-m)\\theta} k_n \\end{aligned} \\] <ul> <li>\u200b\u62d3\u5c55\u200b\u81f3\u200b\u591a\u7ef4\u200b\u5f62\u5f0f\u200b\uff0c\u200b\u4e14\u200b\\(d\\%2==0\\)</li> </ul> \\[ \\begin{aligned}     R_{\\Theta, m}^d \\in \\mathbb{R}^{d\\times d} = \\begin{pmatrix}         \\cos m\\theta_0 &amp; -\\sin m\\theta_0 &amp; \\cdots &amp; 0 &amp; 0 \\\\         \\sin m\\theta_0 &amp; \\cos m\\theta_0 &amp; \\cdots &amp; 0 &amp; 0 \\\\         \\vdots &amp; \\vdots  &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\         0 &amp; 0 &amp;  \\cdots &amp; \\sin m\\theta_{d/2 - 1} &amp; \\cos m\\theta_{d/2 - 1} \\\\         0 &amp; 0 &amp;  \\cdots &amp; \\sin m\\theta_{d/2 - 1} &amp; \\cos m\\theta_{d/2 - 1} \\\\     \\end{pmatrix} \\end{aligned} \\] </li> <li> <p>\u200b\u4f4d\u7f6e\u200b\u4fe1\u606f\u200b\u6ce8\u5165\u200b\u4f18\u5316\u200b\uff1a\u200b\u7531\u4e8e\u200b\\(R_{\\Theta, m}^d\\) \u200b\u7684\u200b\u7a00\u758f\u200b\u6027\u200b\uff0c\u200b\u76f4\u63a5\u200b\u5e94\u7528\u200b\u77e9\u9635\u200b\u4e58\u6cd5\u200b\u6d6a\u8d39\u200b\u7b97\u529b\u200b\uff0c\u200b\u53ef\u200b\u4f18\u5316\u200b\u4e3a\u200b</p> \\[ \\begin{aligned}     R_{\\Theta, m}^d = \\begin{pmatrix}         x_0 \\\\         x_1 \\\\         x_2 \\\\         x_3 \\\\         \\vdots \\\\         x_{d-2} \\\\         x_{d-1}      \\end{pmatrix} \\otimes \\begin{pmatrix}         \\cos m\\theta_0 \\\\         \\cos m\\theta_0 \\\\         \\cos m\\theta_1 \\\\         \\cos m\\theta_1 \\\\         \\vdots \\\\         \\cos m\\theta_{d/2-1} \\\\         \\cos m\\theta_{d/2-1}      \\end{pmatrix} + \\begin{pmatrix}         -x_1 \\\\         x_0 \\\\         -x_3 \\\\         x_2 \\\\         \\vdots \\\\         -x_{d-1} \\\\         x_{d-2}      \\end{pmatrix} \\otimes \\begin{pmatrix}         \\sin m\\theta_0 \\\\         \\sin m\\theta_0 \\\\         \\sin m\\theta_1 \\\\         \\sin m\\theta_1 \\\\         \\vdots \\\\         \\sin m\\theta_{d/2-1} \\\\         \\sin m\\theta_{d/2-1}     \\end{pmatrix} \\end{aligned} \\] <p></p> <p></p> </li> </ol> <ul> <li>RoPE\u200b\u63a8\u5bfc\u200b\u8fc7\u7a0b\u200b\uff1a\u200b\u76f8\u5bf9\u200b\u4f4d\u7f6e\u200b\u4e3a\u200b\u3010n-m\u3011\u200b\u800c\u200b\u4e0d\u662f\u200b\u3010m-n\u3011</li> <li>RoPE\u200b\u76f8\u5f53\u4e8e\u200b\u5728\u200b\u8ba1\u7b97\u200b\\(q\\)\u200b\u4e0e\u200b\\(k\\)\u200b\u5185\u79ef\u200b\u524d\u200b\u5bf9\u200b\\(q\\)\u200b\u7684\u200b\u6bcf\u200b2\u200b\u4e2a\u200b\u7279\u5f81\u200b\uff08\u200b\u5404\u200b\u7279\u5f81\u200b\u7f29\u653e\u200b\u9891\u7387\u200b\u4e0d\u540c\u200b\uff09\u200b\u6267\u884c\u200b\u4e00\u6b21\u200b\u76f8\u5bf9\u200b\u4f4d\u7f6e\u200b\u4e3a\u200b\\(n-m\\)\u200b\u4e14\u200b\u4e0d\u200b\u6539\u53d8\u200b\u6a21\u957f\u200b\u7684\u200b\u65cb\u8f6c\u200b(\u200b\u672c\u8d28\u200b\u4e0a\u200b\u4e3a\u200b\u77e9\u9635\u200b\u76f8\u4e58\u200b\uff0c\u200b\u4f46\u200b\u7531\u4e8e\u200b\u77e9\u9635\u200b\u7a00\u758f\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u52a0\u6027\u200b\u5b9e\u73b0\u200b)\uff0c\u200b\u4e4b\u540e\u200b\u518d\u200b\u6267\u884c\u200b\u5185\u79ef\u200b\u8ba1\u7b97\u200b</li> <li>\\(\\theta_i = 10000 ^{-2i/d}\\)\uff0c\u200b\u4f4e\u200b\u7ef4\u5ea6\u200b\u7279\u5f81\u200b\u5927\u200b\u65cb\u8f6c\u200b\u89d2\u200b\u9ad8\u9891\u200b\u65cb\u8f6c\u200b\uff0c\u200b\u9ad8\u200b\u7ef4\u5ea6\u200b\u7279\u5f81\u200b\u5c0f\u200b\u65cb\u8f6c\u200b\u89d2\u200b\u4f4e\u9891\u200b\u65cb\u8f6c\u200b\uff08\u200b\u7c7b\u6bd4\u200b\u65f6\u949f\u200b\uff0c\u200b\u4f4e\u4f4d\u200b\u79d2\u9488\u200b\u6700\u5feb\u200b\uff0c\u200b\u9ad8\u4f4d\u200b\u65f6\u9488\u200b\u6700\u6162\u200b\uff09</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Position_Embedding/RelativePE/RoPE.html#long-term-decay","title":"Long-term Decay","text":"<ol> <li>\u200b\u8fdc\u8ddd\u79bb\u200b\u8870\u51cf\u200b\uff1a\u200b\u968f\u7740\u200b\u8ddd\u79bb\u200b\u7684\u200b\u589e\u52a0\u200b\uff08\u200b\u5047\u5b9a\u200bq\u200b\u5728\u200b\u4f4d\u7f6e\u200b0\uff0ck\u200b\u5728\u200b\u4f4d\u7f6e\u200b0~max_seq_len\uff09\uff0c\u200b\u5185\u79ef\u200b\u7ed3\u679c\u200b\u8868\u73b0\u200b\u5982\u4e0b\u200b\u56fe\u200b\u6240\u793a\u200b\uff0c\u200b\u6a21\u578b\u200b\u5bf9\u200b\u76f8\u5bf9\u200b\u4f4d\u7f6e\u200b\u7684\u200b\u654f\u611f\u5ea6\u200b\u4f1a\u200b\u9010\u6e10\u200b\u51cf\u5f31\u200b\uff08\u200b\u7b26\u5408\u200b\u81ea\u7136\u8bed\u8a00\u200b\u6587\u672c\u200b\u4e2d\u200b\u76f8\u90bb\u200b\u8bcd\u8bed\u200b\u95f4\u200b\u8bed\u4e49\u200b\u76f8\u5173\u200b\u76f8\u5bf9\u200b\u66f4\u5f3a\u200b\u7684\u200b\u7279\u6027\u200b\uff09\uff0c\u200b\u76f8\u5bf9\u200b\u8ddd\u79bb\u200b\u5185\u79ef\u200b\u7ed3\u679c\u200b\u76f8\u5bf9\u200b\u8d8a\u5c0f\u200b\uff08\u200b\u4e5f\u200b\u4f1a\u200b\u5b58\u5728\u200b\uff09\u3002</li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/bge.html","title":"Bge","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/bge.html#bge","title":"BGE","text":"<p>\u200b\u8bba\u6587\u200b\uff1aC-Pack: Packed Resources For General Chinese Embeddings BGE\uff1aBAAI General Embeddings Github\uff1aFlagEmbedding BAAI &amp; Renmin University of China &amp; HuggingFace &amp; USTC &amp; University of Montreal, 2023 Sep, SIGIR 2024</p>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/bge.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<p>bge\uff0c\u200b\u667a\u6e90\u200b\u7814\u7a76\u9662\u200b\u63a8\u51fa\u200b 1, 1.5, 2, pro C-Park\u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u4e2d\u6587\u200b\u7684\u200b\u901a\u7528\u200b\u6587\u672c\u200bembedding\u200b\u8d44\u6e90\u200b\u5305\u200b\uff0c\u200b\u5305\u542b\u200b\u4ee5\u4e0b\u200b\u90e8\u5206\u200b\uff1a</p>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/bge.html#c-mtp","title":"C-MTP","text":"<p>C-MTP\uff08Chinese Massive Text Pairs\uff09</p> <ul> <li>semantically related text pairs leveraging the rich-structured information within the data, such as title-to-document, subtitle-to-passage, question-to-answer, question-to-similar-question, etc. further cleaned for the massive weakly supervised training of the text embeddings.</li> <li>a question and its answer</li> <li>two documents on the same topic</li> <li>topic to review</li> <li>title-body</li> <li> <p>C-MTP (unlabeled), 100M text pairs</p> <ul> <li>\u200b\u53bb\u9664\u200b\u91cd\u590d\u200b\u3001\u200b\u65e0\u200b\u8bed\u4e49\u200b\u548c\u200b\u6076\u610f\u200b\u6587\u672c\u200b</li> <li>\u200b\u57fa\u4e8e\u200bText2VecChinese\u200b\u8fc7\u6ee4\u200b\u8bed\u4e49\u200b\u4f4e\u200b\u76f8\u5173\u200b\u6587\u672c\u200b\u5bf9\u200b\uff0c</li> </ul> </li> <li> <p>C-MTP (high-quality labeled) 838,465 text pairs</p> </li> <li>200M text pairs for English </li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/bge.html#c-mteb","title":"C-MTEB","text":"<p>C-MTEB\uff08Chinese Massive Text Embedding Benchmark\uff09\uff1acomprehensive benchmark for Chinese text embeddings covering 6 tasks and 35 datasets</p> <p></p>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/bge.html#bgetrain-recipe","title":"BGE+Train Recipe","text":"<p>BGE\uff1aa family of embedding models covering multiple sizes</p> <p></p> <ol> <li> <p>pre-training with plain texts, MAE-style\u200b\u65b9\u6cd5\u200b\u7c7b\u4f3c\u200b\u4e8e\u200bELECTRA\uff0c\u200b\u901a\u8fc7\u200bencoder\u200b\u8fdb\u884c\u200btext MASK\uff0c\u200b\u968f\u540e\u200b\u901a\u8fc7\u200b\u8f7b\u91cf\u7ea7\u200bdecoder\u200b\u6062\u590d\u200b</p> \\[ \\min \\sum_{x \\in X} -\\log \\text{Dec}(x\\vert h_{\\tilde{X}}), h_{\\tilde{X}} = \\text{Enc}(\\tilde{X}) \\] </li> <li> <p>contrastive learning with C-MTP text-pair (unlabeled), using in-batch negatives and big batch size</p> </li> <li> <p>\uff08multi-task\uff09 contrastive learning with C-MTP (labeled)\uff0c\u200b\u7531\u4e8e\u200b\u542b\u6709\u200b\u591a\u4e2a\u200b\u4efb\u52a1\u200b\uff0c\u200b\u4e0d\u540c\u200b\u4efb\u52a1\u200b\u4e00\u8d77\u200b\u8fdb\u884c\u200b\u5b66\u4e60\u200b\u53ef\u80fd\u200b\u5b58\u5728\u200b\u77db\u76fe\u200b\u73b0\u8c61\u200b\uff0c\u200b\u56e0\u6b64\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u65b9\u5f0f\u200b\u907f\u514d\u200b\u8be5\u200b\u95ee\u9898\u200b</p> <ul> <li>\u200b\u57fa\u4e8e\u200b\u6307\u4ee4\u200b\u6765\u200b\u8fdb\u884c\u200b\u591a\u4efb\u52a1\u200bSFT\uff0c\u200b\u4e0d\u540c\u200b\u4efb\u52a1\u200b\u4f7f\u7528\u200b\u4e0d\u540c\u200b\u6307\u4ee4\u200b\u52a0\u4ee5\u200b\u533a\u5206\u200b  </li> <li>\u200b\u901a\u8fc7\u200bANN\u200b\u65b9\u5f0f\u200b\u4ece\u200b\u76f8\u5e94\u200b\u8bed\u6599\u200b\u4e2d\u200b\u83b7\u53d6\u200bhard negative\u200b\u589e\u5f3a\u200b\u8d1f\u200b\u6837\u672c\u200b\uff0c\u200b\u8fdb\u4e00\u6b65\u200b\u5f3a\u5316\u200b\u5bf9\u6bd4\u200b\u5b66\u4e60\u6548\u679c\u200b</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/bge.html#_2","title":"\u6d88\u878d\u200b\u5b9e\u9a8c","text":"<ul> <li>BGE-pretrain\uff1apretrained by plain texts, and then weakly SFT by MTP\uff08unlabeled\uff09</li> <li>BGE w.o. pre-train\uff1ainitialized with chinese-roberta, and then weakly SFT by MTP\uff08unlabeled\uff09</li> <li>BGE w.o. Instruct\uff1aSFT by MTP\uff08labeled\uff09without a hard prompt</li> <li>BGE-finetune\uff1aBGE</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/bge.html#bge-m3","title":"BGE-M3","text":"<p>\u200b\u8bba\u6587\u200b\uff1aM3-Embedding: Multi-Linguality, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation Github\uff1aFlagEmbedding BAAI &amp; USTC, 2024 Mon, ACL 2024</p>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/bge.html#_3","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/e5.html","title":"E5","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/e5.html#e5","title":"E5","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/e5.html#me5","title":"mE5","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/e5.html#e5-llm","title":"E5-LLM","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html","title":"Gte","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#gte","title":"GTE","text":"<p>\u200b\u8bba\u6587\u200b\uff1aTowards General Text Embeddings with Multi-stage Contrastive Learning Alibaba Group, 2023 Aug</p>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#gte-training-pipeline","title":"GTE Training Pipeline","text":"<p>\u200b\u7ecf\u7531\u200b\u4ee5\u4e0b\u200b\u6b65\u9aa4\u200b\u8bad\u7ec3\u200b\u5f97\u5230\u200bGTE\u200b\u6a21\u578b\u200b\uff1a</p> <ol> <li>Weakly Supervised Contrastive Pre-training\uff1a\u200b\u4f7f\u7528\u200b\u5927\u91cf\u200b\u65e0\u200b\u76d1\u7763\u200b\u6587\u672c\u200b\u5bf9\u200b\u8fdb\u884c\u200b\u5bf9\u6bd4\u200b\u9884\u200b\u8bad\u7ec3\u200b</li> <li> <p>Supervised Contrastive Fine-tuning\uff1a\u200b\u4f7f\u7528\u200b\u591a\u4e2a\u200b\u4efb\u52a1\u200b\u7684\u200b\u9ad8\u8d28\u91cf\u200b\u6709\u200b\u6807\u7b7e\u200b\u6570\u636e\u200b\u4e09\u5143\u7ec4\u200b\u8fdb\u884c\u200b\u6709\u200b\u76d1\u7763\u200b\u5bf9\u6bd4\u200b\u8bad\u7ec3\u200b\u5fae\u8c03\u200b</p> <p>\u200b\u8be5\u200b\u9636\u6bb5\u200b\u4f7f\u7528\u200b\u4e86\u200b\u6709\u200b\u6807\u7b7e\u200b\u4ee3\u7801\u200b\u6570\u636e\u200b\u8bad\u7ec3\u200b\u5fae\u8c03\u200b</p> </li> </ol> <p>Training Objective\uff1a\u200b\u4e24\u200b\u9636\u6bb5\u200b\u5747\u200b\u7684\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u5747\u200b\u4e3a\u200b\u6539\u5584\u200b\u7248\u200bInfoNCE loss\uff0c\u200b\u5206\u6bcd\u200b\u5305\u62ec\u200b\u4ee5\u4e0b\u200b\u90e8\u5206\u200b</p> <ul> <li>\u200b\u67e5\u8be2\u200b\u4e0e\u200b\u76ee\u6807\u200b\u6587\u6863\u200b\uff1a\\(s(q_i, d_i^{+})\\) </li> <li>\u200b\u67e5\u8be2\u200b\u4e0e\u200bhard negative\u200b\u96be\u200b\u5206\u8fa8\u200b\u8d1f\u200b\u6837\u672c\u200b\uff1a\\(\\sum s(q_i, d_i^{-})\\)</li> <li>\u200b\u67e5\u8be2\u200b\u4e0e\u200bin-batch\u200b\u6587\u6863\u200b\uff1a\\(\\sum_{j\\ne i} s(q_i, d_j)\\) </li> <li>\u200b\u67e5\u8be2\u200b\u4e0e\u200bin-batch\u200b\u67e5\u8be2\u200b\uff1a\\(\\sum_{j\\ne i} s(q_i, q_j)\\) </li> <li>\u200b\u6587\u6863\u200b\u4e0e\u200bin-batch\u200b\u67e5\u8be2\u200b\uff1a\\(\\sum_{j\\ne i} s(q_j, d_i)\\) </li> <li> <p>\u200b\u6587\u6863\u200b\u4e0e\u200bin-batch\u200b\u6587\u6863\u200b\uff1a\\(\\sum_{i\\ne i} s(d_j, d_i)\\)</p> \\[ \\begin{aligned}     L_\\text{icl} =&amp; - \\frac{1}{N} \\sum_{i=1}^N \\log \\frac{e^{s(q_i, d_i^{+})/\\tau}} {Z_i} \\\\     Z_i =&amp; \\sum_{j}e^{s(q_i, d_j)/\\tau} + \\sum_{j \\ne i}e^{s(q_i, q_j)/\\tau} + \\sum_{j \\ne i}e^{s(q_j, d_i)/\\tau} + \\sum_{j \\ne i}e^{s(d_j, d_i)/\\tau} \\\\ \\end{aligned} \\] <p>\\(\\tau\\) \u200b\u6e29\u5ea6\u200b\u7cfb\u6570\u200b\u6b64\u200b\u5de5\u4f5c\u200b\u4e2d\u8bbe\u200b\u4e3a\u200b 0.01</p> </li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#dataset-collection","title":"Dataset Collection","text":"<ol> <li> <p>Weakly Supervised Pre-training Data\uff1a\u200b\u4ec5\u200b\u4f7f\u7528\u200b\u722c\u53d6\u200b\u7684\u200b\u5f00\u6e90\u200b\u6570\u636e\u200b\uff0c\u200b\u6ca1\u6709\u200b\u91c7\u7528\u200b\u4efb\u4f55\u200b\u8fc7\u6ee4\u200b\u6216\u200b\u6e05\u7406\u200b\u65b9\u6cd5\u200b\u3002\u200b\u6570\u636e\u683c\u5f0f\u200b\u4e3a\u200b\u6587\u672c\u200b\u5bf9\u200b\uff0c\u200b\u5305\u62ec\u200b\u4ee5\u4e0b\u200b\u51e0\u79cd\u200b\u6570\u636e\u200b\u6765\u6e90\u200b</p> <ul> <li>Web Page\uff1a<code>(title, most_relevant_body_text from randomly_sampled_body_texts)</code></li> <li>Academic Paper\uff1a<code>(title, abstract)</code></li> <li>Hyperlink\uff1a<code>(citation_argument, text_from_reference)</code></li> <li>Community QA\uff1astructured <code>(question, answer_by_text-length_and_voting-numbers_heuristics)</code></li> <li>Social Media\uff1astructured <code>(post, comment)</code></li> <li>News\uff1astructured <code>(highlighted_sentences, content)</code></li> <li>Knowledge Base\uff1a<code>(entity, description)</code></li> <li>Code Repository\uff1a<code>(requirement_text, code)</code></li> <li>Others\uff1a<code>(good, review)</code>\u3001<code>(argument, debeat)</code>\u3001<code>(googaq_q, googqa_a)</code>, etc. <p>more details about data resource in Appendix A.1, A.3</p> </li> </ul> <p></p> <p></p> </li> <li> <p>Supervised Fine-tuning Data\uff1a\u200b\u5305\u62ec\u200b\u65e2\u6709\u200b\u7684\u200b\u6709\u200b\u6807\u7b7e\u200b\u6587\u672c\u200b\u5bf9\u200b\u4ee5\u53ca\u200b\u53ef\u9009\u200b\u7684\u200b\u7279\u610f\u200b\u6316\u6398\u200b\u7684\u200bhard negatives\u200b\u96be\u200b\u5206\u8fa8\u200b\u8d1f\u200b\u6837\u672c\u200b\uff0c\u200b\u4ee5\u200b\u6784\u6210\u200b\u6587\u672c\u200b\u4e09\u5143\u7ec4\u200b\uff0c\u200b\u5305\u62ec\u200b\u4ee5\u4e0b\u200b\u51e0\u79cd\u200b\u6570\u636e\u200b\u6765\u6e90\u200b</p> <ul> <li>Web Search\uff1a<code>MS_MARCO + high-ranked hard negatives by doc retriever</code> </li> <li>Open QA\uff1a<code>open QA datasets + top-ranked negative passages by retriever</code> </li> <li>NLI\uff1a<code>entailment + contradiction</code></li> <li>Fact Verification\uff1a<code>one argument and supporting source</code></li> <li>Paraphrase\uff1a<code>two sentences with similar meanings</code></li> <li>Others\uff1a<code>MEDI, BERRI and sub-sampled version of pre-training data</code> <p>\u200b\u603b\u200b\u6837\u672c\u6570\u200b ~3M\uff0c\u200b\u4e09\u5143\u7ec4\u200b\u7684\u200bhard negative\u200b\u90e8\u5206\u200b\u53ef\u200b\u4e3a\u200b\u591a\u4e2a\u200b\u8d1f\u200b\u6837\u672c\u200b more details about data resource in Appendix A.1, A.3</p> </li> </ul> <p></p> <p></p> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#unsupervised-cpt","title":"Unsupervised CPT","text":"<p>\u200b\u5bf9\u6bd4\u200b\u9884\u200b\u8bad\u7ec3\u200b Contrastive Pre-Training \u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u5177\u6709\u200b\u4ee5\u4e0b\u200b\u8bad\u7ec3\u200b\u7ec6\u8282\u200b</p> <ol> <li> <p>Data Sampling\uff1a\u200b\u7531\u4e8e\u200b\u5404\u200b\u6765\u6e90\u200b\u6570\u636e\u91cf\u200b\u5b58\u5728\u200b\u5de8\u5927\u200b\u5dee\u5f02\u200b\uff0c\u200b\u8981\u6c42\u200b\u6bcf\u200bbatch\u200b\u4ec5\u200b\u6765\u6e90\u4e8e\u200b\u540c\u4e00\u200b\u4efb\u52a1\u200b\uff0c\u200b\u56e0\u6b64\u200b\u8bbe\u8ba1\u200b\u4e86\u200b\u591a\u9879\u5f0f\u200b\u91c7\u6837\u200b\u5206\u5e03\u200b\u51fd\u6570\u200b\uff0c\u200b\u5404\u200b\u6570\u636e\u200b\u96c6\u200b\u6837\u672c\u200b\u91c7\u6837\u200b\u6982\u7387\u200b\u4e3a\u200b</p> \\[ p_i = \\frac{\\vert  D_i \\vert^{\\alpha}}{\\sum_{i=1}^m \\vert D_i \\vert ^\\alpha} \\] <p>\\(\\alpha\\) \u200b\u4e3a\u200b\u591a\u9879\u5f0f\u200b\u5404\u200b\u6210\u5206\u200b\u6df7\u5408\u200b\u6bd4\u4f8b\u200b mixing ratio</p> </li> <li> <p>Ensure Large Batch Size\uff1a\u200b\u5c3d\u53ef\u80fd\u200b\u5730\u200b\u901a\u8fc7\u200b\u5404\u79cd\u200b\u6280\u5de7\u200b\u589e\u5927\u200bCPT\u200b\u9636\u6bb5\u200b\u7684\u200b <code>batch_size</code>\uff0c\u200b\u5f97\u5230\u200b\u66f4\u200b\u591a\u200b\u7684\u200bin-batch negatives\uff0c\u200b\u4ece\u800c\u200b\u7f29\u5c0f\u200b\u8bad\u7ec3\u200b\u548c\u200b\u63a8\u7406\u200b\u9636\u6bb5\u200b\uff08\u200b\u5982\u200b\u68c0\u7d22\u200b\uff09\u200b\u7684\u200b\u5dee\u8ddd\u200b\uff0c\u200b\u63d0\u9ad8\u200b\u6a21\u578b\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</p> <ul> <li><code>max_seq_len=128</code></li> <li>AMP training with fp16</li> <li>\u200b\u5c06\u200b\u5206\u5e03\u200b\u5728\u200b\u5404\u200bGPU\u200b\u4e0a\u200b\u7684\u200b\u6837\u672c\u200b\u7528\u4f5c\u200b\u8d1f\u200b\u6837\u672c\u200b</li> <li>DeepSpeed ZeRO stage 1</li> <li>gradient checkpointing</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#supervised-cft","title":"Supervised CFT","text":"<p>\u200b\u6709\u200b\u76d1\u7763\u200b\u5bf9\u6bd4\u200b\u8bad\u7ec3\u200b\u5fae\u8c03\u200bSupervised Contrastive Fine-tuning \u200b\u5177\u6709\u200b\u4ee5\u4e0b\u200b\u8bad\u7ec3\u200b\u7ec6\u8282\u200b</p> <ol> <li> <p>Unnecessary Large Batch Size\uff1a\u200b\u7531\u4e8e\u200b\u4f7f\u7528\u200b\u4e86\u200b\u9ad8\u8d28\u91cf\u200b\u6570\u636e\u200b\u548c\u200b\u96be\u200b\u533a\u5206\u200b\u8d1f\u200b\u6837\u672c\u200bhard negatives\u200b\u8fdb\u884c\u200bSFT\u200b\u8db3\u591f\u200b\u83b7\u53d6\u200b\u53ef\u9760\u200b\u7684\u200b\u68af\u5ea6\u200b\u4f30\u8ba1\u200b\uff0c\u200b\u56e0\u6b64\u200b\u65e0\u9700\u200b\u523b\u610f\u200b\u4fdd\u6301\u200b\u5927\u200b <code>batch_size</code> \u200b\u8fdb\u884c\u200b\u5bf9\u6bd4\u200b\u8bad\u7ec3\u200b  </p> <ul> <li><code>batch_size=128</code>, 16 contrastive samples (1 positive + 1 hard + remaining in-batch random)</li> <li><code>max_seq_length=512</code> \u200b\u4f7f\u200b\u6a21\u578b\u200b\u66f4\u597d\u200b\u5904\u7406\u200b\u957f\u200b\u6587\u672c\u200b\u95ee\u9898\u200b</li> <li>amp with fp16</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#evaluation","title":"Evaluation","text":"<p>\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</p> <ul> <li>GTE\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u8f83\u200bBM25\u200b\u4ee5\u53ca\u200bE5\u200b\u6a21\u578b\u200b\u6709\u200b\u66f4\u200b\u51fa\u8272\u200b\u7684\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</li> <li>SFT\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0cGTE-small\u200b\u6a21\u578b\u200b\u4e0e\u200bE5-large\u200b\u6a21\u578b\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u76f8\u5f53\u200b\uff08\u200b\u6a21\u578b\u200b\u89c4\u6a21\u200b\u5b58\u5728\u200b10\u00d7\u200b\u5dee\u8ddd\u200b\uff09</li> <li>GTE-large\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u4f18\u4e8e\u200b\u591a\u4efb\u52a1\u200b\u6307\u4ee4\u200b\u5fae\u8c03\u200b\u5d4c\u5165\u200b\u6a21\u578b\u200bInstructOR-xl\uff0c\u200b\u4e14\u200b\u53d6\u5f97\u200bSOTA\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</li> </ul> <p>PT\uff0c+\uff1a5\u200b\u4e2a\u200b\u6700\u5927\u200b\u6570\u636e\u200b\u96c6\u200b\uff1b++\uff1a5\u200b\u4e2a\u200b\u6700\u5927\u200b\u6570\u636e\u200b\u96c6\u200b + 10\u200b\u4e2a\u200b\u968f\u673a\u200b\u62bd\u53d6\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b\uff1b+++\uff1aall 33\u200b\u6570\u636e\u200b\u96c6\u200b FT\uff0c+\uff1aE5\u200b\u4e2d\u200b3\u200b\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b\uff1b++\uff1aE5\u200b\u4e2d\u200b3\u200b\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b + MEDI\uff1b+++\uff1aE5\u200b\u4e2d\u200b3\u200b\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b + MEDI + BERRI</p> <p>\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</p> <ul> <li>\u200b\u66f4\u200b\u591a\u6837\u5316\u200b\u7684\u200b\u6570\u636e\u6e90\u200b\u53ef\u4ee5\u200b\u6301\u7eed\u200b\u63d0\u5347\u200b\u6a21\u578b\u200b\u5728\u200b\u9884\u200b\u8bad\u7ec3\u200b\u548c\u200b\u5fae\u8c03\u200b\u9636\u6bb5\u200b\u7684\u200b\u6027\u80fd\u200b  </li> <li>\u200b\u968f\u7740\u200b<code>batch_size</code>\u200b\u589e\u5927\u200b\uff0c\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u6548\u679c\u200b\u8d8a\u200b\u597d\u200b\uff0c\u200b\u4e14\u200b\u5728\u200b10000\u200b\u5de6\u53f3\u200b\u8fbe\u5230\u200b\u9971\u548c\u200b</li> </ul> <p>\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</p> <ul> <li>\u200b\u6570\u636e\u200b\u96c6\u200b\u5747\u5300\u200b\u91c7\u6837\u200b(\\(\\alpha=0\\))\u200b\u548c\u200b\u5355\u7eaf\u200b\u57fa\u4e8e\u200b\u6570\u636e\u200b\u96c6\u200b\u6837\u672c\u91cf\u200b\u91c7\u6837\u200b(\\(\\alpha=1\\))\u200b\u5747\u200b\u4e0d\u662f\u200b\u6700\u4f18\u200b\u9009\u62e9\u200b  </li> <li>mixing ratio \\(\\alpha=0.5\\) \u200b\u7684\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u6700\u4f73\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#ablation-study","title":"Ablation Study","text":"<p>\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</p> <ul> <li>\u200b\u4e24\u200b\u9636\u6bb5\u200b\u8bad\u7ec3\u200b\u5bf9\u200bGTE\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u5747\u200b\u6709\u200b\u63d0\u5347\u200b\u6548\u679c\u200b</li> <li>imporved in-batch negatives \u200b\u8f83\u200b\u4f20\u7edf\u200bin-batch negatives\u200b\u6709\u200b\u66f4\u4f73\u200b\u6548\u679c\u200b\u63d0\u5347\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#mgte","title":"mGTE","text":"<p>\u200b\u8bba\u6587\u200b\uff1amGTE: Generalized Long-Context Text Representation and Reranking Models for Multilingual Text Retrieval Alibaba Group, 2024 Jul\uff0cEMNLP 2024</p>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#_2","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#qwen3-embedding","title":"Qwen3 Embedding","text":"<p>\u200b\u8bba\u6587\u200b\uff1aQwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models Github\uff1aQwen3-Embedding Blog\uff1aQwen3 Embedding Alibaba Group, 2025 Jun</p>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#_3","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#qwen3-embedding-pipeline","title":"Qwen3 Embedding Pipeline","text":"<p>Qwen3 Embedding\u200b\u6a21\u578b\u200b\u4f7f\u7528\u200bQwen3 Causal LLM\u200b\u521d\u59cb\u5316\u200b\uff0c\u200b\u7ecf\u200b\u4ee5\u4e0b\u200b\u6b65\u9aa4\u200b\u5f97\u5230\u200b\u76ee\u6807\u200b\u6a21\u578b\u200b\uff1a</p> <ol> <li>Weakly Supervised Pre-Training\uff1a\u200b\u57fa\u4e8e\u200b\u5408\u6210\u200b\u7684\u200b\u5f31\u200b\u76d1\u7763\u200b\u6587\u672c\u200b\u5bf9\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b  </li> <li>Supervised Fine Tuning\uff1a\u200b\u57fa\u4e8e\u200b\u9ad8\u8d28\u91cf\u200b\u7684\u200b\u5408\u6210\u200b\u6570\u636e\u200b\u548c\u200b\u6807\u6ce8\u200b\u6570\u636e\u200b\u6709\u200b\u76d1\u7763\u200b\u5fae\u8c03\u200b\u6a21\u578b\u200b  </li> <li>Model Merging\uff1a\u200b\u91c7\u6837\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u7684\u200b\u591a\u4e2a\u200bCheckpoint\uff0c\u200b\u5408\u5e76\u200b\u51fa\u200b\u6700\u7ec8\u200b\u6a21\u578b\u200b</li> </ol> <ul> <li>Embedding Model\u200b\u5305\u542b\u200b\u4e86\u200b\u5b8c\u6574\u200b\u7684\u200b3\u200b\u4e2a\u200b\u9636\u6bb5\u200b  </li> <li>Reraning Model\u200b\u53ea\u200b\u5305\u542b\u200b\u4e86\u200b\u540e\u200b2\u200b\u4e2a\u200b\u9636\u6bb5\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#synthetic-dataset","title":"Synthetic Dataset","text":"<ol> <li>\u200b\u9636\u6bb5\u200b1 Synthetic Data\uff1a\u200b\u57fa\u4e8e\u200bQwen3-32B\uff0c\u200b\u751f\u6210\u200b\u5927\u91cf\u200b\u7684\u200b\u9ad8\u8d28\u91cf\u200b\u3001\u200b\u591a\u4efb\u52a1\u200b\uff08\u200b\u5305\u62ec\u200bretrieval, bitext mining, classification, and STS\uff09\u3001\u200b\u591a\u8bed\u79cd\u200b\u7684\u200b\u5f31\u200b\u76d1\u7763\u200b\u6587\u672c\u200b\u76f8\u5173\u200b\u6570\u636e\u200b\u5bf9\u200b\u3002 \u200b\u5176\u4e2d\u200b\u68c0\u7d22\u200b\u4efb\u52a1\u200b\u4ee5\u200bDoc2Query\u200b\u65b9\u5f0f\u200b\u751f\u6210\u200b\u6570\u636e\u200b\uff0c\u200b\u6b65\u9aa4\u200b\u5982\u4e0b\u200b\uff1a<ol> <li>\u200b\u4f7f\u7528\u200b\u68c0\u7d22\u200b\u6a21\u578b\u200b\u5bf9\u200b\u8f93\u5165\u200b\u6587\u6863\u200b\uff08\u200b\u6e90\u4e8e\u200bQwen3\u200b\u591a\u8bed\u79cd\u200b\u9884\u200b\u8bad\u7ec3\u200b\u8bed\u6599\u5e93\u200b\uff09\u200b\u68c0\u7d22\u200b\u5e76\u200b\u4fdd\u7559\u200btop-5\u200b\u5019\u9009\u200b\u6587\u6863\u200b\uff08\u200b\u6e90\u4e8e\u200bPersona Hub\uff09\uff1b</li> <li>\u200b\u8f93\u5165\u200b\u6587\u6863\u200b\u4e0e\u200btop-5\u200b\u5019\u9009\u200b\u6587\u6863\u200b\uff0c\u200b\u4f7f\u7528\u200bQwen3-32B\u200b\u81ea\u4e3b\u200b\u9009\u62e9\u200b\u6587\u6863\u200b\u53ef\u80fd\u200b\u611f\u5174\u8da3\u200b\u7684\u200b\u5019\u9009\u200b\u6587\u6863\u200b\uff0c\u200b\u95ee\u9898\u200b\u7c7b\u578b\u200b\u4ee5\u53ca\u200b\u95ee\u9898\u200b\u96be\u5ea6\u200b\u4f5c\u4e3a\u200b\u751f\u6210\u200bQuery\u200b\u7684\u200b\u8bbe\u7f6e\u200b\u8981\u6c42\u200b\uff0c\u200b\u5177\u4f53\u200b\u8f93\u51fa\u200b <code>Character, Quetion_Type, Difficulty</code> \u200b\u5b57\u200b\u6bb5\u200b\uff1b  </li> <li>\u200b\u57fa\u4e8e\u200bQuery\u200b\u8bbe\u7f6e\u200b\u8981\u6c42\u200b\u4ee5\u53ca\u200b\u81ea\u5b9a\u4e49\u200b\u7684\u200bQeury\u200b\u751f\u6210\u200b\u957f\u5ea6\u200b\u4e0e\u200b\u8bed\u79cd\u200b\u7c7b\u578b\u200b\u8fdb\u884c\u200bDoc2Query\u200b\u751f\u6210\u200b  </li> </ol> </li> <li>\u200b\u9636\u6bb5\u200b2 High-quality Synthetic Data\uff1a\u200b\u4ece\u200b\u9636\u6bb5\u200b1\u200b\u7684\u200b Synthetic Data \u200b\u4e2d\u200b\u968f\u673a\u200b\u62bd\u53d6\u200b\u6570\u636e\u200b\uff0c\u200b\u4fdd\u7559\u200b\u9636\u6bb5\u200b1\u200b\u7ed3\u679c\u200b\u4e2d\u200b\u8bed\u4e49\u200b\u76f8\u5173\u6027\u200b <code>cos_similarity &gt; 0.7</code> \u200b\u7684\u200b\u6837\u672c\u200b\uff0c\u200b\u6700\u7ec8\u200b\u9ad8\u8d28\u91cf\u200b\u5408\u6210\u200b\u6837\u672c\u6570\u200b ~12M</li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#embedding-model","title":"Embedding Model","text":"<ol> <li> <p>Prompt\uff1aEmbedding Model\u200b\u91c7\u7528\u200b\u4e86\u200b\uff08\u200b\u5171\u4eab\u200b\u53c2\u6570\u200b\u7684\u200b\uff09\u200b\u53cc\u5854\u200b\u7ed3\u6784\u200b\u5206\u522b\u200b\u5904\u7406\u200b\u67e5\u8be2\u200b Query \u200b\u548c\u200b\u6587\u6863\u200b Doc\uff0c\u200b\u5176\u4e2d\u200b</p> <ul> <li>Query Prompt: <code>{Embedding Instruction} + {Query} + [EOS]</code> </li> <li>Doc Prompt: <code>{Doc} + [EOS]</code> <p><code>[EOS]</code>\u200b\u4e3a\u200b<code>&lt;|endoftext|&gt;</code>\uff0c\u200b\u8be5\u200btoken\u200b\u5bf9\u5e94\u200b\u7684\u200b <code>last_hidden_state</code> \u200b\u5373\u200b\u4e3a\u200b\u53e5\u200b\u5411\u91cf\u200b</p> </li> </ul> </li> <li> <p>Training Objective\uff1aEmbedding Model\u200b\u5728\u200b\u4e24\u4e2a\u200b\u9636\u6bb5\u200b\u4e2d\u200b\u7684\u200b\u8bad\u7ec3\u200b\u76ee\u6807\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u76f8\u540c\u200b\uff0c\u200b\u5747\u200b\u4e3a\u200b\u6539\u5584\u200b\u7248\u200bInfoNCE loss\uff0c\u200b\u5206\u6bcd\u200b\u5305\u62ec\u200b\u4ee5\u4e0b\u200b\u90e8\u5206\u200b\uff1a</p> <ul> <li>\u200b\u67e5\u8be2\u200b\u4e0e\u200b\u76ee\u6807\u200b\u6587\u6863\u200b\uff1a\\(s(q_i, d_i^{+})\\) </li> <li>\u200b\u67e5\u8be2\u200b\u4e0e\u200bhard negative\u200b\u96be\u200b\u5206\u8fa8\u200b\u8d1f\u200b\u6837\u672c\u200b\uff1a\\(\\sum s(q_i, d_i^{-})\\)</li> <li>\u200b\u67e5\u8be2\u200b\u4e0e\u200bin-batch\u200b\u6587\u6863\u200b\uff1a\\(\\sum_{i\\ne j} s(q_i, d_j)\\) </li> <li>\u200b\u67e5\u8be2\u200b\u4e0e\u200bin-batch\u200b\u67e5\u8be2\u200b\uff1a\\(\\sum_{i\\ne j} s(q_i, q_j)\\) </li> <li>\u200b\u6587\u6863\u200b\u4e0e\u200bin-batch\u200b\u6587\u6863\u200b\uff1a\\(\\sum_{i\\ne j} s(d_i, d_j)\\)</li> </ul> \\[ \\begin{aligned}     L_\\text{embedding} =&amp; - \\frac{1}{N} \\sum_{i=1}^N \\log \\frac{e^{s(q_i, d_i^{+})/\\tau}} {Z_i} \\\\     Z_i =&amp; e^{s(q_i, d_i^+)/\\tau} + \\sum_{k}^K m_{i,k} e^{s(q_i, d_{i,k}^-)/\\tau} + \\sum_{i\\ne j} m_{i,j} e^{s(q_i, d_{j})/\\tau} \\\\     + &amp; \\sum_{i \\neq j} m_{i,j} e^{s(q_i, q_j)/\\tau} + \\sum_{i \\neq j} m_{i,j} e^{s(d_i^+, d_j)/\\tau} \\\\     m_{i, j} =&amp; \\begin{cases}         0 &amp; \\text{if } s_{i, j} \\gt s(q_i, d_i^+) + 0.1 \\text{ or is_equal}(d_j, d_i^+)  \\\\         1 &amp; \\text{otherwise}     \\end{cases} \\end{aligned} \\] <ul> <li>\\(s_{i, j}\\) \u200b\u4e3a\u200b\u76f8\u5e94\u200b\u5bf9\u8c61\u200b\u7684\u200b\u76f8\u5173\u6027\u200b\u5206\u6570\u200b  </li> <li>mask\u200b\u7cfb\u6570\u200b \\(m_{i,j}\\) \u200b\u7528\u4e8e\u200b\u6d88\u9664\u200bin-batch\u200b\u6837\u672c\u200b\u4e2d\u200b\u7684\u200bFalse Negatives</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#reranking-model","title":"Reranking Model","text":"<ol> <li> <p>Prompt\uff1aReranking Model\u200b\u57fa\u4e8e\u200bPoint-wise Reranking\uff08\u200b\u72ec\u7acb\u200b\u8bc4\u4f30\u200b\u67e5\u8be2\u200b\u4e0e\u200b\u6bcf\u4e2a\u200b\u5019\u9009\u200b\u6587\u6863\u200b\u7684\u200b\u76f8\u5173\u6027\u200b\u5206\u6570\u200b\uff09 \u200b\u7684\u200b\u5355\u5854\u200b\u7ed3\u6784\u200b\u5904\u7406\u200b Query \u200b\u548c\u200b\u5019\u9009\u200b Docs\uff08\u200b\u5982\u200btop-100\uff09\uff0c\u200b\u5176\u4e2d\u200b</p> <ul> <li><code>{Reranking Instruction} + {Query} + {Doc} + assistant:</code></li> <li><code>next_token_prediction</code> \u200b\u5bf9\u5e94\u200b<code>yes</code>\u200b\u548c\u200b<code>no</code>\u200b\u6982\u7387\u200b\u7684\u200bsoftmax\u200b\u503c\u200b\u5373\u200b\u4e3a\u200b\u5206\u6570\u200b</li> </ul> \\[ score(q, d)  = \\frac{e^{P(\\text{yes}\\vert I, q, d)}}{e^{P(\\text{yes}\\vert I, q, d)} + e^{P(\\text{no}\\vert I, q, d)}} \\] </li> <li> <p>Training Objective\uff1a\u200b\u91c7\u7528\u200b\u6807\u51c6\u200b\u5206\u7c7b\u200bSFT\u200b\u65b9\u5f0f\u200b\u5fae\u8c03\u200b\u6a21\u578b\u200b\uff0c\\(l \\in \\{\\text{yes}, \\text{no}\\}\\)</p> \\[ L_\\text{reranking} = -\\log p(l \\vert q, d) \\] </li> </ol>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#evaluation_1","title":"Evaluation","text":"<p>\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</p> <ul> <li>Qwen3 Embedding Model\u3001Reranking Model\u200b\u80fd\u200b\u5728\u200b\u5404\u200bbenchmarks\u200b\u4e2d\u200b\u53d6\u5f97\u200bSOTA\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/gte.html#ablation-study_1","title":"Ablation Study","text":"<p><code>synthetic data</code> \u200b\u4e3a\u200bLLM\u200b\u751f\u6210\u200b\u7684\u200b\u5e94\u7528\u200b\u4e8e\u200b\u9636\u6bb5\u200b1\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b</p> <p>\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</p> <ul> <li>LLM\u200b\u751f\u6210\u200b\u7684\u200b\u5f31\u200b\u76d1\u7763\u200b\u6570\u636e\u200b\u4e0e\u200b\u6a21\u578b\u200b\u5408\u5e76\u200b\u5747\u200b\u5bf9\u6a21\u578b\u200b\u6548\u679c\u200b\u6709\u200b\u63d0\u5347\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/jina.html","title":"Jina","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/jina.html#jina-1","title":"Jina-1","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/jina.html#jina-2","title":"Jina-2","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/jina.html#jina-3","title":"Jina-3","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/sentence_embedding.html","title":"Sentence embedding","text":"<ul> <li>GTE</li> <li>BEG</li> <li>E5</li> <li>jina</li> <li>XLM-RoBERTa</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/xlm-roberta.html","title":"Xlm roberta","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/xlm-roberta.html#xlm-roberta","title":"XLM-RoBERTa","text":"<p>\u200b\u8bba\u6587\u200b\uff1aUnsupervised Cross-lingual Representation Learning at Scale Github: fairseq FAAI, 2019 Nov, ACL 2020  </p>"},{"location":"AI/Paper_Reading/Component/Embedding/Sentence_Embedding/xlm-roberta.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>different languages using the same sampling distribution as Lample and Conneau (2019), but with \u03b1 = 0.3  </li> <li>\u200b\u591a\u200b\u8bed\u8a00\u200b\u4e0a\u4e0b\u6587\u200b\u8bad\u7ec3\u200b\uff1a\u200b\u540c\u4e00\u200b\u6279\u6b21\u200b\uff08batch\uff09\u200b\u4e2d\u200b\u5305\u542b\u200b\u4e0d\u540c\u200b\u8bed\u8a00\u200b\u7684\u200b\u6837\u672c\u200b\uff0c\u200b\u901a\u8fc7\u200b\u68af\u5ea6\u200b\u66f4\u65b0\u200b\u9690\u5f0f\u200b\u5bf9\u9f50\u200b\u8bed\u8a00\u200b\u95f4\u200b\u7684\u200b\u8bed\u4e49\u200b\u7a7a\u95f4\u200b\u3002</li> <li>\u200b\u5171\u4eab\u200b\u8bcd\u8868\u200b\u4e0e\u200b\u53c2\u6570\u200b  </li> <li>\u200b\u5927\u89c4\u6a21\u200b\u6570\u636e\u200b\u8986\u76d6\u200b\uff1a\u200b\u4f4e\u200b\u8d44\u6e90\u200b\u8bed\u8a00\u200b\u901a\u8fc7\u200b\u9ad8\u200b\u8d44\u6e90\u200b\u8bed\u8a00\u200b\u7684\u200b\u53c2\u6570\u200b\u5171\u4eab\u200b\u83b7\u5f97\u200b\u8fc1\u79fb\u200b\u80fd\u529b\u200b\u3002</li> <li>TLM: translation language model</li> <li>wiki-100: using for XLM-100 and mBERT</li> <li>cc-100: using for XLM-R</li> </ul>"},{"location":"AI/Paper_Reading/Component/Embedding/Token_Embedding/token_embedding.html","title":"Token embedding","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Token_Embedding/token_embedding.html#token-modality","title":"Token Modality","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Token_Embedding/token_embedding.html#embedding_table","title":"\u591a\u200b\u6bb5\u200bembedding_table\u200b\u62fc\u63a5","text":"<p>\u200b\u901a\u8fc7\u200b\u8fde\u63a5\u200b\u591a\u4e2a\u200b\u4e0d\u540c\u200b\u6765\u6e90\u200b\u7684\u200bembedding_table\uff0c\u200b\u4ee5\u200b\u589e\u52a0\u200b\u8bcd\u8868\u200bvocab\u200b\u7684\u200b\u591a\u6837\u6027\u200b\uff08\u200b\u5982\u200b\u6c49\u5b57\u200b\u3001\u200b\u5b57\u7b26\u200b\u3001emoji\u200b\u7b49\u200b\uff09\uff1b\u200b\u53c8\u200b\u7531\u4e8e\u200b\u591a\u79cd\u4e0d\u540c\u200b\u6765\u6e90\u200b\u7684\u200bembedding_table\u200b\u7684\u200b\u7279\u5f81\u200b\u6570\u200b\u4e0d\u200b\u4e00\u81f4\u200b\uff0c\u200b\u56e0\u6b64\u200b\u9700\u8981\u200b\uff1a</p> <ol> <li>\u200b\u9009\u53d6\u200b\u5404\u200bembedding_table\u200b\u4e2d\u200b\u5bf9\u5e94\u200b\u7684\u200b\u5411\u91cf\u200b</li> <li>\u200b\u6295\u5f71\u200b\u81f3\u200b\u540c\u4e00\u200b\u7ef4\u5ea6\u200b<code>dim</code></li> <li>\u200b\u62fc\u63a5\u200b\u6210\u200b\u4e00\u4e2a\u200b\u6700\u7ec8\u200b\u7684\u200b<code>sequence embedding</code></li> </ol> TF 1.x <pre><code>word_embedding = 0.\nfor i, offset in enumerate(offsets):\n    word_embedding += tf.nn.embedding_lookup(\n        tf.get_variable(f\"word_embeddings_part_{i}\"),\n        word_ids - offset\n    )\n</code></pre> <p><code>tf.nn.embedding_lookup</code>\uff1a\u200b\u5f53\u200b<code>id \u2208 [0, vocab_size)</code> \u200b\u65f6\u200b\u9009\u53d6\u200b\u5bf9\u5e94\u200b\u7684\u200bembedding\uff0c\u200b\u5426\u5219\u200b\u8fd4\u56de\u200b<code>[0, 0, ..., 0]</code></p>"},{"location":"AI/Paper_Reading/Component/Embedding/Token_Embedding/token_embedding.html#sound-modality","title":"Sound Modality","text":""},{"location":"AI/Paper_Reading/Component/Embedding/Token_Embedding/token_embedding.html#shape-modality","title":"Shape Modality","text":""},{"location":"AI/Paper_Reading/Component/HyperParameter/index.html","title":"HyperParameter","text":""},{"location":"AI/Paper_Reading/Component/HyperParameter/index.html#general","title":"general","text":"<ul> <li>temperature</li> </ul>"},{"location":"AI/Paper_Reading/Component/HyperParameter/index.html#nlu","title":"NLU","text":""},{"location":"AI/Paper_Reading/Component/HyperParameter/index.html#nlg","title":"NLG","text":"<ul> <li>top-p</li> <li>top-k</li> <li>num_beams</li> <li>length_penalty</li> <li>repetition_penalty</li> </ul>"},{"location":"AI/Paper_Reading/Component/HyperParameter/NLG/generation_config.html","title":"Generation config","text":""},{"location":"AI/Paper_Reading/Component/HyperParameter/NLG/generation_config.html#do_sample","title":"do_sample","text":"<p>\u200b\u63a7\u5236\u200b\u6a21\u578b\u200b\u662f\u5426\u200b\u4ece\u200b\u57fa\u4e8e\u200b\u6982\u7387\u200b\u7684\u200b\u5019\u9009\u8bcd\u200b\u4e2d\u200b\u968f\u673a\u200b\u91c7\u6837\u200b\u83b7\u53d6\u200b\u4e0b\u200b\u4e00\u4e2a\u200b\u8bcd\u200b\u8fd8\u662f\u200b\u786e\u5b9a\u6027\u200b\u65b9\u6cd5\u200b\u751f\u6210\u200b\u4e0b\u200b\u4e00\u4e2a\u200b\u8bcd\u200b\u3002</p>"},{"location":"AI/Paper_Reading/Component/HyperParameter/NLG/generation_config.html#num_beamsbeam_width","title":"num_beams/beam_width","text":"<p>\u200b\u4f7f\u7528\u200bbeam search\u200b\u675f\u200b\u641c\u7d22\u200b\u65b9\u5f0f\u200b\u751f\u6210\u200b\u5e8f\u5217\u200b\uff08\u200b\u53ea\u8981\u200bseed\u200b\u4e00\u81f4\u200b\uff0c\u200b\u751f\u6210\u200b\u7684\u200b\u5e8f\u5217\u200b\u96c6\u5408\u200b\u662f\u200b\u786e\u5b9a\u6027\u200b\u7684\u200b\uff09\uff0c\u200b\u7ef4\u62a4\u200b\u4e00\u4e2a\u200b\u56fa\u5b9a\u200b\u5927\u5c0f\u200b\u7684\u200b\u5019\u9009\u200b\u5e8f\u5217\u200b\u96c6\u5408\u200b\uff08\u200b\u6982\u7387\u200b\u6700\u9ad8\u200b\u7684\u200bk\u200b\u4e2a\u200b\u5e8f\u5217\u200b\uff09\uff0c\u200b\u5e76\u200b\u9010\u6b65\u200b\u6269\u5c55\u200b\u8fd9\u4e9b\u200b\u5e8f\u5217\u200b\u76f4\u5230\u200b\u8fbe\u5230\u200b\u9884\u5b9a\u200b\u7684\u200b\u6700\u5927\u200b\u957f\u5ea6\u200b\u6216\u200b\u6ee1\u8db3\u200b\u5176\u4ed6\u200b\u505c\u6b62\u200b\u6761\u4ef6\u200b\u3002</p>"},{"location":"AI/Paper_Reading/Component/HyperParameter/NLG/generation_config.html#early_stopping","title":"early_stopping","text":"<p>\u200b\u5f53\u200b <code>early_stopping=True</code> \u200b\u65f6\u200b\uff0c\u200b\u675f\u200b\u641c\u7d22\u200b\u4f1a\u200b\u5728\u200b\u6240\u6709\u200b\u5f53\u524d\u200b\u7684\u200b\u5019\u9009\u200b\u5e8f\u5217\u200b\u90fd\u200b\u8fbe\u5230\u200b\u4e86\u200b\u7ed3\u675f\u200b\u6761\u4ef6\u200b\uff08\u200b\u4f8b\u5982\u200b\u9047\u5230\u200b\u4e86\u200b\u7ed3\u675f\u200b\u6807\u8bb0\u200b <code>&lt;eos&gt;</code> \u200b\u6216\u8005\u200b\u8fbe\u5230\u200b\u4e86\u200b\u6700\u5927\u200b\u957f\u5ea6\u200b <code>max_length</code>\uff09\u200b\u65f6\u200b\u63d0\u524d\u200b\u505c\u6b62\u200b\u641c\u7d22\u200b\u3002\u200b\u8fd9\u200b\u610f\u5473\u7740\u200b\u5373\u4f7f\u200b\u6ca1\u6709\u200b\u8fbe\u5230\u200b\u6700\u5927\u200b\u6b65\u6570\u200b\uff0c\u200b\u53ea\u8981\u200b\u6240\u6709\u200b\u7684\u200b\u5019\u9009\u200b\u5e8f\u5217\u200b\u90fd\u200b\u5b8c\u6210\u200b\u4e86\u200b\uff0c\u200b\u641c\u7d22\u200b\u5c31\u200b\u4f1a\u200b\u505c\u6b62\u200b\u3002</p>"},{"location":"AI/Paper_Reading/Component/HyperParameter/NLG/generation_config.html#temperature","title":"temperature","text":"<p>\u200b\u6e29\u5ea6\u200b\u7cfb\u6570\u200b\uff0c\\(p_i=\\frac{e^{z_i/T}}{\\sum_j e^{e_j/T}}\\)\uff0c\u200b\u6e29\u5ea6\u200b\u503c\u8d8a\u200b\u9ad8\u200b\uff08\u200b\u5dee\u5f02\u200b\u53d8\u5c0f\u200b\uff09\uff0c\u200b\u6982\u7387\u5206\u5e03\u200b\u8d8a\u200b\u5e73\u6ed1\u200b\uff0c\u200b\u751f\u6210\u200b\u6587\u672c\u200b\u8d8a\u200b\u591a\u6837\u5316\u200b\uff1b\u200b\u53cd\u4e4b\u200b\u6982\u7387\u5206\u5e03\u200b\u8d8a\u200b\u5c16\u9510\u200b\uff0c\u200b\u751f\u6210\u200b\u6587\u672c\u200b\u66f4\u200b\u8d8b\u8fd1\u200b\u9ad8\u200b\u6982\u7387\u200b\u7ed3\u679c\u200b\u3002</p>"},{"location":"AI/Paper_Reading/Component/HyperParameter/NLG/generation_config.html#length_penalty","title":"length_penalty","text":"<p>\u200b\u8be5\u200b\u53c2\u6570\u200b\u901a\u8fc7\u200b\u5bf9\u200b\u6bcf\u4e2a\u200b\u5019\u9009\u200b\u5e8f\u5217\u200b\u7684\u200b\u6982\u7387\u200b\u8fdb\u884c\u200b\u8c03\u6574\u200b\uff0c\u200b\u4ee5\u200b\u5e73\u8861\u200b\u8f83\u200b\u77ed\u200b\u548c\u200b\u8f83\u957f\u200b\u5e8f\u5217\u200b\u4e4b\u95f4\u200b\u7684\u200b\u6982\u7387\u200b\uff0c\u200b\u6700\u7ec8\u200b\u8c03\u8282\u200b\u751f\u6210\u200b\u5e8f\u5217\u200b\u7684\u200b\u957f\u5ea6\u200b\u504f\u597d\u200b\uff0c\u200b\u5177\u4f53\u200b\u8fc7\u7a0b\u200b\u5982\u4e0b\u200b</p> \\[ P^{'}=\\frac{P}{(L+1)^\\alpha} \\] <ul> <li>\\(P\\) \u200b\u8868\u793a\u200b\u539f\u59cb\u200b\u5e8f\u5217\u200b\u79ef\u7d2f\u200b\u6982\u7387\u200b(\\(-\\log\\big(\\prod p_1\\cdots p_{L}\\big)\\))\uff0c\\(L\\) \u200b\u8868\u793a\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b\uff0c\\(\\alpha\\) \u200b\u4e3a\u200b<code>length_penalty</code></li> <li><code>\u03b1 &gt; 0</code>\uff0c\u200b\u5e42\u200b\u5e95\u6570\u200b&lt;1\uff0c\u200b\u56e0\u6b64\u200b\u503e\u5411\u200b\u4e8e\u200b\u751f\u6210\u200b\u66f4\u200b\u77ed\u200b\u7684\u200b\u5e8f\u5217\u200b(\u200b\u7531\u200b\u957f\u5ea6\u200b\u5f15\u8d77\u200b\u7684\u200b\u5e8f\u5217\u200b\u79ef\u7d2f\u200b\u6982\u7387\u200b\u5f71\u54cd\u200b\u6ca1\u200b\u5e42\u6307\u6570\u200b\u51fd\u6570\u200b\u5927\u200b)</li> <li><code>\u03b1 &lt; 0</code>\uff0c\u200b\u5e42\u200b\u5e95\u6570\u200b&gt;1\uff0c\u200b\u56e0\u6b64\u200b\u503e\u5411\u200b\u4e8e\u200b\u751f\u6210\u200b\u66f4\u957f\u200b\u7684\u200b\u5e8f\u5217\u200b(\u200b\u7531\u200b\u957f\u5ea6\u200b\u5f15\u8d77\u200b\u7684\u200b\u5e8f\u5217\u200b\u79ef\u7d2f\u200b\u6982\u7387\u200b\u5f71\u54cd\u200b\u6ca1\u200b\u5e42\u6307\u6570\u200b\u51fd\u6570\u200b\u5927\u200b)</li> <li><code>\u03b1 = 0</code>\uff0c\u200b\u65e0\u200b\u957f\u5ea6\u200b\u60e9\u7f5a\u200b</li> <li><code>\u03b1 = 1</code>\uff0c\u200b\u7f3a\u7701\u200b\u72b6\u6001\u200b\uff0c\u200b\u9f13\u52b1\u200b\u751f\u6210\u200b\u66f4\u200b\u77ed\u200b\u7684\u200b\u5e8f\u5217\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Component/HyperParameter/NLG/generation_config.html#repetation_penalty","title":"repetation_penalty","text":"<p>\u200b\u8be5\u200b\u53c2\u6570\u200b\u7528\u4e8e\u200b\u63a7\u5236\u200b\u6a21\u578b\u200b\u751f\u6210\u200b\u6587\u672c\u200b\u65f6\u200b\u5bf9\u200b\u91cd\u590d\u200b\u8bcd\u8bed\u200b\u6216\u200b\u77ed\u8bed\u200b\u7684\u200b\u60e9\u7f5a\u200b\u7a0b\u5ea6\u200b(\u200b\u8c03\u6574\u200b\u8bcd\u200b\u6982\u7387\u200b)\uff0c\u200b\u5177\u4f53\u200b\u8fc7\u7a0b\u200b\u4e3a\u200b\uff1a  </p> <ol> <li> <p>\u200b\u8c03\u6574\u200b\u5019\u9009\u8bcd\u200b\u6982\u7387\u200b\uff0c\\(R\\)\u200b\u8868\u793a\u200b<code>repetation_penalty</code> </p> \\[ p^{'}(x)=\\begin{cases}     {p(x)^{1/R}} &amp; x\\text{ has occurred} \\\\     {p(x)} &amp; x\\text{ has not occurred} \\end{cases} \\] </li> <li> <p>\u200b\u5f52\u4e00\u5316\u200b\u5019\u9009\u8bcd\u200b\u6982\u7387\u200b  </p> \\[ p^{''}(x)=\\frac{p^{'}(x)}{\\sum_y p^{'}(y)} \\] </li> </ol> <ul> <li>\u200b\u5b9e\u9645\u200b\u5e94\u7528\u200b\u4e2d\u200b<code>R</code>\u200b\u901a\u5e38\u200b\u8bbe\u5b9a\u200b\u5728\u200b0.8\u200b\u5230\u200b1.2\u200b\u4e4b\u95f4\u200b</li> <li><code>R &gt; 1.0</code>\uff0c\u200b\u589e\u52a0\u200b\u6a21\u578b\u200b\u5bf9\u200b\u91cd\u590d\u200b\u8bcd\u200b\u7684\u200b\u60e9\u7f5a\u200b\uff0c\u200b\u964d\u4f4e\u200b\u51fa\u73b0\u200b\u6982\u7387\u200b\uff0c\u200b\u9f13\u52b1\u200b\u591a\u6837\u6027\u200b  </li> <li><code>R &lt; 1.0</code>\uff0c\u200b\u964d\u4f4e\u200b\u6a21\u578b\u200b\u5bf9\u200b\u91cd\u590d\u200b\u8bcd\u200b\u7684\u200b\u60e9\u7f5a\u200b\uff0c\u200b\u63d0\u5347\u200b\u51fa\u73b0\u200b\u6982\u7387\u200b\uff0c\u200b\u53ef\u80fd\u200b\u6709\u52a9\u4e8e\u200b\u4fdd\u6301\u200b\u4e0a\u4e0b\u6587\u200b\u4e00\u81f4\u6027\u200b  </li> <li><code>R = 1.0</code>\uff0c\u200b\u7f3a\u7701\u200b\u60c5\u51b5\u200b\uff0c\u200b\u4e0d\u200b\u5bf9\u200b\u8be5\u200b\u91cd\u590d\u200b\u5355\u8bcd\u200b\u8fdb\u884c\u200b\u4efb\u4f55\u200b\u7279\u522b\u200b\u5904\u7406\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Component/HyperParameter/NLG/generation_config.html#top-k","title":"top-k","text":"<p>\u200b\u5bf9\u200btop-k\u200b\u4e2a\u200b\u5019\u9009\u8bcd\u200b\u8fdb\u884c\u200b\u91c7\u6837\u200b\u4f5c\u4e3a\u200b\u4e0b\u200b\u4e00\u200b\u751f\u6210\u200b\u8bcd\u200b\u3002</p>"},{"location":"AI/Paper_Reading/Component/HyperParameter/NLG/generation_config.html#top-p","title":"top-p","text":"<p>\u200b\u5373\u200bnuclear sampling\uff0c\u200b\u5bf9\u200b\u6309\u200b\u7f6e\u4fe1\u5ea6\u200b\u964d\u5e8f\u200b\u6392\u5217\u200b\u7684\u200b\u524d\u200bn\u200b\u4e2a\u200b\u8bcd\u200b\u8fdb\u884c\u200b\u91c7\u6837\u200b\u4f5c\u4e3a\u200b\u4e0b\u200b\u4e00\u200b\u751f\u6210\u200b\u8bcd\u200b\uff0c\u200b\u8981\u6c42\u200b\u6ee1\u8db3\u200b\\(\\sum_{i=1}^{n-1} p_i \\lt p\\text{ and }\\sum_{i=1}^{n} p_i \\ge p\\)</p>"},{"location":"AI/Paper_Reading/Component/Normalization/normalization.html","title":"Normlization","text":"<ul> <li>RMSNorm\u200b\u53ea\u6709\u200b\u7f29\u653e\u200b\u53c2\u6570\u200b</li> <li>LN\u200b\u989d\u5916\u200b\u589e\u52a0\u200b\u504f\u79fb\u200b\u53c2\u6570\u200b</li> <li>BN\u200b\u5728\u200b\u4e0a\u8ff0\u200b\u57fa\u7840\u200b\u4e0a\u200b\u52a8\u91cf\u200b\u4fdd\u7559\u200b\u5386\u53f2\u200b\u65b9\u5dee\u200b\u548c\u200b\u5747\u503c\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Component/Normalization/normalization.html#bn","title":"BN","text":"<p>\u200b\u5373\u200b Batch Normalization</p>"},{"location":"AI/Paper_Reading/Component/Normalization/normalization.html#ln","title":"LN","text":"<p>\u200b\u5373\u200b Layer Normalization\uff0c\u200b\u57fa\u4e8e\u200b\u6837\u672c\u200b\u6240\u6709\u200b\u7ef4\u5ea6\u200b\u4fe1\u606f\u200b\u8fdb\u884c\u200b\u5e73\u79fb\u200b\u4e0d\u200b\u6362\u200b\u8f6c\u5316\u200b\u548c\u200b\u7f29\u653e\u200b\u4e0d\u53d8\u200b\u8f6c\u5316\u200b\uff0c\u200b\u968f\u540e\u200b\u8fdb\u884c\u200b\u6295\u5f71\u53d8\u6362\u200b\u3002</p> \\[ \\begin{aligned}     \\text{LN}(x_i) = \\hat{x_i} =&amp;\\frac{x_i - \\mu}{\\sqrt{\\frac{1}{d}\\sum_{j=1}^d (x_j - \\mu)^2} + \\epsilon}    \\\\     y_i =&amp; \\gamma_i\\hat{x_i} + \\beta_i \\\\     &amp;\\gamma, \\beta \\in \\mathbb{R}^{d} \\end{aligned} \\]"},{"location":"AI/Paper_Reading/Component/Normalization/normalization.html#pre-norm-post-norm","title":"Pre-Norm &amp; Post-Norm","text":"<p>Pre-Norm/Post-Norm \u200b\u662f\u200b\u6307\u200b\u5728\u200b\u6b8b\u5dee\u200b\u8fde\u63a5\u200b\u64cd\u4f5c\u200b\u4e4b\u524d\u200b/\u200b\u4e4b\u540e\u200b\u6267\u884c\u200bNorm\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u76f4\u767d\u200b\u7684\u200b\u533a\u522b\u200b\u662f\u200b\u5728\u200b\u8981\u200b\u7528\u200b\u7684\u200b\u65f6\u5019\u200b\u8fdb\u884c\u200bNorm\u200b\u64cd\u4f5c\u200b\u8fd8\u662f\u200b\u7528\u200b\u4e4b\u524d\u200b\u5c31\u200b\u6267\u884c\u200bNorm\u200b\u64cd\u4f5c\u200b</p> \\[ \\begin{aligned}     x_{t+1}^{pre-norm} = x_t + F_t\\big(\\text{Norm}(x_t)\\big) \\\\     x_{t+1}^{post-norm} = \\text{Norm}\\big(x_t + F_t(x_t)\\big) \\end{aligned} \\] <ol> <li> <p>Pre-Norm</p> <ul> <li> \u200b\u8bad\u7ec3\u200b\u7a33\u5b9a\u200b\uff0c\u200b\u6536\u655b\u200b\u5feb\u200b\uff0c\u200b\u9002\u5408\u200b\u6df1\u5c42\u200b\u6a21\u578b\u200b</li> <li> \u200b\u8fd0\u7528\u200b\\(h_t\\)\u200b\u4f5c\u4e3a\u200b\u9884\u6d4b\u200b\u5c42\u200b\u8f93\u5165\u200b\u524d\u200b\u6700\u597d\u200b\u8fdb\u884c\u200bNorm\u200b\u64cd\u4f5c\u200b\u4ee5\u200b\u5f52\u4e00\u5316\u200b\u65b9\u5dee\u200b</li> <li>\u200b\u76f8\u540c\u200b\u6761\u4ef6\u200b\u4e0b\u8f83\u200bPost-Norm\u200b\u6700\u4f18\u200b\u8868\u8fbe\u80fd\u529b\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u7565\u4f4e\u200b\u3002</li> </ul> </li> <li> <p>Post-Norm</p> <ul> <li> \u200b\u8868\u8fbe\u80fd\u529b\u200b\u66f4\u5f3a\u200b\uff0c\u200b\u4f46\u200b\u8bad\u7ec3\u200b\u4e0d\u200b\u7a33\u5b9a\u200b\uff0c\u200b\u6536\u655b\u200b\u6162\u200b\uff0c\u200b\u9002\u5408\u200b\u6d45\u5c42\u200b\u6a21\u578b\u200b\u3002</li> <li>Post-Norm\u200b\u6a21\u578b\u200b\u7684\u200b\u8bad\u7ec3\u200b\u6781\u5ea6\u200b\u4f9d\u8d56\u200bwarmup</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Normalization/normalization.html#rmsnorm","title":"RMSNorm","text":"<p>\u200b\u5373\u200b Root Mean Squared Layer Normalization\uff0cRMS\u200b\u8ba4\u4e3a\u200bLN\u200b\u53d6\u5f97\u200b\u7684\u200b\u6210\u529f\u200b\u662f\u200b\u7f29\u653e\u200b\u4e0d\u53d8\u6027\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u5e73\u79fb\u200b\u4e0d\u53d8\u6027\u200b\uff0c\u200b\u56e0\u6b64\u200b\u8f83\u200bLN\u200b\u53ea\u200b\u4fdd\u7559\u200b\u4e86\u200b\u7f29\u653e\u200b\u8f6c\u5316\u200b\uff08\u200b\u9664\u4ee5\u200b\u6807\u51c6\u5dee\u200b\uff09\uff0c\u200b\u53bb\u200b\u9664\u4e86\u200b\u5e73\u79fb\u200b\u8f6c\u5316\u200b\uff08\u200b\u51cf\u53bb\u200b\u5747\u503c\u200b\uff09\uff0c\u200b\u968f\u540e\u200b\u8fdb\u884c\u200b\u65e0\u200b\u504f\u7f6e\u200b\u9879\u200b\u7684\u200b\u6295\u5f71\u53d8\u6362\u200b</p> \\[ \\begin{aligned}     \\text{RMS}(x_i)=\\hat{x_i} =&amp; \\frac{x_i}{\\sqrt{\\frac{1}{d}\\sum_{j=1}^{d}x_j^2}+\\epsilon} \\\\     y_i =&amp; \\gamma_i \\hat{x_i} \\\\     &amp; \\gamma \\in \\mathbb{R}^d \\end{aligned} \\]"},{"location":"AI/Paper_Reading/Component/Normalization/pre-norm_post-norm.html","title":"Pre norm post norm","text":""},{"location":"AI/Paper_Reading/Component/Normalization/pre-norm_post-norm.html#post-norm","title":"Post-Norm","text":"<p>\u200b\u5373\u200b\u5728\u200b\u6b8b\u5dee\u200b\u8fde\u63a5\u200b\u64cd\u4f5c\u200b\u540e\u200b\u6267\u884c\u200bNorm\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u5982\u4e0b\u200b\u5f0f\u200b\uff1a</p> \\[ \\begin{aligned}     x_{t+1} =&amp; \\text{Norm}\\big(x_t + F_t(x_t)\\big) \\\\     \\text{\u200b\u53ef\u200b\u7406\u89e3\u200b\u4e3a\u200b } x_{t+1} =&amp; \\frac{x_{t} + F_{t}(x_t)}{\\sqrt{2}} \\\\     \\Rightarrow x_l =&amp; \\frac{x_{l-1}}{\\sqrt{2}} + \\frac{F_{l-1}(x_{l-1})}{\\sqrt{2}} \\\\     =&amp; \\frac{x_{l-2}}{2} + \\frac{F_{l-2}(x_{l-2})}{2} + \\frac{F_{l-1}(x_{l-1})}{\\sqrt{2}} \\\\     =&amp; \\cdots \\\\     =&amp; \\frac{x_{0}}{2^{l/2}} + \\frac{F_{0}(x_{0})}{2^{l/2}} + \\frac{F_{1}(x_{1})}{2^{(l-1)/2}} + \\frac{F_{2}(x_{2})}{2^{(l-2)/2}} + \\cdots + \\frac{F_{l-1}(x_{l-1})}{2^{1/2}} \\end{aligned} \\] <p>\u200b\u5728\u200bPost-Norm\u200b\u4e2d\u200b\uff0c\u200b\u8d8a\u200b\u4f4e\u5c42\u200b\u7684\u200bLayer\u200b\u6b8b\u5dee\u200b\u6743\u91cd\u200b\u5360\u200b\u6bd4\u8d8a\u200b\u5c0f\u200b\uff0c\u200b\u5176\u200b\u6b8b\u5dee\u200b\u201c\u200b\u540d\u5b58\u5b9e\u4ea1\u200b\u201d</p> <ul> <li>\u200b\u968f\u7740\u200b\\(l\\)\u200b\u7684\u200b\u589e\u957f\u200b\uff0c\u200b\u6a21\u578b\u200b\uff08\u200b\u4f4e\u5c42\u200b\uff09\u200b\u8bad\u7ec3\u200b\u4e0d\u7a33\u5b9a\u6027\u200b\u589e\u52a0\u200b\uff0c\u200b\u6536\u655b\u200b\u6162\u200b\uff1b</li> <li>Post-Norm\u200b\u6a21\u578b\u200b\u7684\u200b\u8bad\u7ec3\u200b\u6781\u5ea6\u200b\u4f9d\u8d56\u200bwarmup</li> </ul>"},{"location":"AI/Paper_Reading/Component/Normalization/pre-norm_post-norm.html#pre-norm","title":"Pre-Norm","text":"<p>\u200b\u5373\u200b\u5728\u200b\u6b8b\u5dee\u200b\u8fde\u63a5\u200b\u64cd\u4f5c\u524d\u200b\u6267\u884c\u200bNorm\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u5982\u4e0b\u200b\u5f0f\u200b\uff1a</p> \\[ \\begin{aligned}     x_{t+1} =&amp; x_t + F_t\\big(\\text{Norm}(x_t)\\big)\\\\     =&amp; x_{t-1} + F_{t-1}\\big(\\text{Norm}(x_{t-1})\\big) + F_{t}\\big(\\text{Norm}(x_{t})\\big) \\\\     =&amp; \\cdots \\\\     =&amp; x_{0} +\\underbrace{F_{0}\\big(\\text{Norm}(x_{0})\\big) + F_{1}\\big(\\text{Norm}(x_{1})\\big) + \\cdots  + F_{t}\\big(\\text{Norm}(x_{t})\\big)}_{t+1} \\\\     \\text{\u200b\u7531\u200b\u4e0a\u5f0f\u200b\u53ef\u77e5\u200b }x_{t+1}&amp;\\text{ \u200b\u662f\u200b\u589e\u91cf\u200b\u6a21\u578b\u200b\uff0c\u200b\u540e\u200bt+1\u200b\u9879\u4e3a\u200b\u540c\u4e00\u200b\u6570\u91cf\u7ea7\u200b\uff0c\u200b\u4e8e\u662f\u200b\u6709\u200b}\\text{Norm}(x_t) = \\frac{x_t}{\\sqrt{t+1}} \\\\     \\Rightarrow x_l =&amp; x_0 + F_{0}(x_{0}) + F_{1}\\Big(\\frac{x_1}{\\sqrt{2}}\\Big) + \\cdots + F_t\\Big(\\frac{x_{l-1}}{\\sqrt{l}}\\Big) \\\\ \\end{aligned} \\] <p>\u200b\u5728\u200bPre-Norm\u200b\u4e2d\u200b\uff0c\u200b\u5404\u5c42\u200bLayer\u200b\u6b8b\u5dee\u200b\u901a\u9053\u200b\u662f\u200b\u5e73\u6743\u200b\u7684\u200b\uff0c\u200b\u66f4\u200b\u9002\u5408\u200b\u8bad\u7ec3\u200b\u591a\u5c42\u200b\u6a21\u578b\u200b</p> <ul> <li>\u200b\u6b8b\u5dee\u200b\u4f5c\u7528\u200b\u8f83\u200b Post-Norm \u200b\u66f4\u52a0\u200b\u660e\u663e\u200b\uff0c\u200b\u56e0\u6b64\u200b\u66f4\u597d\u200b\u4f18\u5316\u200b\u6a21\u578b\u200b\uff1b</li> <li>\u200b\u968f\u7740\u200b\\(l\\)\u200b\u7684\u200b\u589e\u957f\u200b\uff0c\\(x_l\\)\u200b\u65b9\u5dee\u200b\u5c06\u4f1a\u200b\u5f88\u5927\u200b\uff0c\u200b\u6240\u4ee5\u200b\u5728\u200b\u63a5\u200b\u9884\u6d4b\u200b\u5c42\u200b\u4e4b\u524d\u200b\\(x_l\\)\u200b\u4e5f\u200b\u8fd8\u8981\u200b\u52a0\u4e2a\u200bNorm\u200b\u64cd\u4f5c\u200b  </li> <li>\u200b\u5728\u200bEmbedding\u200b\u5c42\u540e\u200b\u6dfb\u52a0\u200bnorm\u200b\u518d\u200b\u8f93\u5165\u200b\uff0c\u200b\u6709\u5229\u4e8e\u200b\u63d0\u5347\u200b\u8bad\u7ec3\u200b\u7a33\u5b9a\u6027\u200b\uff0c\u200b\u4f46\u200b\u8be5\u200bPre-Norm\u200b\u64cd\u4f5c\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u5e26\u6765\u200b\u4e00\u5b9a\u200b\u7684\u200b\u6027\u80fd\u200b\u635f\u5931\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Component/Optimizer/muonw.html","title":"Muonw","text":""},{"location":"AI/Paper_Reading/Component/Optimizer/muonw.html#muonw","title":"MuonW","text":"<p>\u200b\u8bba\u6587\u200b\uff1aMuon is Scalable for LLM Training Moonshot AI &amp; UCLA, 2025 Feb  </p>"},{"location":"AI/Paper_Reading/Component/Optimizer/muonw.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li> <p> \u200b\u901a\u8fc7\u200b\u6dfb\u52a0\u200b\u6743\u91cd\u200b\u8870\u51cf\u200b\u9879\u200b\u3001\u200b\u5c06\u200bMuon RMS\u200b\u4e0e\u200bAdamW\u200b\u4f18\u5316\u200b\u5668\u200b\u5339\u914d\u200b\u7b49\u200b\u6539\u8fdb\u200b\u63aa\u65bd\u200b\uff0c\u200b\u63d0\u5347\u200b\u5927\u200b\u6a21\u578b\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6548\u7387\u200b\uff08~2x\uff09\u200b\u4e0e\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</p> <p></p> <p></p> </li> </ul>"},{"location":"AI/Paper_Reading/Component/Optimizer/muonw.html#weight-decay","title":"Weight Decay","text":"<p>\u200b\u4f7f\u7528\u200bMuon\u200b\u9884\u200b\u8bad\u7ec3\u200b\u65f6\u200b\uff0c\u200b\u53d1\u73b0\u200b \u200b\u65e0\u200bweight decay\u200b\u7ea6\u675f\u200b\u7684\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b Root Mean Square \u200b\u4f1a\u200b\u4e00\u76f4\u200b\u589e\u5927\u200b\uff0c\u200b\u6700\u7ec8\u200b\u8d85\u51fa\u200bbf16\u200b\u7684\u200b\u7cbe\u5ea6\u200b\u8303\u56f4\u200b \uff0c\u200b\u5f71\u54cd\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u6548\u679c\u200b\u3002\u200b\u56e0\u6b64\u200b\u63d0\u51fa\u200bMounW</p> \\[ \\theta_t = \\theta_{t-1} - \\eta_t(o_t  + \\lambda \\theta_{t-1}) \\] <ul> <li>Muon\u200b\u8f83\u200bAdamW\u200b\u5728\u200b\u5c0f\u89c4\u6a21\u200b\u6a21\u578b\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u66f4\u4f73\u200b\uff0c\u200b\u4f46\u200b\u968f\u7740\u200b\u6a21\u578b\u200b\u89c4\u6a21\u200b\u589e\u5927\u200b\u63d0\u5347\u200b\u589e\u76ca\u200b\u9010\u6e10\u200b\u6d88\u5931\u200b</li> <li>MuonW\u200b\u8868\u73b0\u200b\u4f18\u4e8e\u200bMuon\u200b\u548c\u200bAdamW\uff0c\u200b\u5728\u200b\u5927\u89c4\u6a21\u200b\u8bad\u7ec3\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u66f4\u200b\u4f4e\u200b\u7684\u200bvalid loss</li> </ul>"},{"location":"AI/Paper_Reading/Component/Optimizer/muonw.html#update-rescale","title":"Update Rescale","text":"\\[ \\theta_t = \\theta_{t-1} - \\eta_t(0.2\\cdot o_t \\cdot \\sqrt{\\max(n, m)} + \\lambda \\theta_{t-1}) \\] <p>\u200b\u5176\u4e2d\u200b\\(0.2 \\cdot \\sqrt{\\max(n, m)}\\) \u200b\u7edf\u79f0\u200b\u4e3a\u200b\u4e3a\u200b\u8c03\u6574\u200b\u5b66\u4e60\u200b\u7387\u200b \\(\\eta\\) \u200b\u64cd\u4f5c\u200b</p> <ol> <li> <p>theoretical Muon update\uff1a\u200b\u7ed9\u5b9a\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b\uff08shape \\([n, m]\\)\uff09\uff0c\u200b\u5176\u200b\u68af\u5ea6\u200b\u77e9\u9635\u200b\\(g = USV^T\\)\uff0c\u200b\u6b63\u4ea4\u200b\u5316\u200b\u7ed3\u679c\u200b \\(o = U_{[:, :r]}V_{[:r, :]}\\)\uff0c\u200b\u5176\u4e2d\u200b \\(n \\ge m \\ge r\\)</p> \\[ \\begin{aligned}     o_{i, j} =&amp; \\sum_{k=1}^r U_{i, k} V_{k, j} \\\\     \\text{RMS}(o)^2 =&amp; \\frac{1}{nm} \\sum_{i=1}^{n}\\sum_{j=1}^m \\sum_{k=1}^r U_{i, k}^2 V_{k, j}^2 \\\\     =&amp; \\frac{1}{nm} \\sum_{k=1}^r \\sum_{i=1}^n U_{i, k}^2 \\sum_{j=1}^m V_{k, j}^2\\\\     =&amp; \\frac{1}{nm} \\sum_{k=1}^r 1\\\\     =&amp; \\frac{r}{nm} \\end{aligned} \\] <p>\\(\\text{RMS}(o)=\\sqrt{r/nm}\\)\uff0c\u200b\u5176\u4e2d\u200b\u5728\u200b\u6ee1\u200b\u79e9\u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u4e3a\u200b \\(\\text{RMS}(o)=\\sqrt{1/n}\\)</p> </li> <li> <p>maintain consistent update RMS\uff0c\u200b\u7531\u4e8e\u200b \\(\\text{RMS}(o)\\) \u200b\u548c\u200b\u77e9\u9635\u200b\u578b\u200b\u76f8\u5173\u200b\uff0c\u200b\u9700\u200b\u6267\u884c\u200b \\(o_t \\cdot \\sqrt{\\max(n, m)}\\) \u200b\u4ee5\u200b\u4fdd\u6301\u200bRMS\u200b\u4e00\u81f4\u6027\u200b\uff0c\u200b\u9632\u6b62\u200b\uff1a</p> <ul> <li> \\(\\max(n, m)\\) \u200b\u8fc7\u5927\u200b\uff1adense MLP matrix\u200b\u68af\u5ea6\u200b\u66f4\u65b0\u200b\u5e45\u5ea6\u200b\u8fc7\u200b\u5c0f\u200b\uff0c\u200b\u9650\u5236\u200b\u6a21\u578b\u200b\u8868\u5f81\u200b\u80fd\u529b\u200b</li> <li> \\(\\max(n, m)\\) \u200b\u8fc7\u200b\u5c0f\u200b\uff1aGQA\u200b\u6216\u200bMLA\u200b\u4e2d\u200b\u7684\u200b\u5404\u200bk\u3001v head\u200b\u5bf9\u5e94\u200b\u7684\u200b\u6743\u91cd\u200b\u77e9\u9635\u200b\u4e2d\u200b\uff0c\u200b\u66f4\u65b0\u200b\u5e45\u5ea6\u200b\u8fc7\u5927\u200b\u5bfc\u81f4\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u4e0d\u200b\u7a33\u5b9a\u200b\uff0c\u200b\u524a\u51cf\u200b\u6a21\u578b\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</li> </ul> </li> <li> <p>match update RMS of AdamW\uff0c\u200b\u7531\u4e8e\u200bMuon\u200b\u65e0\u6cd5\u200b\u5904\u7406\u200bEmbedding\u200b\u548c\u200bNorm\u200b\u7b49\u200b\u975e\u200b\u77e9\u9635\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b\u5c42\u200b\uff0c\u200b\u4e00\u822c\u200b\u9700\u8981\u200b\u4e0e\u200bAdamW\u200b\u642d\u914d\u200b\u4f7f\u7528\u200b\uff0c\u200b\u540c\u65f6\u200b\u4e3a\u4e86\u200b\u8fdb\u4e00\u6b65\u200b\u5171\u4eab\u200b\u4f18\u5316\u200b\u5668\u8d85\u200b\u53c2\u200b\uff08\\(\\eta, \\lambda\\)\uff09\uff0c\u200b\u56e0\u6b64\u200b\u9700\u8981\u200b\u548c\u200bAdamW\u200b\u7684\u200bRMS\u200b\u76f8\u5339\u914d\u200b\uff0c\u200b\u5b9e\u9a8c\u200b\u53d1\u73b0\u200b\u53d6\u200b0.2~0.4\u200b\u6700\u4f73\u200b</p> <p></p> <p></p> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Optimizer/muonw.html#evaluation","title":"Evaluation","text":"<ol> <li> <p>Learning Curve</p> <ul> <li>loss\u200b\u548c\u200bgradient norm\u200b\u5e73\u6ed1\u200b\u4e0b\u964d\u200b\uff0c\u200b\u65e0\u200b\u663e\u8457\u200b\u7a81\u523a\u200b\u73b0\u8c61\u200b</li> <li>\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u4e2d\u200battention logit\u200b\u6570\u503c\u200b\u3001\u200b\u9891\u7387\u200b\u5747\u200b\u5b58\u5728\u200b\u4e0d\u200b\u5065\u5eb7\u200b\u7206\u70b8\u200b\u589e\u957f\u200b\u9636\u6bb5\u200b</li> </ul> <p></p> <p></p> </li> <li> <p>Consistent Update RMS </p> <ul> <li>Baseline\uff1a\\(\\theta_t = \\theta_{t-1} - \\eta_t(0.2 \\cdot o_t \\cdot \\sqrt{d_\\text{hidden_state}} + \\lambda \\theta_{t-1})\\) </li> <li>Update Norm\uff1a\\(\\theta_t = \\theta_{t-1} - \\eta_t(0.2 \\cdot o_t/ \\sqrt{\\text{RMS}(o_t)} + \\lambda \\theta_{t-1})\\) </li> <li>Adjusted LR\uff08MuonW\uff09\uff1a\\(\\theta_t = \\theta_{t-1} - \\eta_t(0.2 \\cdot o_t \\cdot \\sqrt{\\max(n, m)} + \\lambda \\theta_{t-1})\\)</li> </ul> <p></p> <p></p> <p>attention query (shape \\([H, H]\\))\uff0cMLP\uff08shape \\([H, 4H]\\)\uff09</p> <p>Update Norm \u200b\u548c\u200b Adjusted LR loss\u200b\u8868\u73b0\u200b\u5747\u200b\u4f18\u4e8e\u200bBaseline\uff0c\u200b\u4e14\u200bAdjusted LR\u200b\u6548\u679c\u200b\u66f4\u4f18\u200b</p> </li> <li> <p>Scaling Law of Muon</p> <p></p> <p></p> <p>\u200b\u5728\u200b\u6700\u4f73\u200b\u8ba1\u7b97\u200b\u5f00\u9500\u200b\u8bbe\u7f6e\u200b\u4e0b\u200b\uff0cMuonW \u200b\u4ec5\u200b\u9700\u8981\u200b\u7ea6\u200b 52% \u200b\u7684\u200b\u8bad\u7ec3\u200b FLOPs \u200b\u5373\u53ef\u200b\u8fbe\u5230\u200b AdamW \u200b\u7684\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\uff0c\u200b\u4e14\u200bMuonWScaling Law\u200b\u7684\u200b\u4f18\u5316\u200b\u66f2\u7ebf\u200b\u4e0a\u9650\u200b\u66f4\u4f73\u200b\u3002</p> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Optimizer/muonw.html#abaltion","title":"Abaltion","text":"<ol> <li> <p>Pretraining with Muon\uff1a\u200b\u4f7f\u7528\u200bMuonW Optmizer\u200b\u8f83\u200bAdamW\u200b\u5728\u200bPretained LLM\u200b\u65f6\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u66f4\u4f73\u200b</p> <p></p> <p></p> <p>Moonlight-A\u200b\u8868\u793a\u200b\u4f7f\u7528\u200bAdamW Optimizer\u200b\u9884\u200b\u8bad\u7ec3\u200b</p> </li> <li> <p>SFT with Muon </p> <p></p> <ul> <li>\u200b\u5728\u200bPretrain + SFT\u200b\u9636\u6bb5\u200b\u4e2d\u200b\uff0c\u200b\u5747\u200b\u5e94\u7528\u200bMuonW Optmizer\u200b\u6a21\u578b\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u6700\u4f18\u200b</li> <li>MuonW\u200b\u548c\u200bAdamW\u200b\u4f18\u5316\u200b\u5668\u200b\u5b58\u5728\u200b\u4e0d\u200b\u5339\u914d\u200b\u95ee\u9898\u200b\uff0c\u200b\u5728\u200bPretrain\u200b\u548c\u200bSFT\u200b\u9636\u6bb5\u200b\u66f4\u6362\u200bOptimizer\u200b\u4f1a\u200b\u5bfc\u81f4\u200b\u6a21\u578b\u200b\u6027\u80fd\u200b\u524a\u5f31\u200b</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Optimizer/muonw.html#kimi-k2","title":"Kimi-K2","text":"<p>\u200b\u8bba\u6587\u200b\uff1aKimi K2: Open Agentic Intelligence Blog Kimi Team, 2025 Jul</p>"},{"location":"AI/Paper_Reading/Component/Optimizer/muonw.html#_2","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Component/Optimizer/muonw.html#mounclip","title":"MounClip","text":"<p>\u200b\u7531\u200bMuonW\u200b\u53ef\u77e5\u200b\uff0c\u200b\u5728\u200b\u6a21\u578b\u200b\u9884\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u4e00\u5c0f\u90e8\u5206\u200bhead\u200b\u4e2d\u200battention logits\u200b\u7684\u200b\u6570\u503c\u200b\u548c\u200b\u51fa\u73b0\u200b\u9891\u7387\u200b\u4f1a\u200b\u51fa\u73b0\u200b\u4e0d\u200b\u5065\u5eb7\u200b\u7684\u200b\u7206\u70b8\u200b\u589e\u957f\u200b\u73b0\u8c61\u200b\uff0c\u200b\u5b9e\u9a8c\u200b\u53d1\u73b0\u200b\u8be5\u200b\u95ee\u9898\u200b\u4f1a\u200b\u5bfc\u81f4\u200b\u8bad\u7ec3\u200b\u4e0d\u200b\u7a33\u5b9a\u200b\u3002\u200b\u57fa\u4e8e\u200b\u4e0a\u8ff0\u200b\u73b0\u8c61\u200b\u63d0\u51fa\u200b\u4e86\u200b<code>per-head QK-Clip</code>\u200b\u65b9\u6848\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u6bcf\u4e2a\u200bhead\uff0c\u200b\u6267\u884c\u200b</p> \\[ \\begin{aligned}     q_i =&amp; \\eta^\\alpha W_q x_i \\\\     k_j =&amp; \\eta^{1-\\alpha} W_k x_j \\\\     q_i^Tk_j =&amp; \\eta (W_q x_i)^TW_k x_j \\\\     \\eta =&amp; \\min \\left( \\frac{\\tau}{\\max_{i, j} \\frac{1}{\\sqrt{d}}\\left(\\left(W_q x_i\\right)^TW_k x_j\\right)}, 1\\right) \\end{aligned} \\] <pre><code>if max(1/sqrt(d)*W_qQ(W_kK).T) &gt; \u03c4:\n    \u03b3 = \u03c4/max(1/sqrt(d)*W_qQ(W_kK).T)\n    W_q, W_k = pow(\u03b3, \u03b1) W_q, pow(\u03b3, 1-\u03b1)\n</code></pre> <p>\u200b\u622a\u65ad\u200battention logits\u200b\u4e0a\u9650\u200b\u4e3a\u200b\u9608\u503c\u200b \\(\\tau\\)</p>"},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html","title":"Optimizer","text":"<ul> <li>An overview of gradient descent optimization algorithms</li> </ul>"},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html#gradient-descent-variant","title":"Gradient Descent Variant","text":""},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html#sgd","title":"SGD","text":"<p>\u200b\u968f\u673a\u200b\u68af\u5ea6\u200b\u4e0b\u964d\u200b Stochastic Gradient Descent\uff0c\u200b\u4e00\u6b21\u200b\u8fed\u4ee3\u200b\u4f7f\u7528\u200b\u5355\u4e2a\u200b\u6837\u672c\u200b\u6216\u200b\u5c0f\u6279\u91cf\u200b(mini-batch)\u200b\u6837\u672c\u200b</p> \\[ \\begin{aligned}     g_t =&amp; \\nabla_{\\theta_{t-1}} J\\left(\\theta_{t-1}; x^{(i:i+n)}; y^{(i:i+n)}\\right) \\\\     \\theta_t  =&amp; \\theta_{t-1} -\\eta g_t     \\end{aligned} \\] <p>\\(1 \\le n \\lt \\text{batch_size}\\)</p>"},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html#bgd","title":"BGD","text":"<p>\u200b\u6279\u91cf\u200b\u68af\u5ea6\u200b\u4e0b\u964d\u200b Batch Gradient Descent, \u200b\u4e00\u6b21\u200b\u8fed\u4ee3\u200b\u4f7f\u7528\u200b\u6279\u91cf\u200b\u4e2d\u200b\u6240\u6709\u200b\u6837\u672c\u200b</p> \\[ \\begin{aligned}     g_t =&amp; \\nabla_{\\theta_{t-1}} J\\left(\\theta_{t-1}; x; y\\right) = \\nabla_{\\theta}J(\\theta) \\\\     \\theta_t  =&amp; \\theta_{t-1} -\\eta g_t     \\end{aligned} \\]"},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html#gradient-descent-optimization","title":"Gradient Descent Optimization","text":""},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html#momentum","title":"Momentum","text":"<p>\u200b\u52a8\u91cf\u200b\u6cd5\u200b Momentum \u200b\u6a21\u62df\u200b\u7269\u4f53\u200b\u8fd0\u52a8\u200b\u65f6\u200b\u7684\u200b\u60ef\u6027\u200b\uff0c\u200b\u5728\u200b\u68af\u5ea6\u200b\u66f4\u65b0\u200b\u65f6\u200b\u4e00\u5b9a\u200b\u7a0b\u5ea6\u200b\u4e0a\u200b\u4fdd\u7559\u200b\u4e4b\u524d\u200b\u66f4\u65b0\u200b\u7684\u200b\u65b9\u5411\u200b</p> \\[ \\begin{aligned}     v_t =&amp; \\gamma v_{t-1} + \\eta g_t \\\\     \\theta_t =&amp; \\theta_{t-1} - v_t \\end{aligned} \\]"},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html#nag","title":"NAG","text":"<p>Nesterov Accelerated Gradient\uff0c\u200b\u7ed3\u5408\u200b\u52a8\u91cf\u200b\u66f4\u65b0\u200b\u63d0\u524d\u200b\u63d0\u524d\u200b\"\u200b\u8df3\u8dc3\u200b\"\u200b\u5230\u200b\u4e00\u4e2a\u200b\u524d\u77bb\u200b\u4f4d\u7f6e\u200b\uff0c\u200b\u518d\u200b\u5728\u200b\u8be5\u200b\u4f4d\u7f6e\u200b\u8ba1\u7b97\u200b\u68af\u5ea6\u200b\u5e76\u200b\u4fee\u6b63\u200b\uff0c\u200b\u5728\u200b\u51f8\u200b\u4f18\u5316\u200b\u95ee\u9898\u200b\u4e2d\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u66f4\u200b\u5feb\u200b\u7684\u200b\u6536\u655b\u200b\u901f\u5ea6\u200b</p> \\[ \\begin{aligned}     v_t =&amp; \\gamma v_{t-1} + \\eta \\nabla_{\\theta_{t-1}} J(\\theta_{t-1} -\\gamma v_{t-1}) \\\\     \\theta_t =&amp; \\theta_{t-1} - v_t \\end{aligned} \\]"},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html#adagrad","title":"Adagrad","text":"<p>\u200b\u52a8\u6001\u200b\u8c03\u6574\u200b\u5b66\u4e60\u200b\u7387\u200b \\(\\eta\\)</p> \\[ \\begin{aligned}     G_{t} =&amp; \\sqrt{\\sum_{i=0}^{t}{(g_i)^2}} \\\\     \\theta_{t} =&amp; \\theta_{t-1}-\\frac{\\eta}{\\sqrt{G_{t} + \\epsilon}} \\odot g_t\\\\ \\end{aligned} \\]"},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html#adadelta","title":"Adadelta","text":"<p>\\(\\Delta \\theta\\) \u200b\u8868\u793a\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u66f4\u65b0\u200b\u91cf\u200b\uff0c\u200b\u5373\u200b \\(\\Delta\\theta_t = \\theta_t^\\text{tmp} - \\theta_{t-1}\\)</p> \\[ \\begin{aligned}     \\mathbb{E}\\left[ g^2 \\right]_t =&amp; \\gamma \\mathbb{E}\\left[ g^2 \\right]_{t-1} + (1 - \\gamma) g^2_t \\\\     \\mathbb{E}\\left[ \\Delta \\theta^2 \\right]_t =&amp; \\gamma \\mathbb{E}\\left[ \\Delta \\theta^2 \\right]_{t-1} + (1-\\gamma) \\Delta\\theta^2_t \\\\     \\theta_{t} =&amp; \\theta_{t-1}-\\frac{\\sqrt{\\mathbb{E}\\left[ \\Delta \\theta^2 \\right]_{t-1} + \\epsilon}}{\\sqrt{\\mathbb{E}\\left[ g^2 \\right]_t + \\epsilon}}\\odot g_t\\\\ \\end{aligned} \\]"},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html#rmsprop","title":"RMSprop","text":"\\[ \\begin{aligned}     \\mathbb{E}\\left[ g^2 \\right]_t =&amp; \\gamma \\mathbb{E}\\left[ g^2 \\right]_{t-1} + (1 - \\gamma) g^2_t \\\\     \\theta_{t} =&amp; \\theta_{t-1}-\\frac{\\eta}{\\sqrt{\\mathbb{E}\\left[ g^2 \\right]_t + \\epsilon}}\\odot g_t\\\\ \\end{aligned} \\]"},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html#adam","title":"Adam","text":"<p>Adaptive Moment Estimation\uff0c\u200b\u52a8\u6001\u200b\u8c03\u6574\u200b\u5b66\u4e60\u200b\u7387\u200b \\(\\eta\\) \u200b\u548c\u200b \u200b\u68af\u5ea6\u200b</p> \\[ \\begin{aligned}     m_t =&amp; \\beta_1 m_{t-1} + (1-\\beta_1) g_t\\\\     v_t =&amp; \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2\\\\     \\hat{m}_t =&amp; \\frac{m_t}{1-\\beta_1^{t}} \\\\     \\hat{v}_t =&amp; \\frac{v_t}{1-\\beta_2^{t}} \\\\     \\theta_{t} =&amp; \\theta_{t-1} -\\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon}\\odot \\hat{m}_t \\end{aligned} \\] <p>\\(\\hat{m}_t, \\hat{v}_t\\) \u200b\u4e3a\u200b\u521d\u59cb\u200b\u9636\u6bb5\u200b\u5bf9\u200b \\(m_t, v_t\\) \u200b\u7684\u200b\u504f\u5dee\u200b\u7ea0\u6b63\u200b\u9879\u200b\uff0c\u200b\u5206\u6bcd\u200b\u90e8\u5206\u200b \\(\\lim\\limits_{t \\rightarrow \\infty} \\beta^t = 0\\)</p>"},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html#adamax","title":"AdaMax","text":"<p>\u200b\u4f7f\u7528\u200b\u65e0\u7a77\u200b\u8303\u6570\u200b \\(L_{\\infty}\\) \u200b\u66ff\u4ee3\u200b \\(L_2\\) \u200b\u8303\u6570\u200b\u8ba1\u7b97\u200b\\(v_t\\) \uff0c\u200b\u5e76\u200b\u53d6\u6d88\u200b\u4e86\u200b\u5206\u6bcd\u200b\u7684\u200b\u504f\u5dee\u200b\u7ea0\u6b63\u200b\u9879\u200b</p> \\[ \\begin{aligned}     m_t =&amp; \\beta_1 m_{t-1} + (1-\\beta_1) g_t \\\\     v_t =&amp; \\max \\left(\\beta_2 v_{t-1}, \\vert g_t \\vert \\right)\\\\     \\hat{m}_t =&amp; \\frac{m_t}{1-\\beta_1^{t}} \\\\     \\theta_{t} =&amp; \\theta_{t-1} -\\frac{\\eta}{v_t}\\odot \\hat{m}_t \\end{aligned} \\]"},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html#nadam","title":"Nadam","text":"<p>Nesterov-accelerated Adaptive Moment Estimation\uff0c\u200b\u4e0e\u200bAdam\u200b\u5bf9\u200b\u68af\u5ea6\u200b\u90e8\u5206\u200b\u4f7f\u7528\u200b\u504f\u5dee\u200b\u7ea0\u6b63\u200b\u9879\u200b\u4e0d\u540c\u200b\uff0cNadam\u200b\u5bf9\u200b\u68af\u5ea6\u200b\u989d\u5916\u200b\u5e94\u7528\u200b\u4e86\u200b\u52a8\u91cf\u200b\u7684\u200b\u601d\u60f3\u200b</p> \\[ \\begin{aligned}     m_t =&amp; \\beta_1 m_{t-1} + (1-\\beta_1) g_t\\\\     v_t =&amp; \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2\\\\     \\hat{v}_t =&amp; \\frac{v_t}{1-\\beta_2^{t}} \\\\     \\hat{m}_t^{'} =&amp; \\beta_1 m_{t} + \\frac{1- \\beta_1}{1-\\beta^t_1}g_t\\\\     \\theta_{t} =&amp; \\theta_{t-1} -\\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon}\\odot \\hat{m}_t^{'} \\end{aligned} \\]"},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html#adamw","title":"AdamW","text":"<p>\u200b\u5728\u200bAdam\u200b\u7684\u200b\u57fa\u7840\u200b\u4e0a\u200b\uff0c\u200b\u52a0\u5165\u200b\u4e86\u200b\u4e0e\u200b\u5b66\u4e60\u200b\u7387\u200b \\(\\eta\\) \u200b\u89e3\u200b\u8026\u200b\u7684\u200b\u6743\u91cd\u200b\u8870\u51cf\u200b\u9879\u200b</p> \\[ \\begin{aligned}     m_t =&amp; \\beta_1 m_{t-1} + (1-\\beta_1) g_t\\\\     v_t =&amp; \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2\\\\     \\hat{m}_t =&amp; \\frac{m_t}{1-\\beta_1^{t}} \\\\     \\hat{v}_t =&amp; \\frac{v_t}{1-\\beta_2^{t}} \\\\     \\theta_{t} =&amp; \\theta_{t-1} -\\eta(\\frac{\\hat{m}_t}{{\\sqrt{\\hat{v}_t} + \\epsilon}} + \\lambda \\theta_{t-1}) \\end{aligned} \\]"},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html#muon-blog-github","title":"Muon: Blog, Github","text":"<p>MomentUm Orthogonalized by Newton-Schulz \u200b\u662f\u200b\u4e00\u4e2a\u4e8c\u7ef4\u200b\u53c2\u6570\u200b\u795e\u7ecf\u7f51\u7edc\u200b\uff08e.g., shape \\([n, m]\\)\uff09\u200b\u4f18\u5316\u200b\u5668\u200b\uff0c\u200b\u901a\u8fc7\u200b\u5bf9\u5f85\u200b\u66f4\u65b0\u200b\u7684\u200b\u52a8\u91cf\u200b\u68af\u5ea6\u200b\u6b63\u4ea4\u200b\u5316\u200b\uff0c\u200b\u4ee5\u200b\u63d0\u5347\u200b\u6a21\u578b\u200b\u9884\u200b\u8bad\u7ec3\u200b\u671f\u95f4\u200b\u7684\u200b\u6027\u80fd\u200b\u548c\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</p> \\[ \\begin{aligned}     m_t =&amp; \\mu m_{t-1} + g_t \\\\     o_t =&amp; \\text{Newton-Schulz} (m_t) \\\\     \\theta_t =&amp; \\theta_{t-1} - \\eta_t o_t \\end{aligned} \\] <ul> <li>\u200b\u5b9e\u9645\u4e0a\u200b\u9700\u8981\u200b\u5bf9\u200b \\(m_t\\) \uff08\u200b\u68af\u5ea6\u200b\u77e9\u9635\u200b\u6761\u4ef6\u200b\u6570\u200b\\(\\text{high_number} \\gg 1\\)\uff0c\u200b\u6570\u503c\u200b\u654f\u611f\u6027\u200b\u8fc7\u9ad8\u200b\uff09 \u200b\u5f52\u4e00\u5316\u200b\uff0c\u200b\u5373\u200b\\(m_t/\\Vert m_t \\Vert_\\text{F}\\) \u200b\u4f7f\u200b\u77e9\u9635\u200b\u5947\u5f02\u200b\u503c\u200b\u88ab\u200b\u7f29\u653e\u200b\u81f3\u200b\\([-1, 1]\\)\u200b\u8303\u56f4\u200b\u5185\u200b\uff0c\u200b\u786e\u4fdd\u200b Newton-Schulz \u200b\u8fed\u4ee3\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u7684\u200b\u6570\u503c\u200b\u7a33\u5b9a\u200b</li> <li>\u200b\u7531\u4e8e\u200b\u53ea\u80fd\u200b\u5bf9\u200b\u77e9\u9635\u200b\u8fdb\u884c\u200b\u6b63\u4ea4\u200b\u5316\u200b\uff0c\u200b\u56e0\u6b64\u200bEmbedding\u200b\u548c\u200bNorm\u200b\u7b49\u200b\u975e\u200b\u77e9\u9635\u200b\u53c2\u6570\u200b\u5c42\u200b\u7684\u200b\u4f18\u5316\u200b\u9700\u200b\u4f7f\u7528\u200b\u5176\u5b83\u200b\u4f18\u5316\u200b\u5668\u200b\uff0c\u200b\u5982\u200bAdamW</li> </ul> <ol> <li> <p>\u200b\u68af\u5ea6\u200b\u6b63\u4ea4\u200b\u5316\u200bOrthogonalization\uff0c\u200b\u57fa\u4e8e\u200bShampoo Optimizer\u200b\u65b9\u6848\u200b\uff0c\u200b\u53bb\u9664\u200b\u5de6\u53f3\u200b\u77e9\u9635\u200b\u7684\u200b\u52a8\u91cf\u200b\u7d2f\u52a0\u200b\u9879\u200b\uff0cSVD\u200b\u5206\u89e3\u200b\u68af\u5ea6\u200b\u77e9\u9635\u200b \\(G_t = USV^T\\)\uff0c\u200b\u5f97\u5230\u200b\u76ee\u6807\u200b\u4f18\u5316\u200b\u65b9\u6848\u200b\uff1a\\(\\theta_t = \\theta_{t-1} - \\eta UV^T\\)</p> <p></p> <p></p> <ul> <li>\u200b\u76f4\u89c2\u200b\u7406\u89e3\u200b\uff0c\u200b\u5f3a\u5236\u200b\u68af\u5ea6\u200b\u77e9\u9635\u200b\u6b63\u4ea4\u200b\u5316\u200b\u80fd\u591f\u200b\u51cf\u5c11\u200b\u68af\u5ea6\u200b\u5206\u91cf\u200b\u65b9\u5411\u200b\u5197\u4f59\u200b\u7684\u200b\u540c\u65f6\u200b\u6709\u6548\u200b\u5730\u200b\u589e\u52a0\u200b\u4e86\u200b\u5176\u5b83\u200b\u7a00\u6709\u200b\u65b9\u5411\u200b\u7684\u200b\u66f4\u65b0\u200b\uff08\u200b\u5947\u5f02\u200b\u503c\u8f83\u200b\u5c0f\u200b\u7684\u200b\u65b9\u5411\u200b\u5bf9\u200b\u5b66\u4e60\u200b\u4ecd\u200b\u5f88\u200b\u91cd\u8981\u200b\uff09\uff0c\u200b\u51cf\u5c11\u200b\u4e86\u200b\u4f18\u5316\u200b\u51b2\u7a81\u200b\uff0c\u200b\u63d0\u5347\u200b\u4f18\u5316\u200b\u6548\u7387\u200b</li> <li>\u200b\u5b9e\u9a8c\u200b\u53d1\u73b0\u200b\u5bf9\u200b \\(m_t\\) \u200b\u8fdb\u884c\u200bNS\u200b\u8fed\u4ee3\u200b\u524d\u200b\u989d\u5916\u200b\u5e94\u7528\u200b\u52a8\u91cf\u200b\u7d2f\u8ba1\u200b \\(m_t = \\mu m_{t-1} + g_t\\) \u200b\u6548\u679c\u200b\u66f4\u4f18\u200b</li> </ul> </li> <li> <p>Newton-Schulz iteration \u200b\u4e0d\u200b\u5b58\u5728\u200b\u4ee5\u4e0b\u200b\u95ee\u9898\u200b\u5e76\u200b\u80fd\u591f\u200b\u4ec5\u200b\u5728\u200bbf16\u200b\u7cbe\u5ea6\u200b\u4e0b\u200b\u5feb\u901f\u200b\u5b9e\u73b0\u200b\u77e9\u9635\u200b\u6b63\u4ea4\u200b\u5316\u200b</p> <ul> <li> SVD\u200b\u5c06\u200b\u77e9\u9635\u200b\u6b63\u4ea4\u200b\u5316\u200b\u901f\u5ea6\u200b\u592a\u6162\u200b</li> <li> Coupled Newton\u200b\u81f3\u5c11\u200b\u9700\u8981\u200b\u57fa\u4e8e\u200bfp32\u200b\u7684\u200b\u7cbe\u5ea6\u200b\u6765\u200b\u9632\u6b62\u200b\u6570\u503c\u200b\u4e0d\u200b\u7a33\u5b9a\u200b\u73b0\u8c61\u200b\u53d1\u751f\u200b\uff0cGPU\u200b\u6548\u7387\u200b\u8fc7\u4f4e\u200b</li> </ul> \\[ \\begin{aligned}     G^{'} &amp;= aG + b(GG^T)G + c(GG^T)^2G \\\\     &amp;= \\left(aI + b\\left(GG^T\\right) + c \\left(GG^T\\right)^2 \\right) G \\\\     &amp;= \\left(aI + bUS^2U^T + c US^4U^T \\right) USV^T \\\\     &amp;= U(aS + bS^3 + cS^5) V^T \\end{aligned} \\] <p>\\(\\varphi(x) = ax + bx^3 + cx^5 \\approx 1\\)\uff0c\u200b\u8fed\u4ee3\u200b\u7ed3\u679c\u200b\u624d\u80fd\u200b\u8fd1\u4f3c\u200b \\(UV^T\\)</p> </li> <li> <p>\u200b\u8fed\u4ee3\u200b\u7ec6\u8282\u200b</p> <p></p> <p></p> <ul> <li>\u200b\u5b9e\u9a8c\u200b\u53d1\u73b0\u200b\u4f7f\u7528\u200b3\u200b\u9636\u200b\u6216\u200b7\u200b\u9636\u200b\u591a\u9879\u5f0f\u200b\u8fdb\u884c\u200bNS\u200b\u8fed\u4ee3\u200b\u4f7f\u200b\u5bf9\u200b\u65f6\u95f4\u200b\u5f00\u9500\u200b\u65e0\u200b\u660e\u663e\u200b\u63d0\u5347\u200b\uff0c\u200b\u56e0\u6b64\u200b\u9009\u5b9a\u200b5\u200b\u9636\u200b\u591a\u9879\u5f0f\u200b\u8fdb\u884c\u200bNS\u200b\u8fed\u4ee3\u200b</li> <li>\u200b\u8fed\u4ee3\u200b\u6b21\u6570\u200b \\(T=5\\) \u200b\u5f97\u5230\u200b\u7684\u200b\u8fd1\u4f3c\u200b\u7ed3\u679c\u200b\u51c6\u786e\u7387\u200b\u80fd\u591f\u200b\u4fdd\u8bc1\u200b</li> <li>\u200b\u5728\u200b\\(x\\in [0, 1]\\)\u200b\u8303\u56f4\u200b\u5185\u200b\uff0c\\(\\varphi^T(x) \\in [1-\\epsilon, 1+\\epsilon] = [0.7, 1.3]\\)</li> <li>\\(\\varphi^{'}(0)=a\\) \u200b\u7528\u4e8e\u200b\u63a7\u5236\u200b\u5c0f\u200b\u5947\u5f02\u200b\u503c\u200b\u65b9\u5411\u200b\u5206\u91cf\u200b\uff0c\u200b\u8981\u6c42\u200b\u503c\u200b\u5c3d\u53ef\u80fd\u200b\u5927\u200b\u68af\u5ea6\u200b\u8d8a\u200b\u9661\u200b</li> <li><code>(a, b, c)=(3.4445, -4.7750, 2.0315)</code></li> </ul> </li> <li> <p>\u200b\u7b97\u6cd5\u200b\u5206\u6790\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u6743\u91cd\u200b\u77e9\u9635\u200b\uff08shape \\([n, m], n\\ge m\\)\uff09\uff0c\u200b\u6d6e\u70b9\u6570\u200b\u8fd0\u7b97\u200b\u60c5\u51b5\u200b\u5982\u4e0b\u200b</p> <ul> <li>Newton-Schulz \u200b\u4e3a\u200b\\(2*(2nm^2 + m^3)*T\\)\uff0c\u200b\u6700\u5dee\u200b\\(m==n\\)\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u4e3a\u200b \\(6Tnm^2\\)</li> <li>Forward + Backward \u200b\u4e3a\u200b \\(2*(nm + 2nm) = 6nm\\)\uff0cBatch\u200b\u989d\u5916\u200b\u8ba1\u7b97\u200b\u5f00\u9500\u200b\u4e3a\u200b \\(Tm/B\\)\uff0c\u200b\u5728\u200b\u5927\u200b<code>batch_size</code>\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u989d\u5916\u200b\u8ba1\u7b97\u200b\u5f00\u9500\u200b\u5360\u200b\u6bd4\u200b\u66f4\u200b\u5c0f\u200b</li> </ul> <pre><code>def zeropower_via_newtonschulz5(G, steps: int):\n    \"\"\"\n    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a 5-time iteration whose \n    coefficients are selected to maximize the slope at zero. For the purpose of minimizing steps, \n    it turns out to be empirically effective to keep increasing the slope at zero even beyond the point where the iteration no longer converges all the way to one everywhere on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model performance at all relative to UV^T, where USV^T = G is the SVD.\n    \"\"\"\n    assert G.ndim &gt;= 2 # batched Muon implementation by @scottjmaddox, and put into practice in the record by @YouJiacheng\n    a, b, c = (3.4445, -4.7750,  2.0315)\n    X = G.bfloat16()\n    # \u200b\u5947\u5f02\u200b\u503c\u200b\u5206\u89e3\u200b\u524d\u200b\u8c03\u6574\u200b\u5c0f\u200b\u7ef4\u5ea6\u200b\u5728\u200b\u540e\u200b\n    if G.size(-2) &gt; G.size(-1):\n        X = X.mT\n\n    # Ensure spectral norm is at most 1\n    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)\n    # Perform the NS iterations\n    for _ in range(steps):\n        A = X @ X.mT\n        B = b * A + c * A @ A # quintic computation strategy adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng\n        X = a * X + B @ X\n\n    if G.size(-2) &gt; G.size(-1):\n        X = X.mT\n    return X\n</code></pre> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Optimizer/optimizer.html#muonw","title":"MuonW","text":""},{"location":"AI/Paper_Reading/Component/Tokenizer/index.html","title":"Tokenizer","text":""},{"location":"AI/Paper_Reading/Component/Tokenizer/index.html#subword","title":"SubWord\u200b\u7b97\u6cd5","text":"<p>SubWord\u200b\u7b97\u6cd5\u200b\uff0c\u200b\u987e\u540d\u601d\u4e49\u200b\u5c31\u662f\u200b\u628a\u200b\u4e00\u4e2a\u200b\u6587\u672c\u200b\u5e8f\u5217\u200b\u5212\u5206\u200b\u4e3a\u200b\u66f4\u200b\u5c0f\u200b\u7684\u200b\u4e00\u4e2a\u200b\u4e2a\u5b50\u200b\u8bcd\u200b\uff08\u200b\u53ef\u80fd\u200b\u4e3a\u200b\u5355\u4e2a\u200b\u5b57\u8bcd\u200b\u7684\u200b\u4e00\u90e8\u5206\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u4e3a\u200b\u5e38\u7528\u200b\u7684\u200b\u591a\u4e2a\u200b\u8bcd\u200b\uff09</p> <p>Info</p> <ul> <li>\u200b\u751f\u6210\u200b\u6a21\u578b\u200b\u5728\u200btrain\u200b\u65f6\u200b\u56e0\u4e3a\u200b\u6574\u4e2a\u200b\u53e5\u5b50\u200b\u5df2\u7ecf\u200b\u786e\u5b9a\u200b\uff0c<code>right_padding</code> \u200b\u4e5f\u200b\u53ef\u200b\u901a\u8fc7\u200b <code>attention_mask</code> \u200b\u7ed3\u679c\u200b\u51c6\u786e\u200b\u5730\u200b\u8bc6\u522b\u200b\u6240\u6709\u200btoken</li> <li>\u200b\u751f\u6210\u200b\u6a21\u578b\u200b\u5728\u200bgenerate\u200b\u65f6\u200b\u7531\u4e8e\u200b\u6574\u4e2a\u200b\u53e5\u5b50\u200b\u8fd8\u200b\u672a\u200b\u751f\u6210\u200b\u786e\u5b9a\u200b\uff0c\u200b\u5728\u200bbatch infer\u200b\u65f6\u200b\u4e3a\u4e86\u200b\u9632\u6b62\u200b\u6700\u200b\u53f3\u8fb9\u200btoken\u200b\u4e3a\u200b<code>[PAD]</code>\u200b\u5f71\u54cd\u200b\u751f\u6210\u200b\uff0c\u200b\u56e0\u6b64\u200b\u901a\u8fc7\u200b<code>left_padding</code>\u200b\u5b9e\u73b0\u200b<code>pad_to_longest</code></li> </ul>"},{"location":"AI/Paper_Reading/Component/Tokenizer/index.html#subword_1","title":"SubWord\u200b\u5206\u8bcd\u5668","text":"<ol> <li>WordPiece</li> <li>UnigramUnigram Language Model (ULM)</li> <li>BPE (Byte Pair Encoding)</li> </ol> <p>Info</p> <ul> <li>pre_tokenizer\u200b\u7528\u4e8e\u200bsplit\u200b\u5206\u5272\u200b\u53e5\u5b50\u200b\uff0cbytelevel\u200b\u62c6\u5206\u200b\u5355\u8bcd\u200b\u81f3\u200b\u5b57\u8282\u200b\u7ea7\u200b\uff0c\u200b\u56e0\u6b64\u200bBPE\u200b\u5b57\u5178\u200b\u4e2d\u200b\u4e0d\u4f1a\u200b\u6709\u200b\u4e2d\u6587\u200b\uff08\u200b\u4e2d\u6587\u200b\u4e3a\u200b\u591a\u200b\u5b57\u8282\u200b\u5b57\u7b26\u200b\uff09\uff0c\u200b\u53cd\u800c\u200b\u6709\u200b\u5f88\u591a\u200b\u65e0\u6cd5\u200b\u7406\u89e3\u200b\u7684\u200b\u5355\u5b57\u8282\u200b\u4e32\u200b</li> <li>\u200b\u4e3a\u200b\u4fdd\u8bc1\u200b\u4fe1\u606f\u200b\u65e0\u635f\u200b\uff0cBPE\u200b\u5206\u8bcd\u5668\u200b\u4f1a\u200b\u4fdd\u7559\u200b\u7a7a\u683c\u200b\uff0c\u200b\u56e0\u6b64\u200b\u9700\u8981\u200b\u9884\u5148\u200b\u5c06\u200b\u7a7a\u683c\u200b\" \"\u200b\u66ff\u6362\u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u4e0d\u200b\u5e38\u7528\u200b\u7684\u200b\u5b57\u7b26\u200b\uff0c\u200b\u5982\u200b<code>replace(\" \", \"\u0120\")</code>\uff0c\u200b\u4e00\u822c\u200b\u53ef\u4ee5\u200b\u66ff\u6362\u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u8bcd\u9891\u200b\u5c11\u200b\u7684\u200bchar</li> </ul>"},{"location":"AI/Paper_Reading/Component/Tokenizer/index.html#_1","title":"\u5e38\u7528\u200b\u5206\u200b\u8bcd\u5e93","text":"<ol> <li>SentencePiece</li> <li>Tiktoken\uff1a\u200b\u4f7f\u7528\u200bRust\u200b\u8bed\u8a00\u200b\u7f16\u5199\u200b\uff0c\u200b\u9ad8\u5ea6\u200b\u4f18\u5316\u200b\uff0c\u200b\u901f\u5ea6\u200b\u6bd4\u200b\u57fa\u4e8e\u200bPython\u200b\u7684\u200b\u6807\u51c6\u200bBPE\u200b\u5feb\u200b3-6\u200b\u500d\u200b\uff0c\u200b\u524d\u8005\u200b\u76f4\u63a5\u200b\u4f7f\u7528\u200b\u9884\u5b9a\u200b\u4e49\u200b\u7684\u200b\u7f16\u7801\u200b\u8bcd\u8868\u200b\uff0c\u200b\u540e\u8005\u200b\u53ef\u4ee5\u200b\u81ea\u884c\u200b\u6784\u5efa\u200b\u8bcd\u8868\u200b</li> </ol> <p>todo\uff1aPinyin Tokenizer\u3001\u200b\u62c6\u5b57\u200b\u3001\u200b\u7e41\u7b80\u200b\u3001\u200b\u5b57\u7d20\u200b(\u200b\u5b57\u200b\u7ec4\u6210\u200b\u7ed3\u6784\u200b)\u3001OCR</p> <p>EM\u200b\u7b97\u6cd5\u200b </p> <ol> <li>\u200b\u901a\u8fc7\u200b\u5b9e\u9a8c\u200b\u7ed3\u679c\u200b\u548c\u200b\u6982\u7387\u200b\uff0c\u200b\u627e\u51fa\u200b\u6700\u6709\u200b\u53ef\u80fd\u200b\u5bfc\u81f4\u200b\u8fd9\u4e2a\u200b\u7ed3\u679c\u200b\u7684\u200b\u539f\u56e0\u200b\u6216\u8005\u8bf4\u200b\u53c2\u6570\u200b\uff0c\u200b\u8fd9\u4e2a\u200b\u5c31\u200b\u53eb\u505a\u200b\u6700\u5927\u200b\u4f3c\u7136\u200b\u4f30\u8ba1\u200b\u3002  </li> <li> <p>Expectation Maximization algorithm  </p> <ul> <li>\u200b\u5f15\u5165\u200b\u9690\u200b\u53d8\u91cf\u200b\uff1a\u200b\u5373\u200b\u6bcf\u4e2a\u200b\u6837\u672c\u200b\u4e2d\u200b\u90fd\u200b\u6709\u200b\u4e00\u4e2a\u200b\u65e0\u6cd5\u200b\u5f97\u77e5\u200b\u9690\u85cf\u200b\u4fe1\u606f\u200b\u7684\u200b\u53d8\u91cf\u200b\uff0c\u200b\u9700\u8981\u200b\uff08\u200b\u66b4\u529b\u200b\uff09\u200b\u7834\u89e3\u200b  </li> <li>\\(\\log P(X\\vert \\theta) = \\log \\sum_{Z} P(X, Z\\vert \\theta)\\) </li> <li> <p>E step\uff1a\u200b\u8ba1\u7b97\u200b\u5404\u200b\u6837\u672c\u200b\u4e0b\u200b\u5404\u9690\u200b\u53d8\u91cf\u200b\u7684\u200b\u671f\u671b\u200b\u6982\u7387\u200b\uff0c\u200b\u5373\u200b\u586b\u8865\u200b\u7f3a\u5931\u200b\u9690\u85cf\u200b\u53d8\u91cf\u200b\uff0c\\(P(Z_A\\vert X_i, \\theta_A) = \\frac{P(X_i\\vert Z_A, \\theta_A)P(Z_A)}{P(X_i\\vert \\theta_A)}\\)\uff0c\u200b\u6ee1\u8db3\u200b\\(P(Z_A)\\)\u200b\u548c\u200b\\(P(\\theta_A)\\)\u200b\u4e92\u76f8\u200b\u72ec\u7acb\u200b  </p> \\[ P(Z_A\\vert X_i, \\theta_A) = \\frac{\\theta_A^{H_i}(1-\\theta_A)^{T_i}}{\\sum_{z\\in Z} \\theta_z^{H_i}(1-\\theta_z)^{T_i}} \\] <p>\\(P(X\\vert \\theta)\\) \u200b\u8868\u793a\u200b\u6240\u6709\u200b\\(Z\\)\u200b\u7684\u200b\u603b\u200b\u6982\u7387\u200b \\(H_i\\)\u200b\u548c\u200b\\(T_i\\)\u200b\u5206\u522b\u200b\u8868\u793a\u200bi-th\u200b\u6837\u672c\u200b\u4e2d\u200b\u6b63\u9762\u200b\u548c\u200b\u53cd\u9762\u200b\u6b21\u6570\u200b</p> </li> <li> <p>M step: \u200b\u57fa\u4e8e\u200bE\u200b\u6b65\u200b\u7684\u200b\u7ed3\u679c\u200b\u91cd\u65b0\u200b\u4f30\u8ba1\u200b\\(\\theta\\)\uff08\u200b\u6781\u5927\u200b\u4f3c\u7136\u200b\u4f30\u8ba1\u200b\uff09\uff0c\u200b\u66f4\u65b0\u200b\u53c2\u6570\u200b  </p> \\[ \\theta_A = \\frac{\\sum_{i=1}^n P(Z_A\\vert X_i, \\theta_A)H_i}{\\sum_{i=1}^n P(Z_A\\vert X_i, \\theta_A)(H_i + T_i)} \\] </li> <li> <p>\u200b\u91cd\u590d\u200b\u8fed\u4ee3\u200b\uff0c\u200b\u76f4\u81f3\u200b\u53c2\u6570\u200b \\(\\theta\\) \u200b\u6536\u655b\u200b</p> </li> <li>\u200b\u57fa\u4e8e\u200b\u7ed3\u679c\u200b\u53cd\u63a8\u200b\u9690\u200b\u53d8\u91cf\u200b\u6982\u7387\u200b\uff0c\u200b\u5404\u200b\u6295\u63b7\u200b\u7ed3\u679c\u200b\u4e92\u76f8\u200b\u72ec\u7acb\u200b\uff0c\u200b\u6982\u7387\u200b\u8ba1\u7b97\u516c\u5f0f\u200b\u4e3a\u200b \\(p^{H}(1-p)^{T}\\)</li> <li>\u200b\u8be5\u200b\u9884\u6d4b\u200b\u9690\u200b\u53d8\u91cf\u200b\u7684\u200b\u65b9\u6cd5\u200b\u662f\u200b\u8f6f\u200b\u5206\u914d\u200bsoft assignment\uff0cKmeas\u200b\u7b97\u6cd5\u200b\u662f\u200b\u786c\u200b\u5206\u914d\u200b\uff0cKmeans\u200b\u662f\u200bEM\u200b\u7b97\u6cd5\u200b\u7684\u200b\u4e00\u79cd\u200b\u7b80\u5316\u200b\u7248\u672c\u200b</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/BPE.html","title":"BPE","text":"<p>BPE (Byte Pair Encoding, \u200b\u5b57\u8282\u200b\u5bf9\u200b\u7f16\u7801\u200b) \u200b\u662f\u200b\u4e00\u79cd\u200b\u7b80\u5355\u200b\u7684\u200b\u6570\u636e\u538b\u7f29\u200b\u6280\u672f\u200b\uff0c\u200b\u5b83\u200b\u8fed\u4ee3\u200b\u5730\u200b\u5408\u5e76\u200b\u5e8f\u5217\u200b\u4e2d\u200b\u6700\u200b\u9891\u7e41\u200b\u7684\u200b\u5b57\u8282\u200b\u4e3a\u200b\u5355\u4e2a\u200b\u672a\u200b\u4f7f\u7528\u200b\u7684\u200b\u5b57\u8282\u200b\u3002\u200b\u5728\u200b\u5206\u8bcd\u200b\u4efb\u52a1\u200b\u4e2d\u200b\uff0c\u200b\u5408\u5e76\u200b\u7684\u200b\u5219\u200b\u662f\u200b\u5b57\u7b26\u200b\u6216\u200b\u5b57\u7b26\u200b\u5e8f\u5217\u200b\u3002    </p> <ul> <li>BPE\u200b\u662f\u200b\u4e00\u4e2a\u200b\u786e\u5b9a\u200b(\u200b\u65e0\u200b\u6b67\u4e49\u200b)\u200b\u7684\u200b\u3001subwords\u200b\u66ff\u6362\u200bword\u200b\u7684\u200b\u8d2a\u5fc3\u200b\u7b97\u6cd5\u200b</li> <li>Paper</li> </ul>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/BPE.html#_1","title":"\u65b9\u6cd5\u200b\u4ecb\u7ecd","text":""},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/BPE.html#_2","title":"\u57fa\u672c\u539f\u7406","text":"<p>\u200b\u7b97\u6cd5\u200b\u6d41\u7a0b\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li>\u200b\u8bbe\u5b9a\u200b\u5b57\u5178\u200b\u4e2d\u200b\u6700\u5927\u200bsubwords\u200b\u4e2a\u6570\u200b|V|</li> <li>\u200b\u5c06\u200b\u6240\u6709\u200b\u5355\u8bcd\u200b\u62c6\u200b\u5206\u4e3a\u200bsubword\u200b\u5e8f\u5217\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u6700\u540e\u200b\u6dfb\u52a0\u200b\u4e00\u4e2a\u200b\u505c\u6b62\u200b\u7b26\u200b<code>&lt;/w&gt;</code>\uff0c\u200b\u540c\u65f6\u200b\u6807\u8bb0\u200b\u51fa\u8be5\u200b\u5355\u8bcd\u200b\u51fa\u73b0\u200b\u7684\u200b\u6b21\u6570\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c<code>\"low\"</code>\u200b\u8fd9\u4e2a\u200b\u5355\u8bcd\u200b\u51fa\u73b0\u200b\u4e86\u200b 5 \u200b\u6b21\u200b\uff0c\u200b\u90a3\u4e48\u200b\u5b83\u200b\u5c06\u200b\u4f1a\u200b\u88ab\u200b\u5904\u7406\u200b\u4e3a\u200b<code>{'l o w &lt;/w&gt;': 5}</code></li> <li>\u200b\u7edf\u8ba1\u200b\u6bcf\u200b\u4e00\u4e2a\u200b\u8fde\u7eed\u200b\u5b57\u8282\u200b\u5bf9\u200b\u7684\u200b\u51fa\u73b0\u200b\u9891\u7387\u200b\uff0c\u200b\u9009\u62e9\u200b\u6700\u200b\u9ad8\u9891\u200b\u8005\u200b\u5408\u5e76\u200b\u6210\u65b0\u200b\u7684\u200bsubword</li> <li>\u200b\u91cd\u590d\u200b\u7b2c\u200b3\u200b\u6b65\u200b\u76f4\u5230\u200b\u8fbe\u5230\u200b\u7b2c\u200b1\u200b\u6b65\u200b\u8bbe\u5b9a\u200b\u7684\u200bsubwords\u200b\u8bcd\u8868\u200b\u5927\u5c0f\u200b|V|\u200b\u6216\u200b\u4e0b\u200b\u4e00\u4e2a\u200b\u6700\u200b\u9ad8\u9891\u200b\u7684\u200b\u5b57\u8282\u200b\u5bf9\u200b\u51fa\u73b0\u200b\u9891\u7387\u200b\u4e3a\u200b1</li> </ol> <p></p><pre><code>{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w e s t &lt;/w&gt;': 6, 'w i d e s t &lt;/w&gt;': 3}\n</code></pre> \u200b\u6700\u200b\u9891\u7e41\u200b\u7684\u200b<code>subword_pair</code>\u200b\u662f\u200b<code>e</code>\u200b\u548c\u200b<code>s</code>\uff0c\u200b\u5171\u200b\u51fa\u73b0\u200b 6+3=9 \u200b\u6b21\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5c06\u200b\u5b83\u4eec\u200b\u5408\u5e76\u200b <pre><code>{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w es t &lt;/w&gt;': 6, 'w i d es t &lt;/w&gt;': 3}\n</code></pre> \u200b\u6700\u200b\u9891\u7e41\u200b\u7684\u200b<code>subword_pair</code>\u200b\u662f\u200b<code>es</code>\u200b\u548c\u200b<code>t</code>\uff0c\u200b\u5171\u200b\u51fa\u73b0\u200b 6+3=9 \u200b\u6b21\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5c06\u200b\u5b83\u4eec\u200b\u5408\u5e76\u200b <pre><code>{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w est &lt;/w&gt;': 6, 'w i d est &lt;/w&gt;': 3}\n</code></pre> \u200b\u6700\u200b\u9891\u7e41\u200b\u7684\u200b<code>subword_pair</code>\u200b\u662f\u200b<code>est</code>\u200b\u548c\u200b<code>&lt;/w&gt;</code>\uff0c\u200b\u5171\u200b\u51fa\u73b0\u200b\u4e86\u200b 6+3=9 \u200b\u6b21\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5c06\u200b\u5b83\u4eec\u200b\u5408\u5e76\u200b <pre><code>{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w est&lt;/w&gt;': 6, 'w i d est&lt;/w&gt;': 3}\n</code></pre> \u200b\u6700\u200b\u9891\u7e41\u200b\u7684\u200b<code>subword_pair</code>\u200b\u662f\u200b<code>l</code>\u200b\u548c\u200b<code>o</code>\uff0c\u200b\u5171\u200b\u51fa\u73b0\u200b\u4e86\u200b 5+2=7 \u200b\u6b21\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5c06\u200b\u5b83\u4eec\u200b\u5408\u5e76\u200b <pre><code>{'lo w &lt;/w&gt;': 5, 'lo w e r &lt;/w&gt;': 2, 'n e w est&lt;/w&gt;': 6, 'w i d est&lt;/w&gt;': 3}\n</code></pre> ......\u200b\u6301\u7eed\u200b\u8fed\u4ee3\u200b\u76f4\u5230\u200b\u8fbe\u5230\u200b\u9884\u8bbe\u200b\u7684\u200bsubwords\u200b\u8bcd\u8868\u200b\u5927\u5c0f\u200b|V|\u200b\u6216\u200b\u4e0b\u200b\u4e00\u4e2a\u200b\u6700\u200b\u9ad8\u9891\u200b\u7684\u200b\u5b57\u8282\u200b\u5bf9\u200b\u51fa\u73b0\u200b\u9891\u7387\u200b\u4e3a\u200b1\u3002<p></p>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/BPE.html#_3","title":"\u4ee3\u7801\u200b\u5b9e\u73b0","text":"<pre><code>import re, collections\ndef get_stats(vocab):\n    '''\n    # input\n        vocab: {' '.join(subwords) + '&lt;/w&gt;': freq},  (\u200b\u8bcd\u200b\u7684\u200bsubwords list\u200b\u52a0\u4e0a\u200b\u8bcd\u200b\u7ec8\u6b62\u7b26\u200b)\n    # return\n        pairs: {tuple_of_subword_pair: freq}\n    '''\n    pairs = collections.defaultdict(int)\n    for word, freq in vocab.items():\n        # \u200b\u83b7\u53d6\u200bsubwords\n        symbols = word.split()\n        for i in range(len(symbols)-1):\n            pairs[symbols[i],symbols[i+1]] += freq\n    return pairs\n\n\ndef merge_vocab(best_pair, v_in):\n    '''\n    # input\n        pair: {tuple_of_subword_pair: freq}\n        v_in: {tuple_of_subword_pair: freq}\n    # return\n        v_out: {' '.join(subwords) + '&lt;/w&gt;': freq}\n    '''\n    v_out = {}\n    # \u200b\u5b57\u7b26\u4e32\u200b\u8f6c\u4e49\u200b\u8868\u793a\u200b\n    bigram = re.escape(' '.join(best_pair))\n    # \u200b\u901a\u8fc7\u200b\u6307\u5b9a\u200b\u524d\u540e\u200b\u4e0d\u662f\u200b\u975e\u200b\u7a7a\u5b57\u7b26\u200b(\\S\u200b\u4e3a\u200b\\s\u200b\u7684\u200b\u8865\u96c6\u200b, \u200b\u5305\u62ec\u200b^\u200b\u548c\u200b$)\u200b\u7ea6\u675f\u200b\u53ea\u200b\u5339\u914d\u200bsubword_pair\u200b\u6bb5\u200b\n    p = re.compile(r'(?&lt;!\\S)' + bigram + r'(?!\\S)')     \n    for word in v_in:\n        # \u200b\u5408\u5e76\u200bsubword_pair\u200b\u5e76\u200b\u66f4\u65b0\u200b\u5f53\u524d\u200b\u72b6\u6001\u200b\n        w_out = p.sub(''.join(best_pair), word)\n        v_out[w_out] = v_in[word]\n    return v_out\n\n\nvocab = {'l o w &lt;/w&gt;' : 5, 'l o w e r &lt;/w&gt;' : 2,\n         'n e w e s t &lt;/w&gt;':6, 'w i d e s t &lt;/w&gt;':3}\nnum_merges = 10\nfor i in range(num_merges):\n    pairs = get_stats(vocab)\n    best = max(pairs, key=pairs.get)    # \u200b\u83b7\u53d6\u200bmax_freq\u200b\u5bf9\u5e94\u200b\u7684\u200btuple_of_subword_pair\n    vocab = merge_vocab(best, vocab)\n    print(best)\n</code></pre>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/BPE.html#_4","title":"\u7f16\u7801\u200b\u548c\u200b\u89e3\u7801","text":""},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/BPE.html#_5","title":"\u7f16\u7801","text":""},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/BPE.html#_6","title":"\u89e3\u7801","text":""},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/BPE.html#_7","title":"\u6ce8\u610f\u4e8b\u9879","text":""},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/BPE.html#_8","title":"\u7279\u6b8a\u200b\u7f16\u7801\u200b\u793a\u4f8b","text":"<ol> <li>\u200b\u90e8\u5206\u200b\u8d2a\u5fc3\u200b\u5339\u914d\u200b --&gt; <code>&lt;unk&gt;</code> <pre><code>vocab1 = {'\u2460', '#\u2461\u2462'}\nvocab2 = {'\u2460', '\u2460\u2461', '#\u2461\u2462'}\nprint(tokenze('\u2460\u2461\u2462', vocab1))   # ['\u2460', '#\u2461\u2462']\nprint(tokenze('\u2460\u2461\u2462', vocab2))   # [&lt;unk&gt;]\n</code></pre></li> </ol>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/BPE.html#bpe","title":"BPE\u200b\u8bcd\u8868\u200b\u751f\u6210","text":"<ul> <li>\u200b\u8bad\u7ec3\u200b\u96c6\u200b\u548c\u200b\u6d4b\u8bd5\u200b\u96c6\u200b\u4e00\u8d77\u200b\u53c2\u4e0e\u200b\u8bcd\u8868\u200b\u7684\u200b\u751f\u6210\u200b   <p>\u200b\u4fdd\u8bc1\u200b\u8bcd\u8868\u200b\u4e00\u81f4\u6027\u200b</p> </li> <li>\u200b\u7ffb\u8bd1\u200b\u6216\u200b\u751f\u6210\u200b\u4efb\u52a1\u200b\u4e2d\u200b\uff0c\u200b\u4e0d\u540c\u200b\u8bed\u79cd\u200b\u7684\u200b\u6570\u636e\u200b\u4e5f\u200b\u53ef\u200b\u7edf\u4e00\u200b\u53c2\u4e0e\u200b\u8bcd\u8868\u200b\u7684\u200b\u751f\u6210\u200b   <p>\u200b\u907f\u514d\u200b\u4e00\u4e9b\u200b\u4e13\u6709\u540d\u8bcd\u200b\u5728\u200b\u4e0d\u540c\u200b\u8bed\u79cd\u200b\u4e2d\u200b\u5212\u5206\u200b\u4e3a\u200b\u4e0d\u540c\u200b\u7684\u200bsubword\u200b\u5e8f\u5217\u200b</p> </li> </ul>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/SentencePiece.html","title":"SentencePiece","text":"<p>SentencePiece\u200b\u5b9e\u73b0\u200b\u4e86\u200b BPE \u200b\u548c\u200b ULM \u200b\u4e24\u79cd\u200bsubword\u200b\u7b97\u6cd5\u200b\uff0c\u200b\u4e14\u200b\u80fd\u200b\u76f4\u63a5\u200b\u4ece\u200b\u539f\u59cb\u200b\u6587\u672c\u200b\u8bed\u6599\u200b\u8bad\u7ec3\u200b\u5f97\u5230\u200bsubword\u200b\u8bcd\u8868\u200b\u3002</p> <ul> <li>Paper</li> <li>Github </li> </ul>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/SentencePiece.html#_1","title":"\u65b9\u6cd5\u200b\u4ecb\u7ecd","text":"<p>SentencePiece\u200b\u5305\u542b\u200b\u4ee5\u4e0b\u200b4\u200b\u4e2a\u200b\u4e3b\u8981\u200b\u90e8\u4ef6\u200b\uff1a<code>Normalizer</code>\u3001<code>Trainer</code>\u3001<code>Encoder</code> \u200b\u548c\u200b <code>Decoder</code></p>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/SentencePiece.html#normalizer","title":"Normalizer","text":""},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/SentencePiece.html#trainer","title":"Trainer","text":""},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/SentencePiece.html#encoder","title":"Encoder","text":""},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/SentencePiece.html#decoder","title":"Decoder","text":""},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/SentencePiece.html#_2","title":"\u793a\u4f8b\u200b\u4ee3\u7801","text":"<pre><code>--vocab_size=&lt;size&gt;             # \u200b\u8bcd\u5178\u200b\u5927\u5c0f\u200b|V|, \u200b\u5728\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u8bbe\u7f6e\u200b\n--normalization_rule_name=nfkc  # \u200b\u6b63\u5219\u200b\u5316\u200b\u89c4\u5219\u200b, \u200b\u5728\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u8bbe\u7f6e\u200b\n--normalization_rule_tsv=&lt;file&gt; # hard convert map(\u200b\u6700\u957f\u200b\u5339\u914d\u200b\u4f18\u5148\u200b), str1 &lt;tab&gt; str2, \u200b\u5728\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u8bbe\u7f6e\u200b\n</code></pre>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/ULM.html","title":"ULM","text":""},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/WordPiece.html","title":"WordPiece","text":""},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/subword_tokenize.html","title":"Subword tokenize","text":""},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/subword_tokenize.html#ulm","title":"ULM","text":"<p>ULM \u200b\u4e3a\u200b\u6982\u7387\u6a21\u578b\u200b\u9a71\u52a8\u200b\uff0c\u200b\u5c06\u5b50\u200b\u8bcd\u200b\u5207\u5206\u200b\u89c6\u4e3a\u200b\u4e00\u4e2a\u200b\u6982\u7387\u200b\u751f\u6210\u200b\u95ee\u9898\u200b\uff0c\u200b\u901a\u8fc7\u200b\u7edf\u8ba1\u200b\u8bed\u6599\u5e93\u200b\u4e2d\u5b50\u200b\u8bcd\u200b\u7684\u200b\u51fa\u73b0\u200b\u9891\u7387\u200b\uff0c\u200b\u5efa\u7acb\u200b Unigram \u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff0c\u200b\u8ba1\u7b97\u200b\u6240\u6709\u200b\u53ef\u80fd\u200b\u7684\u200b\u5b50\u200b\u8bcd\u200b\u5207\u5206\u200b\u6982\u7387\u200b\uff0c\u200b\u627e\u5230\u200b\u6700\u200b\u53ef\u80fd\u200b\u7684\u200b\u5b50\u200b\u8bcd\u200b\u5e8f\u5217\u200b\u3002</p>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/subword_tokenize.html#_1","title":"\u57fa\u672c\u539f\u7406","text":"<ol> <li>\u200b\u521d\u59cb\u5316\u200b\u8bcd\u8868\u200b\uff1a\u200b\u4ece\u200b\u8bad\u7ec3\u200b\u8bed\u6599\u200b\u4e2d\u200b\u7edf\u8ba1\u200b\u6240\u6709\u200b\u5b57\u7b26\u200b\u548c\u200b\u5e38\u89c1\u200b\u5b50\u4e32\u200b\uff0c\u200b\u4f5c\u4e3a\u200b\u521d\u59cb\u200b\u5019\u9009\u8bcd\u200b\u8868\u200b\u3002  </li> <li> <p>\u200b\u8bad\u7ec3\u200bUnigram\u200b\u6a21\u578b\u200b\uff1a\u200b\u901a\u8fc7\u200bEM\u200b\u7b97\u6cd5\u200b\u8fed\u4ee3\u200b\u4f18\u5316\u200b\u5b50\u8bcd\u200b\u6982\u7387\u200b \\(p(w_i)\\)\uff0c\u200b\u4f7f\u200b\u8bed\u6599\u200b\u7684\u200b\u4f3c\u7136\u200b\u6700\u5927\u200b</p> <ul> <li> <p>E-Step\uff1a\u200b\u5bf9\u200b\u6bcf\u4e2a\u200b\u53e5\u5b50\u200b\\(x\\)\uff0c\u200b\u4f7f\u7528\u200b\u52a8\u6001\u200b\u89c4\u5212\u200b\u6216\u200bViterbi\u200b\u7b97\u6cd5\u200b\u679a\u4e3e\u200b\u6240\u6709\u200b\u53ef\u80fd\u200b\u7684\u200b\u5b50\u200b\u8bcd\u200b\u5207\u5206\u200b \\(S(x)\\)\uff0c\u200b\u5e76\u200b\u8ba1\u7b97\u200b\u5404\u79cd\u200b\u5207\u5206\u200b\\(w\\)\u200b\u7684\u200b\u6982\u7387\u200b</p> \\[ \\begin{aligned}     P(w\\vert x) =&amp; \\frac{\\prod_{i=1}^{\\vert w \\vert} p(w_i)}{\\sum_{w^{'}\\in S(x)}\\prod_{i=1}^{\\vert w^{'} \\vert} p(w^{'}_i)} \\\\     c(w_i) =&amp; \\sum_{x\\in X} \\sum_{w \\in S(x)} P(w\\vert x)\\cdot \\text{count}(w_i, x) \\end{aligned} \\] <p>\\(p(w_i)\\) \u200b\u4e3a\u200b\u5f53\u524d\u200b\u5b50\u8bcd\u200b \\(w_i\\) \u200b\u7684\u200b\u6982\u7387\u200b\uff08\u200b\u521d\u59cb\u5316\u200b\u4e3a\u200b\u5747\u5300\u5206\u5e03\u200b\u6216\u200b\u9891\u7387\u200b\u7edf\u8ba1\u200b\uff09 \\(\\text{count}(w_i, x)\\) \u200b\u4e3a\u5b50\u200b\u8bcd\u200b \\(w_i\\) \u200b\u5728\u200b\u53e5\u5b50\u200b \\(x\\) \u200b\u5207\u5206\u200b\u4e2d\u200b\u7684\u200b\u51fa\u73b0\u200b\u6b21\u6570\u200b</p> </li> <li> <p>M-Step\uff0c\u200b\u66f4\u65b0\u200b\u5b50\u8bcd\u200b\u6982\u7387\u200b\\(p(w_i)\\)\uff0c\u200b\u6700\u5927\u5316\u200b\u8bed\u6599\u200b\u4f3c\u7136\u200b</p> \\[ p(w_i) = \\frac{c(w_i)}{\\sum_{w^{'}_i \\in V} c(w^{'}_i)} \\] </li> </ul> </li> <li> <p>\u200b\u4ea4\u66ff\u200b\u6267\u884c\u200b\u6b65\u9aa4\u200bE-Step\u200b\u548c\u200bM-Step\uff0c\u200b\u76f4\u5230\u200b\u5b50\u8bcd\u200b\u6982\u7387\u200b\u6536\u655b\u200b\u6216\u200b\u8fbe\u5230\u200b\u6307\u5b9a\u200b\u8fed\u4ee3\u200b\u6b21\u6570\u200b</p> </li> <li>\u200b\u526a\u679d\u200b\u8bcd\u8868\u200b\uff1a\u200b\u4fdd\u7559\u200b\u6982\u7387\u200b\u6700\u9ad8\u200b\u7684\u200bTop-K \u200b\u5b50\u8bcd\u200b\uff08\u200b\u5982\u200b8K~32K\uff09</li> </ol> <p>Info</p> <p>\u200b\u5206\u8bcd\u200b\u65f6\u200b\u5bf9\u5e94\u200b\u5206\u6570\u200b\u6700\u9ad8\u200b\u7684\u200b \\(p(w\\vert x)\\) \u200b\u5373\u200b\u4e3a\u200b\u5206\u8bcd\u200b\u7ed3\u679c\u200b</p>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/subword_tokenize.html#subword-regularization","title":"Subword Regularization","text":"<p>Subword Regularization \u200b\u662f\u200b ULM \u200b\u7684\u200b\u6269\u5c55\u200b\u6280\u672f\u200b\uff0c\u200b\u57fa\u4e8e\u200b\u8bad\u7ec3\u200b\u597d\u200b\u7684\u200bULM\u200b\u5206\u8bcd\u5668\u200b\uff0c\u200b\u901a\u8fc7\u200b\u5f15\u5165\u200b\u968f\u673a\u200b\u5b50\u8bcd\u200b\u5207\u5206\u200b\uff0c\u200b\u4f7f\u200b\u6a21\u578b\u200b\u5b66\u4f1a\u200b\u5bf9\u200b\u4e0d\u540c\u200b\u5207\u5206\u200b\u751f\u6210\u200b\u4e00\u81f4\u200b\u7684\u200b\u8868\u5f81\u200b\uff0c\u200b\u63d0\u5347\u200b\u5206\u8bcd\u200b\u6a21\u578b\u200b\u7684\u200b\u9c81\u68d2\u6027\u200b\u548c\u200b\u6cdb\u5316\u200b\u80fd\u529b\u200b\u3002\u200b\u6838\u5fc3\u601d\u60f3\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li> <p>\u200b\u91c7\u6837\u200b\u5019\u9009\u200b\u7684\u200b\u591a\u200b\u5206\u8bcd\u200b\uff0c\u200b\u4ece\u200b\u53e5\u5b50\u200b\\(N\\)\u200b\u4e2a\u200b\u53ef\u80fd\u200b\u7684\u200b\u5b50\u200b\u8bcd\u200b\u5207\u5206\u200b\u6309\u200b^\\({1/\\alpha}\\)\u200b\u5f52\u4e00\u5316\u200b\u540e\u200b\u7684\u200b\u6982\u7387\u200b\u91c7\u6837\u200b\uff0c\u200b\u800c\u200b\u975e\u200b\u56fa\u5b9a\u200b\u9009\u62e9\u200b\u5206\u6570\u200b\u6700\u9ad8\u200b\u5207\u5206\u200b\u3002</p> \\[ P_\\text{sample}(w\\vert x) \\propto P(w\\vert x) ^{1/\\alpha} \\] </li> <li> <p>\u200b\u52a8\u6001\u200b\u566a\u58f0\u200b\u6ce8\u5165\u200b\uff0c\u200b\u5728\u200b\u6bcf\u4e2a\u200b epoch\uff08\u200b\u6216\u200b batch\uff09\u200b\u4e3a\u200b\u540c\u4e00\u200b\u53e5\u5b50\u200b\u9009\u62e9\u200b\u4e0d\u540c\u200b\u7684\u200b\u5207\u5206\u200b\u8f93\u5165\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff0c\u200b\u4f7f\u200b\u6a21\u578b\u200b\u5b66\u4f1a\u200b\u5bf9\u200b\u4e0d\u540c\u200b\u5207\u5206\u200b\u751f\u6210\u200b\u4e00\u81f4\u200b\u7684\u200b\u8868\u5f81\u200b\u3002</p> </li> </ol> <p>Info</p> <p>\u200b\u672c\u8d28\u200b\u4e0a\u200b\u5728\u200btokenizer\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u4e86\u200b\u6570\u636e\u200b\u589e\u5f3a\u200b\uff0c\u200b\u5373\u5c06\u200b\u540c\u4e00\u200b\u6587\u672c\u200b\u5212\u5206\u200b\u4e3a\u200b\u4e0d\u540c\u200b\u7684\u200bsubword\u200b\u5e8f\u5217\u200b</p>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/subword_tokenize.html#wordpiece","title":"WordPiece","text":"<p>WordPiece\u200b\u9700\u8981\u200b\u524d\u7f00\u200b<code>##</code>\u200b\u4f5c\u4e3a\u200b\u4e2d\u95f4\u200bsubword\u200b\u6807\u5fd7\u200b\uff0c\u200b\u56e0\u6b64\u200b\u9700\u8981\u200b\u9884\u5148\u200b\u5206\u8bcd\u200b\u3002</p>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/subword_tokenize.html#_2","title":"\u57fa\u672c\u539f\u7406","text":"<p>\u200b\u7b97\u6cd5\u200b\u6d41\u7a0b\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li>\u200b\u521d\u59cb\u5316\u200b\uff1a\u200b\u5bf9\u200b\u8bad\u7ec3\u200b\u8bed\u6599\u200b\u8fdb\u884c\u200b\u5206\u5272\u200b\u4e3a\u200b\u5355\u8bcd\u200b\uff08\u200b\u5982\u200b\u6309\u200b\u7a7a\u683c\u200b\u3001\u200b\u6807\u70b9\u7b26\u53f7\u200b\u7b49\u200b\u5206\u5272\u200b\uff09\u200b\u518d\u8fdb\u4e00\u6b65\u200b\u62c6\u5206\u200b\u5355\u8bcd\u200b\u4e3a\u200bsubword\u200b\u5e8f\u5217\u200b  </li> <li> <p>\u200b\u7edf\u8ba1\u200b\u6240\u6709\u200b\u53ef\u80fd\u200b\u7684\u200bsubword-pair \u200b\u7684\u200b\u5171\u73b0\u200b\u9891\u6b21\u200b\uff0c\u200b\u9009\u62e9\u200b\u4f3c\u7136\u200b\u5206\u6570\u200b\\(score\\)\u200b\u6700\u5927\u200b\u7684\u200bsubword-pair\u200b\u5408\u5e76\u200b\u4e3a\u200b\u65b0\u200b\u7684\u200bsubword</p> \\[ score = \\frac{\\text{freq}(\\text{subword-pair})}{\\big(\\text{freq}(\\text{pair-left}) + \\text{freq}(\\text{pair-right})\\big)} \\] </li> <li> <p>\u200b\u91cd\u590d\u200b\u7b2c\u200b2\u200b\u6b65\u200b\u76f4\u5230\u200bsubwords\u200b\u6570\u200b\u8fbe\u5230\u200b\u6700\u5927\u200b\\(\\vert V \\vert\\)\u200b\u6216\u200b\u5f53\u524d\u200bstep\u200b\u6700\u200b\u9ad8\u9891\u200b\u7684\u200bsubword-pair\u200b\u9891\u7387\u200b\u4e3a\u200b1\uff0c\u200b\u9000\u51fa\u200b\u5faa\u73af\u200b</p> </li> </ol>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/subword_tokenize.html#_3","title":"\u56de\u9000\u200b\u4f18\u5316","text":"\u6807\u51c6\u7248\u200b\u4f18\u5316\u200b\u7248\u200b <pre><code>for token in whitespace_tokenize(text):\n    chars = list(token)\n    if len(chars) &gt; self.max_input_chars_per_word:\n        output_tokens.append(self.unk_token)\n        continue\n\n    is_bad = False\n    start = 0\n    sub_tokens = []\n    while start &lt; len(chars):\n        end = len(chars)\n        cur_substr = None\n        while start &lt; end:\n            substr = \"\".join(chars[start:end])\n            if start &gt; 0:\n                substr = \"##\" + substr\n            if substr in self.vocab:\n                cur_substr = substr\n                break\n            # \u200b\u8d2a\u5fc3\u200b\u5339\u914d\u200b\u65f6\u200b\uff0c\u200b\u672a\u5168\u200b\u5339\u914d\u200b\u65f6\u200b\u56de\u9000\u200b1\uff0c\u200b\u76f4\u81f3\u200b\u56de\u9000\u200b\u81f3\u200b\u5b57\u7b26\u200b\u7ea7\u200b\n            end -= 1\n        if cur_substr is None:\n            is_bad = True\n            break\n        sub_tokens.append(cur_substr)\n        # \u200b\u76f8\u5e94\u200b\u56de\u9000\u200b\n        start = end\n\n    if is_bad:\n        output_tokens.append(self.unk_token)\n    else:\n        output_tokens.extend(sub_tokens)\n</code></pre> <p>\u200b\u4f18\u5316\u200b\u7248\u200b\u8fdb\u4e00\u6b65\u200b\u5904\u7406\u200b\u5c40\u90e8\u200boov\u200b\u5bfc\u81f4\u200b\u6574\u4f53\u200b[UNK]\u200b\u7684\u200b\u6bd2\u6027\u200b\u6269\u6563\u200b\u60c5\u51b5\u200b\uff0c\u200b\u5373\u200b  </p> <ul> <li>\u200b\u6807\u51c6\u7248\u200b\uff1a<code>\u011fxcluo \u2192 [UNK]</code> </li> <li>\u200b\u4f18\u5316\u200b\u7248\u200b\uff1a<code>\u011fxcluo \u2192 [UNK] ##x ##c ##luo</code></li> </ul> <pre><code>for token in whitespace_tokenize(text):\n  chars = list(token)\n  if len(chars) &gt; self.max_input_chars_per_word:\n    output_tokens.append(self.unk_token)\n    continue\n\n  # is_bad = False\n  start = 0\n  sub_tokens = []\n  while start &lt; len(chars):\n    end = len(chars)\n    cur_substr = None\n    while start &lt; end:\n      substr = \"\".join(chars[start:end])\n      if start &gt; 0:\n        substr = \"##\" + substr\n      if substr in self.vocab:\n        cur_substr = substr\n        break\n      end -= 1\n\n    if cur_substr is None:\n        # unify multiple-unk_token or one_unk-to-one_token\n        if len(sub_tokens) == 0 or sub_tokens[-1] != self.unk_token:\n            sub_tokens.append(self.unk_token)\n        start += 1\n    else:\n        sub_tokens.append(cur_substr)\n        start = end\n\n  output_tokens.extend(sub_tokens)\n</code></pre>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/subword_tokenize.html#bpe","title":"BPE","text":"<p>\u200b\u65e0\u9700\u200b\u524d\u7f00\u200b<code>##</code>\u200b\u4f5c\u4e3a\u200b\u4e2d\u95f4\u200bsubword\u200b\u6807\u8bb0\u200b</p>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/subword_tokenize.html#_4","title":"\u57fa\u672c\u539f\u7406","text":"<p>\u200b\u7b97\u6cd5\u200b\u6d41\u7a0b\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li>\u200b\u521d\u59cb\u5316\u200b\uff1a\u200b\u5c06\u200b\u6240\u6709\u200b\u6587\u672c\u200b\u5e8f\u5217\u200b\u4ee5\u200b\u5b57\u8282\u200bByte\u200b\u6216\u200b\u5b57\u200b\u7ea7\u522b\u200b\u4e3a\u200b\u5355\u4f4d\u200b\u62c6\u5206\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u5c3e\u90e8\u200b\u6dfb\u52a0\u200b\u4e00\u4e2a\u200b\u505c\u6b62\u200b\u7b26\u200b<code>&lt;/w&gt;</code></li> <li>\u200b\u7edf\u8ba1\u200b\u5404\u200b\u76f8\u90bb\u200b subword-pair \u200b\u7684\u200b\u9891\u6b21\u200b\uff0c\u200b\u9009\u62e9\u200b\u6700\u9ad8\u200b\u9891\u6b21\u200b subword-pair \u200b\u5408\u5e76\u200b\u6210\u65b0\u200b\u7684\u200bsubword\uff08subword-pair\u200b\u66f4\u65b0\u200b\u5165\u200b\u5408\u5e76\u200b\u89c4\u5219\u200b\uff09\uff0c\u200b\u57fa\u4e8e\u200b\u65b0\u200bsubword\u200b\u66f4\u65b0\u200bsubword-pair \u200b\u7684\u200b\u7edf\u8ba1\u200b\u7ed3\u679c\u200b</li> <li>\u200b\u91cd\u590d\u200b\u7b2c\u200b2\u200b\u6b65\u200b\u76f4\u5230\u200bsubwords\u200b\u6570\u200b\u8fbe\u5230\u200b\u6700\u5927\u200b\\(\\vert V \\vert\\)\u200b\u6216\u200b\u5f53\u524d\u200bstep\u200b\u6700\u200b\u9ad8\u9891\u200b\u7684\u200bsubword-pair\u200b\u9891\u7387\u200b\u4e3a\u200b1\uff0c\u200b\u9000\u51fa\u200b\u5faa\u73af\u200b</li> </ol> <pre><code># \u200b\u521d\u59cb\u5316\u200b\uff1a\u200b\u6309\u7167\u200b\u5b57\u8282\u200b\u4e3a\u200b\u5355\u4f4d\u200b\u5212\u5206\u200b\u6587\u672c\u200b\u5e8f\u5217\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u5c3e\u90e8\u200b\u6dfb\u52a0\u200b\u505c\u6b62\u200b\u7b26\u200b &lt;/w&gt;\n{'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w e s t &lt;/w&gt;': 6, 'w i d e s t &lt;/w&gt;': 3}\n# \u200b\u57fa\u4e8e\u200bsubword-pair \u200b\u5171\u73b0\u200b\u9891\u6b21\u200b\u5bf9\u200b subwords\u200b\u8fdb\u884c\u200b\u5408\u5e76\u200b\n  # 1. \u200b\u6700\u200b\u9ad8\u9891\u200b\u7684\u200bsubword-pair\u200b\u662f\u200b`es`\uff0c\u200b\u5171\u73b0\u200b 6+3=9 \u200b\u6b21\u200b\uff0c\u200b\u5408\u5e76\u200b\n    {'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w es t &lt;/w&gt;': 6, 'w i d es t &lt;/w&gt;': 3}\n  # 2. \u200b\u6700\u200b\u9ad8\u9891\u200b\u7684\u200bsubword-pair\u200b\u662f\u200b`est`\uff0c\u200b\u5171\u73b0\u200b 6+3=9 \u200b\u6b21\u200b\uff0c\u200b\u5408\u5e76\u200b\n    {'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w est &lt;/w&gt;': 6, 'w i d est &lt;/w&gt;': 3}\n  # 3. \u200b\u6700\u200b\u9ad8\u9891\u200b\u7684\u200bsubword-pair\u200b\u662f\u200b`est&lt;/w&gt;`\uff0c\u200b\u5171\u73b0\u200b 6+3=9 \u200b\u6b21\u200b\uff0c\u200b\u5408\u5e76\u200b\n    {'l o w &lt;/w&gt;': 5, 'l o w e r &lt;/w&gt;': 2, 'n e w est&lt;/w&gt;': 6, 'w i d est&lt;/w&gt;': 3}\n  # 4. \u200b\u6700\u200b\u9ad8\u9891\u200b\u7684\u200bsubword_pair\u200b\u662f\u200b`lo`\uff0c\u200b\u5171\u73b0\u200b 5+2=7 \u200b\u6b21\u200b\uff0c\u200b\u5408\u5e76\u200b\n    {'lo w &lt;/w&gt;': 5, 'lo w e r &lt;/w&gt;': 2, 'n e w est&lt;/w&gt;': 6, 'w i d est&lt;/w&gt;': 3}\n  # ...\n# \u200b\u91cd\u590d\u200b\u8fed\u4ee3\u200b\u76f4\u5230\u200bsubwords\u200b\u6570\u200b\u8fbe\u5230\u200b\u8bcd\u8868\u200b\u5927\u5c0f\u200b|V|\u200b\u6216\u200b\u5f53\u524d\u200bstep\u200b\u6700\u200b\u9ad8\u9891\u200b\u7684\u200b\u5b57\u8282\u200b\u5bf9\u200b\u9891\u7387\u200b\u4e3a\u200b1\uff0c\u200b\u9000\u51fa\u200b\u5faa\u73af\u200b\n</code></pre>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/subword_tokenize.html#bpe-dropout","title":"BPE-Dropout","text":"<p>BPE-Dropout \u200b\u5728\u200b BPE \u200b\u7684\u200b\u5408\u5e76\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u5f15\u5165\u200b\u968f\u673a\u6027\u200b\uff0c\u200b\u4ee5\u200b\u6982\u7387\u200b \\(p\\) \u200b\u8df3\u8fc7\u200b\u67d0\u4e9b\u200b\u5408\u5e76\u200b\u6b65\u9aa4\u200b\uff0c\u200b\u4ece\u800c\u200b\u751f\u6210\u200b\u540c\u4e00\u200b\u5355\u8bcd\u200b\u7684\u200b\u591a\u79cd\u200b\u5206\u8bcd\u200b\u7ed3\u679c\u200b\u3002</p> <ol> <li>\u200b\u5408\u5e76\u200b\u89c4\u5219\u200b\uff1a<code>\"l\" + \"o\" \u2192 \"lo\", \"lo\" + \"w\" \u2192 \"low\", \"e\" + \"r\" \u2192 \"er\"</code></li> <li>\u200b\u57fa\u4e8e\u200b\u5408\u5e76\u200b\u89c4\u5219\u200b\uff0c\u200b\u5e94\u7528\u200bBPE-Dropout\u200b\u540e\u200b\uff0c\"lower\"\u200b\u7684\u200b\u53ef\u80fd\u200b\u5206\u8bcd\u200b\u4e3a\u200b\uff1a<ul> <li><code>\"low\" + \"er\"</code>\uff08\u200b\u672a\u200b\u8df3\u200b\u8fc7\u200b\u4efb\u4f55\u200b\u5408\u5e76\u200b\uff09</li> <li><code>\"lo\" + \"w\" + \"er\"</code> \uff08\u200b\u8df3\u8fc7\u200b <code>\"lo\" + \"w\" \u2192 \"low\"</code>\uff09</li> <li><code>\"l\" + \"o\" + \"w\" + \"er\"</code> \uff08\u200b\u8df3\u8fc7\u200b\u6240\u6709\u200b\u5408\u5e76\u200b\uff09</li> </ul> </li> </ol> <p>\u200b\u4f18\u52bf\u200b</p> <ol> <li>\u200b\u5bf9\u200b\u62fc\u5199\u9519\u8bef\u200b\u3001\uff08\u200b\u5927\u5c0f\u5199\u200b\u6216\u200b\u5f62\u6001\u200b\uff09\u200b\u53d8\u4f53\u200b\u3001\u200b\u591a\u200b\u8bed\u8a00\u200b\u6df7\u5408\u200b\u6587\u672c\u200b\u66f4\u9c81\u68d2\u200b\uff08\u200b\u5982\u200b<code>\"l0wer\", \"lOwer\", \"l\u200b\u3007\u200bwer\"</code>\uff09</li> <li>Github\uff1aSubword regularization and BPE-dropout</li> </ol>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/subword_tokenize.html#_5","title":"\u9884\u5148\u200b\u5206\u8bcd\u200b\u9009\u62e9","text":"<ul> <li> \u200b\u5904\u7406\u200b\u5305\u62ec\u200b\u5927\u91cf\u200b\u56fa\u5b9a\u200b\u5c5e\u4e8e\u200b\u7684\u200b\u4e13\u4e1a\u200b\u9886\u57df\u200b\u6587\u672c\u200b\uff08\u200b\u533b\u5b66\u200b\u3001\u200b\u6cd5\u5f8b\u200b\u7b49\u200b\uff09\u200b\u65f6\u200b</li> <li> \u200b\u8bad\u7ec3\u200b\u9762\u5411\u200b\u7279\u5b9a\u200b\u4e0b\u6e38\u200b\u4efb\u52a1\u200b\u7684\u200btokenizer</li> <li> \u200b\u8bad\u7ec3\u200b\u901a\u7528\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff0c\u200b\u5904\u7406\u200b\u591a\u200b\u8bed\u8a00\u200b\u6df7\u5408\u200b\u6587\u672c\u200b\uff0c\u200b\u8ffd\u6c42\u200b\u6700\u5927\u200b\u7075\u6d3b\u6027\u200b\u548c\u200b\u8986\u76d6\u7387\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Component/Tokenizer/SubWord/subword_tokenize.html#_6","title":"\u56fa\u5b9a\u200b\u9ad8\u9891\u8bcd\u200b\u3001\u200b\u7ef4\u62a4\u200b\u9886\u57df\u200b\u8bcd\u5178","text":"<pre><code>def preprocess_chinese(text):\n    # \u200b\u9886\u57df\u200b\u8bcd\u5178\u200b\n    fixed_phrases = {\"\u200b\u5317\u4eac\u200b\", \"\u200b\u4e0a\u6d77\u200b\", \"\u200b\u4eba\u5de5\u667a\u80fd\u200b\", \"\u200b\u673a\u5668\u200b\u5b66\u4e60\u200b\"}\n    for phrase in fixed_phrases:\n        # \u200b\u5728\u200btokenize\u200b\u65f6\u4f1a\u200b\u4f7f\u7528\u200bwhite_split\uff0c\u200b\u4ee5\u200b\u786e\u4fdd\u200b\u56fa\u5b9a\u200b\u5206\u8bcd\u200b\u88ab\u200b\u5212\u5206\u200b\n        text = text.replace(phrase, \" \" + phrase + \" \")\n    # \u200b\u5206\u8bcd\u200b\u5904\u7406\u200b\uff08\u200b\u53ef\u200b\u9009\u200b\uff09\n    text = ' '.join(jieba.cut(text))\n</code></pre>"},{"location":"AI/Paper_Reading/Computer_Vision/computer_vision.html","title":"Computer vision","text":"<p>\u200b\u5355\u5f20\u200b\u56fe\u7247\u200b\u7684\u200b\u50cf\u7d20\u200b\u8868\u793a\u200b\u4e3a\u200b<code>(C, H, W)</code>\uff0c\u200b\u5176\u4e2d\u200b  </p> <ul> <li><code>C</code> \u200b\u4e3a\u200bchannel\uff0c\u200b\u9ad8\u5ea6\u200bz\uff08\u22a5\uff09</li> <li><code>H</code> \u200b\u4e3a\u200b\u9ad8\u5ea6\u200b\uff0c\u200b\u7eb5\u8f74\u200by\uff08\u2193\uff09</li> <li><code>W</code> \u200b\u4e3a\u200b\u5bbd\u5ea6\u200b\uff0c\u200b\u6a2a\u8f74\u200bx\uff08\u2192\uff09</li> </ul>"},{"location":"AI/Paper_Reading/Computer_Vision/computer_vision.html#detection","title":"Detection","text":""},{"location":"AI/Paper_Reading/Computer_Vision/computer_vision.html#detection_1","title":"Detection","text":""},{"location":"AI/Paper_Reading/Computer_Vision/computer_vision.html#localization","title":"Localization","text":""},{"location":"AI/Paper_Reading/Computer_Vision/computer_vision.html#segmentatoin","title":"Segmentatoin","text":""},{"location":"AI/Paper_Reading/Computer_Vision/computer_vision.html#tracking","title":"Tracking","text":""},{"location":"AI/Paper_Reading/Computer_Vision/computer_vision.html#generation","title":"Generation","text":""},{"location":"AI/Paper_Reading/Computer_Vision/computer_vision.html#style-transfer","title":"Style-Transfer","text":""},{"location":"AI/Paper_Reading/Computer_Vision/computer_vision.html#resolution","title":"Resolution","text":""},{"location":"AI/Paper_Reading/Computer_Vision/computer_vision.html#inpainting","title":"Inpainting","text":""},{"location":"AI/Paper_Reading/Computer_Vision/computer_vision.html#multi-modality","title":"Multi-Modality","text":""},{"location":"AI/Paper_Reading/Computer_Vision/Classificatoin/classification.html","title":"Classification","text":""},{"location":"AI/Paper_Reading/Computer_Vision/Classificatoin/classification.html#image-classification","title":"Image Classification","text":""},{"location":"AI/Paper_Reading/Computer_Vision/Classificatoin/classification.html#multi-label-classfication","title":"Multi-Label Classfication","text":""},{"location":"AI/Paper_Reading/Computer_Vision/Classificatoin/classification.html#image-quality-assement","title":"Image Quality Assement","text":""},{"location":"AI/Paper_Reading/Computer_Vision/Classificatoin/inception.html","title":"Inception","text":""},{"location":"AI/Paper_Reading/Computer_Vision/Classificatoin/inception.html#inception-1","title":"Inception-1","text":"<p>\u200b\u8bba\u6587\u200b\uff1aGoing deeper with convolutions Google &amp; University of North Carolina &amp; University of Michigan, 2014 Sep, CVPR 2015</p>"},{"location":"AI/Paper_Reading/Computer_Vision/Classificatoin/inception.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Computer_Vision/Classificatoin/inception.html#inception","title":"Inception","text":"<p> 1. Naive Version\uff1a[1x1 conv, 3x3 conv, 5x5 conv] 2. Dimension Reduction Version\uff1a[1x1 conv, 1x1 conv + 3x3 conv, 1x1 conv + 5x5 conv, 3x3 max-pooling + 1x1 conv] - based on the Hebbian principle and the intuition of multi-scale processing - #3x3 reduce\u200b\u8868\u793a\u200b\u524d\u7f6e\u200b\u7684\u200b1x1 conv filter\u200b\u6570\u76ee\u200b - pool proj\u200b\u8868\u793a\u200b3x3 max-pooling\u200b\u540e\u200b\u7684\u200b1x1 conv filter\u200b\u6570\u76ee\u200b - reduction/projection     - input: <code>(N, H, W, C_in)</code>     - 1x1 filter: <code>(1, 1, C_in, C_out)</code>     - output: <code>(N, H, W, C_out)</code>     - \u200b\u5f53\u200b <code>C_in &gt; C_out</code>\u200b\u5373\u200breduction\uff0c\u200b\u53cd\u4e4b\u200b\u4e3a\u200bprojection - All these reduction/projection layers use rectified linear activation as well. - filter sizes 1x1, 3x3 and 5x5, however this decision was based more on convenience rather than necessity. - higher layers, their spatial concentration is expected to decrease suggesting that the ratio of 3x3 and 5x5 convolutions should increase as we move to higher layers. - \u200b\u5c11\u200b\u901a\u9053\u200b\u8fdb\u884c\u200b\u538b\u7f29\u200b\uff1a1x1 convolutions are used to compute reductions before the expensive 3x3 and 5x5 convolutions. - occasional max-pooling layers with stride 2 to halve the resolution of the grid. - start using Inception modules only at higher layers while keeping the lower layers in traditional convolutional fashion - Patch Size=kernel size - \u200b\u6df1\u5ea6\u200b\u62fc\u63a5\u200b=channel dimension concatenation</p>"},{"location":"AI/Paper_Reading/Computer_Vision/Classificatoin/inception.html#googlenet","title":"GoogLeNet","text":"<ul> <li>AveragePool 7x7+1(V) \u200b\u548c\u200b Conv 1x1+1(V) \u200b\u4e2d\u200b\u7684\u200bV\u200b\u8868\u793a\u200bvalid\u200b\u586b\u5145\u200b\uff0c+\\d\u200b\u540e\u9762\u200b\u7684\u200b\\d\u200b\u8868\u793a\u200b\u6b65\u957f\u200b</li> <li>Conv 1x1+1(S) \u200b\u4e2d\u200b\u7684\u200bS\u200b\u8868\u793a\u200bsame\u200b\u586b\u5145\u200b</li> <li>\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u4e09\u4e2a\u200b\u5206\u7c7b\u5668\u200b\u7684\u200b\u635f\u5931\u200b\u52a0\u6743\u200b\u6c42\u548c\u200b\uff08\u200b\u4e3b\u200b\u5206\u7c7b\u5668\u200b\u6743\u91cd\u200b1\uff0c\u200b\u8f85\u52a9\u200b\u5206\u7c7b\u5668\u200b\u5404\u200b0.3\uff09,\u200b\u6d4b\u8bd5\u200b\u65f6\u200b\u53ea\u200b\u4f7f\u7528\u200b\u4e3b\u200b\u5206\u7c7b\u5668\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Computer_Vision/Classificatoin/inception.html#inception-2","title":"Inception-2","text":""},{"location":"AI/Paper_Reading/Computer_Vision/Classificatoin/inception.html#inception-3","title":"Inception-3","text":""},{"location":"AI/Paper_Reading/Computer_Vision/Classificatoin/inception.html#inception-4","title":"Inception-4","text":""},{"location":"AI/Paper_Reading/Computer_Vision/Classificatoin/inception.html#xception","title":"Xception","text":""},{"location":"AI/Paper_Reading/Computer_Vision/Detection/detection.html","title":"Detection","text":"<ul> <li>https://cloud.tencent.com/developer/article/1549986</li> </ul>"},{"location":"AI/Paper_Reading/Computer_Vision/Detection/r-cnn.html","title":"R cnn","text":""},{"location":"AI/Paper_Reading/Computer_Vision/Detection/r-cnn.html#r-cnn","title":"R-CNN","text":"<p>\u200b\u8bba\u6587\u200b\uff1aRich feature hierarchies for accurate  object detection and semantic segmentation Github\uff1arcnn UCBerkeley, 2013 Nov, CVPR 2014</p> <p>Region-CNN</p>"},{"location":"AI/Paper_Reading/Computer_Vision/Detection/r-cnn.html#fast-r-cnn","title":"Fast R-CNN","text":"<p>\u200b\u8bba\u6587\u200b\uff1aFast R-CNN Github\uff1afast-rcnn MSR, 2015 Apr, ICCV 2015</p>"},{"location":"AI/Paper_Reading/Computer_Vision/Detection/r-cnn.html#faster-r-cnn","title":"Faster R-CNN","text":"<p>\u200b\u8bba\u6587\u200b\uff1aFaster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks Github\uff1apy-faster-rcnn USTC &amp; MSR &amp; FAIR, 2015 Jun, NeruIPS 2015</p>"},{"location":"AI/Paper_Reading/Computer_Vision/Detection/yolo.html","title":"Yolo","text":""},{"location":"AI/Paper_Reading/Computer_Vision/Detection/yolo.html#yolo-1","title":"YOLO-1","text":"<p>\u200b\u8bba\u6587\u200b\uff1aYou Only Look Once: Unified, Real-Time Object Detection Website\uff1ayolo University of Washington &amp; Allen AI &amp; FAIR, 2015 Jun, CVPR 2016</p>"},{"location":"AI/Paper_Reading/Computer_Vision/Detection/yolo.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>https://mp.weixin.qq.com/s?__biz=MzU0NjgzMDIxMQ==&amp;mid=2247628868&amp;idx=3&amp;sn=7e0aaa9e8d07313541a3f5aa659ba27e&amp;chksm=faf613ee7aec7cd3d8b4554c8e86527891e5fa52f3c8129c06d1f90927ee7fd453a43d3be4cb&amp;scene=27</li> </ul>"},{"location":"AI/Paper_Reading/Computer_Vision/Detection/yolo.html#yolo-2","title":"YOLO-2","text":""},{"location":"AI/Paper_Reading/Computer_Vision/Detection/yolo.html#ssd","title":"SSD","text":"<p>Single Shot MultiBox Detector</p>"},{"location":"AI/Paper_Reading/Computer_Vision/MultiModality/clip.html","title":"Clip","text":""},{"location":"AI/Paper_Reading/Computer_Vision/MultiModality/multimodality.html","title":"Multimodality","text":""},{"location":"AI/Paper_Reading/LM/Constrastive_Learning/index.html","title":"Index","text":""},{"location":"AI/Paper_Reading/LM/LMs/index.html","title":"\u8bed\u8a00\u200b\u6a21\u578b","text":""},{"location":"AI/Paper_Reading/LM/LMs/index.html#_1","title":"\u6a21\u578b\u200b\u67b6\u6784","text":""},{"location":"AI/Paper_Reading/LM/LMs/index.html#encoder","title":"Encoder","text":"<ul> <li>BERT</li> <li>ELECTRA</li> <li>RoBERTa</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/index.html#causalprefix-decoder","title":"Causal/Prefix Decoder","text":"<ul> <li>OpenAI: GPT</li> <li>Google: Gemini</li> <li>Anthropic: Cladue</li> <li>DeBERTa\u3001DeBERTa_v3</li> <li>LLaMA</li> <li>DeepSeek</li> <li>Mistral</li> <li>UniLM</li> <li>\u200b\u963f\u91cc\u200b\uff1a\u200b\u901a\u4e49\u200b\u5343\u6587\u200b</li> <li>\u200b\u6708\u200b\u4e4b\u200b\u6697\u9762\u200bMoonshot\uff1aKimi</li> <li>\u200b\u767e\u5ddd\u200b\u667a\u80fd\u200b\uff1a\u200b\u767e\u5ddd\u200b\u5927\u200b\u6a21\u578b\u200b</li> <li> <p>\u200b\u767e\u5ea6\u200b\uff1a\u200b\u6587\u5fc3\u200b\u4e00\u200b\u8a00\u200b</p> </li> <li> <p>\u200b\u667a\u8c31\u200bAI\uff1aGLM</p> \u200b\u7ffb\u8bd1\u200b<pre><code>from zhipuai import ZhipuAI\nimport json\n\n\napi_key = \"my_api_key\"\nclient = ZhipuAI(api_key=api_key)\n\ndef get_response(sample_input):\n    response = client.chat.completions.create(\n        model=\"GLM-4-Flash\",  # \u200b\u8bf7\u200b\u586b\u5199\u200b\u60a8\u200b\u8981\u200b\u8c03\u7528\u200b\u7684\u200b\u6a21\u578b\u200b\u540d\u79f0\u200b\n        messages=[\n            {\"role\": \"user\", \"content\": \"\u200b\u4f60\u200b\u662f\u200b\u4e00\u4e2a\u200b\u7ffb\u8bd1\u200b\u4e13\u5bb6\u200b\uff0c\u200b\u4f60\u200b\u9700\u8981\u200b\u5c06\u200b\u7528\u6237\u200b\u8f93\u5165\u200b\u7684\u200bjson\u200b\u683c\u5f0f\u200b\u4e2d\u200bcontent\u200b\u5bf9\u5e94\u200b\u7684\u200b\u6587\u672c\u200b\u7ffb\u8bd1\u200b\u4e3a\u200b\u4e2d\u6587\u200b\uff0c\u200b\u5e76\u200b\u5c06\u200b\u4e2d\u6587\u7ffb\u8bd1\u200b\u7ed3\u679c\u200b\u4f5c\u4e3a\u200b\u8be5\u200bjson\u200b\u6837\u672c\u200b\u4e2d\u200b\\\"t\\\"\u200b\u952e\u200b\u5bf9\u5e94\u200b\u7684\u200b\u503c\u200b\uff0c\u200b\u7ed3\u679c\u200b\u8fd4\u56de\u200bjson\u200b\u683c\u5f0f\u200b\"},\n            {\"role\": \"user\", \"content\": json.dumps(sample, ensure_ascii=False)},\n        ],\n    )\n\n    return response.choices[0].message.content\n\nresponse = get_response(line)\n# \u200b\u8fd4\u56de\u200b\u683c\u5f0f\u200b\u4e3a\u200b ```json ... ```\nleft_index, right_index = response.find(\"{\"), response.rfind(\"}\")\ntrans_line = json.loads(response[left_index: right_index + 1])\nif trans_line[\"content\"] != line[\"content\"]:\n    continue\n</code></pre> </li> <li> <p>\u200b\u8baf\u200b\u98de\u200b\uff1a\u200b\u661f\u706b\u200b</p> </li> <li>\u200b\u6606\u4ed1\u200b\u4e07\u7ef4\u200b\uff1a\u200b\u5929\u5de5\u200b</li> <li>\u200b\u817e\u8baf\u200b\uff1a\u200b\u6df7\u5143\u200b</li> <li>\u200b\u534e\u4e3a\u200b\uff1a\u200b\u76d8\u53e4\u200b</li> <li>\u200b\u5b57\u8282\u200b\uff1a\u200b\u8c46\u5305\u200b</li> <li>MiniMax\uff1aMiniMax</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/index.html#encoder-decoder","title":"Encoder-Decoder","text":"<ul> <li>MASS</li> <li>BART</li> <li>T5</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/index.html#_2","title":"\u4e0b\u6e38\u200b\u4efb\u52a1","text":""},{"location":"AI/Paper_Reading/LM/LMs/index.html#rag","title":"RAG","text":""},{"location":"AI/Paper_Reading/LM/LMs/Agent/index.html","title":"Index","text":""},{"location":"AI/Paper_Reading/LM/LMs/Agent/toolformer.html","title":"Toolformer","text":""},{"location":"AI/Paper_Reading/LM/LMs/Agent/toolformer.html#toolformer","title":"Toolformer","text":"<p>\u200b\u8bba\u6587\u200b\uff1aToolformer: Language Models Can Teach Themselves to Use Tools Github\uff1atoolformer Meta AI Research &amp; Universitat Pompeu Fabra, 2023 Feb, NeurIPS 2023</p>"},{"location":"AI/Paper_Reading/LM/LMs/Agent/toolformer.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li> <p>\u200b\u57fa\u4e8e\u200bprompt input\u200b\u4fe1\u606f\u200b\uff0c\u200b\u8bc6\u522b\u200b\u610f\u56fe\u200b\u518d\u200b\u901a\u8fc7\u200b\u8c03\u7528\u200bAPI\u200b\u8fdb\u884c\u200b\u66f4\u65b0\u200b\u66f4\u200b\u7cbe\u786e\u200b\u7684\u200b\u56de\u7b54\u200b</p> </li> <li> <p>\u200b\u8bad\u7ec3\u200bPrompt     </p> <p></p> </li> <li> <p>infer\u200b\u9636\u6bb5\u200b\uff0cLLM\u200b\u57fa\u4e8e\u200binput\u200b\u5185\u5bb9\u5206\u6790\u200b\u6587\u672c\u200b\u8bed\u4e49\u200b\uff0c\u200b\u81ea\u52a8\u200b\u51b3\u5b9a\u200bAPI call\u200b\u5e76\u200b\u6267\u884c\u200b\uff0c\u200b\u968f\u540e\u200b\u57fa\u4e8e\u200b\u8bed\u4e49\u200b\u4fe1\u606f\u200b\u548c\u200b\u7ed3\u679c\u200b\u6574\u5408\u200b\u6700\u7ec8\u200b\u8f93\u51fa\u200b</p> </li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/BART/bart.html","title":"Bart","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/BART/bart.html#bart","title":"BART","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDenoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension BART: Bidirectional and Auto-Regressive Transformers Facebook AI, ACL 2020</p>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/BART/bart.html#_1","title":"\u5de5\u4f5c\u200b\u8981\u70b9","text":"<ul> <li>corrupt text with an arbitrary noising function;</li> <li>seq-to-seq model to reconstruct the original text</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/BERT/DeBERTa/deberta.html","title":"Deberta","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/BERT/DeBERTa/deberta.html#deberta_v1","title":"DeBERTa_v1","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDeBERTa: Dcoding-enhanced BERT with disentangled attention Microsoft Dynamics 365 AI &amp; MSR, ICLR 2021</p>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/BERT/DeBERTa/deberta.html#_1","title":"\u5de5\u4f5c\u200b\u4eae\u70b9","text":"<ul> <li>\u200b\u63d0\u5347\u200bBERT\u200b\u548c\u200bRoBERTa\u200b\u6a21\u578b\u200b\u6548\u679c\u200b</li> <li>disentangled(\u200b\u89e3\u5f00\u200b\u3001\u200b\u89e3\u200b\u8026\u200b\uff0c\u200b\u6307\u200b\u5206\u89e3\u200b\u64cd\u4f5c\u200b\u3010emb_total \u2192 pos_emb, token_emb\u3011) attention mechanism<ul> <li>each layer, a token is comprised of content and relative position vectors rather than their sum</li> <li>attention weights are computed using disentangled matrices on two vectors</li> </ul> </li> <li>enhanced mask decoder(EMD)\uff0c\\(P\\in\\mathbb{R}^{2k*d}\\)<ul> <li>consider absoluate position when decoding the masked words before softmax layer</li> <li>enhanced MLM</li> </ul> </li> <li>virtual adversarial training (VAT) when finetune to improving models\u2019 generalization.<ul> <li>Scale-invariant-Fine-Tuning, a regularization method for improving model's generalization</li> <li>\u200b\u5148\u200b\u8fdb\u884c\u200bnormalization\uff0c\u200b\u518d\u200b\u6dfb\u52a0\u200b\u6270\u52a8\u200b\u566a\u58f0\u200b</li> </ul> </li> <li>share relative position embedding projection matrices with \\(W_q, W_k\\)</li> <li>add convolution layer (induces n-gram knowledge) aside 1-st layer and sum-up together feeding into next layer</li> <li>DeBERTa-MT pretrained using MLM and auto-regressive as in UniLM</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/BERT/DeBERTa/deberta.html#deberta_v3","title":"DeBERTa_v3","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDeBERTav3: improving DeBERTa using electra-style pre-training with gradient-disentangled embedding sharing AI &amp; MSR, ICLR 2023</p>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/BERT/DeBERTa/deberta.html#_2","title":"\u5de5\u4f5c\u200b\u4eae\u70b9","text":"<ul> <li>Embedding Sharing (ES), No Embedding Sharing (NES), Gradient-Disentangled Embedding Sharing (GDES)</li> <li>table 2\u30019, ablation embedding sharing methods</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/BERT/ELECTRA/electra.html","title":"Electra","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/BERT/ELECTRA/electra.html#electra","title":"ELECTRA","text":"<p>\u200b\u8bba\u6587\u200b\uff1aELECTRA: pre-training text encoders as discriminators rather than generators ELECTRA: Efficiently Learning an Encoder that Classifies Token Replacements Accurately Stanford University &amp; Google Brain, ICLR 2020</p>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/BERT/RoBERTa/roberta.html","title":"Roberta","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/BERT/RoBERTa/roberta.html#roberta","title":"RoBERTa","text":"<p>\u200b\u8bba\u6587\u200b\uff1aRoBERTa: a Robustly optimized BERT pretraining approach University of Washington &amp; Facebook AI, NAACL-HLT 2019</p> <ul> <li>\u200b\u52a8\u6001\u200bmask\uff0c\u200b\u6bcf\u6b21\u200b\u8f93\u5165\u200btoken seq\u200b\u65f6\u200b\u968f\u673a\u200bmask</li> <li>\u200b\u53d6\u6d88\u200bnsp\uff0c\u200b\u53ea\u6709\u200bMLM</li> <li>\u200b\u6269\u5927\u200bbatch_size</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/Baichuan/baichuan.html","title":"Baichuan","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek-coder.html","title":"Deepseek coder","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek-coder.html#deepseek-coder","title":"DeepSeek-Coder","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDeepSeek-Coder: When the Large Language Model Meets Programming - The Rise of Code Intelligence Github\uff1aDeepSeek-Coder DeepSeek-AI &amp; Peking University, 2024 Jan</p>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek-coder.html#deepseek-coder-2","title":"DeepSeek-Coder-2","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence Github\uff1aDeepSeek-Coder-V2 DeepSeek-AI, 2024 Jun</p>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek-math.html","title":"Deepseek math","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek-math.html#deepseekmath","title":"DeepSeekMath","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models Github\uff1aDeepSeek-Math DeepSeek-AI &amp; Tsinghua University &amp; Peking University, 2024 Feb  </p>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek-math.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li> \u200b\u63d0\u51fa\u200b\uff08PPO\u200b\u53d8\u79cd\u200b\uff09GRPO\u200b\u5f3a\u5316\u200b\u5b66\u4e60\u200b\u65b9\u6848\u200b\u63d0\u5347\u200b\u6a21\u578b\u200b\u5bf9\u9f50\u200b\u6548\u679c\u200b</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek-math.html#grpo","title":"GRPO","text":"<p>GRPO (Group Relative Policy Optimization)\u200b\u662f\u200bPPO\u200b\u7b97\u6cd5\u200b\u7684\u200b\u4e00\u4e2a\u200b\u53d8\u79cd\u200b\uff0c\u200b\u4e0d\u518d\u200b\u9700\u8981\u200b\u7ef4\u62a4\u200b\u4e00\u4e2a\u200b\u8ba1\u7b97\u200b\u91cf\u200b\u9700\u6c42\u200b\u5de8\u5927\u200b\u7684\u200b\u4ef7\u503c\u200b\u6a21\u578b\u200b\u8f93\u51fa\u200bbaseline\u200b\u6765\u200b\u8ba1\u7b97\u200b\u6837\u672c\u200b\u4f18\u52bf\u200b\uff0c\u200b\u800c\u662f\u200b</p> <ol> <li>\u200b\u4f7f\u7528\u200b\\(\\pi_{old}\\)\u200b\u5bf9\u200b\u540c\u4e00\u200b\u95ee\u9898\u200b\u91c7\u6837\u200b\u751f\u6210\u200b\\(G\\)\u200b\u4e2a\u200b\u56de\u7b54\u200b  </li> <li>\u200b\u6839\u636e\u200bRM\u200b\u8f93\u51fa\u200b\u5bf9\u5e94\u200b\u7684\u200b\u5956\u52b1\u200b\u5206\u6570\u200b  </li> <li>\u200b\u5bf9\u200b\u5956\u52b1\u200b\u5206\u6570\u200b\u7ed3\u679c\u200b \\(\\mathbb{R}^{G}\\) \u200b\u8fdb\u884c\u200bnorm\u200b\u64cd\u4f5c\u200b\u5f97\u5230\u200b\u6837\u672c\u200b\u4f18\u52bf\u200b\u7ed3\u679c\u200b\\(A_{i}\\) </li> </ol> \\[ \\begin{aligned}     \\mathcal{J}_{GRPO}&amp;(\\theta) = \\mathbb{E}\\left[q \\sim P(Q), \\{o_i\\}_{i=1}^G \\sim \\pi_{\\theta_{\\text{old}}} (O|q)\\right] \\\\     \\frac{1}{G} &amp;\\sum_{i=1}^G  \\left( \\min \\left( \\frac{\\pi_{\\theta}(o_i|q)} {\\pi_{\\theta_{\\text{old}}}(o_i|q)} A_i, \\operatorname{clip} \\left( \\frac{\\pi_{\\theta}(o_i|q)}{\\pi_{\\theta_{\\text{old}}}(o_i|q)}, 1 - \\varepsilon, 1 + \\varepsilon \\right) A_i \\right) - \\beta \\mathbb{D}_{KL} (\\pi_{\\theta} | \\pi_{\\text{ref}}) \\right) \\\\     &amp;\\mathbb{D}_{KL} (\\pi_{\\theta} | \\pi_{\\text{ref}}) = \\frac{\\pi_{\\text{ref}}(o_i|q)}{\\pi_{\\theta}(o_i|q)} - \\log \\frac{\\pi_{\\text{ref}}(o_i|q)}{\\pi_{\\theta}(o_i|q)} - 1. \\end{aligned} \\]"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek-reasoning.html","title":"Deepseek reasoning","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek-reasoning.html#deepseek-r1","title":"DeepSeek-R1","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning Github\uff1aDeepSeek-V3 DeepSeek-AI, 2025 Jan</p>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek-reasoning.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>DeepSeek-R1-Zero(w/o SFT), DeepSeek-R1(multi-stage training + cold-start data)</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html","title":"Deepseek","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#deepseek-1","title":"DeepSeek-1","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDeepSeek LLM Scaling Open-Source Language Models with Longtermism DeepSeek-AI &amp; Tsinghua University &amp; PKU, 2024 Jan</p>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#architecture","title":"Architecture","text":"<p>\u200b\u4e3b\u4f53\u200b\u57fa\u4e8e\u200bLLaMA\u200b\u6a21\u578b\u200b\u6846\u67b6\u200b\uff0c\u200b\u8fdb\u884c\u200b\u4e86\u200b\u90e8\u5206\u200b\u6539\u52a8\u200b\uff1a</p> <ul> <li><code>Pre-RMSNorm</code></li> <li><code>8/3 d_model FFN + SwiGLU</code> (8/3 d_model\u200b\u7684\u200bSwiGLU\u200b\u7b97\u529b\u200b\u7b49\u4ef7\u200b\u4e8e\u200b\u534a\u4e2a\u200bFFN\uff0c\u200b\u4ee5\u6b64\u200b\u603b\u4f53\u200b\u8fd8\u662f\u200b<code>8*d_model\\*d_model</code>)</li> <li> <p>67B: <code>GQA \u2190 MHA</code> </p> <p>\u200b\u76f8\u540c\u200b\u53c2\u200b\u6570\u91cf\u200b\u4e0b\u200b\uff0c\u200b\u52a0\u6df1\u200b\u6a21\u578b\u200b\u5c42\u6570\u200b\u800c\u200b\u4e0d\u662f\u200b\u62d3\u5bbd\u200b\\(d_\\text{ff}\\)\u200b\u66f4\u200b\u5bb9\u6613\u200b\u83b7\u5f97\u200b\u6548\u679c\u200b\u63d0\u5347\u200b</p> </li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#pre-training","title":"Pre-Training","text":"<ol> <li>Dataset\uff0c\u200b\u5305\u542b\u200b2T \u200b\u4e2d\u82f1\u6587\u200btokens       <ul> <li>\u200b\u53bb\u200b\u91cd\u200bdeduplication\uff1a\u200b\u5bf9\u200bCommom Crawl corpus\u200b\u7684\u200b91\u200b\u4e2a\u200b\u5168\u7f51\u200b\u6570\u636e\u200b\u722c\u53d6\u200b\u5b58\u6863\u200b(CC dump split by month)\u200b\u53bb\u200b\u91cd\u6bd4\u200b\u5bf9\u200b\u5355\u4e2a\u200b\u5b58\u6863\u200b\u53bb\u200b\u91cd\u200b\uff0c\u200b\u53bb\u200b\u91cd\u200b\u7ed3\u679c\u200b\u66f4\u4f18\u200b  </li> <li>\u200b\u8fc7\u6ee4\u200bfiltering: \u200b\u96c6\u5408\u200b\u8bed\u6cd5\u200b\u548c\u200b\u8bed\u4e49\u200b\u7b49\u200b\u5c40\u90e8\u200b\u548c\u200b\u5168\u5c40\u200b\u89c6\u89d2\u200b\u5bf9\u200b\u6587\u6863\u200b\u8d28\u91cf\u200b\u8bc4\u4f30\u200b  </li> <li>\u200b\u6df7\u5408\u200bremixing: \u200b\u5904\u7406\u200b\u6570\u636e\u200b\u4e0d\u200b\u5e73\u8861\u200b\u95ee\u9898\u200b\uff0c\u200b\u91cd\u70b9\u200b\u589e\u52a0\u200b\u4ee3\u8868\u6027\u200b\u4e0d\u8db3\u200b\u7684\u200b\u9886\u57df\u200b\u6837\u672c\u200b</li> </ul> </li> <li> <p>Tokenizer\uff0cByte-level BPE</p> <ul> <li>Pre-tokenization \u200b\u7c7b\u4f3c\u200b\u4e8e\u200bGPT-2\uff0c\u200b\u9632\u6b62\u200b\u4e0d\u540c\u200b\u7c7b\u522b\u200b\u7b26\u53f7\u200b\u5408\u5e76\u200b\uff0c\u200b\u5982\u200b\u6362\u884c\u7b26\u200b\u3001\u200b\u6807\u70b9\u7b26\u53f7\u200b\u4ee5\u53ca\u200bCJK\u200b\u7b26\u53f7\u200b  </li> <li>Split Number \u200b\u7c7b\u4f3c\u200b\u4e8e\u200bLLaMA\uff0c\u200b\u5c06\u200b\u6570\u503c\u200b\u5212\u5206\u200b\u4e3a\u200b\u5355\u4e2a\u200b\u6570\u5b57\u200b\u5e8f\u5217\u200b</li> <li>Vocab: <code>100000 conventional + 15 special + used for future \u2192 102400</code></li> </ul> </li> <li> <p>Hyperparameter</p> <ul> <li>AdamW\uff1a\\(\\beta_1 = 0.9, \\beta_2 = 0.95, \\text{weight_decay}=0.1\\)</li> <li><code>gradient_clip=1.0</code></li> <li> <p>Multi-step LR scheduler</p> <ul> <li>~2000 steps\uff0cwarmup\u200b\u5347\u81f3\u200bmax_lr</li> <li>~80% tokens\uff0c\u200b\u964d\u200b\u81f3\u200b 0.316*max_lr</li> <li>~90% tokens\uff0c\u200b\u964d\u200b\u81f3\u200b 0.1*max_lr  </li> </ul> <ol> <li>multi-step LR\u200b\u548c\u200bcos LR\u200b\u6548\u679c\u200b\u4e00\u81f4\u200b\uff0c\u200b\u4f46\u200b\u524d\u8005\u200b\u7684\u200b\u9636\u6bb5\u6027\u200b\u7ed3\u679c\u200b\u4fbf\u4e8e\u200b\u4fdd\u5b58\u200b\u590d\u7528\u200b\uff0c\u200b\u56e0\u6b64\u200b\u9009\u62e9\u200bmulti-step\u200b\u65b9\u6848\u200b</li> <li>\u200b\u8c03\u6574\u200b\u5404\u200bstep\u200b\u7684\u200btoken\u200b\u5360\u200b\u6bd4\u200b\u53ef\u80fd\u200b\u83b7\u5f97\u200b\u4e9b\u5fae\u200b\u63d0\u5347\u200b\uff0c\u200b\u7efc\u5408\u200b\u8003\u8651\u200b\u9009\u62e9\u200b 80% + 10% + 10% \u200b\u65b9\u6848\u200b</li> </ol> </li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#scaling-laws","title":"Scaling Laws","text":"<p>\u200b\u57fa\u4e8e\u200bAttention\u200b\u673a\u5236\u200b\u7684\u200bTransformer\u200b\u67b6\u6784\u200b\u4e2d\u200b\uff0c\u200b\u76f4\u63a5\u200b\u4f7f\u7528\u200b\\(C=6ND\\) \u200b\u8ba1\u7b97\u200b\u7b97\u529b\u200b\u6709\u200b\u660e\u663e\u200b\u7684\u200b\u8fd1\u4f3c\u200b\u4f30\u8ba1\u200b\u8bef\u5dee\u200b\uff0c\u200b\u672c\u6587\u200b\u6539\u4e3a\u200b\\(C=MD\\)\uff0c\\(M\\)\u200b\u5355\u4f4d\u200b\u4e3a\u200b <code>FLOPs/token</code>\uff0c\u200b\u5177\u4f53\u200b\u5982\u4e0b\u200b\uff1a</p> \\[ \\begin{aligned}     6N_1 =&amp; 72 n_\\text{layer} d^2_\\text{model} \\\\     6N_2 =&amp; 72 n_\\text{layer} d^2_\\text{model} + 6n_\\text{vocab}d_\\text{model}\\\\     M =&amp; 72 n_\\text{layer}d^2_\\text{model} + 12 n_\\text{layer}d_\\text{model} l_\\text{seq} \\end{aligned} \\] <ul> <li>\u200b\u5de6\u5f0f\u200b 6\u200b\u500d\u200b \u200b\u6765\u6e90\u4e8e\u200b <code>multiply-add * (forward + 2*backward)</code></li> <li>\u200b\u53f3\u5f0f\u200b 72\u200b\u500d\u200b \u200b\u6765\u6e90\u4e8e\u200b <code>6*(W_q + W_k + W_v + W_o + 8*W_ffn)</code></li> <li>\\(N_2\\) \u200b\u5305\u62ec\u200bEmbedding\u200b\u53c2\u6570\u200b\uff0c\u200b\u56e0\u6b64\u200b\u989d\u5916\u200b\u52a0\u4e0a\u200b <code>next_token_prediction</code> \u200b\u5c42\u200b</li> <li>\\(M\\) \u200b\u8f83\u200b\\(6N_1\\)\u200b\u65b0\u589e\u200battention\u200b\u673a\u5236\u200b\u7b97\u529b\u200b 12\u200b\u500d\u200b \u200b\u6e90\u4e8e\u200b\uff0c<code>6 * (d*l_seq + d*l_seq)</code></li> </ul> <ol> <li> <p>Scaling Laws for BS/LR\uff0c</p> <ul> <li>\u200b\u5728\u200b\u5c0f\u89c4\u6a21\u200b\u6a21\u578b\u200b\u7684\u200bgrid search\u200b\u5b9e\u9a8c\u200b\u53d1\u73b0\u200b\u6cdb\u5316\u200b\u8bef\u5dee\u200b\u5728\u200b\u5404\u79cd\u200b <code>bs</code>\u200b\u548c\u200b<code>lr</code>\u200b\u9009\u62e9\u200b\u8303\u56f4\u200b\u5185\u200b\u4fdd\u6301\u7a33\u5b9a\u200b</li> <li>\u200b\u6700\u4f18\u200b <code>bs</code> \u200b\u968f\u7740\u200b\u7b97\u529b\u200b \\(C\\) \u200b\u589e\u5927\u200b\u800c\u200b\u589e\u5927\u200b\uff0c\u200b\u6700\u4f18\u200b <code>lr</code> \u200b\u968f\u7740\u200b\u7b97\u529b\u200b \\(C\\) \u200b\u589e\u5927\u200b\u800c\u200b\u51cf\u5c0f\u200b</li> <li>\\(\\eta_\\text{opt}=0.3118\\cdot C^{-0.1250}, B_\\text{opt} = 0.2920 \\cdot C^{0.3271}\\)</li> </ul> <p></p> <p></p> <p></p> <p></p> </li> <li> <p>Estimating Optimal Model/Data Scaling(#token)\uff0c\u200b\u57fa\u4e8e\u200b\u6700\u4f18\u200b\u8d85\u53c2\u200b\\(\\eta_\\text{opt}, B_\\text{opt}\\)</p> \\[ \\begin{aligned}     M_\\text{opt}, D_\\text{opt}(C) =&amp; \\mathop{\\text{argmin}}\\limits_{M, D \\text{ s.t. } C=MD} L(N, D) \\\\     M_\\text{opt} =&amp; M_\\text{base} \\cdot C^{a} \\\\     D_\\text{opt} =&amp; D_\\text{base} C^{b} \\\\     1 \\approx &amp; M_\\text{base} \\cdot D_\\text{base} \\\\     1 = &amp; a + b \\\\ \\end{aligned} \\] <ul> <li>\\(L(N, D)\\) \u200b\u8ba1\u7b97\u516c\u5f0f\u200b\u6e90\u4e8e\u200b Chinchilla</li> </ul> <p></p> <p></p> <p>Fig. 4(a) \u200b\u76f8\u540c\u200b\u7b97\u529b\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u9009\u5b9a\u200bbits-per-byte on valid set\u200b\u6700\u5c0f\u503c\u200b\u5bf9\u5e94\u200b\u7684\u200b\\(M\\)\u200b\u8fdb\u884c\u200b\u6295\u5f71\u200b\u5f97\u5230\u200b Fig. 4(b)</p> <p></p> <p></p> </li> <li> <p>Scaling Laws with Different Data\uff0c\u200b\u4e0d\u540c\u200b\u6570\u636e\u200b\u96c6\u4f1a\u200b\u5bfc\u81f4\u200bscaling laws\u200b\u53c2\u6570\u200b\u6539\u53d8\u200b</p> <ul> <li>\u200b\u6570\u636e\u200b\u8d28\u91cf\u200b\u8d8a\u9ad8\u200b\uff0c\u200b\u5206\u914d\u200b\u7ed9\u200b\u6a21\u578b\u200b\u7684\u200b\u7b97\u529b\u200b\u5360\u200b\u6bd4\u5e94\u200b\u8d8a\u200b\u591a\u200b\uff08\u200b\u8d28\u91cf\u200b\u8d8a\u9ad8\u200b\uff0c\u200b\u5e94\u200b\u4f7f\u7528\u200b\u903b\u8f91\u200b\u80fd\u529b\u200b\u66f4\u200b\u6e05\u6670\u200b\u7684\u200b\u66f4\u200b\u5927\u200b\u6a21\u578b\u200b\uff09\uff0c\u200b\u5373\u200b\u76f8\u540c\u200b\u6570\u636e\u200b\u89c4\u6a21\u200b\u4e0b\u200b\uff0c\u200b\u9ad8\u8d28\u91cf\u200b\u6570\u636e\u200b\u53ef\u4ee5\u200b\u9a71\u52a8\u200b\u66f4\u5927\u200b\u6a21\u578b\u200b\u7684\u200b\u8bad\u7ec3\u200b</li> </ul> <p></p> <p></p> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#post-training","title":"Post-Training","text":"<ol> <li>Dataset\uff1a1.5M \u200b\u4e2d\u82f1\u6587\u200b\u6570\u636e\u200b\uff1a<ul> <li>1.2M helpfulness<ul> <li>31.2% \u200b\u901a\u7528\u200b\u8bed\u8a00\u200b\u4efb\u52a1\u200b</li> <li>46.6% \u200b\u6570\u5b66\u200b\u95ee\u9898\u200b\uff0c\u200b\u6570\u636e\u200b\u8d28\u91cf\u200b\u4f4e\u6613\u200b\u5bfc\u81f4\u200bSFT\u200b\u9636\u6bb5\u200b\u91cd\u590d\u200b\u8f93\u51fa\u200b\u95ee\u9898\u200b</li> <li>22.2% \u200b\u7f16\u7801\u200b\u7ec3\u4e60\u200b</li> </ul> </li> <li>300K harmlessness/safty\uff0c\u200b\u5305\u542b\u200b\u5927\u91cf\u200b\u654f\u611f\u8bdd\u9898\u200b\u6570\u636e\u200b</li> </ul> </li> <li> <p>SFT\uff1a</p> <ul> <li>7B\uff1a<code>4 epochs, lr=1e-4</code></li> <li>67B\uff1a<code>2 epochs(avoid overfit), lr=5e-6 with warmup and cos_lr_scheduler</code></li> </ul> </li> <li> <p>DPO\uff0c<code>1 epochs, lr=5e-6, bs=512</code></p> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#deepseek-2","title":"DeepSeek-2","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model DeepSeek-AI, 2024 May</p> <ul> <li> MLA\u200b\u901a\u8fc7\u200b\u9ad8\u6548\u200b\u538b\u7f29\u200bK\u3001V\u200b\u5411\u91cf\u200b\u65b9\u5f0f\u200b\u51cf\u5c11\u200bKV cache\u200b\u4ee5\u200b\u63d0\u5347\u200b\u8bad\u7ec3\u200b\u548c\u200b\u9884\u6d4b\u200b\u6548\u7387\u200b\uff0c\u200b\u5e76\u200b\u83b7\u5f97\u200b\u66f4\u597d\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</li> <li> \u200b\u90e8\u7f72\u200b\u6a21\u578b\u200b\u524d\u200b\uff0c\u200b\u5bf9\u6a21\u578b\u200b\u91cf\u5316\u200b\u3001\u200b\u538b\u7f29\u200b\u540e\u200b\uff0cgeneration throughput \u200b\u8d85\u8fc7\u200b 50K token/s\uff0cprompt throughput \u200b\u8d85\u8fc7\u200b 100K token/s</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#_2","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#mla","title":"MLA","text":"<p>MLA\uff08Multi-head Latent Attention\uff09\u200b\u5bf9\u200bQ\u3001K\u3001V\u200b\u5411\u91cf\u200b\u8fdb\u884c\u200b\u4e86\u200b\u538b\u7f29\u200b\uff0c\u200b\u5e76\u200b\u5c06\u200bRoPE\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b\u4e0e\u200b\u538b\u7f29\u200b\u540e\u200b\u7684\u200bQ\u3001K\u3001V\u200b\u5411\u91cf\u200b\u89e3\u200b\u8026\u200b\u8fde\u63a5\u200b\uff0c\u200b\u8f83\u200bMHA\u200b\u5f97\u5230\u200b\u83b7\u53d6\u200b\u66f4\u52a0\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u7684\u200b\u540c\u65f6\u200b\u4e5f\u200b\u6781\u5927\u200b\u5730\u200b\u51cf\u5c11\u200b\u4e86\u200bKV cache</p> <ol> <li> <p>QKV\u200b\u5411\u91cf\u200b\u4f4e\u200b\u79e9\u200b\u538b\u7f29\u200b\uff0c\u200b\u7c7b\u4f3c\u200b\u4e8e\u200bLoRA \\(Wx=W^{U}W^{D}x\\)\uff0c\u200b\u5176\u4e2d\u200b D(own) \u200b\u548c\u200b U(pper)</p> \\[ \\begin{aligned}     c_{t}^{KV} =&amp; W^{DKV}h_t \\\\     k_t^C =&amp; W^{UK}c_t^{KV} \\\\     v_t^C =&amp; W^{UV}c_t^{KV} \\\\      c_{t}^{Q} =&amp; W^{DQ}h_t \\\\     q_t^C =&amp; W^{UQ}c_t^{Q}  \\end{aligned} \\] <ul> <li>\\(W^{DKV} \\in \\mathbb{R}^{d_c \\times d}\\)\uff0c\\(W^{DQ}\\in \\mathbb{R}^{d_c^{'}\\times d}\\)</li> <li>\\(W^{UK},W^{UV}\\in \\mathbb{R}^{d_hn_h\\times d_c}\\)\uff0c\\(W^{UQ}\\in \\mathbb{R}^{d_hn_h\\times d_c^{'}}\\)\uff0c \\(d_c,d_c^{'} \\ll d_hn_h\\) </li> <li>\\(c\\) \u200b\u4e3a\u200b\u538b\u7f29\u200b\u540e\u200b\u7684\u200b\u5411\u91cf\u200b\uff0c\\(C\\) \u200b\u4e3a\u200b\u964d\u7ef4\u200b\u3001\u200b\u5347\u7ef4\u200b\u64cd\u4f5c\u200b\u540e\u200b\u7684\u200b\u7ed3\u679c\u200b\u6807\u5fd7\u200b  </li> </ul> </li> <li> <p>RoPE\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b\u89e3\u200b\u8026\u5408\u200b\uff0c\u200b\u76ee\u7684\u200b\u662f\u200bcache\u200b\u538b\u7f29\u200b\u540e\u200b\u7684\u200b\u5411\u91cf\u200b \\(c^{KV}\\)\uff0c\u200b\u800c\u200b\u5bf9\u200b\\(k^C\\)\u200b\u5e94\u7528\u200bRoPE\u200b\u64cd\u4f5c\u8fc7\u7a0b\u200b\u5982\u4e0b\u200b</p> \\[ \\begin{aligned}     \\langle \\text{RoPE}(q^C_t, m), \\text{RoPE}(k^C_t, n) \\rangle =&amp;      \\left(c_t^Q\\right)^T\\left(W^{UQ}\\right)^Te^{-im\\theta} e^{in\\theta}W^{UK}c_t^{KV} \\\\     = &amp;  g(W^{UQ}c_t^Q, W^{UK}c_t^{KV}, n-m) \\end{aligned} \\] <p>\u200b\u867d\u7136\u200b\u80fd\u200b\u63d2\u5165\u200b\u76f8\u5bf9\u200b\u4f4d\u7f6e\u200b\u4fe1\u606f\u200b\uff0c\u200b\u4f46\u200b\u7531\u4e8e\u200b\\(W^{UQ}\\)\u200b\u4e0e\u200b\\(W^{UK}\\)\u200b\u88ab\u200b\u65cb\u8f6c\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b\u77e9\u9635\u200b\u95f4\u9694\u200b\u65e0\u6cd5\u200b\u878d\u5408\u200b\uff0c\u200b\u6bcf\u6b21\u200b\u8ba1\u7b97\u200b\\(\\langle q, k \\rangle\\) \u200b\u4ecd\u200b\u9700\u200b\u8ba1\u7b97\u200b\\(k^C=W^{UK}c^{KV}_t\\)\uff0c\u200b\u65e0\u6cd5\u200b\u8d77\u5230\u200b\u7f13\u5b58\u200b \\(c^{KV}\\) \u200b\u7684\u200b\u76ee\u7684\u200b\u3002\u200b\u4e3a\u200b\u63d0\u5347\u200bkv cache\u200b\u6548\u7387\u200b\uff0c\u200b\u4f7f\u7528\u200bRoPE\u200b\u4e0e\u200b\u538b\u7f29\u200b\u540e\u200b\u7684\u200bQ\u3001K\u200b\u5411\u91cf\u200b\u89e3\u200b\u8026\u200b\u7684\u200b\u65b9\u5f0f\u200b\u6ce8\u5165\u200b\u4f4d\u7f6e\u200b\u4fe1\u606f\u200b\u3002</p> \\[ \\begin{aligned}     q_t^R \\in \\mathbb{R}^{d_h^{R}n_h} =&amp; \\text{RoPE}(W^{QR}c_t^Q) \\\\     k_t^R \\in \\mathbb{R}^{d_h^R} =&amp; \\text{RoPE}(W^{KR}h_t) \\\\     q_{t, i} =&amp; [q^C_{t, i}; q^R_{t, i}] \\\\     k_{t, i} =&amp; [k^C_{t, i}; k^R_{t}] \\\\ \\end{aligned} \\] <ul> <li>\u200b\u8ba1\u7b97\u200b\\(k^R_t\\)\u200b\u65f6\u200b\u4f7f\u7528\u200b\\(h_t\\)\u200b\u800c\u200b\u4e0d\u662f\u200b\u4f7f\u7528\u200b\\(c_t^{KV}\\) \u200b\u662f\u200b\u4e00\u4e2a\u200b\u76f4\u89c2\u200b\u4e0a\u200b\u7684\u200b\u9009\u62e9\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u524d\u8005\u200b\u4fdd\u7559\u200b\u4e86\u200b\u66f4\u200b\u591a\u200b\u8bed\u4e49\u200b\u4fe1\u606f\u200b</li> <li>per-head\u200b\u62e5\u6709\u200b\\(q_{t,i}^R\\)\uff0call-head\u200b\u5171\u4eab\u200b\u4e00\u4e2a\u200b\\(k_t^R\\) </li> <li>\u200b\u8ba1\u7b97\u200blogit\u200b\u503c\u200b\u65f6\u5206\u200b\u6bcd\u4e3a\u200b \\(\\sqrt{d_h + d_h^R}\\)</li> </ul> </li> <li> <p>Inference\u200b\u9636\u6bb5\u200bTrick\uff0c\u200b\u5728\u200b\u9884\u6d4b\u200b\u5e94\u7528\u200b\u9636\u6bb5\u200b\uff0cMLA\u200b\u7684\u200bper-head Attention\u200b\u8fc7\u7a0b\u200b\u8ba1\u7b97\u200b\u5982\u4e0b\u200b</p> \\[ \\begin{aligned}     o_{t} =&amp; \\sum_{j=1}^t \\text{Softmax}_j \\left(\\frac{q^T_{t}k_{j}}{\\sqrt{d_h + d_h^R}}\\right)v_{j}^C \\\\     = &amp; \\sum_{j=1}^t \\text{Softmax}_j \\left(\\frac{[q^C_{t}; q^R_{t}]^T[k^C_{j}; k^R_{j}]}{\\sqrt{d_h + d_h^R}}\\right)v_{j}^C\\\\     = &amp; \\sum_{j=1}^t \\text{Softmax}_j \\left(\\frac{[W^{UQ}c^{Q}_t; \\text{RoPE}(W^{QR}c^Q_t)]^T[W^{UK}c^{KV}_j; k^R_t)]}{\\sqrt{d_h + d_h^R}}\\right)W^{UV}c^{KV}_j\\\\     u_t =&amp; W^Oo_{t} \\end{aligned} \\] <ul> <li>\u200b\u5411\u91cf\u200b\u4e58\u6cd5\u200b\u524d\u534a\u90e8\u200b\u5206\u53ef\u200b\u5408\u5e76\u200b\u4e3a\u200b \\(W^{UQ}_{absorb} = (W^{UQ})^TW^{UK}\\)\uff0c\u200b\u65e0\u9700\u200b\u91cd\u200b\u8ba1\u7b97\u200b \\(k^C_t\\)</li> <li>\u200b\u7531\u4e8e\u200bAttention\u200b\u5206\u6570\u200b\u77e9\u9635\u200b\u5143\u7d20\u200b\u4e3a\u200b\u6807\u91cf\u200b\uff0c\u200b\u8f93\u51fa\u200b\u90e8\u5206\u200b\u53ef\u200b\u5408\u5e76\u200b\u4e3a\u200b \\(W^O_{absorb}=W^{O}W^{UV}\\)\uff0c\u200b\u65e0\u9700\u200b\u51b2\u6d17\u200b\u8ba1\u7b97\u200b \\(v^C_t\\)</li> <li>\u200b\u6700\u7ec8\u200bkv cache \u200b\u7ed3\u679c\u200b\u4e3a\u200b \\(c^{KV}\\) \u200b\u4e0e\u200b \\(k^R\\)\uff0c\u200b\u7a7a\u95f4\u200b\u590d\u6742\u5ea6\u200b\u4e3a\u200b \\((d_c + d^R_h)l_\\text{seq}\\)</li> </ul> </li> <li> <p>KV cache \u200b\u7a7a\u95f4\u200b\u590d\u6742\u5ea6\u200b\u5bf9\u6bd4\u200b\uff0cMLA KV cache\u200b\u7a7a\u95f4\u200b\u590d\u6742\u5ea6\u200b\u63a5\u8fd1\u200bMQA</p> <p></p> <p></p> <p>\\(d_c = 4d_h, d^R_h = \\frac{d_h}{2}\\)</p> </li> <li> <p>Attention \u200b\u6548\u679c\u200b\u5bf9\u6bd4\u200b\uff0c\u200b\u8f83\u200bMHA\u200b\u4ecd\u200b\u6709\u200b\u660e\u663e\u200b\u63d0\u5347\u200b\uff0c\u200b\u6574\u4f53\u200b\u6548\u679c\u200b\u6700\u4f73\u200b     </p> <p></p> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#deepseekmoe","title":"DeepSeekMoE","text":"<p>DeepSeekMoE\u200b\u5728\u200b\u4f20\u7edf\u200bMoE\u200b\u7684\u200b\u57fa\u7840\u200b\u4e0a\u5c06\u200b\u4e13\u5bb6\u200b\u7f51\u7edc\u200b\u7ec6\u5206\u200b\u4e3a\u200bRouted Experts\u200b\u548c\u200bShared experts\uff0c\u200b\u7528\u4e8e\u200b\u89e3\u51b3\u200bMoE\u200b\u5185\u200b\u77e5\u8bc6\u200b\u6df7\u5408\u200b(Knowledge Hybridity)\u200b\u548c\u200bMoE\u200b\u95f4\u200b\u77e5\u8bc6\u200b\u5197\u4f59\u200b(Knowledge Redundancy)\u200b\u95ee\u9898\u200b</p> <ul> <li>\u200b\u77e5\u8bc6\u200b\u6df7\u5408\u200b\uff1aMoE\u200b\u80fd\u529b\u200b\u8fc7\u4e8e\u200b\u590d\u6742\u200b\u805a\u5408\u200b\u4e86\u200b\u4e0d\u540c\u200b\u7c7b\u578b\u200b\u7684\u200b\u77e5\u8bc6\u200b\uff0c\u200b\u9886\u57df\u4e13\u5bb6\u200b\u6027\u200b\u4e0d\u591f\u200b</li> <li>\u200b\u77e5\u8bc6\u200b\u5197\u4f59\u200b\uff1a\u200b\u4e0d\u540c\u200bMoE\u200b\u9700\u8981\u200b\u5171\u540c\u200b\u7684\u200b\u57fa\u7840\u77e5\u8bc6\u200b\uff0c\u200b\u5bfc\u81f4\u200b\u5404\u200bMoE\u200b\u5747\u200b\u6536\u655b\u200b\u83b7\u53d6\u200b\uff0c\u200b\u9020\u6210\u200b\u53c2\u6570\u200b\u5197\u4f59\u200b</li> </ul> <ul> <li>\u200b\u4e3a\u200b\u4fdd\u6301\u200bMoE\u200b\u9886\u57df\u200b\u6027\u200b\uff0c\u200b\u5c06\u200bMoE\u200b\u6570\u91cf\u200b\u53d8\u4e3a\u200b\u539f\u6765\u200b\u7684\u200b \\(m\\) \u200b\u500d\u200b\uff0c\u200b\u540c\u65f6\u200b\u4e3a\u200b\u4fdd\u8bc1\u200b\u53c2\u6570\u200b\u603b\u91cf\u200b\u4e0d\u53d8\u200b\uff0c\u200b\u6bcf\u4e2a\u200bMoE\u200b\u7684\u200b\\(d_\\text{ff}\\) \u200b\u53d8\u4e3a\u200b\u539f\u6765\u200b\u7684\u200b \\(\\frac{1}{m}\\)</li> <li>\u200b\u4e3a\u200b\u4fdd\u6301\u200b\u4e0e\u200b\u7c92\u5ea6\u200b\u62c6\u5206\u200b\u524d\u200b\u6fc0\u6d3b\u200b\u90e8\u5206\u200b\u5bf9\u9f50\u200b\uff0cMoE\u200b\u7684\u200b\u6fc0\u6d3b\u200b\u6570\u76ee\u200b\u4e5f\u200b\u76f8\u5e94\u200b\u53d8\u4e3a\u200b\u4e4b\u524d\u200b\u7684\u200b \\(m\\) \u200b\u500d\u200b</li> <li>e.g. \\(N_r=16, K_r=2, m=4\\)\uff0c\u200b\u8def\u7531\u200b\u7b56\u7565\u200b\u4ece\u200b\\(\\begin{pmatrix} 2 \\\\ 16 \\end{pmatrix}=120\\) \u200b\u5267\u589e\u200b\u4e3a\u200b \\(\\begin{pmatrix} 8 \\\\ 64 \\end{pmatrix}=4426165368\\)\uff0c\u200b\u7075\u6d3b\u6027\u200b\u5927\u5927\u200b\u63d0\u5347\u200b</li> <li>\u200b\u7531\u4e8e\u200b\u7ec6\u5206\u200bMoE\u200b\u540e\u200b\u6fc0\u6d3b\u200b\u7684\u200bMoE\u200b\u6570\u91cf\u200b\u6fc0\u589e\u200b\uff0c\u200b\u5728\u200b\u8fd0\u884c\u200bEP\u200b\u65f6\u200b\u901a\u4fe1\u200b\u5ef6\u8fdf\u200b\u8017\u65f6\u200b\u975e\u5e38\u200b\u4e25\u91cd\u200b\uff0c\u200b\u4e3a\u200b\u51cf\u7f13\u200b\u8be5\u200b\u95ee\u9898\u200b\uff0c\u200b\u9650\u5236\u200b\u4e86\u200btoken\u200b\u6fc0\u6d3b\u200b\u7684\u200bMoE\u200b\u6700\u200b\u591a\u200b\u5206\u5e03\u200b\u5728\u200b \\(M\\ge 3\\) \u200b\u4e2a\u200b\u8bbe\u5907\u200b\u4e0a\u200b\uff0c\u200b\u5373\u200b\u5728\u200b\u5206\u6570\u200b\u603b\u548c\u200b\u6700\u5927\u200b\u7684\u200btop-M\u200b\u4e2a\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u9009\u62e9\u200btop-K\u200b\u4e2a\u200bMoE</li> </ul> DeepSeekMoE \\[ \\begin{aligned}  \\mathbf{h}_t' =&amp; \\mathbf{u}_t + \\sum_{i=1}^{N_s} \\text{FFN}_i^{(s)} (\\mathbf{u}_t) + \\sum_{i=1}^{N_r} g_{i,t} \\text{FFN}_i^{(r)} (\\mathbf{u}_t) \\\\ g_{i,t} = &amp;  \\begin{cases}  s_{i,t}, &amp; s_{i,t} \\in \\text{Topk}(\\{s_{j,t}|1 \\leq j \\leq N_r\\}, K_r), \\\\ 0, &amp; \\text{otherwise} \\end{cases} \\\\ s_{i,t} =&amp; \\text{Softmax}_i (\\mathbf{u}_t^T e_i) \\\\ E \\in \\mathbb{R}^{N_r \\times d} =&amp; [e_1^T; e_2^T; \\cdots; e_{N_r}^T] \\end{aligned} \\] <p>top-K\u200b\u64cd\u4f5c\u200b\u540e\u200b\u7684\u200bRouted Experts\u200b\u95e8\u9650\u200b\u6743\u91cd\u200b\u672a\u200b\u5f52\u4e00\u5316\u200b</p> <p>\u200b\u4e3a\u200b\u9632\u6b62\u200b\u8bad\u7ec3\u200b\u65f6\u200bMoE\u200b\u8def\u7531\u200b\u574d\u584c\u200b\uff0c\u200b\u91c7\u7528\u200b\u4e86\u200b\u4e00\u7cfb\u5217\u200b\u8f85\u52a9\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u52a0\u4ee5\u200b\u7ea6\u675f\u200b\u77eb\u6b63\u200b\uff0c\\(T\\) \u200b\u8868\u793a\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b\uff1a</p> <ol> <li> <p>Expert-Level Balance Loss\uff0c\u200b\u5747\u8861\u200b\u5404\u200bMoE\u200b\u88ab\u200b\u6fc0\u6d3b\u200b\u65f6\u200b\u7684\u200b\u52a0\u6743\u200b\u5206\u6570\u200b</p> \\[ \\begin{aligned}     \\mathcal{L}_{\\text{ExpBal}} =&amp; \\alpha_1\\sum_{i=1}^{N_r}f_iP_i \\\\     f_i =&amp; \\frac{N_r}{K_rT}\\sum_{t=1}^T \\mathbb{1}\\text{ (Token }t\\text{ selects Expert }i\\text{)} \\\\     P_i =&amp; \\frac{1}{T}\\sum_{t=1}^T s_{i, t} \\end{aligned} \\] <p>\\(f_i\\) \u200b\u8868\u793a\u200b i-th MoE\u200b\u52a0\u6743\u200b\u6fc0\u6d3b\u200b\u6b21\u6570\u200b\uff0c\u200b\u5904\u7406\u200b\u5e8f\u5217\u200b\u65f6\u200b\u6fc0\u6d3b\u200b\u6b21\u6570\u200b\u671f\u671b\u200b\u4e3a\u200b \\(T*\\frac{K_r}{N_r}\\)\uff0c\u200b\u6982\u7387\u200b\u671f\u671b\u200b\u4e3a\u200b\u5012\u6570\u200b</p> </li> <li> <p>Device-Level Balance Loss\uff0c\u200b\u5747\u8861\u200b\u5404\u200b\u8bbe\u5907\u200b\u4e0a\u200bMoE\u200b\u88ab\u200b\u6fc0\u6d3b\u200b\u65f6\u200b\u7684\u200b\u52a0\u6743\u200b\u5206\u6570\u200b</p> \\[ \\begin{aligned}     \\mathcal{L}_{\\text{DevBal}} =&amp; \\alpha_2\\sum_{i=1}^{D}f_i^{'}P_i^{'} \\\\     f_i^{'} =&amp; \\frac{1}{\\vert \\varepsilon_i \\vert}\\sum_{j \\in \\varepsilon_i} f_j \\\\     P_i^{'} =&amp; \\sum_{j \\in \\varepsilon_i }P_j \\end{aligned} \\] <p>Routed MoE\u200b\u88ab\u200b\u5206\u6210\u200b\\(D\\)\u200b\u7ec4\u200b\\(\\{\\varepsilon_1, \\varepsilon_2, \\dots, \\varepsilon_D\\}\\)\uff0c\u200b\u4e00\u7ec4\u200b\u5bf9\u5e94\u200b\u4e00\u4e2a\u200b\u8bbe\u5907\u200b</p> </li> <li> <p>Communication Balance Loss\uff0c\u200b\u5747\u8861\u200b\u5404\u200b\u8bbe\u5907\u200b\u95f4\u200b\u7684\u200b\u901a\u4fe1\u200b\u5f00\u9500\u200b</p> \\[ \\begin{aligned}     \\mathcal{L}_{\\text{CommBal}} =&amp; \\alpha_3\\sum_{i=1}^{D}f_i^{''}P_i^{'} \\\\     f_i^{''} =&amp; \\frac{D}{MT}\\sum_{t=1}^T \\mathbb{1}\\text{ (Token }t\\text{ is sent to Device }i\\text{)} \\\\     P_i^{'} =&amp; \\sum_{j \\in \\varepsilon_i }P_j \\end{aligned} \\] <ul> <li>\\(f_i^{''}\\) \u200b\u8868\u793a\u200b -th \u200b\u8bbe\u5907\u200b\u52a0\u6743\u200b\u6fc0\u6d3b\u200b\u6b21\u6570\u200b\uff0c\u200b\u5904\u7406\u200b\u5e8f\u5217\u200b\u65f6\u200b\u6fc0\u6d3b\u200b\u6b21\u6570\u200b\u671f\u671b\u200b\u4e3a\u200b \\(T*\\frac{M}{D}\\)\uff0c\u200b\u6982\u7387\u200b\u671f\u671b\u200b\u4e3a\u200b\u5012\u6570\u200b</li> <li>\u200b\u4e0e\u200bMoE\u200b\u7c7b\u4f3c\u200b\uff0c\u200b\u5e76\u884c\u200b\u65f6\u200b\u9650\u5236\u200b\u6700\u200b\u591a\u200b\u6fc0\u6d3b\u200b\\(M \\ge 3\\) \u200b\u4e2a\u200b\u8bbe\u5907\u200b</li> </ul> </li> </ol> <p>\u200b\u5373\u4f7f\u200b\u5e94\u7528\u200b\u4e86\u200b\u4e0a\u8ff0\u200b\u8d1f\u8f7d\u200b\u5747\u8861\u200b\u7b56\u7565\u200b\uff0c\u200b\u4f46\u200b\u4f9d\u7136\u200b\u65e0\u6cd5\u200b\u4fdd\u8bc1\u200b\u4e25\u683c\u200b\u7684\u200b\u8d1f\u8f7d\u5e73\u8861\u200b\uff0c\u200b\u56e0\u6b64\u200b\u8fdb\u4e00\u6b65\u200b\u63d0\u51fa\u200b\u4e86\u200b <code>device-level token-dropping</code> \u200b\u65b9\u6848\u200b\uff0c\u200b\u5177\u4f53\u6b65\u9aa4\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li>\u200b\u8ba1\u7b97\u200b\u5404\u200b\u8bbe\u5907\u200b\u5e73\u5747\u200b\u7b97\u529b\u200b\u5f00\u9500\u200b </li> <li>\u200b\u820d\u5f03\u200b\u8d85\u51fa\u200b\u7b97\u529b\u200b\u5f00\u9500\u200b\u7684\u200b\u4f4e\u5206\u200btoken\uff1a\u200b\u4ee5\u200b\u8bbe\u5907\u200b\u4e3a\u200b\u5355\u4f4d\u200b\uff0c\u200b\u6309\u200bMoE\u200b\u6fc0\u6d3b\u200b\u6743\u91cd\u200b\u5206\u6570\u200b\u964d\u5e8f\u200b\u6392\u5217\u200b\uff0c\u200b\u820d\u5f03\u200b\u8d85\u51fa\u200b\u5e73\u5747\u200b\u7b97\u529b\u200b\u5f00\u9500\u200b\u7684\u200b\u5269\u4f59\u200b\u4f4e\u5206\u200btoken\u200b\u6fc0\u6d3b\u200b</li> </ol> <ul> <li>\u200b\u8bbe\u8ba1\u200b\u4e86\u200b\u65b9\u6848\u200b\u786e\u4fdd\u200b\u7ea6\u200b10%\u200b\u7684\u200b\u8bad\u7ec3\u200b\u5e8f\u5217\u200b\u4e0d\u200b\u6267\u884c\u200b <code>token-dropping</code> \u200b\u7b56\u7565\u200b</li> <li>\u200b\u6d4b\u8bd5\u200b\u65f6\u200b\uff0c\u200b\u53ef\u200b\u57fa\u4e8e\u200b\u6548\u7387\u200b\u548c\u200b\u4e00\u81f4\u6027\u200b\u8003\u91cf\u200b\u662f\u5426\u200b\u8981\u200b\u6267\u884c\u200b <code>token-dropping</code> \u200b\u7b56\u7565\u200b</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#pre-training_1","title":"Pre-Training","text":"<ol> <li> <p>Dataset Counstruction\uff0c\u200b\u5728\u200bDeepSeek 67B\u200b\u7684\u200b\u57fa\u7840\u200b\u4e0a\u200b\u8fdb\u4e00\u6b65\u200b\u589e\u5927\u200b\u6570\u636e\u91cf\u200b\u3001\u200b\u63d0\u9ad8\u200b\u6570\u636e\u200b\u8d28\u91cf\u200b\uff0c\u200b\u5305\u542b\u200b8.1T tokens\uff0c\u200b\u5176\u4e2d\u200b\u6587\u200btoken\u200b\u6570\u6bd4\u200b\u82f1\u6587\u200btoken\u200b\u6570\u7ea6\u200b\u591a\u200b12%</p> <ul> <li>Enlarge Corpus<ol> <li>\u200b\u6316\u6398\u200b\u7f51\u7edc\u200b\u6570\u636e\u200b\uff0c\u200b\u4f18\u5316\u200b\u6e05\u6d17\u200b\u6d41\u7a0b\u200b\uff0c\u200b\u8fd8\u539f\u200b\u5927\u91cf\u200b\u8bef\u5220\u9664\u200b\u6570\u636e\u200b</li> <li>\u200b\u6574\u5408\u200b\u4e86\u200b\u66f4\u200b\u591a\u200b\u4e2d\u6587\u200b\u8bed\u6599\u5e93\u200b</li> </ol> </li> <li>Elevate Quality<ol> <li>\u200b\u4f18\u5316\u200bfiltering\u200b\u7b97\u6cd5\u200b\uff0c\u200b\u53bb\u9664\u200b\u5927\u90e8\u5206\u200b\u65e0\u200b\u610f\u4e49\u200b\u6570\u636e\u200b\uff0c\u200b\u4fdd\u7559\u200b\u5927\u90e8\u5206\u200b\u9ad8\u8d28\u91cf\u200b\u6570\u636e\u200b\uff1b</li> <li>\u200b\u53bb\u9664\u200b\u4e89\u8bae\u200b\u6570\u636e\u200b\uff0c\u200b\u51cf\u8f7b\u200b\u7531\u200b\u7279\u5b9a\u200b\u6587\u5316\u200b\u9886\u57df\u200b\u6570\u636e\u200b\u5f15\u5165\u200b\u7684\u200b\u504f\u5dee\u200b\uff08\u200b\u5982\u200b\u4ef7\u503c\u89c2\u200b\uff0c\u200b\u4e3b\u89c2\u200b\u504f\u89c1\u200b\u7b49\u200b\uff09</li> </ol> </li> </ul> </li> <li> <p>Tokenizer\uff1aBBPE as DeepSeek-1</p> </li> <li>Hyperparameter<ul> <li>AdamW\uff1a\\(\\beta_1 = 0.9, \\beta_2 = 0.95, \\text{weight_decay}=0.1\\)</li> <li><code>max_seq_len=4K</code> </li> <li><code>gradient_clip=1.0</code></li> <li>Multi-step LR Scheduler<ul> <li>~2000 steps\uff0clinearly increase warmup\u200b\u4ece\u200b0\u200b\u5347\u81f3\u200b<code>max_lr=2.4*1e-4</code></li> <li>~60% tokens\uff0c\u200b\u964d\u200b\u81f3\u200b <code>0.316*max_lr</code></li> <li>~90% tokens\uff0c\u200b\u964d\u200b\u81f3\u200b <code>0.316*0.316*max_lr\u22480.1*max_lr</code></li> </ul> </li> <li>BS Scheduler\uff1a~225B tokens\uff0c\u200b\u4ece\u200b2304\u200b\u5347\u81f3\u200b9216\uff0c\u200b\u968f\u540e\u200b\u4fdd\u6301\u200b</li> <li>DeepSeekMoE\u200b\u914d\u7f6e\u200b \\(D=8, M=3\\)</li> <li>Balance Factor\uff1a\\(\\alpha_1=0.003, \\alpha_2=0.05, \\alpha_3=0.02\\)</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#context-window-extension","title":"Context Window Extension","text":"<p>\u200b\u5728\u200b\u9884\u200b\u8bad\u7ec3\u200bLLM\u200b\u540e\u200b\uff0c\u200b\u5e94\u7528\u200bYaRN\u200b\u5c06\u200b\u6587\u672c\u200b\u7a97\u53e3\u200b\u957f\u5ea6\u200b\u7531\u200b4K\u200b\u62d3\u5c55\u200b\u81f3\u200b128K\uff0c\u200b\u5b9e\u9645\u200b\u4e3a\u200b\u5bf9\u89e3\u200b\u8026\u5408\u200b\u7684\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b \\(q^{R}_t, k^{R}_t\\) \u200b\u5e94\u7528\u200bYaRN\uff0c\u200b\u5176\u4e2d\u200b  </p> <ul> <li>\\(s=40, \\alpha=1, \\beta=32\\)\uff0c\u200b\u7406\u8bba\u200b\u4e0a\u200b\u6700\u5927\u200b\u62d3\u5c55\u200b\u957f\u5ea6\u200b\u4e3a\u200b160K  </li> <li>\u200b\u957f\u5ea6\u200b\u7f29\u653e\u200b\u7cfb\u6570\u200b \\(\\sqrt{\\frac{1}{t}} = 0.0707 \\ln s + 1\\) </li> <li><code>train_steps=1000, seq_len=32K, batch_size=576</code> </li> <li> \u200b\u867d\u7136\u200b\u4ec5\u200b\u5728\u200b 32K \u200b\u7684\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b\u4e0a\u200bYaRN\u200b\u8bad\u7ec3\u200b\u8fdb\u884c\u200b<code>context_window</code>\u200b\u62d3\u5c55\u200b\uff0c\u200b\u4f46\u200b\u5728\u200b 128K \u200b\u7684\u200b\u4e0a\u4e0b\u6587\u200b\u957f\u5ea6\u200b\u4e0b\u200b\u8fdb\u884c\u200b\u8bc4\u4f30\u200b\u65f6\u200b\uff0c\u200b\u8be5\u200b\u6a21\u578b\u200b\u4ecd\u7136\u200b\u8868\u73b0\u200b\u51fa\u200b\u7a33\u5065\u200b\u7684\u200b\u6027\u80fd\u200b\u3002</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#infrastructure","title":"Infrastructure","text":"<ol> <li>\u200b\u5c06\u200b\u6240\u6709\u200b\u53c2\u6570\u200b\u91cf\u5316\u200b\u4e3a\u200bFP8\u200b\u7cbe\u5ea6\u200b\u7c7b\u578b\u200b</li> <li>\u200b\u8fdb\u4e00\u6b65\u200b\u5bf9\u200bKV cache\u200b\u8fdb\u884c\u200b\u91cf\u5316\u200b\uff0c\u200b\u538b\u7f29\u200b\u540e\u200b\u5e73\u5747\u200b\u5927\u5c0f\u200b\u4e3a\u200b 6-bit</li> <li>HAI-LLM framework</li> <li>zero-bubble</li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#post-training_1","title":"Post-Training","text":"<ol> <li> <p>SFT\uff0c1.5M = 1.2M helpfulness + 0.3M safety</p> </li> <li> <p>GRPO</p> </li> </ol> <p>\u200b\u6a21\u578b\u200b\u67b6\u6784\u200b\uff1a</p> <ol> <li>DeepSeek-V2</li> <li>DeepSeek-V2-Lite</li> <li>DeepSeek-V2-Chat_SFT</li> <li>DeepSeek-V2-Chat_RL</li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#deepseek-3","title":"DeepSeek-3","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDeepSeek-V3 Technical Report DeepSeek-AI, 2024 Dec</p>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#_3","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#mla-modified","title":"MLA modified","text":"<p>DeepSeek-3 \u200b\u8f83\u200b DeepSeek-2\uff0c\u200b\u5bf9\u200b\\(c^{KV}, c^Q\\) \u200b\u65b0\u589e\u200b\u4e86\u200bRMSNorm\u200b\u64cd\u4f5c\u200b\u540e\u200b\uff08\u200b\u5305\u62ec\u200b Norm + Scale\uff09</p> \\[ \\begin{aligned}     c_{t}^{KV} =&amp; W^{DKV}h_t \\\\     c_{t}^{KV} =&amp; \\text{RMSNorm}(c_{t}^{KV}) \\\\     k_t^C =&amp; W^{UK}c_t^{KV} \\\\     v_t^C =&amp; W^{UV}c_t^{KV} \\\\      c_{t}^{Q} =&amp; W^{DQ}h_t \\\\     c_{t}^{Q} =&amp; \\text{RMSNorm}(c_{t}^{Q}) \\\\     q_t^C =&amp; W^{UQ}c_t^{Q}  \\end{aligned} \\]"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#deepseekmoe-modified","title":"DeepSeekMoE modified","text":"<ol> <li> <p>Auxiliary-Loss-Free Load Balancing\uff0c\u200b\u5728\u200bDeepSeekMoE\u200b\u57fa\u7840\u200b\u4e0a\u200b\u4fee\u6b63\u200b\u5e76\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u65e0\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u8d1f\u8f7d\u200b\u5747\u8861\u200b</p> <ul> <li> \u200b\u4e3a\u200b\u5747\u8861\u200bMoE\u200b\u8d1f\u8f7d\u200b\u4e0e\u200b\u6a21\u578b\u200b\u6548\u679c\u200b\uff0c\u200b\u65b0\u589e\u200b per-expert trainable\u200b\u504f\u7f6e\u200b\u9879\u200b \\(b_i\\) \u200b\u7528\u4e8e\u200b top-K\u200b\u9009\u53d6\u200b</li> <li>\u200b\u5bf9\u200btop-K\u200b\u64cd\u4f5c\u200b\u540e\u200b\u7684\u200bRouted MoE\u200b\u6743\u91cd\u200b\\(g'_{i, t}\\)\u200b\u5f52\u4e00\u5316\u200b  </li> <li>\u200b\u56e0\u4e3a\u200b\u540e\u7eed\u200b\u6709\u200b\u5f52\u4e00\u5316\u200b\u64cd\u4f5c\u200b \\(s_{i, t}\\) \u200b\u7684\u200b\u8ba1\u7b97\u200b\u6539\u4e3a\u200b\u4e86\u200b <code>sigmoid</code></li> </ul> \\[ \\begin{aligned}  \\mathbf{h}_t' =&amp; \\mathbf{u}_t + \\sum_{i=1}^{N_s} \\text{FFN}_i^{(s)} (\\mathbf{u}_t) + \\sum_{i=1}^{N_r} g_{i,t} \\text{FFN}_i^{(r)} (\\mathbf{u}_t) \\\\ g_{i, t} =&amp; \\frac{g'_{i, t}}{\\sum_{j=1}^{N_r}g'_{j, t}} \\\\ g'_{i,t} = &amp;  \\begin{cases}  s_{i,t}, &amp; s_{i,t} + b_i \\in \\text{Topk}\\left(\\{s_{j,t}|1 \\leq j \\leq N_r\\}, K_r\\right), \\\\ 0, &amp; \\text{otherwise} \\end{cases} \\\\ s_{i,t} =&amp; \\text{Sigmoid} (\\mathbf{u}_t^T e_i) \\\\ E \\in \\mathbb{R}^{N_r \\times d} =&amp; [e_1^T; e_2^T; \\cdots; e_{N_r}^T] \\end{aligned} \\] <ul> <li>\u200b\u504f\u7f6e\u200b\u9879\u200b \\(b_i\\) \u200b\u53ea\u200b\u7528\u4e8e\u200btop-K\u200b\u8def\u7531\u200b\u9009\u62e9\u200b\uff0c\u200b\u4e0d\u200b\u53c2\u4e0e\u200b\u95e8\u9650\u200b\u6743\u91cd\u200b \\(g_{i, t}\\) \u200b\u8ba1\u7b97\u200b</li> <li>\u200b\u8bad\u7ec3\u200b\u65f6\u200b\uff0c\u200b\u5f53\u200bExpert\u200b\u7684\u200b\u8d85\u8f7d\u200b \\(b_i -= \\gamma\\)\uff0c\u200b\u8d1f\u8f7d\u200b\u4e0d\u8db3\u200b \\(b_i += \\gamma\\)\uff0c\\(\\gamma\\) \u200b\u4e3a\u200b\u504f\u7f6e\u200b\u9879\u200b\u66f4\u65b0\u200b\u901f\u5ea6\u200b\u3002\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u65e0\u9700\u200b\u501f\u52a9\u200b\u989d\u5916\u200b\u8f85\u52a9\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u4fbf\u200b\u53ef\u200b\u5747\u8861\u200b\u8d1f\u8f7d\u200b</li> <li>\u200b\u63a8\u7406\u200b\u65f6\u200b\uff0c\u200b\u79fb\u9664\u200b\\(b_i\\) \u200b\u9879\u200b\uff0c\u200b\u5373\u200btop-K\u200b\u90e8\u5206\u200b\u6539\u4e3a\u200b \\(s_{i,t} \\in \\text{Topk}(\\{s_{j,t}|1 \\leq j \\leq N_r\\}, K_r)\\)\uff0c\u200b\u67d0\u4e9b\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u4ecd\u200b\u5e0c\u671b\u200b\u4fdd\u6301\u200b\u67d0\u79cd\u200b\u8d1f\u8f7d\u200b\u5747\u8861\u200b\u65f6\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u4fdd\u7559\u200b \\(b_i\\)</li> </ul> </li> <li> <p>Expert-Level Auxiliary Loss\uff0c\u200b\u867d\u7136\u200b\u4e0a\u8ff0\u200b\u65e0\u200b\u8f85\u52a9\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u653e\u200b\u53ef\u4ee5\u200b\u6709\u6548\u200b\u5747\u8861\u200b\u8d1f\u8f7d\u200b\uff0c\u200b\u4f9d\u7136\u200b\u4fdd\u7559\u200b\u4e86\u200b sequence\u200b\u7684\u200b expert-level \u200b\u635f\u5931\u200b\u51fd\u6570\u200b\uff0c\u200b\u9632\u6b62\u200b\u6837\u672c\u200bMoE\u200b\u6fc0\u6d3b\u200b\u6781\u7aef\u200b\u5931\u8861\u200b</p> <p>\u200b\u5747\u8861\u200b\u7cfb\u6570\u200b \\(\\alpha\\) \u200b\u6570\u503c\u200b\u975e\u5e38\u200b\u5c0f\u200b\uff0c\u200b\u4e0e\u200b\u6a21\u578b\u200b\u76ee\u6807\u200b\u635f\u5931\u200b\u503c\u200b\u76f8\u6bd4\u200b\u6781\u5c0f\u200b</p> \\[ \\begin{aligned}     \\mathcal{L}_\\text{SeqBal} =&amp; \\alpha \\sum_{i=1}^{N_r} f_iP_i \\\\     f_i =&amp; \\frac{N_r}{K_r T} \\sum_{t=1}^T \\mathbb{1} \\left( s_{i, t} \\in \\text{Topk}\\left( \\left\\{s_{j, t}\\vert 1 \\le j \\le N_r\\right\\}, K_r\\right)\\right)\\\\     P_i =&amp; \\frac{1}{T} \\sum_{t=1}^T g_{i, t} \\\\ \\end{aligned} \\] </li> <li> <p>Node-Limited Routing\uff0c\u200b\u7ee7\u7eed\u200b\u7ea6\u675f\u200b\u5e76\u884c\u200b\u65f6\u200b\u6700\u200b\u591a\u200b\u9009\u53d6\u200b \\(M\\) \u200b\u4e2a\u200b\u8bbe\u5907\u200b\uff08\u200b\u9009\u62e9\u200b \\(\\frac{K_r}{M}\\) Expert\u200b\u5206\u6570\u200b\u548c\u200b\u5bf9\u5e94\u200b\u7684\u200btop-M\u200b\u8bbe\u5907\u200b\uff09</p> </li> <li>No Token-Dropping\uff0c\u200b\u7531\u4e8e\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u9ad8\u6548\u200b\u7684\u200b\u8d1f\u8f7d\u200b\u5747\u8861\u200b\u7b56\u7565\u200b\u4ee5\u53ca\u200b\u63a8\u529b\u200b\u65f6\u200b\u4e13\u95e8\u200b\u7684\u200b\u90e8\u7f72\u200b\u7b56\u7565\u200b\uff0c\u200b\u4e0d\u518d\u200b\u50cf\u200bDeekSeek-2 \u200b\u4f7f\u7528\u200btoken-dropping\u200b\u65b9\u6848\u200b</li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#deepseek-mtp","title":"DeepSeek-MTP","text":"<p>MTP (Multi-Token Predictoin) \u200b\u901a\u8fc7\u200b\u65f6\u5e8f\u200b\u987a\u5e8f\u200b\u8fde\u63a5\u200b\u7684\u200b \\(n\\) \u200b\u4e2a\u200bMTP\u200b\u6a21\u5757\u200b\uff08\u200b\u5bf9\u5e94\u200b\u6df1\u5ea6\u200b\\(n\\)\uff09\u200b\u5b9e\u73b0\u200b\u4e86\u200b \u200b\u989d\u5916\u200b \u200b\u7684\u200b<code>next_n_token_prediction</code>\u200b\u5c06\u200b\u9884\u6d4b\u200b\u8303\u56f4\u200b\u6269\u5c55\u200b\u5230\u200b\u6bcf\u4e2a\u200b\u4f4d\u7f6e\u200b\u7684\u200b\u672a\u6765\u200b\u591a\u4e2a\u200btoken\uff0c\u200b\u4e3b\u8981\u200b\u90e8\u5206\u200b\u5305\u62ec\u200b\uff1a</p> <ol> <li> <p>MTP Module \u200b\u5305\u62ec\u200b\u5171\u4eab\u200bEmbedding\u200b\u5c42\u200b\u548c\u200bOutput Head\u3001\u200b\u5355\u5c42\u200bTransformer block \\(\\text{MTP}_k\\) \u200b\u4ee5\u53ca\u200b\u6295\u5f71\u200b\u77e9\u9635\u200b \\(M_k \\in \\mathbb{R}^{d\\times 2d}\\)\uff0cMTP\u200b\u6a21\u5757\u200b\u5177\u4f53\u200b\u4e3a\u200b</p> \\[ \\begin{aligned}     h{'}_t^k =&amp; M_k[\\text{RMSNorm}(h_t^{k-1}), \\text{RMSNorm}\\left(\\text{Emb}\\left(x_{t+k}\\right)\\right)] \\\\     h_{1:T-k}^k =&amp; \\text{TRM}_k(h{'}_{1:T-k}) \\\\     P^k_{t+k+1} \\in \\mathbb{R}^{\\vert V\\vert} =&amp; \\text{OutHead}(h_{t}^k) \\end{aligned} \\] <ul> <li>\\(h_t^{0}\\) \u200b\u4e3a\u200bMain Model\u200b\u7684\u200b <code>next_token_last_layer_hidden_state</code> </li> <li>\u200b\u6bcf\u4e2a\u200bMTP\u200b\u6a21\u5757\u200b\u5747\u200b\u6267\u884c\u200b<code>next_token_prediction</code></li> </ul> <p></p> <p></p> </li> <li> <p>MTP Training Objective</p> \\[ \\begin{aligned}     \\mathcal{L}_\\text{MTP}^{k} =&amp; \\text{CrossEntropy}(p^k_{2+k:T+1}, x_{2+k:T+1}) = - \\frac{1}{T} \\sum_{i=2+k}^{T+1} \\log p_i^k(x_i) \\\\     \\mathcal{L}_\\text{MTP} =&amp; \\frac{\\lambda}{n} \\sum_{k=1}^n \\mathcal{L}_\\text{MTP}^{k} \\end{aligned} \\] </li> <li> <p>MTP in Inference\uff0cMTP \u200b\u6a21\u5757\u200b\u65e8\u5728\u200b\u63d0\u5347\u200b\u4e3b\u6a21\u578b\u200b\u7684\u200b\u6027\u80fd\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5728\u200b\u63a8\u7406\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u53ef\u4ee5\u200b</p> <ul> <li>\u200b\u76f4\u63a5\u200b\u4e22\u5f03\u200b MTP \u200b\u6a21\u5757\u200b\uff0c\u200b\u4ec5\u200b\u4fdd\u6301\u200bMain Model\u200b\u72ec\u7acb\u200b\u8fd0\u884c\u200b</li> <li>\u200b\u5c06\u200b MTP \u200b\u6a21\u5757\u200b\u7ee7\u7eed\u200b\u7528\u4e8e\u200b\u63a8\u7406\u200b\u89e3\u7801\u200b\uff08\u200b\u53ef\u200b\u9009\u62e9\u200b \\(n\\) \u200b\u7684\u200b\u957f\u5ea6\u200b\uff09\uff0c\u200b\u6539\u5584\u200b\u751f\u6210\u200b\u5ef6\u8fdf\u200b</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#infrastructure_1","title":"Infrastructure","text":"<ul> <li>FP8 Training</li> <li>low-precision training</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#pre-training_2","title":"Pre-Training","text":"<ol> <li>Data Construction </li> <li>pretrained on 14.8T diverse and high-quality tokens</li> <li> <p>compared with DeepSeek-2, enhancing the ratio of mathematical and programming samples, while expanding multilingual coverage beyond English and Chinese.</p> </li> <li> <p>Tokenizer\uff1aBBPE with vocabulary of 128K tokens\uff0c\u200b\u901a\u8fc7\u200b\u4e0b\u5217\u200b\u65b9\u6cd5\u200b\u4f18\u5316\u200b\u591a\u8bed\u79cd\u200b\u538b\u7f29\u200b\u6548\u7387\u200b  </p> <ul> <li>Pre-tokenization\uff0c\u200b\u8f83\u200bDeepSeek-1\u200b\u65b0\u589e\u200b\u4e86\u200b\u6807\u70b9\u7b26\u53f7\u200b\u548c\u200b\u6362\u884c\u7b26\u200b\u5206\u8bcd\u200b\uff0c\u200b\u4e14\u200b\u4e3a\u200b\u9632\u6b62\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u8fc7\u5206\u200b\u62c6\u5206\u200b\u5bfc\u81f4\u200b\u5206\u8bcd\u200b\u8fb9\u754c\u200b\u8bef\u5dee\u200b\uff0c\u200b\u901a\u8fc7\u200b\u5728\u200b\u8bad\u7ec3\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u8bbe\u7f6e\u200b\u4e00\u5b9a\u200b\u7684\u200b\u5212\u5206\u200b\u6982\u7387\u200b\u6765\u200b\u51cf\u8f7b\u200b\u5206\u8bcd\u200b\u8bef\u5dee\u200b\uff08\u200b\u7c7b\u4f3c\u200b\u4e8e\u200bBPE-Dropout\uff09\u200b\u4ee5\u200b\u63d0\u9ad8\u200b\u6cdb\u5316\u200b\u6027\u200b\u3002</li> </ul> </li> <li> <p>Hyperparameter</p> <ul> <li>AdamW\uff1a\\(\\beta_1 = 0.9, \\beta_2 = 0.95, \\text{weight_decay}=0.1\\)</li> <li><code>max_seq_len=4K</code></li> <li><code>gradient_clip=1.0</code></li> <li>Multi-step LR Scheduler<ul> <li>~2000 steps\uff0clinearly increase warmup\u200b\u4ece\u200b0\u200b\u5347\u81f3\u200b<code>max_lr=2.2*1e-4</code></li> <li>~10T tokens\uff0c\u200b\u4fdd\u6301\u200b <code>max_lr</code></li> <li>~14.3T tokens, consine decay\u200b\u964d\u200b\u81f3\u200b <code>0.1*max_lr</code></li> <li>~14.633T tokens\uff0c\u200b\u4fdd\u6301\u200b<code>0.1*max_lr</code></li> <li>~14.8T tokens\uff0c\u200b\u4fdd\u6301\u200b<code>lr=7.3*1e-6</code></li> </ul> </li> <li>BS Scheduler\uff1a~469B tokens\uff0c\u200b\u4ece\u200b3072\u200b\u5347\u81f3\u200b15360\uff0c\u200b\u968f\u540e\u200b\u4fdd\u6301\u200b</li> <li>DeepSeekMoE\u200b\u914d\u7f6e\u200b: \\(D=8, M=4, \\alpha=0.0001\\)\uff0c\u200b\u9664\u4e86\u200b\u524d\u200b3\u200b\u5c42\u200b\uff0c\u200b\u6240\u6709\u200bFFN\u200b\u5747\u200b\u66ff\u6362\u200b\u4e3a\u200bMoE<ul> <li>~14.3T tokens \\(\\gamma=0.001\\)</li> <li>~14.8T tokens \\(\\gamma=0\\)</li> </ul> </li> <li>MTP\u200b\u914d\u7f6e\u200b\uff1a\\(n=1\\)<ul> <li>~10T tokens \\(\\lambda=0.3\\)</li> <li>~14.8T tokens \\(\\lambda=0.1\\)</li> </ul> </li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#context-window-extension_1","title":"Context Window Extension","text":"<p>\u200b\u5728\u200b\u9884\u200b\u8bad\u7ec3\u200bLLM\u200b\u540e\u200b\uff0c\u200b\u5e94\u7528\u200bYaRN\u200b\u9636\u6bb5\u6027\u200b\u4f4e\u200b\u5c06\u200b\u6587\u672c\u200b\u7a97\u53e3\u200b\u957f\u5ea6\u200b\u7531\u200b4K\u200b\u62d3\u5c55\u200b\u81f3\u200b128K\uff0c\u200b\u5b9e\u9645\u200b\u4e3a\u200b\u5bf9\u89e3\u200b\u8026\u5408\u200b\u7684\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b \\(q^{R}_t, k^{R}_t\\) \u200b\u5e94\u7528\u200bYaRN\uff0c\u200b\u5176\u4e2d\u200b  </p> <ul> <li>\\(s=40, \\alpha=1, \\beta=32\\)\uff0c\u200b\u7406\u8bba\u200b\u4e0a\u200b\u6700\u5927\u200b\u62d3\u5c55\u200b\u957f\u5ea6\u200b\u4e3a\u200b160K  </li> <li>\u200b\u957f\u5ea6\u200b\u7f29\u653e\u200b\u7cfb\u6570\u200b \\(\\sqrt{\\frac{1}{t}} = 0.1 \\ln s + 1\\) </li> <li><code>lr=7.3*1e-6</code></li> <li>stage 1\uff1a<code>train_steps=1000, seq_len=32K, batch_size=1920</code> </li> <li>stage 2\uff1a<code>train_steps=1000, seq_len=128K, batch_size=480</code> </li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/DeepSeek/deepseek.html#post-training_2","title":"Post-Training","text":"<ul> <li>SFT</li> <li>RL</li> <li> <ol> <li>R1\u200b\u4e2d\u200b\u7684\u200breward model\u200b\u548c\u200bv2\u200b\u4e2d\u200b\u7684\u200b\u4e0d\u200b\u76f8\u540c\u200b\uff0c\u200b\u5b9e\u9645\u4e0a\u200b\u662f\u200b\u4e00\u4e2a\u200brulee-based system</li> </ol> </li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html","title":"Gpt","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#gpt-1","title":"GPT-1","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#gpt-2","title":"GPT-2","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#gpt-3","title":"GPT-3","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#instructgpt","title":"InstructGPT","text":"<p>\u200b\u8bba\u6587\u200b\uff1aTraining language models to follow instructions with human feedback OpenAI, 2022 Mar, NeurIPS 2022</p>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff08human feedback\uff09\u200b\u5bf9\u9f50\u200b\uff0c\u200b\u9f13\u52b1\u200b\u663e\u793a\u200b\u610f\u56fe\u200b\u4e0e\u200b\uff08staying truthful, not being biased, toxic or harmful\u200b\u7b49\u200b\uff09\u200b\u9690\u5f0f\u200b\u610f\u56fe\u200b</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#rlhf","title":"RLHF\u200b\u6b65\u9aa4","text":"<ol> <li> <p>\u200b\u901a\u8fc7\u200b\u4f18\u8d28\u200b\u6807\u6ce8\u200b\u6570\u636e\u200b\uff08prompt + demonstration\uff09 SFT \u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b  </p> <ul> <li>screening test(such as personally identifiable information) to select prompt  </li> <li>get prompts submitted to the OpenAI API  </li> <li>some labeler-written prompts weren\u2019t often submitted to the regular GPT-3 models on the API.<ul> <li>Plain: \u200b\u6807\u6ce8\u200b\u8005\u200b\u81ea\u5df1\u200b\u968f\u610f\u200b\u60f3\u4e2a\u200b\u4efb\u52a1\u200b\uff0c\u200b\u8981\u6c42\u200b\u4fdd\u8bc1\u200b\u4efb\u52a1\u200b\u7684\u200b\u591a\u6837\u6027\u200b</li> <li>Few-shot: \u200b\u7ed9\u51fa\u200b\u4e00\u4e2a\u200b\u6307\u4ee4\u200b\uff0c\u200b\u8981\u6c42\u200b\u6807\u6ce8\u200b\u8005\u200b\u5199\u51fa\u200b\u4e00\u4e9b\u200bquery/response pair\u200b\u4f5c\u4e3a\u200bprompt</li> <li>User-based: \u200b\u57fa\u4e8e\u200bOpenAI API\u200b\u7684\u200b\u7528\u6237\u200b\u7528\u4f8b\u200b\u8bbe\u8ba1\u200b\u76f8\u5e94\u200b\u7684\u200bprompt</li> </ul> </li> <li>SFT dataset contains about 13k training prompts (from the API and labeler-written),</li> </ul> </li> <li> <p>\u200b\u6536\u96c6\u200b\u6570\u636e\u200b\uff08prompt + K demonstrations sampled by model outputs\uff09\u200b\u5e76\u200brank\uff0c\u200b\u8bad\u7ec3\u200b RM\u200b\u6a21\u578b\u200b  </p> <ul> <li>collect a dataset of human-labeled comparisons between outputs from our models on a larger set of API prompts.  </li> <li>use the output of the RM as a scalar reward</li> <li>RM dataset has 33k training prompts (from the API and labeler-written)</li> </ul> </li> <li> <p>\u200b\u57fa\u4e8e\u200b\u5f3a\u5316\u200b\u5b66\u4e60\u200b\u8fdb\u4e00\u6b65\u200b\u4f18\u5316\u200b\u5bf9\u9f50\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b</p> <ul> <li>PPO dataset has 31k training prompts (only from the API).</li> <li>A.2.1 Illustrative user prompts from InstructGPT distribution</li> </ul> </li> </ol> <p></p>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#dataset","title":"Dataset","text":"<ul> <li>We heuristically deduplicate prompts by checking for prompts that share a long common prefix, and we limit the number of prompts to 200 per user ID.</li> <li>create our train, validation, and test splits based on user ID, validation and test sets contain no data from users whose data is in the training set</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#model-details","title":"Model Details","text":"<ol> <li>SFT</li> <li> <p>Reward Model Training: train on reward model training set</p> <ul> <li>\u200b\u5bf9\u200blr\u200b\u548c\u200bschedule\u200b\u4e0d\u200b\u654f\u611f\u200b\uff1alr\u200b\u964d\u4f4e\u200b50%\u200b\u7684\u200b\u7ed3\u679c\u200b\u4e5f\u200b\u76f8\u4f3c\u200b</li> <li>\u200b\u5bf9\u200b#epoch\u200b\u654f\u611f\u200b\uff0c\u200b\u5927\u200bepoch\u200b\u5bb9\u6613\u200b\u8fc7\u200b\u62df\u5408\u200b</li> <li>\u200b\u5956\u52b1\u200b\u6a21\u578b\u200bpair-rank-loss\uff0c\u200b\u6bcf\u4e2a\u200bprompt\u200b\u6709\u200bK\u200b\u4e2a\u200bcompletions\uff0c\u200b\u6bcf\u6b21\u200b\u901a\u8fc7\u200b\u4e24\u200b\u4e24\u200b\u5bf9\u6bd4\u200b\u5b66\u4e60\u200b\u6765\u200b\u8fdb\u884c\u200b\u6bd4\u8f83\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u56e0\u6b64\u200b\u6709\u200b\\(C(K, 2)\\)\u200b\u4e2a\u200b\u7ec4\u5408\u200b\u6570\u200b</li> <li>bs = M * C(K, 2)</li> </ul> </li> <li> <p>initialization models for RLHF</p> </li> <li>RLHF Training</li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#prompt-data-details","title":"Prompt Data Details","text":"<ol> <li>API used prompts</li> <li>Dataset sizes</li> <li>Data diversity</li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#human-data-collection-details","title":"Human Data Collection Details","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#gpt-35","title":"GPT-3.5","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#chatgpt","title":"ChatGPT","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#gpt-4","title":"GPT-4","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#gpt-4-turbo","title":"GPT-4 Turbo","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#gpt-4o","title":"GPT-4o","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#openai-o1","title":"OpenAI o1","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#gpt-45","title":"GPT-4.5","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#openai-o3","title":"OpenAI o3","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/GPT/gpt.html#openai-o4","title":"OpenAI O4","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/LLaMA/llama.html","title":"Llama","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/LLaMA/llama.html#_1","title":"\u6458\u8981","text":"<ol> <li>\u200b\u53c2\u6570\u200b405B\uff0c\u200b\u6700\u957f\u200b\u652f\u6301\u200b128K context window\uff0cdense(vanilla) rather than MoE transformer</li> <li>\u200b\u591a\u8bed\u79cd\u200b\u3001\u200b\u4ee3\u7801\u200b\u3001\u200b\u63a8\u7406\u200b\u80fd\u529b\u200b\u5168\u9762\u200b\u589e\u5f3a\u200b\uff0ccomparable with GPT-4</li> <li>\uff08\u200b\u4fdd\u8bc1\u200b\u81ea\u7136\u8bed\u8a00\u200b\u80fd\u529b\u200b\u524d\u63d0\u200b\u4e0b\u200b\uff09\u200b\u589e\u91cf\u200b\u63d0\u5347\u200b\u8bed\u97f3\u200b\uff0c\u200b\u89c6\u9891\u200b\u4ee5\u53ca\u200b\u56fe\u50cf\u200b\u7b49\u200b\u6a21\u6001\u200b\u5904\u7406\u200b\u529f\u80fd\u200b</li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/LLaMA/llama.html#_2","title":"\u9884\u200b\u8bad\u7ec3\u200b\u6570\u636e","text":"<p>\u200b\u6570\u636e\u91cf\u200b\u89c4\u6a21\u200b\u66f4\u5927\u200b\uff0c\u200b\u8d28\u91cf\u200b\u66f4\u9ad8\u200b\uff0c\u200b\u6700\u7ec8\u200b\u83b7\u5f97\u200b15T \u200b\u622a\u81f3\u200b\u65e5\u671f\u200b\u4e3a\u200b2023\u200b\u5e74\u5e95\u200b\u7684\u200b\u591a\u8bed\u79cd\u200btokens, \u200b\u4e0e\u200b\u4e4b\u200b\u5bf9\u5e94\u200b\u7684\u200bllama 2\u200b\u5219\u200b\u4f7f\u7528\u200b\u4e86\u200b1.8T tokens</p> <ol> <li> <p>\u200b\u6570\u636e\u200b\u6765\u6e90\u200b  </p> <ul> <li>\u200b\u6570\u636e\u6e90\u200b\u7248\u6743\u200b\u4e0d\u4fbf\u200b\u5c55\u5f00\u200b\u7ec6\u8bf4\u200b\uff0c\u200b\u5982\u200bcommon crawl\u3001\u200b\u7f51\u7edc\u200b\u56fe\u4e66\u200b\u3001github code\u3001youtube\u200b\u5b57\u5e55\u200b\u7b49\u200b</li> </ul> </li> <li> <p>\u200b\u6570\u636e\u200b\u6e05\u6d17\u200b  </p> <ul> <li>\u200b\u8fc7\u6ee4\u200b\u5305\u542b\u200b\u5927\u91cf\u200b\u4e2a\u4eba\u9690\u79c1\u200b\u4fe1\u606f\u200b\u4ee5\u53ca\u200b\u6210\u4eba\u200b\u5185\u5bb9\u200b\u6570\u636e\u200b</li> <li>\u200b\u53bb\u9664\u200b\u7f51\u9875\u200b\u5e7f\u544a\u200b\u3001html tags\uff08\u200b\u4fdd\u7559\u200bcode\u200b\u4ee5\u53ca\u200b\u63a8\u7406\u200b\u5185\u5bb9\u200b\u7b49\u200b\u590d\u6742\u200btags\uff09</li> <li>\u200b\u53bb\u200b\u91cd\u200b<ul> <li>url-level\uff1a\u200b\u4fdd\u7559\u200b\u5404\u200burl\u200b\u7684\u200b\u6700\u65b0\u7248\u200b\u7f51\u9875\u200b\u6570\u636e\u200b</li> <li>document-level\uff1aMinHash de-duplication</li> <li>line-level\uff1ain 30M lines\uff0c#freq &gt; 6 \\(\\rightarrow\\) remove\u3002\u200b\u5927\u591a\u200b\u4e3a\u200b\u5bfc\u822a\u200b\u83dc\u5355\u200b\u3001cookie\u200b\u7b49\u200b\u6587\u672c\u200b\uff0c\u200b\u53bb\u9664\u200b\u540e\u80fd\u200b\u6709\u6548\u200b\u63d0\u5347\u200b\u9884\u6599\u200b\u8d28\u91cf\u200b</li> </ul> </li> <li>heuristic filtering<ul> <li>n-gram coverage ratio &gt; p \\(\\rightarrow\\) remove\u3002\u200b\u5927\u591a\u200b\u4e3a\u200b\u65e0\u200b\u610f\u4e49\u200b\u6570\u636e\u200b\uff0c\u200b\u5982\u200b\u65e5\u5fd7\u200b\u6216\u200b\u62a5\u9519\u200b\u6570\u636e\u200b\uff08\u200b\u65e5\u5fd7\u200b\u6570\u636e\u200b\u901a\u5e38\u200b\u552f\u4e00\u200b\uff0c\u200b\u65e0\u6cd5\u200b\u901a\u8fc7\u200b\u7b80\u5355\u200buniq\u200b\u53bb\u200b\u91cd\u200b\uff09</li> <li>dirty word count\uff0c\u200b\u9ed1\u540d\u5355\u200b\u5173\u952e\u8bcd\u200b\u8fc7\u6ee4\u200b</li> <li>\u200b\u6bd4\u8f83\u200b\u722c\u53d6\u200b\u8bed\u6599\u200b\u548c\u200b\u65e2\u6709\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u96c6\u200bKL\u200b\u6563\u5ea6\u200b\uff0c\u200b\u6570\u503c\u200b\u8d85\u8fc7\u200b\u4e00\u5b9a\u200b\u8303\u56f4\u200b\u7684\u200b\u89c6\u4e3a\u200b\u4e88\u4ee5\u200b\u5220\u9664\u200b</li> </ul> </li> <li>model-based filtering<ul> <li>fasttext, RoBERTa\u200b\u53bb\u9664\u200b\u4f4e\u8d28\u91cf\u200b\u5185\u5bb9\u200b</li> </ul> </li> </ul> </li> <li> <p>\u200b\u786e\u5b9a\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b     \u200b\u5c3d\u53ef\u80fd\u200b\u5730\u200b\u4f7f\u7528\u200b\u9ad8\u8d28\u91cf\u200b\u7684\u200b\u6570\u636e\u200b\u53c2\u4e0e\u200b\u8bad\u7ec3\u200b</p> <ul> <li>\u200b\u77e5\u8bc6\u200b\u5206\u7c7b\u200b\uff1a\u200b\u5c06\u200b\u8bed\u6599\u200b\u8fdb\u884c\u200b\u5206\u7c7b\u200b\uff0c\u200b\u5e76\u200b\u5bf9\u6a21\u578b\u200b\u6548\u679c\u200b\u8d21\u732e\u200b\u4e0d\u5927\u200b\u7684\u200b\u7c7b\u522b\u200b\uff08\u200b\u5bf9\u200b\u827a\u672f\u200b\u548c\u200b\u5a31\u4e50\u200b\u677f\u5757\u200b\u9884\u6599\u200b\uff09\u200b\u8fdb\u884c\u200b\u8f83\u5c11\u200b\u7684\u200b\u91c7\u6837\u200b</li> <li>data mix\uff1a~50%\u200b\u901a\u7528\u200b\u6570\u636e\u200b\uff0c25%\u200b\u6570\u5b66\u200b\u548c\u200b\u63a8\u7406\u200b\u6570\u636e\u200b\uff0c17%\u200b\u4ee3\u7801\u200b\u6570\u636e\u200b\uff0c8%\u200b\u591a\u8bed\u79cd\u200b\u6570\u636e\u200b</li> </ul> </li> <li> <p>annealing data     \u200b\u6a21\u578b\u200b\u9884\u200b\u8bad\u7ec3\u200b\u672b\u671f\u200b\uff08\u200b\u975e\u200bSFT\uff09\uff0c\u200b\u4f7f\u7528\u200b\u5c11\u91cf\u200b\u4f46\u200b\u8d28\u91cf\u200b\u7279\u522b\u200b\u9ad8\u200b\u7684\u200b\u6570\u636e\u200b\u8fdb\u884c\u200b\u6536\u5c3e\u200b\uff08\u200b\u5982\u200b\u9ad8\u8d28\u91cf\u200b\u7684\u200bcode\u200b\u548c\u200b\u6570\u5b66\u200b\u6570\u636e\u200b\uff09</p> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/LLaMA/llama.html#_3","title":"\u9884\u200b\u8bad\u7ec3","text":"<ol> <li>\u200b\u6a21\u578b\u200b\u7ed3\u6784\u200b  <ul> <li>llama 3.1\uff0c16k H100 (405B), compared to llama 2 using A100</li> <li>GQA(grouped query attention) with 8 key-value heads</li> <li>\u200b\u540c\u4e00\u4e2a\u200bsequence\u200b\u4e2d\u200b\uff0c\u200b\u9694\u7edd\u200b\u4e0d\u540c\u200b\u6587\u6863\u200b\u95f4\u200b\u7684\u200b\u6570\u636e\u200battention\uff08\u200b\u5bf9\u6a21\u578b\u200b\u6548\u679c\u200b\u63d0\u5347\u200b\u4e0d\u200b\u5927\u200b\uff0c\u200b\u4f46\u662f\u200b\u5bf9\u200b\u8bad\u7ec3\u200b\u8d85\u957f\u200bcontext window\u200b\u5f71\u54cd\u200b\u8f83\u5927\u200b\uff09</li> <li>vocabulary with 128k tokens\uff0c100k from tiktoken and 28k additional non-English tokens</li> <li>BPE \\(\\rightarrow\\) tiktoken\uff08BPE\u200b\u7684\u200b\u9ad8\u6548\u200b\u4f18\u5316\u200b\u5b9e\u73b0\u200b\uff09\uff0c\u200b\u540e\u8005\u200b\u5177\u6709\u200b\u66f4\u597d\u200b\u7684\u200b\u538b\u7f29\u6bd4\u200b3.17 char per token \\(\\rightarrow\\) 3.94 char per token</li> <li>\u200b\u6a21\u578b\u200b\u6548\u679c\u200b\u63d0\u5347\u200b\u4e3b\u8981\u200b\u8fd8\u662f\u200b\u6570\u636e\u200b\u8d28\u91cf\u200b\u3001\u200b\u591a\u6837\u6027\u200b\u548c\u200b\u89c4\u6a21\u200b\u5bfc\u81f4\u200b\u7684\u200b  <p>llama 3\u200b\u6a21\u578b\u200b\u4e3b\u8981\u200b\u8d85\u53c2\u200b</p> </li> </ul> </li> <li>pre-training<ul> <li>next token predication\uff0c\u200b\u529b\u5927\u7816\u200b\u98de\u200b</li> <li>\u200b\u5927\u529b\u200b\u51fa\u200b\u5947\u8ff9\u200b\u4e14\u200b\u7b80\u5355\u200b\uff1asft + RS(reject sampling) + DPO\uff0c\u200b\u6548\u679c\u200b\u63d0\u5347\u200b\u4e3b\u8981\u200b\u8fd8\u662f\u200b\u6570\u636e\u200b\u8d28\u91cf\u200b\u9ad8\u200b\u548c\u200b\u591a\u6837\u6027\u200b</li> <li>70b is comparable better</li> </ul> </li> <li>scaling law     \u200b\u5355\u7eaf\u200b\u7684\u200b\u589e\u5927\u200b\u6a21\u578b\u200b\u89c4\u6a21\u200b\u6216\u200b\u589e\u52a0\u200b\u8bad\u7ec3\u6837\u672c\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u5bfc\u81f4\u200bundertrained\uff0c\u200b\u5bfc\u81f4\u200b\u7b97\u529b\u200b\u6216\u200b\u8bed\u6599\u5e93\u200b\u672a\u200b\u5145\u5206\u5229\u7528\u200b<ul> <li>\u200b\u9884\u6d4b\u200b\u6700\u4f73\u200b\u6a21\u578b\u200b\u89c4\u6a21\u200b\uff1a\u200b\u7edf\u8ba1\u200b\u5404\u79cd\u200b\u7b97\u529b\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u6a21\u578b\u200b\u5728\u200b\u4e0d\u540c\u200b\u89c4\u6a21\u200b\u6570\u636e\u200b\u96c6\u4e0b\u200b\u9884\u200b\u8bad\u7ec3\u200b\u540e\u200b\uff0c\u200b\u5728\u200b\u4e0b\u6e38\u200b\u4efb\u52a1\u200bbenchmark validation set\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u7684\u200b\u76f8\u5173\u6027\u200b\uff08\u200b\u4e4b\u524d\u200b\u4ec5\u200b\u57fa\u4e8e\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200bnext token predication loss\u200b\u9884\u6d4b\u200b\u7684\u200b\u65b9\u6cd5\u200b\u592a\u200b\u8fc7\u4e8e\u200b\u7c97\u7cd9\u200b\u4e86\u200b\uff0c\u200b\u566a\u58f0\u200b\u8f83\u5927\u200b\u4e14\u200b\u51c6\u786e\u6027\u200b\u8f83\u200b\u4f4e\u200b\uff09</li> <li>assume \\(\\#tokens=AC^\\alpha\\)\uff0cA\u200b\u4e3a\u200b\u6807\u91cf\u200b\uff0cC\u200b\u8868\u793a\u200b\u7b97\u529b\u200b\u652f\u6301\u200b  <p>llama 3 scale law. (fixed  compute=#tokens*model_size, #tokens \\(\\uparrow\\)\uff0cmodel_size \\(\\downarrow\\))</p> </li> <li>\u200b\u9884\u6d4b\u200b\u6700\u4f73\u200b\u6a21\u578b\u200b\u89c4\u6a21\u200b\u4e0b\u200b\u6548\u679c\u200b\uff1a\u200b\u901a\u8fc7\u200b\uff08\u200b\u6700\u4f73\u200b\u6a21\u578b\u200b\u89c4\u6a21\u200b\uff09\u200b\u5c0f\u200b\u6a21\u578b\u200b\u548c\u200b\u65e2\u6709\u200b\u7684\u200bllama2\u200b\u6a21\u578b\u200b\u5728\u200bARC benchmark\u200b\u4e0a\u200b\u6548\u679c\u200b\uff0c\u200b\u9884\u6d4b\u200b\u76f8\u5e94\u200b\u89c4\u6a21\u200b\u4e0b\u200bllama 3\u200b\u7684\u200b\u6548\u679c\u200b  </li> </ul> </li> <li> <p>large scale pre-training strategy</p> <ul> <li>Parallelism\uff1aPP(pipeline parallelism), TP(tenspr parallelism), DP(data parallelism), CP(context parallelism)</li> </ul> </li> <li> <p>pre-training recipe     \u200b\u9884\u200b\u8bad\u7ec3\u200b\u5206\u4e3a\u200b\u4e09\u4e2a\u200b\u4e3b\u8981\u200b\u6b65\u9aa4\u200b\uff0c\u200b\u5373\u200b</p> <ul> <li>initial pre-training<ul> <li>(0, 252M] tokens, seq_len=4k, batch_size=4M/seq_len</li> <li>(252M, 2.87T] tokens, seq_len=8k, batch_size=8M/seq_len</li> <li>after 2.87T tokens, seq_len=8k, batch_size=16M/seq_len</li> </ul> </li> <li>long-context (128k) pre-training<ul> <li>final stage of pre-training, 0.8T tokens(0.8/15=5.33%\u200b\u5360\u200b\u6bd4\u200b) for long-context pre-training</li> <li>6\u200b\u4e2a\u200bstep\u200b\u9010\u6b21\u200b\u589e\u52a0\u200bseq_len\uff0c\u200b\u76f4\u5230\u200b\u6a21\u578b\u200b\u80fd\u591f\u200b\u9002\u5e94\u200b\u589e\u957f\u200b\u540e\u200b\u7684\u200bseq_len\uff081. \u200b\u77ed\u6587\u200b\u672c\u200b\u4efb\u52a1\u200b\u6548\u679c\u200b\u4fdd\u6301\u200b\u4e0d\u53d8\u200b\uff1b2. \u200b\u5728\u200b\u5f53\u524d\u200bcontext window\u200b\u5f88\u200b\u597d\u5730\u89e3\u51b3\u200b\u5927\u6d77\u635e\u9488\u200b\u95ee\u9898\u200b\uff09</li> </ul> </li> <li>annealing<ul> <li>\u200b\u8bad\u7ec3\u200b\u672b\u671f\u200b\u901a\u8fc7\u200b\u8d85\u9ad8\u200b\u8d28\u91cf\u200b\u6570\u636e\u200b40M tokens\uff08lr decay\u21920\uff0cseq_len=128k\uff09\u200b\u6765\u200b\u6536\u5c3e\u200b\u6a21\u578b\u200b\uff0coutput=avg(multi finals checkpoints)</li> </ul> </li> </ul> </li> </ol> <ul> <li>Guard 3\u200b\u53ef\u4ee5\u200b\u591a\u200bprompt\u200b\u7684\u200b\u8f93\u5165\u8f93\u51fa\u200b\u8fdb\u884c\u200b\u4e00\u4e9b\u200b\u5b89\u5168\u200b\u4e0a\u200b\u7684\u200b\u6539\u5199\u200b preference data</li> <li>\u200b\u4f7f\u7528\u200b\u591a\u4e2a\u200b\u6a21\u578b\u200b\u5bf9\u200b\u7ed9\u5b9a\u200bprompt\u200b\u8fdb\u884c\u200b\u751f\u6210\u200b\uff0c\u200b\u5e76\u200b\u91c7\u6837\u200b\u4e24\u6761\u200b\u6837\u672c\u200b\uff08\u200b\u7531\u200b\u4e0d\u540c\u200b\u6a21\u578b\u200b\u751f\u6210\u200b\uff09</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/MASS/mass.html","title":"Mass","text":""},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/MASS/mass.html#mass","title":"MASS","text":"<p>\u200b\u8bba\u6587\u200b\uff1aMASS: MAsked Sequence to Sequence pre-training for language generation Nanjing University of Science and Technology &amp; MSR, ICML 2019</p>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/MASS/mass.html#_1","title":"\u5de5\u4f5c\u200b\u4eae\u70b9","text":"<ul> <li>encoder + decoder</li> <li>encoder input: \\(x^{\\backslash u:v}\\)</li> <li>decoder predict: \\(x^{u:v}\\)</li> <li>hpyerparameter \\(k=v-u+1\\)\uff0c\u200b\u5176\u4e2d\u200b\\(k=0.5*m\\)\u200b\u6548\u679c\u200b\u76f8\u5bf9\u200b\u6700\u597d\u200b\uff0c\u200b\u592a\u5927\u200b\u6216\u200b\u5927\u5c0f\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u66f4\u200b\u504f\u5411\u200bNLG\u200b\u548c\u200bNLU</li> <li>\u200b\u8fde\u7eed\u200bmask\u200b\u6548\u679c\u200b\u6bd4\u200b\u79bb\u6563\u200bmask\u200b\u6548\u679c\u200b\u66f4\u597d\u200b\uff0cmass\u200b\u5728\u200bdecoder\u200b\u53ea\u200b\u8f93\u5165\u200b\u5f85\u200b\u9884\u6d4b\u200b\u7684\u200b\u90e8\u5206\u200b\u6bd4\u200b\u5168\u90e8\u200b\u8f93\u5165\u200b\u6548\u679c\u200b\u66f4\u597d\u200b</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/Infrastructure/Qwen/Qwen.html","title":"Qwen","text":"<ul> <li>https://qwenlm.github.io/blog/</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html","title":"Index","text":"<ul> <li>Lucene\u200b\u641c\u7d22\u5f15\u64ce\u200b</li> <li>FAISS: Facebook AI Similarity Search</li> <li>Anserini IR toolkit</li> <li>Anserini\uff0cElasticsearch</li> <li>Pyserini</li> </ul> <p> 1. \u200b\u9996\u5148\u200b\u9700\u8981\u200b\u7ed9\u200b\u77e5\u8bc6\u5e93\u200b\u6dfb\u52a0\u200b\u6570\u636e\u200b\uff1a\u200b\u6bd4\u5982\u200b\u5bfc\u5165\u200b\u6587\u6863\u200b\uff0c\u200b\u6216\u8005\u200b\u67d0\u4e2a\u200b\u7f51\u9875\u200b\u94fe\u63a5\u200b 2. \u200b\u7136\u540e\u200b\u77e5\u8bc6\u5e93\u200b\u4f1a\u200b\u5bf9\u200b\u5bfc\u5165\u200b\u7684\u200b\u6587\u6863\u200b\u6216\u8005\u200b\u7f51\u9875\u5185\u5bb9\u200b\u8fdb\u884c\u200b\u5206\u6bb5\u200b 3. \u200b\u7136\u540e\u200b\u518d\u200b\u5229\u7528\u200bEmbedding\u200b\u5d4c\u5165\u200b\u6280\u672f\u200b\u628a\u200b\u6bcf\u6bb5\u200b\u6570\u636e\u200b\u5411\u200b\u91cf\u5316\u200b\uff0c\u200b\u4fdd\u5b58\u200b\u5230\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b 4. \u200b\u5f53\u200b\u7528\u6237\u200b\u63d0\u51fa\u200b\u95ee\u9898\u200b\uff0c\u200b\u5927\u200b\u6a21\u578b\u200b\u5148\u5bf9\u200b\u95ee\u9898\u200b\u5411\u200b\u91cf\u5316\u200b\uff0c\u200b\u7136\u540e\u200b\u6839\u636e\u200b\u8bed\u4e49\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\uff0c\u200b\u5230\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u4e2d\u200b\u53bb\u200b\u5339\u914d\u200b\uff08\u200b\u68c0\u7d22\u200b\uff09</p> <p>\u200b\u5339\u914d\u200b\u5230\u200b\u6570\u636e\u200b\u540e\u200b\uff0c\u200b\u4f1a\u200b\u5bf9\u200b\u7ed3\u679c\u200b\u8fdb\u884c\u200b\u91cd\u200b\u6392\u5e8f\u200b\uff1a\u200b\u6839\u636e\u200b\u5173\u8054\u5ea6\u200b\u5bf9\u200b\u68c0\u7d22\u200b\u7ed3\u679c\u200b\u8bc4\u5206\u200b\uff0c\u200b\u5173\u8054\u5ea6\u200b\u9ad8\u200b\u7684\u200b\u8bc4\u5206\u200b\u9ad8\u200b\uff0c\u200b\u7136\u540e\u200b\u6839\u636e\u200b\u8bc4\u5206\u200b\u8fdb\u884c\u200b\u91cd\u200b\u6392\u5e8f\u200b\uff0c\u200b\u5206\u6570\u200b\u6700\u9ad8\u200b\u7684\u200b\u653e\u5728\u200b\u6700\u200b\u524d\u9762\u200b\uff0c\u200b\u5206\u6570\u200b\u4f4e\u200b\u7684\u200b\u653e\u5728\u200b\u540e\u9762\u200b\u3002\u200b\u7136\u540e\u200b\u628a\u200b\u91cd\u200b\u6392\u5e8f\u200b\u7ed3\u679c\u200b\uff0c\u200b\u4f5c\u4e3a\u200b\u4e0a\u4e0b\u6587\u200b\u4f20\u9012\u200b\u7ed9\u200b\u2f24\u200b\u6a21\u578b\u200b\uff08\u200b\u589e\u5f3a\u200b\uff09\u3002\u200b\u6700\u540e\u200b\u5927\u200b\u6a21\u578b\u200b\u7ed3\u5408\u200b\u7528\u6237\u200b\u95ee\u9898\u200b\u548c\u200b\u4e0a\u4e0b\u200b\u2f42\u200b\u77e5\u8bc6\u200b\uff0c\u200b\u751f\u6210\u200b\u6700\u7ec8\u200b\u7b54\u6848\u200b</p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#basic-retrieval","title":"Basic Retrieval","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#_1","title":"\u76f8\u4f3c\u200b\u5ea6\u200b\u8861\u91cf","text":"<ol> <li>Exact Match\uff1a\u200b\u4e3b\u8981\u200b\u57fa\u4e8e\u200b\u8bcd\u6c47\u200b\u7edf\u8ba1\u200b\u7684\u200b BM25 \u200b\u8861\u91cf\u200b  \u200b\u76f8\u5173\u6027\u200b\uff0c\u200b\u57fa\u4e8e\u200b\u5173\u952e\u8bcd\u200b\u8fdb\u884c\u200b\u5339\u914d\u200b</li> <li>Semantic Match\uff1a\u200b\u4e3b\u8981\u200b\u57fa\u4e8e\u200b\u5411\u91cf\u200b\u8868\u793a\u200b\u7684\u200b L2 distance, MSE\u200b\u6216\u200bconsine similarity\u200b\u8861\u91cf\u200b\u76f8\u5173\u6027\u200b\uff0c\u200b\u57fa\u4e8e\u200b\u8bed\u4e49\u200b\u76f8\u5173\u200b\u8fdb\u884c\u200b\u5339\u914d\u200b</li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#_2","title":"\u635f\u5931\u200b\u51fd\u6570","text":"<ol> <li>\u200b\u5bf9\u6bd4\u200b\u5b66\u4e60\u200bInfoNCE\uff1a\u200b\u76ee\u6807\u200b\u4e3a\u200b\u68c0\u7d22\u200b\u51fa\u200b\u6700\u200b\u76f8\u5173\u200b\u7684\u200b\uff0c\u200b\u56e0\u6b64\u200b\u901a\u8fc7\u200b\u5bf9\u6bd4\u200b\u5b66\u4e60\u200b\u601d\u60f3\u200b\u83b7\u53d6\u200b\u76f8\u5bf9\u200b\u9009\u62e9\u200b\u503e\u5411\u200b</li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#retrieval-augmentation","title":"Retrieval Augmentation","text":"<p>\u200b\u4e2d\u5fc3\u601d\u60f3\u200b\u4e3a\u200b\u901a\u8fc7\u200b\u5404\u79cd\u200b\u624b\u6bb5\u200b\u63d0\u5347\u200b\u95ee\u9898\u200b\u67e5\u8be2\u200b\u4e0e\u200b\u76ee\u6807\u200b\u6587\u6863\u200b\u7684\u200b\u5173\u952e\u8bcd\u200b\u76f8\u5173\u6027\u200b\u548c\u200b\u8bed\u4e49\u200b\u76f8\u5173\u6027\u200b</p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#query-expansion","title":"Query expansion","text":"<p>\u200b\u5bf9\u200b\u8f93\u5165\u200b\u7684\u200b\u95ee\u9898\u200b\u67e5\u8be2\u200b\u8fdb\u884c\u200b\u62d3\u5c55\u200b</p> <ol> <li> <p>\u200b\u57fa\u4e8e\u200b\u7edf\u8ba1\u200b\u7ed3\u679c\u200b\u6700\u5927\u200b\u4f3c\u7136\u200b\u7684\u200b PRF\uff08Pseudo-Relevance Feedback\uff09\u200b\u4f2a\u200b\u76f8\u5173\u200b\u53cd\u9988\u200b\u62d3\u5c55\u200b</p> <ul> <li>RM\uff08Relevance Model\uff09v1~v4</li> </ul> </li> <li> <p>\u200b\u57fa\u4e8e\u200b\u8bed\u4e49\u200b\u7684\u200b\u8bcd\u200b\u7ea7\u522b\u200b\u7a00\u758f\u200b\u62d3\u5c55\u200b</p> <ul> <li>SLPADE\uff0c\u200b\u6b64\u5916\u200b\u8fd8\u200b\u4fdd\u7559\u200b\u4e86\u200bSparse Term Interaction</li> </ul> </li> <li> <p>\u200b\u4f7f\u7528\u200b\u6a21\u578b\u200b\u751f\u6210\u200b\u62d3\u5c55\u200b     </p> <p></p> <ul> <li>query2doc</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#document-expansion","title":"Document Expansion","text":"<p>\u200b\u5bf9\u200b\u88ab\u200b\u68c0\u7d22\u200b\u7684\u200b\u6587\u6863\u200b\u8fdb\u884c\u200b\u5185\u5bb9\u200b\u62d3\u5c55\u200b</p> <ol> <li>\u200b\u4f7f\u7528\u200b\u6a21\u578b\u200b\u751f\u6210\u200b<ul> <li>doc2query\u3001docT5query</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#sparse-term-interaction","title":"Sparse Term Interaction","text":"<p>\u200b\u7a00\u758f\u200b\u8bcd\u200b\u7ea7\u522b\u200b\u76f8\u5173\u6027\u200b\u4ea4\u4e92\u200b</p> <ol> <li>\u200b\u8bcd\u9879\u200b\u52a8\u6001\u200b\u52a0\u6743\u200b  <ul> <li>DeepCT</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#dense-representation-interaction","title":"Dense Representation Interaction","text":"<p>\u200b\u8fde\u7eed\u200b\u8bed\u4e49\u200b\uff08\u200b\u4e00\u822c\u200b\u4f1a\u200b\u6295\u5f71\u200b\u81f3\u200b\u8f83\u200b\u5c0f\u200b\u7ef4\u5ea6\u200b\u8868\u793a\u200b\uff09\u200b\u7ea7\u522b\u200b\u76f8\u5173\u6027\u200b\u4ea4\u4e92\u200b</p> <ol> <li>\u200b\u591a\u6d41\u200b\u8bed\u4e49\u200b\u8868\u793a\u200b\u540e\u200b\u4ea4\u4e92\u200b<ul> <li>ColBERT</li> <li>COIL</li> <li>PROMPTAGATOR</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#infonce","title":"InfoNCE\u200b\u4f18\u5316","text":"<ol> <li> <p>\u200b\u589e\u52a0\u200b\u8d1f\u200b\u6837\u672c\u200b</p> <ul> <li>in batch negatives\uff0c\u200b\u540c\u200bbatch\u200b\u5185\u8d1f\u200b\u6837\u672c\u200b  </li> <li>hard negative\uff0c\u200b\u589e\u52a0\u200b\u9ad8\u5206\u200b\u96be\u200b\u533a\u5206\u200b\u8d1f\u200b\u6837\u672c\u200b\uff08\u200b\u5982\u9ad8\u200bBM25\u200b\u8d1f\u200b\u6837\u672c\u200b\u3001\u200b\u76f8\u5173\u200b\u6a21\u578b\u200b\u9ad8\u5206\u200b\u8d1f\u200b\u6837\u672c\u200b\uff09  </li> </ul> </li> <li> <p>\u200b\u8d1f\u200b\u6837\u672c\u200b\u53bb\u200b\u566a\u200b</p> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#_3","title":"\u6570\u636e\u5e93\u200b\u5411\u91cf\u200b\u53bb\u200b\u91cd","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#minhash","title":"MinHash","text":"<p>MinHash \u200b\u662f\u200b\u4e00\u79cd\u200b\u7528\u4e8e\u200b\u68c0\u6d4b\u200b\u8fd1\u200b\u91cd\u590d\u200b\u6587\u672c\u200b\u7684\u200bLSH\u200b\u6280\u672f\u200b\uff0c\u200b\u6838\u5fc3\u200b\u76ee\u6807\u200b\u4e3a\u200b\u9ad8\u6548\u200b\u4f30\u8ba1\u200b\\(J(A, B)\\)\uff0c\u200b\u5177\u4f53\u200b\u5b9e\u73b0\u200b\u5982\u4e0b\u200b\uff1a</p> <ul> <li> <p>\u200b\u76f4\u89c9\u200b\u9009\u53d6\u200b\u7684\u200b\u539f\u7406\u200b</p> </li> <li> <p>\u200b\u7279\u5f81\u63d0\u53d6\u200b\uff1a\u200b\u5c06\u200b\u6587\u6863\u200b\u8868\u793a\u200b\u4e3a\u200b\u8bcd\u53bb\u200b\u91cd\u200b\uff08\u200b\u6216\u975e\u200b\u53bb\u200b\u91cd\u200b\uff09\u200b\u96c6\u5408\u200b\uff08\u200b\u5982\u200bn-gram\uff09</p> </li> <li>\u200b\u6784\u5efa\u200b\u54c8\u5e0c\u200b\u51fd\u6570\u200b\u65cf\u200b\uff1a\u200b\u8bbe\u8ba1\u200b \\(n\\) \u200b\u4e2a\u200b\u72ec\u7acb\u200b\u7684\u200b\u54c8\u5e0c\u200b\u51fd\u6570\u200b \\(h_1, h_2, \\dots, h_n\\)</li> <li> <p>\u200b\u751f\u6210\u200bMinHash\u200b\u7b7e\u540d\u200b\uff1a\u200b\u5bf9\u4e8e\u200b \u200b\u6bcf\u4e2a\u200b\u96c6\u5408\u200bA \uff0c\u200b\u8ba1\u7b97\u200b\u5176\u200bMinHash\u200b\u5411\u91cf\u200b \\(s^A = [s_1, s_2, \\dots, s_n]\\)\uff0c\u200b\u5176\u4e2d\u200b \\(s^A_i = \\min_{x \\in A} h_i(x)\\) \uff0c\u200b\u5176\u4e2d\u200b\\(x \\in A\\) \u200b\u8868\u793a\u200b\u53ea\u200b\u8003\u8651\u200b\u96c6\u5408\u200bA\u200b\u5305\u542b\u200b\u7684\u200b\u7279\u5f81\u200b</p> <p>\u200b\u76f4\u89c9\u200b\uff1a\u200b\u4fdd\u7559\u200b\u6700\u5c0f\u200b\u54c8\u5e0c\u200b\u503c\u200b\uff0c\u200b\u5bf9\u5e94\u200b\u96c6\u5408\u200b\u8be5\u200b\u54c8\u5e0c\u200b\u503c\u200b\u76f8\u540c\u200b\u7684\u200b\u6982\u7387\u200b\u7b49\u4e8e\u200bJaccard Similarity</p> </li> <li> <p>\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\u4f30\u8ba1\u200b\uff1a\\(\\hat{J}(A, B) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{I}(s^A_i = s^B_i)\\)</p> </li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#simhash","title":"SimHash","text":"<p>SimHash \u200b\u662f\u200b\u4e00\u79cd\u200b\u7528\u4e8e\u200b\u68c0\u6d4b\u200b\u8fd1\u200b\u91cd\u590d\u200b\u6587\u672c\u200b\u7684\u200bLSH\u200b\u6280\u672f\u200b\uff0c\u200b\u7531\u200b Google \u200b\u63d0\u51fa\u200b\uff0c\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\u5c06\u200b\u9ad8\u7ef4\u200b\u5411\u91cf\u200b\u6620\u5c04\u200b\u5230\u200b\u4f4e\u7ef4\u4e8c\u503c\u200b\u54c8\u5e0c\u200b\u7801\u200b\uff0c\u200b\u4fdd\u6301\u200b\u76f8\u4f3c\u200b\u5411\u91cf\u200b\u7684\u200b\u54c8\u5e0c\u200b\u7801\u200b\u6c49\u660e\u200b\u8ddd\u79bb\u200b\u5c0f\u200b\uff0c\u200b\u5177\u4f53\u200b\u5b9e\u73b0\u200b\u5982\u4e0b\u200b\uff1a</p> SimHash\u200b\u8ba1\u7b97\u200b\u793a\u610f\u56fe\u200b <ol> <li>\u200b\u7279\u5f81\u63d0\u53d6\u200b\uff1a\u200b\u5c06\u200b\u6587\u6863\u200b\u8868\u793a\u200b\u4e3a\u200b\u8bcd\u200b\u5e8f\u5217\u200b</li> <li>\u200b\u6743\u91cd\u200b\u5206\u914d\u200b\uff1a\u200b\u5bf9\u200b\u6bcf\u4e2a\u200b\u7279\u5f81\u200b\uff08\u200b\u8bcd\u200b\uff09\u200b\u5206\u914d\u200b\u6743\u91cd\u200b\uff0c\u200b\u5982\u200bTF-IDF</li> <li>\u200b\u751f\u6210\u200b\u54c8\u5e0c\u200b\u503c\u200b\uff1a\u200b\u5bf9\u200b\u6bcf\u4e2a\u200b\u7279\u5f81\u200b\u7528\u200b\u54c8\u5e0c\u200b\u51fd\u6570\u200b\u751f\u6210\u200b\u4e00\u4e2a\u200b \\(b\\)-bit \u200b\u4e8c\u8fdb\u5236\u200b\u7f16\u7801\u200b\u503c\u200b \\([v_1, v_2, \\dots, v_b]\\)</li> <li> <p>\u200b\u52a0\u6743\u200b\u83b7\u53d6\u200bSimHash\u200b\u503c\u200b\uff1a\u200b\u52a0\u6743\u200b\u83b7\u53d6\u200b\u5404\u200b\u7279\u5f81\u200b\u5bf9\u5e94\u200b\u7684\u200b\u6743\u91cd\u200b\u548c\u200b\u54c8\u5e0c\u200b\u503c\u200b\uff0c\u200b\u968f\u540e\u200b\u5408\u5e76\u200b\u6240\u6709\u200b\u52a0\u6743\u200b\u7ed3\u679c\u200b\u5e76\u200b\u901a\u8fc7\u200b <code>sign</code> \u200b\u51fd\u6570\u200b\u83b7\u53d6\u200b\u6587\u6863\u200bSimHash\u200b\u503c\u200b</p> \\[ \\begin{aligned}         f_{i} = &amp; [w_i\\text{sign}_1(v_1), w_i\\text{sign}_1(v_2), \\dots, w_i\\text{sign}_1(v_b)]  \\\\         \\text{sign}_1(x) =&amp; \\begin{cases}         1 &amp; x\\gt 0 \\\\         -1 &amp;  x \\le 0         \\end{cases} \\\\         F_d =&amp; \\sum_{i=1}^{D} f_i \\\\         \\text{SimHash}_d =&amp; \\text{sign}_2(F_d) \\\\         \\text{sign}_2(x) =&amp; \\begin{cases}         1 &amp; x\\gt 0 \\\\         0 &amp;  x \\le 0         \\end{cases}  \\end{aligned} \\] </li> <li> <p>\u200b\u8ddd\u79bb\u200b\u8ba1\u7b97\u200b\uff1a\u200b\u5404\u200b\u6587\u6863\u200bSimHash\u200b\u503c\u200b\u6c49\u660e\u7801\u200b\u8ddd\u79bb\u200b\u5373\u200b\u4e3a\u200b\u6587\u6863\u200b\u95f4\u200b\u8ddd\u79bb\u200b</p> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#ann","title":"ANN\u200b\u7b97\u6cd5","text":"<p>\u200b\u67e5\u8be2\u200b\u5411\u91cf\u200b\\(q\\in \\mathbb{R}^{d}\\)\uff0c\u200b\u6587\u6863\u200b\u5411\u91cf\u200b\u96c6\u5408\u200b\\(\\mathcal{X} = \\{d_1, d_2, \\dots, d_N\\}\\)\uff0c\u200b\u5176\u4e2d\u200b\\(d_i \\in \\mathbb{R}^D\\)\uff0c\u200b\u76ee\u6807\u200b\u662f\u200b\u627e\u5230\u200b\\(\\text{Top-}k=\\text{arg}\\mathop{\\text{ max }}\\limits _{x \\in \\mathcal{X}}^k q^T x\\)</p> <ul> <li>\u200b\u66b4\u529b\u200b\u8ba1\u7b97\u200b\u590d\u6742\u5ea6\u200b\u4e3a\u200b\\(O(ND)\\)\uff0c\u200b\u5f53\u200b\\(N\\)\u200b\u5f88\u5927\u200b\u65f6\u200b\uff0c\u200b\u4ee3\u4ef7\u200b\u6781\u9ad8\u200b</li> </ul> <p>\u200b\u56e0\u6b64\u200b\u9700\u8981\u200b\u501f\u52a9\u200bANN\uff08Approximate Nearese Neighbor search\uff09\u200b\u8fd1\u4f3c\u200b\u6700\u8fd1\u200b\u90bb\u200b\u7b97\u6cd5\u200b\u7684\u200b\u7d22\u5f15\u200b\u7ed3\u6784\u200b\u63d0\u5347\u200b\u6548\u7387\u200b\uff0c\u200b\u5e38\u89c1\u200b\u7684\u200b\u5de5\u5177\u200b\u6709\u200b</p> <ul> <li>FAISS: Facebook AI Similarity Search</li> <li>Anserini IR toolkit</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#ivf","title":"IVF","text":"<p>Inverted File Index\u200b\u5012\u6392\u200b\u6587\u4ef6\u200b\u7d22\u5f15\u200b\u7684\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\u5206\u6cbb\u200b\uff0c\u200b\u5305\u62ec\u200b\u4ee5\u4e0b\u200b\u51e0\u4e2a\u200b\u90e8\u5206\u200b\uff1a</p> <ol> <li>\u200b\u79bb\u7ebf\u200b\u805a\u7c7b\u200b\u5212\u5206\u200b\uff1a\u200b\u4f7f\u7528\u200b\u805a\u7c7b\u200b\u7b97\u6cd5\u200b\uff08\u200b\u5982\u200bK-means\uff09\u200b\u5c06\u200b\u5411\u91cf\u200b\u7a7a\u95f4\u200b\u5212\u5206\u200b\u4e3a\u200b\u591a\u4e2a\u200b\u805a\u7c7b\u200b \\(\\{C_1, C_2, \\dots, C_{K}\\}\\)\uff0c\u200b\u5e76\u200b\u8ba1\u7b97\u200b\u805a\u7c7b\u200b\u4e2d\u5fc3\u200b \\(\\{c_1, c_2, \\dots, c_K\\}\\)\uff1b</li> <li>\u200b\u79bb\u7ebf\u200b\u5012\u6392\u200b\u5efa\u8868\u200b\uff1a\u200b\u5bf9\u200b\u6bcf\u4e2a\u200b\u805a\u7c7b\u200b\u7c07\u200b \\(C_i\\) \u200b\u5b58\u50a8\u200b\u5176\u200b\u5305\u542b\u200b\u7684\u200b\u6240\u6709\u200b\u5411\u91cf\u200b\u7684\u200bID\u200b\u548c\u200b\u539f\u59cb\u200b\uff08\u200b\u6216\u200b\u538b\u7f29\u200b\uff09\u200b\u5411\u91cf\u200b\uff0c\u200b\u5e76\u200b\u4f7f\u7528\u200b\u5012\u6392\u200b\u7d22\u5f15\u200b\u65b9\u5f0f\u200b\u5b58\u50a8\u200b\uff0c\u200b\u5373\u200b     <pre><code>c_1 \u2192 [vector id 1, vector id 5, ...]\nc_2 \u2192 [vector id 3, vector id 8, ...]\n...\n</code></pre></li> <li>\u200b\u5728\u7ebf\u200b\u641c\u7d22\u200b\uff1a\u200b\u641c\u7d22\u200b\u65f6\u200b\uff0c\u200b\u53ea\u200b\u9700\u200b\u5728\u200b\u8ddd\u79bb\u200b\u67e5\u8be2\u200b\u5411\u91cf\u200b\u6700\u8fd1\u200b\u7684\u200b\u5c11\u6570\u200b\u805a\u7c7b\u200b\u4e2d\u200b\u904d\u5386\u200b\u5019\u9009\u200b\u5411\u91cf\u200b\uff0c\u200b\u907f\u514d\u200b\u5168\u5c40\u200b\u8ba1\u7b97\u200b<ol> <li>\u200b\u7c97\u7c92\u5ea6\u200b\u641c\u7d22\u200b\uff0c\u200b\u8ba1\u7b97\u200b\u67e5\u8be2\u200b\u5411\u91cf\u200b\\(q\\)\u200b\u4e0e\u200b\u6240\u6709\u200b\u805a\u7c7b\u200b\u4e2d\u5fc3\u200b\\(c_i\\)\u200b\u7684\u200b\u8ddd\u79bb\u200b\uff0c\u200b\u9009\u62e9\u200b\u6700\u8fd1\u200b\u7684\u200b <code>nprobe</code> \u200b\u4e2a\u200b\u805a\u7c7b\u200b</li> <li>\u200b\u7cbe\u200b\u7c92\u5ea6\u200b\u641c\u7d22\u200b\uff0c\u200b\u5728\u200b\u9009\u4e2d\u200b\u7684\u200b <code>nprobe</code> \u200b\u4e2a\u200b\u805a\u7c7b\u200b\u7684\u200b\u5012\u200b\u6392\u5217\u200b\u8868\u4e2d\u200b\uff0c\u200b\u904d\u5386\u200b\u6240\u6709\u200b\u5019\u9009\u200b\u5411\u91cf\u200b\uff0c\u200b\u8ba1\u7b97\u200b\u4e0e\u200b \\(q\\) \u200b\u7684\u200b\u8ddd\u79bb\u200b\u5e76\u200b\u8fd4\u56de\u200b\u5bf9\u5e94\u200b\u7684\u200b top-k \u200b\u4e2a\u200b\u5411\u91cf\u200b</li> </ol> </li> </ol> <ul> <li>\u200b\u641c\u7d22\u200b\u590d\u6742\u5ea6\u200b \\(O(K + \\frac{N}{K}\\cdot nprobe)\\)</li> <li>\u200b\u805a\u7c7b\u200b\u6570\u200b <code>K</code> \u200b\u503c\u8d8a\u200b\u5927\u200b\uff0c\u200b\u641c\u7d22\u200b\u7cbe\u5ea6\u200b\u8d8a\u9ad8\u200b\uff0c\u200b\u4f46\u200b\u805a\u7c7b\u200b\u65f6\u95f4\u200b\u589e\u52a0\u200b\uff0c\u200b\u7ecf\u9a8c\u503c\u200b \\(K=\\sqrt{N}\\) </li> <li>\u200b\u7c97\u7c92\u5ea6\u200b\u641c\u7d22\u200b\u805a\u7c7b\u200b\u6570\u200b <code>nprobe</code> \u200b\u8d8a\u5927\u200b\uff0c\u200b\u641c\u7d22\u200b\u65b9\u4f4d\u200b\u8d8a\u5e7f\u200b\uff0c\u200b\u7cbe\u5ea6\u200b\u8d8a\u9ad8\u200b\uff0c\u200b\u4f46\u200b\u8ba1\u7b97\u200b\u91cf\u200b\u589e\u52a0\u200b\uff0c\u200b\u5178\u578b\u503c\u200b \\(nprob \\in [1, 100]\\)</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#hnsw","title":"HNSW","text":"<p>Hierarchical Navigable Small World graphs\uff0c\u200b\u5206\u5c42\u200b\u53ef\u200b\u5bfc\u822a\u200b\u5c0f\u200b\u4e16\u754c\u200b\u56fe\u200b\uff0c\u200b\u4e5f\u200b\u79f0\u4f5c\u200b\u5206\u5c42\u200bIVF\uff0c\u200b\u5373\u200b\u5bf9\u200b\u805a\u7c7b\u200b\u7c07\u200b\u518d\u6b21\u200b\u805a\u7c7b\u200b\u5212\u5206\u200b\uff0c\u200b\u8fdb\u4e00\u6b65\u200b\u52a0\u901f\u200b\u7c97\u200b\u641c\u7d22\u200b</p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#flat","title":"FLAT","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#tree-based","title":"Tree-based","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#graph-based","title":"Graph-based","text":"<p>NSG\uff08Navigating Spreading-out Graph\uff09</p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#ann_1","title":"ANN\u200b\u4f18\u5316\u200b\u7b56\u7565","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#quantization","title":"Quantization","text":"<ol> <li> <p>PQ\uff08Product Quantization\uff09\u200b\u4e58\u79ef\u200b\u91cf\u5316\u200b\u901a\u8fc7\u200b\u5b50\u200b\u7a7a\u95f4\u200b\u91cf\u5316\u200b\u548c\u200b\u67e5\u8868\u200b\u6cd5\u200b\u63d0\u5347\u200b\u641c\u7d22\u200b\u6548\u7387\u200b\uff0c\u200b\u4e3b\u8981\u200b\u5305\u542b\u200b\u4ee5\u4e0b\u200b\u6838\u5fc3\u601d\u60f3\u200b\uff1a</p> <ol> <li>\u200b\u5212\u5206\u200b\u5b50\u200b\u7a7a\u95f4\u200b\uff1a\u200b\u5c06\u200b \\(D\\) \u200b\u7ef4\u200b\u5411\u91cf\u200b\u5206\u4e3a\u200b \\(m\\) \u200b\u4e2a\u200b \\(\\frac{D}{m}\\) \u200b\u7ef4\u5b50\u200b\u7a7a\u95f4\u200b\uff0c\u200b\u56e0\u6b64\u200b\u53ef\u4ee5\u200b\u5f97\u5230\u200b\\(m\\) \u200b\u4e2a\u200bembedding table\u200b\u5b50\u200b\u7a7a\u95f4\u200b\u77e9\u9635\u200b \\(d^{(i)} \\in \\mathbb{R}^{N \\times \\frac{D}{m}}\\)</li> <li> <p>\u200b\u5b50\u200b\u7a7a\u95f4\u200b\u805a\u7c7b\u200b\uff1a\u200b\u4f7f\u7528\u200bK-means\u200b\u805a\u7c7b\u200b\u65b9\u6cd5\u200b\u5bf9\u200b\u6bcf\u4e2a\u200b\u5b50\u200b\u7a7a\u95f4\u200b\u77e9\u9635\u200b\u8fdb\u884c\u200b\u805a\u7c7b\u200b\u5f97\u5230\u200b\\(K \\ll N\\) \uff08\u200b\u4e00\u822c\u200b\u4e3a\u200b\\(2^{b}\\)\uff09 \u200b\u4e2a\u200b \\(\\frac{D}{m}\\) \u200b\u7ef4\u200b\u5411\u91cf\u200b\u7684\u200b\u805a\u7c7b\u200b\u4e2d\u5fc3\u200b \\(C^{(1)} = \\{c^{(i)}_1, c^{(i)}_2, \\dots, c^{(i)}_K\\} \\in \\mathbb{R}^{K\\times \\frac{D}{m}}\\)\uff0c\u200b\u805a\u7c7b\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u4e3a\u200b\u6700\u5c0f\u5316\u200b\u5404\u5b50\u200b\u7a7a\u95f4\u200b\u5411\u91cf\u200b\u5230\u200b\u6700\u8fd1\u200b\u90bb\u805a\u7c7b\u200b\u4e2d\u5fc3\u200b\u8ddd\u79bb\u200b\u4e4b\u200b\u548c\u200b</p> \\[ \\mathcal{L} = \\sum_{n=1}^{N} \\min_{k=1}^{K} \\Vert d^{(i)}_{n} - c^{(i)}_{k} \\Vert^2 \\] </li> <li> <p>\u200b\u751f\u6210\u200b\u7801\u672c\u200b\uff1a\\(C^{(i)}\\) \u200b\u5373\u200b\u4e3a\u200bi-th \u200b\u5b50\u200b\u7a7a\u95f4\u200b\u7801\u672c\u200bcodebook</p> </li> <li>\u200b\u5206\u6876\u200b\u91cf\u5316\u200b\u5411\u91cf\u200b\uff1a\u200b\u5c06\u200b\u6bcf\u4e2a\u200b\u539f\u59cb\u200b\u7684\u200b\u5b50\u200b\u5411\u91cf\u200b\\(d^{i}_{n}\\) \u200b\u91cf\u5316\u200b\u6620\u5c04\u200b\u4e3a\u200b \\(C^{(i)}\\) \u200b\u4e2d\u200b\u6700\u8fd1\u200b\u7684\u200b\u805a\u7c7b\u200b\u4e2d\u5fc3\u200b \\(\\text{ID}^{(i)}_n\\)\uff0c\u200b\u5373\u200b\uff080~K-1\uff09</li> <li>(\u200b\u67e5\u8868\u200b\u6cd5\u200b)\u200b\u8ddd\u79bb\u200b\u8ba1\u7b97\u200b\uff1a\u200b\u5bf9\u4e8e\u200b\u67e5\u8be2\u200b\u5411\u91cf\u200b\\(q\\)\uff0c\u200b\u540c\u6837\u200b\u8fdb\u884c\u200b\u4e0a\u8ff0\u200b\u5212\u5206\u200b\u5b50\u200b\u7a7a\u95f4\u200b \\(\\{q^{(1)}, q^{(2)}, \\dots, q^{(m)} \\}\\)\uff0c\u200b\u968f\u540e\u200b\u901a\u8fc7\u200b\u67e5\u8868\u200b\u6cd5\u200b\u5f97\u5230\u200b \\(m\\) \u200b\u5b50\u200b\u7a7a\u95f4\u200b\u5185\u200b\u8ddd\u79bb\u200b\u603b\u548c\u200b\u5373\u200b\u4e3a\u200b\u67e5\u8be2\u200b\u4e0e\u200b\u6587\u6863\u200b\u7684\u200b\u6700\u7ec8\u200b\u8ddd\u79bb\u200b</li> </ol> <ul> <li>\u200b\u5b50\u200b\u7a7a\u95f4\u200b\u6570\u200b \\(m\\) \u200b\u8d8a\u5927\u200b\uff0c\u200b\u91cf\u5316\u200b\u7c92\u5ea6\u200b\u66f4\u200b\u7cbe\u7ec6\u200b\uff0c\u200b\u4f46\u200b\u8ba1\u7b97\u200b\u5f00\u9500\u200b\u8d8a\u5927\u200b</li> <li>\u200b\u805a\u7c7b\u200b\u4e2d\u5fc3\u200b\u6570\u200b \\(K=2^{b}\\) \u200b\u8d8a\u200b\u591a\u200b\uff0c\u200b\u91cf\u5316\u200b\u8bef\u5dee\u200b\u66f4\u200b\u5c0f\u200b\uff0c\u200b\u4f46\u200b\u7801\u672c\u200b\u4f4d\u6570\u200b \\(b\\) \u200b\u4f1a\u200b\u8fdb\u800c\u200b\u81a8\u80c0\u200b</li> </ul> </li> <li> <p>SQ\uff08Scalar Quantization\uff09\u200b\u6807\u91cf\u200b\u91cf\u5316\u200b\uff0c\u200b\u5373\u200b\u76f4\u63a5\u200b\u5c06\u200b\u5411\u91cf\u200b\u6bcf\u4e2a\u200b\u7ef4\u5ea6\u200b\u72ec\u7acb\u200b\u5730\u200b\u4ece\u200b\u9ad8\u7cbe\u5ea6\u200b\uff08\u200b\u5747\u5300\u200b\u5206\u6876\u200b\uff09\u200b\u6620\u5c04\u200b\u4e3a\u200b\u4f4e\u200b\u7cbe\u5ea6\u200b\u8868\u793a\u200b\uff0c\u200b\u4ee5\u200b\u51cf\u5c11\u200b\u5185\u5b58\u200b\u5360\u7528\u200b  </p> </li> <li>LSQ\uff08Learned Scalar Quantization\uff09\u200b\u5b66\u4e60\u578b\u200b\u6807\u91cf\u200b\u91cf\u5316\u200b\uff0c\u200b\u901a\u8fc7\u200b\u8bad\u7ec3\u200b\u5b66\u4e60\u200b\u6bcf\u4e2a\u200b\u7ef4\u5ea6\u200b\u7684\u200b\u53ef\u200b\u5b66\u4e60\u200b\u91cf\u5316\u200b\u95f4\u9694\u200b\u5e76\u200b\u5c06\u200b\u5404\u200b\u7ef4\u5ea6\u200b\u5411\u91cf\u200b\u72ec\u7acb\u200b\u5730\u200b\u4ece\u200b\u9ad8\u7cbe\u5ea6\u200b\uff08\u200b\u975e\u200b\u5747\u5300\u200b\u5206\u6876\u200b\uff09\u200b\u6620\u5c04\u200b\u4e3a\u200b\u4f4e\u200b\u7cbe\u5ea6\u200b\u8868\u793a\u200b\uff0c\u200b\u4ee5\u200b\u51cf\u5c11\u200b\u5185\u5b58\u200b\u5360\u7528\u200b  <ol> <li>\u200b\u524d\u5411\u200b\u4f20\u64ad\u200b\uff1a\u200b\u5c06\u200b\u5411\u91cf\u91cf\u5316\u200b\u4e3a\u200b\u4f4e\u200b\u7cbe\u5ea6\u200b\u8868\u793a\u200b\uff1b  </li> <li>\u200b\u53cd\u5411\u200b\u4f20\u64ad\u200b\uff1a\u200b\u4f18\u5316\u200b\u66f4\u65b0\u200b\u91cf\u5316\u200b\u95f4\u9694\u200b\u548c\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b</li> </ol> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#_4","title":"\u8ddd\u79bb\u200b\u8ba1\u7b97\u200b\u4f18\u5316","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#distance-computation","title":"Distance Computation","text":"SDC\u200b\u4e0e\u200bADC\u200b\u8ba1\u7b97\u200b\u793a\u610f\u56fe\u200b\uff08\u200b\u7ea2\u7ebf\u200b\u4e3a\u200b\u771f\u5b9e\u200b\u8ddd\u79bb\u200b\uff0c\u200b\u9ed1\u200b\u5b9e\u7ebf\u200b\u4e3a\u200b\u8ba1\u7b97\u200b\u8ddd\u79bb\u200b\uff09 <ol> <li> <p>SDC\uff08Symmetric Distance Computation\uff09\u200b\u5bf9\u79f0\u200b\u8ddd\u79bb\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u67e5\u8be2\u200b\u5411\u91cf\u200b\\(q\\) \u200b\u548c\u200b \u200b\u6570\u636e\u5e93\u200b\u5411\u91cf\u200b \\(d\\) \u200b\u5747\u200b\u88ab\u200b\u91cf\u5316\u200b\uff0c\u200b\u8ddd\u79bb\u200b\u901a\u8fc7\u200b\u4e24\u8005\u200b\u7684\u200b\u91cf\u5316\u200b\u7ed3\u679c\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u8ba1\u7b97\u200b\u6d41\u7a0b\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li>\u200b\u53cc\u5411\u200b\u91cf\u5316\u200b\uff1a\\(q = \\text{quant}(q)\\)\uff0c\\(d = \\text{quant}(d)\\)\uff0ce.g. \u200b\u4f7f\u7528\u200bPQ\u200b\u91cf\u5316\u200b</li> <li> <p>\u200b\u8ddd\u79bb\u200b\u8ba1\u7b97\u200b\uff1a\u200b\u57fa\u4e8e\u200b\u91cf\u5316\u200b\u7ed3\u679c\u200b\u8ba1\u7b97\u200b\u5411\u91cf\u200b\u95f4\u200b\u8ddd\u79bb\u200b</p> \\[ \\begin{aligned}     Dis^{(i)}[k_1][k_2] =&amp; \\Vert c^{(i)}_{k_1} - c^{(i)}_{k_2} \\Vert^2 \\\\     SDC(q, d_n) \\approx&amp;  \\sum_{i=1}^{m} Dis^{(i)}[\\text{ID}(q^{(i)})][\\text{ID}(d^{(i)}_n)] \\end{aligned} \\] </li> </ol> <ul> <li>\u200b\u641c\u7d22\u200b\u65f6\u200b\u8ba1\u7b97\u200b\u590d\u6742\u5ea6\u200b\u4f18\u5316\u200b\u4e3a\u200b \\(O(m\\cdot K^2 + N\\cdot m)\\)</li> <li>\u200b\u727a\u7272\u200b\u7cbe\u5ea6\u200b\u6362\u53d6\u200b\u6781\u81f4\u200b\u6548\u7387\u200b\uff0c\u200b\u53ef\u200b\u9884\u5148\u200b\u8ba1\u7b97\u200b\\(Dis\\)</li> </ul> </li> <li> <p>ADC\uff08Asymmetric Distance Computation\uff09\u200b\u975e\u5bf9\u79f0\u200b\u8ddd\u79bb\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u4ec5\u200b\u6570\u636e\u5e93\u200b\u5411\u91cf\u200b \\(d\\) \u200b\u88ab\u200b\u91cf\u5316\u200b\uff0c\u200b\u67e5\u8be2\u200b\u5411\u91cf\u200b \\(q\\) \u200b\u4fdd\u6301\u200b\u539f\u59cb\u200b\u7cbe\u5ea6\u200b\uff0c\u200b\u8ddd\u79bb\u200b\u901a\u8fc7\u200b \\(q\\) \u200b\u4e0e\u200b\u91cf\u5316\u200b\u4e2d\u5fc3\u200b\u7684\u200b\u8ddd\u79bb\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u8ba1\u7b97\u200b\u6d41\u7a0b\u200b\u5982\u4e0b\u200b\uff1a  </p> <ol> <li>\u200b\u5355\u5411\u200b\u91cf\u5316\u200b\uff1a\\(d = \\text{quant}(d)\\)\uff0ce.g. \u200b\u4f7f\u7528\u200bPQ\u200b\u91cf\u5316\u200b</li> <li> <p>\u200b\u8ddd\u79bb\u200b\u8ba1\u7b97\u200b\uff1a\u200b\u57fa\u4e8e\u200b\u91cf\u5316\u200b\u7ed3\u679c\u200b\u8ba1\u7b97\u200b\u5411\u91cf\u200b\u95f4\u200b\u8ddd\u79bb\u200b</p> \\[ \\begin{aligned}     Dis^{(i)}[k] =&amp; \\Vert q^{(i)} - c^{(i)}_{k} \\Vert^2\\ \\ (k=1, 2, \\dots K) \\\\     ADC(q, d_n) \\approx &amp; \\sum_{i=1}^{m} Dis^{(i)}[\\text{ID}^{(i)}(d^{(i)}_n)] \\end{aligned} \\] </li> </ol> <ul> <li>\u200b\u641c\u7d22\u200b\u65f6\u200b\u8ba1\u7b97\u200b\u590d\u6742\u5ea6\u200b\u4f18\u5316\u200b\u4e3a\u200b \\(O(m \\cdot K\\cdot \\frac{D}{m} + N\\cdot m) = O(K\\cdot D+ N\\cdot m)\\)</li> <li>\u200b\u5e73\u8861\u200b\u7cbe\u5ea6\u200b\u4e0e\u200b\u6548\u7387\u200b\uff0c\u200b\u9700\u200b\u5b9e\u65f6\u200b\u8ba1\u7b97\u200b\\(Dis\\)</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#lsh","title":"LSH","text":"<p>Locality-Sensitive Hashing\u200b\u5c40\u90e8\u200b\u654f\u611f\u200b\u54c8\u5e0c\u200b\uff0c\u200b\u5373\u200b\u5047\u5b9a\u200bA\u3001B\u200b\u5177\u6709\u200b\u4e00\u5b9a\u200b\u76f8\u4f3c\u6027\u200b\uff0c\u200b\u5728\u200bhash\u200b\u4e4b\u540e\u200b\uff0c\u200b\u4ecd\u80fd\u200b\u4fdd\u6301\u200b\u8fd9\u79cd\u200b\u76f8\u4f3c\u6027\u200b\u3002\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\u901a\u8fc7\u200b\u54c8\u5e0c\u200b\u51fd\u6570\u200b\u5c06\u200b\u9ad8\u200b\u7ef4\u7a7a\u95f4\u200b\u4e2d\u8ddd\u79bb\u200b\u76f8\u8fd1\u200b\u7684\u200b\u5411\u91cf\u200b\u4ee5\u9ad8\u200b\u6982\u7387\u200b\u6620\u5c04\u200b\u5230\u200b\u76f8\u540c\u200b\u7684\u200b\u54c8\u5e0c\u200b\u6876\u200b\u4e2d\u200b\uff0c\u200b\u4ece\u800c\u200b\u5c06\u200b\u641c\u7d22\u200b\u8303\u56f4\u200b\u51cf\u5c11\u200b\u5230\u200b\u5c11\u6570\u200b\u5019\u9009\u200b\u96c6\u200b\uff0c\u200b\u663e\u8457\u200b\u964d\u4f4e\u200b\u8ba1\u7b97\u200b\u590d\u6742\u5ea6\u200b\u3002\u200b\u6838\u5fc3\u601d\u60f3\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li> <p>\u200b\u8bbe\u8ba1\u200b\u54c8\u5e0c\u200b\u51fd\u6570\u200b\uff1a\u200b\u5bf9\u4e8e\u200b\u4efb\u610f\u200b\u4e24\u4e2a\u200b\u5411\u91cf\u200b \\(d_1\\) \u200b\u548c\u200b \\(d_2\\) \u200b\u4ee5\u53ca\u200b\u8ddd\u79bb\u200b\\(dis(\\cdot, \\cdot)\\)\uff0c\u200b\u5b58\u5728\u200b\u6982\u7387\u51fd\u6570\u200b \\(P\\) \u200b\u4f7f\u5f97\u200b</p> \\[ P\\big(h(d_1) = h(d_2)\\big) = f\\big(dis(d_1, d_2)\\big) \\] <p>\u200b\u5176\u4e2d\u200b \\(f\\) \u200b\u4e3a\u200b\u5355\u8c03\u200b\u9012\u51cf\u200b\u51fd\u6570\u200b\uff0c\u200b\u5373\u200b\u8ddd\u79bb\u200b\u5c0f\u200b\u7684\u200b\u5206\u5230\u200b\u76f8\u540c\u200b\u6876\u200b\u7684\u200b\u6982\u7387\u200b\u5927\u200b\uff0c\u200b\u8ddd\u79bb\u200b\u5927\u200b\u7684\u200b\u5206\u5230\u200b\u76f8\u540c\u200b\u6982\u7387\u200b\u5c0f\u200b</p> </li> <li> <p>\u200b\u591a\u200b\u54c8\u5e0c\u200b\u8868\u4e0e\u200b\u653e\u5927\u200b\u6280\u672f\u200b\uff1a\u200b\u5355\u4e00\u200b\u54c8\u5e0c\u200b\u51fd\u6570\u200b\u53ef\u80fd\u200b\u6f0f\u68c0\u200b\u6216\u200b\u8bef\u68c0\u200b\u76f8\u4f3c\u200b\u9879\u200b\uff0c\u200b\u56e0\u6b64\u200bLSH\u200b\u53ef\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u65b9\u6848\u200b\u4f18\u5316\u200b\u6548\u679c\u200b</p> <ul> <li> <p>\u200b\u591a\u200b\u54c8\u5e0c\u200b\u51fd\u6570\u200b k-bit hash\uff0c\u200b\u4f7f\u7528\u200b \\(k\\) \u200b\u4e2a\u200b\u72ec\u7acb\u200b\u54c8\u5e0c\u200b\u51fd\u6570\u200b \\(h(x) = [h_1(x), \\dots, h_k(x)]\\)\uff0c\u200b\u53ea\u6709\u200b\u590d\u5408\u200b\u54c8\u5e0c\u200b\u51fd\u6570\u200b\u6240\u6709\u200b\u54c8\u5e0c\u200b\u503c\u200b\u76f8\u540c\u200b\uff08\u200b\u6216\u200b\u6709\u200b\u4e00\u5b9a\u200b\u7684\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\uff09\u200b\u624d\u80fd\u200b\u89c6\u4e3a\u200b\u5019\u9009\u200b  </p> <p>\u200b\u589e\u5927\u200b \\(k\\) \u200b\u51cf\u5c11\u200b\u8bef\u68c0\u7387\u200b</p> </li> <li> <p>\u200b\u591a\u200b\u54c8\u5e0c\u200b\u8868\u200b L\u200b\u8868\u200b\uff0c\u200b\u6784\u5efa\u200b \\(L\\) \u200b\u4e2a\u200b\u72ec\u7acb\u200b\u7684\u200b\u54c8\u5e0c\u200b\u8868\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u8868\u200b\u4f7f\u7528\u200b\u4e0d\u540c\u200b\u7684\u200b\u54c8\u5e0c\u200b\u51fd\u6570\u200b\u65cf\u200b\uff0c\u200b\u641c\u7d20\u200b\u65f6\u200b\u5408\u5e76\u200b\u6240\u6709\u200b\u8868\u200b\u7684\u200b\u5019\u9009\u200b\u96c6\u200b  </p> <p>\u200b\u901a\u8fc7\u200b\u589e\u5927\u200b \\(L\\) \u200b\u63d0\u9ad8\u200b\u627e\u5230\u200b\u8fd1\u90bb\u200b\u7684\u200b\u6982\u7387\u200b</p> </li> </ul> </li> <li> <p>\u200b\u641c\u7d22\u200b\u6d41\u7a0b\u200b\uff1a\u200b\u79bb\u7ebf\u200b\u6784\u5efa\u200b\u54c8\u5e0c\u200b\u8868\u200b\uff0c\u200b\u5728\u7ebf\u200b\u67e5\u8be2\u200b\u65f6\u200b\u54c8\u5e0c\u200b\u67e5\u8be2\u200b\u5411\u91cf\u200b \\(h(q)\\) \u200b\u5e76\u200b\u4ece\u200b\u5bf9\u5e94\u200b\u54c8\u5e0c\u200b\u6876\u200b\u5019\u9009\u200b\u9879\u4e2d\u200b\u641c\u7d22\u200b</p> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#bq","title":"BQ","text":"<p>Batch Querying\u200b\u6279\u91cf\u200b\u67e5\u8be2\u200b</p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/index.html#learned-indexes","title":"Learned Indexes","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/atlas.html","title":"Atlas","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/atlas.html#atlas","title":"Atlas","text":"<p>\u200b\u8bba\u6587\u200b\uff1aAtlas: Few-shot Learning with Retrieval Augmented Language Models Meta AI &amp; PSL University &amp; Inria &amp; University College London 2022 Aug, JMLR 2023  </p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/coil.html","title":"Coil","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/coil.html#coil","title":"COIL","text":"<p>\u200b\u8bba\u6587\u200b\uff1aCOIL: Revisit Exact Lexical Match in Information Retrieval with COntextualized Inverted List Github\uff1aCOIL Carnegie Mellon University 2021 Apr, ACL 2021</p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/coil.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/coil.html#_2","title":"\u57fa\u4e8e\u200b\u8bed\u4e49\u200b\u7684\u200b\u76f8\u5173\u6027\u200b\u5339\u914d","text":"<ol> <li> <p>\u200b\u8bcd\u6cd5\u200b\u7cbe\u786e\u200b\u5339\u914d\u200b\uff1a\u200b\u5206\u522b\u200b\u8ba1\u7b97\u200b\u95ee\u9898\u200b\u67e5\u8be2\u200b\u4e0e\u200b\u6587\u6863\u200b\u4e2d\u200b\u5404\u200btoekn\u200b\u7684\u200b\u5206\u6570\u200b\uff0c\u200b\u7edf\u8ba1\u200b\u95ee\u9898\u200b\u67e5\u8be2\u200b\u4e0e\u200b\u6587\u6863\u200b\u5171\u6709\u200btoken\u200b\u7684\u200b\u6700\u5927\u200b\u5206\u6570\u200b\u548c\u200b</p> \\[ \\begin{aligned}     v^{(q)}_i =&amp; W_{tok}h_i^{(q)} + b_{tok} \\\\     v^{(d)}_j =&amp; W_{tok}h_j^{(d)} + b_{tok} \\\\     s_{tok}(q, d) =&amp; \\sum_{q_i \\in q \\cap d} \\max_{d_j = q_i} {v^{(q)}_{i}}^Tv_j^{(d)} \\end{aligned} \\] <p>\\(W_{tok}\\) \u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u4f4e\u7ef4\u200b\u6295\u5f71\u200b\u77e9\u9635\u200b \\(n_t \\ll hidden\\_dim\\)</p> </li> <li> <p>\u200b\u53e5\u6cd5\u200b\u5c42\u7ea7\u200b\u8bed\u4e49\u200b\u5339\u914d\u200b\uff1a\u200b\u8fdb\u4e00\u6b65\u200b\u8003\u8651\u200b\u4e0d\u540c\u200b\u8bcd\u6c47\u200b\u7684\u200b\u8bed\u4e49\u200b\u76f8\u5173\u6027\u200b</p> \\[ \\begin{aligned}     v^{(q)}_{cls} =&amp; W_{cls}q_\\text{[CLS]} + b_{cls} \\\\     v^{(d)}_{cls} =&amp; W_{cls}d_\\text{[CLS]} + b_{cls} \\\\     s_{cls}(q, d) =&amp; {v^{(q)}_{cls}}^Tv^{(d)}_{cls} \\end{aligned} \\] <p>\\(W_{cls}\\) \u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u4f4e\u7ef4\u200b\u6295\u5f71\u200b\u77e9\u9635\u200b \\(n_c \\le hidden\\_dim\\)</p> </li> <li> <p>put all together</p> \\[ s_{full}(q, d) = s_{tok}(q, d) + s_{cls}(q, d) \\] </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/coil.html#_3","title":"\u5012\u6392\u200b\u68c0\u7d22","text":"<ol> <li> <p>\u200b\u8bcd\u6cd5\u200b\u7cbe\u786e\u200b\u5339\u914d\u200b</p> <ul> <li>\u200b\u4ece\u200b\u6587\u6863\u200b\u5e93\u4e2d\u4ee5\u200btoken\u200b\u4e3a\u952e\u200b\u5b58\u50a8\u200b\u5bf9\u5e94\u200btoken\uff0c\u200b\u4ee5\u200b\u5217\u8868\u200b\u5f62\u5f0f\u200b\u7684\u200b\u503c\u200b\u5b58\u53d6\u200b\u5bf9\u5e94\u200b\u7684\u200b\u6240\u6709\u200b\u5411\u91cf\u200b\u8868\u793a\u200b</li> </ul> </li> <li> <p>\u200b\u53e5\u6cd5\u200b\u5c42\u7ea7\u200b\u8bed\u4e49\u200b\u5339\u914d\u200b</p> <ul> <li>\u200b\u5e38\u89c4\u200b\u5411\u91cf\u200b\u6570\u636e\u5e93\u200b\u5b58\u50a8\u200b\u5f62\u5f0f\u200b</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/coil.html#_4","title":"\u6027\u80fd\u200b\u3001\u200b\u6548\u679c\u200b\u8868\u73b0","text":"<ol> <li> <p><code>ColBERT \u27f7 COIL-full</code>\uff0c\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u63a5\u8fd1\u200b\u5168\u200b\u91cf\u8bcd\u200b\u6cd5\u200b\u5339\u914d\u200b\u7684\u200bColBERT\uff0c\u200b\u5728\u200bCPU\u200b\u548c\u200bGPU\u200b\u4e0a\u200b\u7684\u200b\u68c0\u7d22\u200b\u6548\u7387\u200b\u6709\u200b\u660e\u663e\u200b\u63d0\u5347\u200b </p> <p></p> </li> <li> <p><code>n_c, n_t</code> \u200b\u7684\u200b\u6d88\u878d\u200b\u5b9e\u9a8c\u200b\u8868\u660e\u200b\u5728\u200b\u4fe1\u606f\u68c0\u7d22\u200b\u4efb\u52a1\u200b\u4e2d\u200b\u63d0\u5347\u200b\u5411\u91cf\u200b\u7ef4\u5ea6\u200b\u6536\u76ca\u200b\u8f83\u200b\u4f4e\u200b\uff0c\u200b\u7efc\u5408\u6027\u200b\u80fd\u200b\u4e0e\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u4f4e\u7ef4\u200b\u8868\u793a\u200b\u662f\u200b\u66f4\u597d\u200b\u7684\u200b\u9009\u62e9\u200b     </p> <p></p> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/colbert.html","title":"Colbert","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/colbert.html#colbert","title":"ColBERT","text":"<ul> <li>\u200b\u8bba\u6587\u200b\uff1aColBERT: Efficient and Effective Passage Search via Contextualized late Interaction over BERT </li> <li>Stanford University 2020 Apr, SIGIR 2020</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/colbert.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/colbert.html#encoder","title":"Encoder","text":"<ol> <li> <p>\u200b\u5b6a\u751f\u200b\u7f51\u7edc\u200b\uff0cquery \u200b\u548c\u200b document \u200b\u7f51\u7edc\u5171\u4eab\u200b\u53c2\u6570\u200b</p> </li> <li> <p>Query Encoder: <code>E_q = Normalize(CNN(BERT([CLS][Q]q_1...q_l[MASK]...[MASK])))</code></p> <ul> <li>\u200b\u4ee5\u200b <code>[CLS][Q]</code> \u200b\u5f00\u5934\u200b</li> <li>\u200b\u7edf\u4e00\u200bPAD <code>[MASK]</code> token \u200b\u81f3\u200b <code>seq_len = N_q</code> \uff08\u200b\u53ef\u200b\u7406\u89e3\u200b\u4e3a\u200bquery expansion\uff0c\u200b\u6d88\u878d\u200b\u5b9e\u9a8c\u200b\u73b0\u5b9e\u200b\u8be5\u200bPAD\u200b\u65b9\u5f0f\u200b\u6709\u200b\u589e\u76ca\u200b\uff09</li> <li>\u200b\u5411\u91cf\u200b\u77e9\u9635\u200b\u6620\u5c04\u200b\u4e3a\u200b\u4f4e\u7ef4\u200b\u5411\u91cf\u200b \\(m \\ll hidden\\_dim\\)</li> <li>L2 Normlization</li> </ul> </li> <li> <p>Document Encoder: <code>E_d = Filter(Normalize(CNN(BERT([CLS][D]d_1...d_n))))</code></p> <ul> <li>\u200b\u4ee5\u200b <code>[CLS][D]</code> \u200b\u5f00\u5934\u200b</li> <li>\u200b\u65e0\u9700\u200bPAD <code>[MASK]</code> token</li> <li>\u200b\u6620\u5c04\u200b\u4e3a\u200b\u4f4e\u7ef4\u200b\u5411\u91cf\u200b \\(m \\ll hidden\\_dim\\)</li> <li>\u200b\u5411\u91cf\u200b\u77e9\u9635\u200bL2 Normlization</li> <li>\u200b\u8fc7\u6ee4\u200b\u6389\u200b\u6807\u70b9\u7b26\u53f7\u200b\u5411\u91cf\u200b\u8868\u793a\u200b</li> </ul> <ul> <li>\\(E_d\\) \u200b\u53ef\u200b\u79bb\u7ebf\u200b\u9884\u8ba1\u200b\u7b97\u200b\uff0c\u200b\u52a0\u901f\u200b\u5728\u7ebf\u200b\u68c0\u7d22\u200b  </li> <li>\u200b\u79bb\u7ebf\u200b\u7f16\u7801\u200b\u65f6\u200b\uff0c\u200b\u4e3a\u200b\u5feb\u901f\u200b\u7f16\u7801\u200b\u901f\u7387\u200b\uff08\u200b\u5c3d\u53ef\u80fd\u51cf\u5c11\u200bpad_to_max token\u200b\u6570\u200b\uff09\uff0c\u200b\u4f7f\u7528\u200b\u57fa\u4e8e\u200b\u6587\u6863\u200b\u957f\u5ea6\u200b\u7684\u200b\u5206\u6876\u200b\u65b9\u6cd5\u200b\u8fdb\u884c\u200b\u7f16\u7801\u200b\uff0c<code>BucketIterator</code> \u200b\u5e93\u200b</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/colbert.html#late-interaction","title":"Late Interaction","text":"<p>query-doc\u200b\u7684\u200b\u8bed\u4e49\u200b\u5411\u91cf\u200b\u4ea4\u4e92\u200b\u8ba1\u7b97\u200b\u5ef6\u8fdf\u200b\u5230\u200b\u6700\u540e\u200b\uff0cMaxSim</p> \\[ S_{q, d} = \\sum_{i=1}^{\\vert q \\vert} \\max_{j = 1}^{\\vert d \\vert} E_{q_{i}}^TE_{d_j} \\] <p>\u200b\u4fdd\u7559\u200b\u8bcd\u200b\u7ea7\u522b\u200b\u5339\u914d\u200b\u7684\u200b\u7ec6\u7c92\u5ea6\u200b\u8bed\u4e49\u200b\uff0c\u200b\u9632\u6b62\u200b\u957f\u200b\u6587\u672c\u200b\u5e8f\u5217\u200b\u538b\u7f29\u200b\u4e3a\u200b\u5355\u4e2a\u200b\u5411\u91cf\u200b\uff0c\u200b\u4e22\u5931\u200b\u7ec6\u7c92\u5ea6\u200b\u8bed\u4e49\u200b  </p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/colbert.html#prefilter-pruning","title":"Prefilter Pruning","text":"<p>\u200b\u4f7f\u7528\u200b\u9884\u200b\u8fc7\u6ee4\u5668\u200b\u6392\u9664\u200b\u6389\u200b\u5927\u90e8\u5206\u200b\u4e0d\u200b\u76f8\u5173\u200b\u6587\u6863\u200b \\(K \\ll N\\)\uff0c\u200b\u5373\u5c06\u200b\u68c0\u7d22\u200b\u5206\u4e3a\u200b\u4e24\u200b\u9636\u6bb5\u200b</p> <ol> <li> <p>\u200b\u8fd1\u4f3c\u200b\u5339\u914d\u200b</p> <ul> <li>\u200b\u65b9\u6cd5\u200b\u4e00\u200b\uff1a\u200b\u57fa\u4e8e\u200bBM25\u200b\u9884\u200b\u8fc7\u6ee4\u200b</li> <li>\u200b\u65b9\u6cd5\u200b\u4e8c\u200b\uff1a\u200b\u4f7f\u7528\u200b\u95ee\u9898\u200b\u67e5\u8be2\u200b\u7684\u200b \\(N_q\\) \u200b\u5411\u91cf\u200b\u8868\u793a\u200b\u8ba1\u7b97\u200b\u4e0e\u200b \\(N\\) \u200b\u4e2a\u200b\u6587\u672c\u200b\u5411\u91cf\u200b\u8868\u793a\u200b\u8fdb\u884c\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\uff0c\u200b\u5206\u522b\u200b\u8fd4\u56de\u200b top-k \u200b\u4e2a\u200b\u6587\u6863\u200b\uff0c\u200b\u6700\u7ec8\u200b\u7ed3\u679c\u200b\u4e3a\u200b \\(K = \\text{unique}(N_q \\times k)\\) \u200b\u4e2a\u200b\u76f8\u5173\u200b\u6587\u6863\u200b</li> </ul> </li> <li> <p>\u200b\u91cd\u200b\u6392\u5e8f\u200brerank\uff1a\u200b\u57fa\u4e8e\u200bMaxSim \u200b\u5bf9\u200b\u7b2c\u4e00\u9636\u6bb5\u200b\u547d\u4e2d\u200b\u7684\u200b\u6587\u6863\u200b\u91cd\u200b\u6392\u5e8f\u200b</p> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/colbert.html#_2","title":"\u6d88\u878d\u200b\u5b9e\u9a8c","text":"<ol> <li> <p>\u200b\u6548\u679c\u200b\u8868\u73b0\u200b  </p> <ul> <li><code>D \u27f7 A, B</code>\uff1aMaxSim\u200b\u6548\u679c\u200b\u4f18\u4e8e\u200b\u5176\u4ed6\u200b\u65b9\u6848\u200b\uff0c\u200b\u67e5\u8be2\u200b\u6587\u6863\u200b\u68c0\u7d22\u200b\u4efb\u52a1\u200b\u4e2d\u200b\u66f4\u200b\u6ce8\u91cd\u200b\u4e2a\u522b\u200b\u5173\u952e\u5b57\u200b  </li> <li><code>D \u27f7 C</code>\uff1aQuery Encoder\u200b\u7684\u200bPAD <code>[MASK]</code> to \\(N_q\\) \u200b\u65b9\u6848\u200b\u5177\u6709\u200b\u67e5\u8be2\u200b\u62d3\u5c55\u200b\u7684\u200b\u589e\u76ca\u200b\u6548\u7528\u200b </li> </ul> </li> <li> <p>\u200b\u6548\u7387\u200b\u8868\u73b0\u200b  </p> <ul> <li><code>length-based bucketing</code>\uff1a\u200b\u57fa\u4e8e\u200b\u6587\u6863\u200b\u957f\u5ea6\u200b\u5206\u6876\u200b\u7684\u200b\u65b9\u6cd5\u200b\u80fd\u200b\u6709\u6548\u200b\u51cf\u5c11\u200b <code>pad_to_max</code> token\u200b\u6570\u200b  </li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/deepct.html","title":"Deepct","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/deepct.html#deepct","title":"DeepCT","text":"<p>\u200b\u8bba\u6587\u200b\uff1aContext-Aware Sentence/Passage Term Importance Estimation For First Stage Retrieval DeepCT: Deep Contextualized Term weighting Carnegie Mellon University 2019 Oct</p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/deepct.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<p>\u200b\u4e3a\u200b\u6539\u8fdb\u200b\u4f20\u7edf\u200b\u9759\u6001\u200b\u8bcd\u9891\u200b\u7edf\u8ba1\u200b\u65b9\u6cd5\u200b\uff08\u200b\u5982\u200bTF-IDF\u3001BM25\uff09\uff0c\u200b\u4f7f\u7528\u200b\u9884\u200b\u8bad\u7ec3\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\u57fa\u4e8e\u200b\u8bed\u4e49\u200b\u52a8\u6001\u200b\u9884\u6d4b\u200b\u6bcf\u4e2a\u200b\u8bcd\u200b\u7684\u200b\u91cd\u8981\u6027\u200b\u6743\u91cd\u200b\u3002</p> \\[ w_i = \\sigma (Wh_i + b) \\]"},{"location":"AI/Paper_Reading/LM/LMs/RAG/deepct.html#_2","title":"\u6570\u636e\u5904\u7406","text":"\\[ \\mathcal{L} = \\frac{1}{N}\\sum_{i=1}^N(w_i - \\hat{w}_i)^2 \\] <p>\u200b\u76d1\u7763\u200b\u8bad\u7ec3\u200b\u9700\u8981\u200b\u8bcd\u7ea7\u200b\u6743\u91cd\u200b\u6807\u7b7e\u200b\uff08\u200b\u4f2a\u200b\u6807\u7b7e\u200b\u53ef\u80fd\u200b\u5f15\u5165\u200b\u566a\u58f0\u200b\uff09\u3002</p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/deepct.html#_3","title":"\u52a8\u6001\u200b\u52a0\u6743\u200b\u6539\u8fdb","text":"<ol> <li> <p>\u200b\u57fa\u4e8e\u200b\u52a0\u6743\u200b\u8bcd\u9891\u200b\u7684\u200bTF-IDF\u200b\u6539\u8fdb\u200b</p> \\[ \\begin{aligned}     \\text{wTF}(word, d) =&amp; \\sum w_{word}^{(d)} \\\\     \\text{wTF-IDF}(word, d) =&amp; \\text{wTF}(word, d)\\cdot \\text{IDF}(word) \\end{aligned} \\] <p>\u200b\u8ba1\u7b97\u200b \\(\\langle q, d\\rangle\\) \u200b\u7684\u200b\u52a0\u6743\u200bTF-IDF\u200b\u5411\u91cf\u200b\u76f8\u4f3c\u200b\u5ea6\u200b</p> </li> <li> <p>\u200b\u57fa\u4e8e\u200b\u52a0\u6743\u200bBM25\u200b\u7684\u200b\u6539\u8fdb\u200b</p> \\[ \\begin{aligned}     \\text{wTF}_\\text{BM25}(word, d) =&amp; \\sum \\frac{w_{word}\\cdot (k_1 + 1)}{w_{word} + k_1\\cdot (1-b + b\\frac{\\vert d \\vert}{\\text{avg dl}})} \\\\     \\text{wBM25}(q, d) =&amp; \\sum_{word \\in q} \\text{IDF}(word)\\cdot \\text{wTF}_\\text{BM25}(word, d) \\end{aligned} \\] <p>\u200b\u4fdd\u7559\u200bBM25\u200b\u7684\u200b\u975e\u7ebf\u6027\u200b\u9971\u548c\u200b\u7279\u6027\u200b\uff0c\u200b\u540c\u65f6\u200b\u5f15\u5165\u200b\u8bed\u4e49\u200b\u6743\u91cd\u200b\u3002</p> </li> <li> <p>\u200b\u57fa\u4e8e\u200b\u7a20\u5bc6\u200b\u68c0\u7d22\u200b\u7684\u200b\u6269\u5c55\u200b</p> <ul> <li>\u200b\u6587\u6863\u200b\u8868\u793a\u200b \\(E_d = \\sum_i w_i \\cdot h_i\\)\uff0c\u200b\u95ee\u9898\u200b\u67e5\u8be2\u200b\u8868\u793a\u200b \\(E_q = \\sum_i w_i \\cdot h_i\\) </li> <li>\u200b\u8ba1\u7b97\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\uff0c\u200b\u5982\u200b\u4f59\u5f26\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\uff0c\u200b\u5411\u91cf\u200b\u4e58\u79ef\u200b\u7b49\u200b</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/doc2query.html","title":"Doc2query","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/doc2query.html#doc2query","title":"Doc2query","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDocument Expansion by Query Prediction Github\uff1adl4ir-doc2query New York University &amp; University of Waterloo &amp; FAIR &amp; Canadian Institute for Advanced Research 2019 Apr, CoRR 2019  </p> <ul> <li> \u200b\u7b2c\u4e00\u4e2a\u200b\u4f7f\u7528\u200b\u795e\u7ecf\u7f51\u7edc\u200b\u8fdb\u884c\u200bdocument expansion\u200b\u7684\u200b\u5de5\u4f5c\u200b</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/doc2query.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<p>\u200b\u57fa\u4e8e\u200b\u6587\u672c\u200b\u5bf9\u200bSFT\u200b\u751f\u6210\u200b\u6a21\u578b\u200b\uff0c\u200b\u9884\u6d4b\u200b\u65f6\u200b\u8f93\u5165\u200bdoc\u200b\u8f93\u51fa\u200btop-k\u200b\u4f2a\u200b\u95ee\u9898\u200b\u67e5\u8be2\u200b \\(q^{'}\\)</p> \\[ d = \\text{concat}(d, q^{'}_1, q^{'}_2, \\dots, d^{'}_k) \\]"},{"location":"AI/Paper_Reading/LM/LMs/RAG/doc2query.html#doct5query","title":"DocT5Query","text":"<p>\u200b\u8bba\u6587\u200b\uff1aFrom doc2query to docTTTTTquery  </p> <p>\u200b\u4f7f\u7528\u200bT5\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u8fdb\u884c\u200bSFT</p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/dpr.html","title":"Dpr","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/dpr.html#dpr","title":"DPR","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDense Passage Retrieval for Open-Domain Question Answering Github\uff1aDPR FAIR &amp; University of Washington &amp; Princeton University 2020 Apr, EMNLP 2020  </p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/dpr.html#_1","title":"\u5de5\u4f5c\u200b\u5185\u5bb9","text":"<ol> <li>\u200b\u68c0\u7d22\u200b\u9636\u6bb5\u200b</li> <li>query\u200b\u548c\u200bdocument\u200b\u4f7f\u7528\u200b\u4e24\u4e2a\u200b\u72ec\u7acb\u200b\u7684\u200bBERT\u200b\u6a21\u578b\u200b</li> <li>\u200b\u5bf9\u6bd4\u200b\u5b66\u4e60\u200b\u8d1f\u200b\u6837\u672c\u200b\u9009\u53d6\u200b\u65b9\u6848\u200b\uff08\u200b\u5c3d\u53ef\u80fd\u200b\u907f\u514d\u200b\u77db\u76fe\u200b\uff0c\u200b\u53c8\u200b\u5e0c\u671b\u200b\u5bf9\u6bd4\u5ea6\u200b\u9ad8\u200b\uff09\uff1a1\uff09Random\uff0c\u200b\u968f\u673a\u200b\u9009\u53d6\u200b\uff1b2\uff09BM25\uff0c\u200b\u57fa\u4e8e\u200bBM25\uff0c\u200b\u9ad8\u200b\u76f8\u5173\u6027\u200b\u4f46\u200b\u4e0d\u200b\u542b\u7b54\u6848\u200b\uff1b3\uff09Gold\uff0c\u200b\u5176\u4f59\u200b\u95ee\u9898\u200b\u7684\u200b\u6b63\u200b\u6837\u672c\u200b</li> <li>inbatch negatives\uff1ain-batch\u200b\u4e2d\u200b\u5176\u4f59\u200b\u6b63\u200b\u6837\u672c\u200b\u4f5c\u4e3a\u200b\u8d1f\u200b\u6837\u672c\u200b</li> <li>\u200b\u672c\u200b\u5de5\u4f5c\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u4e86\u200bin-batch negatives + \uff081 BM25 negative + Gold\uff09</li> <li>\u200b\u4f7f\u7528\u200b1\u200b\u4e2a\u200bBM25\u200b\u6548\u679c\u663e\u8457\u200b\uff0c\u200b\u4f7f\u7528\u200b2\u200b\u4e2a\u200b\u53ca\u200b\u4ee5\u4e0a\u200b\u6548\u679c\u200b\u4e0d\u200b\u660e\u663e\u200b</li> <li>\u200b\u5206\u522b\u200b\u5b9e\u73b0\u200b\u4e86\u200bBM25\uff0cDPR\u200b\u4ee5\u53ca\u200b BM25 + \u03bb\u00b7sim(q, d)\u200b\u65b9\u6848\u200b\uff0c\u200b\u7b2c\u4e09\u79cd\u200b\u65b9\u6848\u200b\u6700\u4f18\u200b</li> <li> <p>gpu dense\u200b\u7528\u200bFAISS\uff0ccpu sparse\u200b\u7528\u200bLucene</p> </li> <li> <p>\u200b\u751f\u6210\u200b\u9636\u6bb5\u200b</p> </li> <li>\u200b\u68c0\u7d22\u200b\u5339\u914d\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u68c0\u7d22\u200b\u751f\u6210\u200b</li> <li>\u200b\u5bf9\u6bd4\u200b\u5b66\u4e60\u200b\uff1a1 positive passage + (m-1) negative passages from k candidate passages returned by retrieval system \uff08\u200b\u57fa\u4e8e\u200bBM25\u200b\u6216\u200bPDR\u200b\u5206\u6570\u200b\uff09<ul> <li>\u200b\u6b63\u4f8b\u200b\u4ece\u200b\u6700\u200b\u76f8\u5173\u200b\u7684\u200btop-5\u200b\u4e2d\u200b\u9009\u62e9\u200b\uff0c\u200b\u8d1f\u4f8b\u200b\u4ece\u200b\u6700\u200b\u4e0d\u200b\u76f8\u5173\u200b\u7684\u200btop30\u200b\u4e2d\u200b\u968f\u673a\u200b\u9009\u62e9\u200b\uff0c\u200b\u5171\u200b24\u200b\u4e2a\u200b</li> </ul> </li> <li> <p>\u200b\u751f\u6210\u200b\u7ed3\u679c\u200bminor normalization\uff1a</p> <ul> <li>Reading Wikipedia to answer opendomain questions</li> <li>Latent retrieval for weakly supervised open domain question answering</li> <li>\u200b\u7edf\u4e00\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u5c0f\u5199\u200b\uff1b\u200b\u79fb\u9664\u200b\u6807\u70b9\u7b26\u53f7\u200b\uff08\u200b\u5982\u200b\",? \"\u200b\u548c\u200b\u7279\u6b8a\u7b26\u53f7\u200b\u7b49\u200b\uff09\uff1b\u200b\u53bb\u9664\u200b\u51a0\u8bcd\u200b\uff1b\u200b\u6807\u51c6\u5316\u200b\u6570\u5b57\u200b\u683c\u5f0f\u200b\uff08\u200b\u5982\u200b\u767e\u5206\u4e4b\u200b20 \u2192 20%\uff09\uff1b\u200b\u7edf\u4e00\u200b\u65e5\u671f\u200b\u8868\u8fbe\u200b\uff08\u200b\u5982\u200b Jan. 1, 2020 \u2192 January 1 2020\uff09\uff1b\u200b\u51cf\u5c11\u200b\u8bcd\u6c47\u200b\u53d8\u4f53\u200b\u5bf9\u200b\u68c0\u7d22\u200b\u548c\u200b\u7b54\u6848\u200b\u5339\u914d\u200b\u7684\u200b\u5e72\u6270\u200b\uff08\u200b\u5982\u200b U.S. \u2192 United States\uff09</li> </ul> </li> <li> <p>\u200b\u68c0\u7d22\u200b\u548c\u200b\u751f\u6210\u200b\u4e24\u4e2a\u200b\u6a21\u5757\u200b\u4e92\u76f8\u200b\u72ec\u7acb\u200b\uff0c\u200b\u4e0d\u200b\u540c\u65f6\u200b\u66f4\u65b0\u200b\u53c2\u6570\u200b</p> </li> <li> <p>\u200b\u6d88\u878d\u200b\u5b9e\u9a8c\u200b</p> <ul> <li>Gold\u200b\u8981\u200b\u4f18\u4e8e\u200bBM25</li> <li>DP\u200b\u8981\u200b\u7531\u4e8e\u200bL2\uff0c\u200b\u591a\u200b\u5bf9\u6bd4\u200bNLL\u200b\u8981\u200b\u4f18\u4e8e\u200b\u5355\u200b\u5bf9\u6bd4\u200btriplet loss</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/dpr.html#ance","title":"ANCE","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/faiss.html","title":"Faiss","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/faiss.html#faiss","title":"FAISS","text":"<p>\u200b\u8bba\u6587\u200b\uff1aBillionscale similarity search with GPUs FAISS: Facebook AI Similarity Search FAIR &amp; 2017 Feb, Big Data 2021  </p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/fid.html","title":"Fid","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/fid.html#fid","title":"FiD","text":"<p>\u200b\u8bba\u6587\u200b\uff1aLeveraging Passage Retrieval with Generative Models for Open Domain Question Answering FiD: Fusion-in-Decoder FAIR &amp; PSL University &amp; Inria 2020 Jul, ACL 2021  </p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/query2doc.html","title":"Query2doc","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/query2doc.html#query2doc","title":"Query2Doc","text":"<p>\u200b\u8bba\u6587\u200b\uff1aQuery2doc: Query Expansion with Large Language Models MSR 2023 Mar, CoRR 2023  </p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/query2doc.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<p>\u200b\u76f4\u63a5\u200b\u5411\u200bLLM\u200b\u8f93\u5165\u200b\u67e5\u8be2\u200b\u5e76\u200b\u8f93\u51fa\u200b\u4f2a\u200b\u6587\u6863\u200b \\(d^{'}\\) \u200b\u5bf9\u200b\u95ee\u9898\u200b\u67e5\u8be2\u200b\u8fdb\u884c\u200b\u62d3\u5c55\u200b</p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/query2doc.html#qeury-expansion","title":"Qeury Expansion","text":"<ol> <li> <p>Sparse Retrival Expansion</p> \\[ q = \\text{concat}(\\{q\\}\\times n, d^{'}) \\] </li> <li> <p>Dense Retrical Expansion</p> \\[ q = \\text{concat}(q, \\text{[SEP]}, d^{'}) \\] </li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/rag.html","title":"Rag","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/rag.html#rag","title":"RAG","text":"<p>\u200b\u8bba\u6587\u200b\uff1aRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks FAIR &amp; University College London &amp; New York University 2020 May, NeruIPS 2020  </p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/realm.html","title":"Realm","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/realm.html#realm","title":"REALM","text":"<p>\u200b\u8bba\u6587\u200b\uff1aREALM: REtrieval-Augmented Language Model Pre-Training Google Research 2020 Feb, ICML 2020  </p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/realm.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>\\(p(y|x) = \\sum_{z \\in Z} p_{\\theta}(z|x)*p_{\\phi}(y|x, z)\\)\uff0cZ\u200b\u4e3a\u200btop-k\u200b\u7684\u200b\u5019\u9009\u200b\u6587\u6863\u200b</li> <li>\u200b\u540e\u200b\u8ba1\u7b97\u200b\u7684\u200bMIPS\u200b\u83b7\u53d6\u200btop-k\uff0c</li> <li>\u200b\u9884\u200b\u8bad\u7ec3\u200b\u9636\u6bb5\u200b\u4f7f\u7528\u200bstale optimization</li> <li>\u200b\u57fa\u4e8e\u200b\u4e0a\u8ff0\u200b\u516c\u5f0f\u200b\u53ef\u77e5\u200b\u68c0\u7d22\u200b\u9636\u6bb5\u200b\u662f\u200b\u62bd\u8c61\u200b\u6f5c\u5728\u200b\u7684\u200b\uff0c\u200b\u6ca1\u6709\u200b\u8bad\u7ec3\u200b\u76ee\u6807\u200b\u8fdb\u884c\u200b\u63a7\u5236\u200b\uff0c\u200b\u56e0\u6b64\u200b\u9700\u8981\u200b\u901a\u8fc7\u200b\u9f13\u52b1\u200b\u673a\u5236\u200b\u63d0\u5347\u200b\u8be5\u200b\u9636\u6bb5\u200b\u80fd\u529b\u200b</li> <li>performance-base signal from unsupervised text: \u200b\u5956\u52b1\u200b\u63d0\u5347\u200bperplexity\u200b\u7684\u200b\u6587\u6863\u200b\u5206\u6570\u200b\uff0c\u200b\u60e9\u7f5a\u200b\u524a\u5f31\u200bperplexity\u200b\u7684\u200b\u6587\u6863\u200b\u5206\u6570\u200b</li> <li>using sentence x with some tokens (z) masked out, retrieve potential documents z, and then extract (not generate, \u200b\u56e0\u6b64\u200b\u5148\u9a8c\u200b\u5730\u200b\u5047\u8bbe\u200b\u76ee\u6807\u200by\u200b\u4e3a\u200b\u51fa\u73b0\u200b\u5728\u200bz\u200b\u4e2d\u200b\u7684\u200b\u8fde\u7eed\u200bspan) y from z</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/rm.html","title":"Rm","text":"<p>Relevance Model\uff0c\u200b\u4e24\u6b21\u200b\u68c0\u7d22\u200b\uff1a  </p> <ol> <li>\u200b\u57fa\u4e8e\u200bquery\u200b\u4ece\u200b\u77e5\u8bc6\u5e93\u200b\u68c0\u7d22\u200btop-k\u200b\u6587\u6863\u200b\uff1b  </li> <li>\u200b\u57fa\u4e8e\u200btop-k\u200b\u6587\u6863\u200b\u7edf\u8ba1\u200b\u7ed3\u679c\u200b\u83b7\u53d6\u200btop-M\u200b\u62d3\u5c55\u200b\u8bcd\u200b\uff0c\u200b\u6574\u5408\u200b \\(q_\\text{expanded} = \\text{concat}\\big(q, RM(D_R, M)\\big)\\) \u200b\u4e2d\u200b\u8fdb\u884c\u200b\u4e8c\u6b21\u200b\u68c0\u7d22\u200b</li> </ol>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/rm.html#rm1","title":"RM1","text":"<p>Relevance-Based Language Models</p> <ol> <li>\u200b\u57fa\u4e8e\u200bDirichlet\u200b\u5e73\u6ed1\u200b \u200b\u6216\u200b Jelinek-Mercer\u200b\u5e73\u6ed1\u200b \u200b\u8ba1\u7b97\u200b\u8bcd\u200b\u5728\u200b\u6587\u6863\u200b\u4e2d\u200b\u7684\u200b\u6982\u7387\u200b\u83b7\u53d6\u200b\u4f2a\u200b\u76f8\u5173\u200b\u6587\u6863\u200b\u7684\u200b\u52a0\u6743\u200b\u5e73\u5747\u200b\u6982\u7387\u200b \\(P(w\\vert R) = \\frac{1}{\\vert D_R \\vert}\\sum_{d\\in D_{R}} P(w\\vert d)\\)</li> </ol> <ul> <li>\u200b\u5982\u679c\u200b\u521d\u59cb\u200btop-k \u200b\u6587\u6863\u200b\u4e0d\u200b\u76f8\u5173\u200b\uff0c\u200b\u62d3\u5c55\u200b\u8bcd\u200b\u53ef\u80fd\u200b\u5f15\u5165\u200b\u566a\u58f0\u200b  </li> <li>\u200b\u672a\u200b\u8003\u8651\u200b\u8bcd\u200b\u6743\u91cd\u200b\uff0c\u200b\u6240\u6709\u200b\u6587\u6863\u200b\u5e73\u5747\u200b\u52a0\u6743\u200b\uff0c\u200b\u53ef\u80fd\u200b\u53d7\u200b\u9ad8\u9891\u8bcd\u200b\u5e72\u6270\u200b  </li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/rm.html#rm2","title":"RM2","text":"<p>A Generative Theory of Relevance\uff0c\u200b\u4e0d\u518d\u200b\u5047\u8bbe\u200b\u6587\u6863\u200b\u4e2d\u200b\u7684\u200b\u8bcd\u200b\u4e92\u76f8\u200b\u72ec\u7acb\u200b\uff0c\u200b\u800c\u662f\u200b\u8003\u8651\u200b\u8bcd\u9879\u200b\u4e4b\u95f4\u200b\u7684\u200b\u4f9d\u8d56\u200b\u5173\u7cfb\u200b\uff08\u200b\u5982\u200b\u4e8c\u5143\u200b\u6a21\u578b\u200b\uff09\uff0c\u200b\u4ece\u800c\u200b\u66f4\u200b\u51c6\u786e\u200b\u5730\u200b\u4f30\u8ba1\u200b\u76f8\u5173\u6027\u200b\u6a21\u578b\u200b</p> \\[ \\begin{aligned}     P(w\\vert R) =&amp; \\sum_{d \\in D_R} P(w\\vert d)\\times P(q\\vert d)\\times P(d\\vert R) \\\\     =&amp; \\frac{1}{\\vert D_R \\vert} \\sum_{d \\in D_R} P(w\\vert d)\\times P(q\\vert d) \\\\     P(w\\vert d) \\approx&amp; P(w\\vert w_\\text{prev}, d) \\\\     P(q\\vert d) =&amp; \\prod_{w \\in q} P(w\\vert d) \\\\     P(d\\vert R) =&amp; \\frac{1}{\\vert D_R \\vert} \\end{aligned} \\] <ul> <li>\\(P(w\\vert d)\\) \u200b\u8bcd\u200b \\(w\\) \u200b\u5728\u200b\u6587\u6863\u200b \\(d\\) \u200b\u4e2d\u200b\u7684\u200b\u6982\u7387\u200b\uff08\u200b\u8003\u8651\u200b\u8bcd\u200b\u4f9d\u8d56\u200b\uff0c\u200b\u5982\u200b\u4e8c\u5143\u200b\u6a21\u578b\u200b\uff09</li> <li>\\(P(q\\vert d)\\) \u200b\u67e5\u8be2\u200b \\(q\\) \u200b\u5728\u200b\u6587\u6863\u200b \\(d\\) \u200b\u4e2d\u200b\u7684\u200b\u751f\u6210\u200b\u6982\u7387\u200b</li> <li>\\(p(d\\vert R)\\) \u200b\u6587\u6863\u200b \\(d\\) \u200b\u7684\u200b\u76f8\u5173\u6027\u200b\u6982\u7387\u200b</li> <li>\u200b\u8ba1\u7b97\u200b\u590d\u6742\u5ea6\u200b\u9ad8\u200b\uff1a\u200b\u9700\u200b\u7ef4\u62a4\u200b\u8bcd\u5171\u73b0\u200b\u7edf\u8ba1\u200b</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/rm.html#rm3","title":"RM3","text":"<p>UMass at TREC 2004: Novelty and HARD\uff0c\u200b\u901a\u8fc7\u200b\u63a7\u5236\u200b\u539f\u59cb\u200b\u67e5\u8be2\u200b\u548c\u200b\u62d3\u5c55\u200b\u8bcd\u200b\u7684\u200b\u6743\u91cd\u200b\u51cf\u5c11\u200b\u566a\u58f0\u200b\u8bcd\u200b\u7684\u200b\u5f71\u54cd\u200b</p> \\[ \\begin{aligned} P(w \\vert q_\\text{expanded}) =&amp; \\lambda P(w\\vert q) + (1-\\lambda) \\sum_{d \\in D_R}P(w\\vert d)P(d\\vert q)   \\\\ P(d\\vert q) =&amp;  \\text{BM25}(q, d) \\end{aligned} \\] <ul> <li>\\(\\lambda \\in [0, 1]\\)\uff0c\u200b\u63d2\u503c\u200b\u7cfb\u6570\u200b\uff0c\u200b\u7ecf\u9a8c\u200b\u53d6\u503c\u200b 0.5~0.7  </li> <li>\u200b\u4e00\u5143\u200b\u6a21\u578b\u200b</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/rm.html#rm4","title":"RM4","text":"<p>Adaptive Relevance Feedback in Information Retrieval\uff0c\u200b\u8fdb\u4e00\u6b65\u200b\u5f15\u5165\u200b\u4e86\u200b\u8d1f\u53cd\u9988\u200b\u6837\u672c\u200b</p> \\[ \\begin{aligned}     P(w \\vert q_\\text{expanded}) =&amp; \\lambda P(w\\vert q) + (1-\\lambda) \\bigg[\\sum_{d \\in D_R} P(w\\vert d)P(d\\vert q) -\\alpha \\sum_{d \\in D_{NR}}P(w\\vert d)P(d\\vert q) \\bigg] \\end{aligned} \\] <ul> <li>\u200b\u4f7f\u7528\u200b\u4e86\u200b\u5206\u6570\u200b\u6392\u540d\u200b\u9760\u200b\u540e\u200b\u7684\u200b \\(D_{NR}\\) \u200b\u4f4e\u200b\u76f8\u5173\u200b\u6587\u6863\u200b\u8fdb\u884c\u200b\u8d1f\u53cd\u9988\u200b\uff0c\u200b\u7ecf\u9a8c\u200b\u53d6\u540e\u200b100~200\u200b\u6587\u6863\u200b  </li> <li>\\(\\alpha\\) \u200b\u8d1f\u53cd\u9988\u200b\u6743\u91cd\u200b\uff0c\u200b\u7ecf\u9a8c\u200b\u53d6\u503c\u200b 0.1~0.5  </li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/rm.html#rocchio","title":"Rocchio","text":"<p>\u200b\u7528\u6237\u200b\u53cd\u9988\u200b\u7b97\u6cd5\u200b\uff0cRocchio\u200b\u7b97\u6cd5\u200b</p> \\[ q_\\text{new} = \\alpha q + \\beta \\frac{1}{\\vert D_R \\vert} \\sum_{d \\in D_R} \\overrightarrow{h(q, d)} - \\gamma \\frac{1}{\\vert D_{NR} \\vert} \\sum_{d \\in D_{NR}} \\overrightarrow{h(q, d)} \\] <ul> <li>\\(\\alpha, \\beta, \\gamma\\) \u200b\u76f8\u5173\u6027\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b\uff0c\u200b\u63a7\u5236\u200b\u5404\u200b\u90e8\u5206\u200b\u53c2\u6570\u200b\uff0c\u200b\u901a\u8fc7\u200b\u4eba\u6237\u200b\u53cd\u9988\u200b\u7684\u200b\u4eba\u5de5\u200b\u6807\u6ce8\u200b\u6570\u636e\u200b\u8fdb\u884c\u200b\u8c03\u4f18\u200b</li> </ul>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/splade.html","title":"Splade","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/splade.html#splade","title":"SPLADE","text":"<p>\u200b\u8bba\u6587\u200b\uff1aSPLADE: SParse Lexical AnD Expansion Model for First Stage Ranking 2021 Jul, SIGIR 2021  </p>"},{"location":"AI/Paper_Reading/LM/LMs/RAG/splade.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/LM/LMs/RAG/splade.html#sparterm","title":"SparTerm","text":"<p>\u200b\u57fa\u4e8e\u200b\u5404\u200btoken\u200b\u5bf9\u200b\u8bcd\u8868\u200b\u4e2d\u200b\u5404\u8bcd\u200b\u7684\u200b\u8bed\u4e49\u200b\u76f8\u5173\u6027\u200b\u8fdb\u884c\u200b\u67e5\u8be2\u200b\u62d3\u5c55\u200b</p> \\[ \\begin{aligned}     w_{i, j} =&amp; h_i^TE_j + b_j \\\\     w_j =&amp; \\sum_{i=1}^{sel\\_len} \\log \\big(1+ \\text{ReLU}(w_{i, j})\\big) \\end{aligned} \\]"},{"location":"AI/Paper_Reading/LM/LMs/RAG/splade.html#rank-loss","title":"Rank Loss","text":"<ol> <li> <p>InfoNCE Loss\u200b\u8d1f\u200b\u6837\u672c\u200b\u9009\u62e9\u200b</p> <ul> <li>in batch negatives</li> <li>hard negative sample with high BM25</li> </ul> \\[ \\mathcal{L}_\\text{rank-IBN} = - \\log \\frac{e^{s(q_i, d_i^+)}}{\\sum_{j}e^{s(q_i, d_j^+)} + e^{s(q_i, d_i^-)}} \\] <p>$s(q, d) = \\langle w^{q}, w^{d} \\rangle $</p> </li> <li> <p>\u200b\u9632\u6b62\u200b\u8bcd\u9879\u200b\u6743\u91cd\u200b\u5206\u5e03\u200b\u51fa\u73b0\u200b\u957f\u5c3e\u200b\u6548\u5e94\u200b</p> \\[ \\begin{aligned}     \\mathcal{L}_\\text{reg}^d =&amp; \\sum_{j=1}^{\\vert V\\vert} \\bigg( \\frac{1}{N}\\sum_{i=1}^N w_j^{(d_i)} \\bigg) ^ 2 \\\\     \\mathcal{L}_\\text{reg}^q =&amp; \\sum_{j=1}^{\\vert V\\vert} \\bigg( \\frac{1}{N}\\sum_{i=1}^N w_j^{(q_i)} \\bigg) ^ 2 \\\\  \\end{aligned} \\] </li> <li> <p>overall loss</p> \\[ \\mathcal{L} = \\mathcal{L}_\\text{rank-IBN} + \\lambda_q\\mathcal{L}_\\text{reg}^q + \\lambda_d\\mathcal{L}_\\text{reg}^d \\] </li> </ol>"},{"location":"AI/Paper_Reading/LM/Model_Analysis/index.html","title":"\u67b6\u6784\u200b\u5206\u6790","text":"<p>ICL</p>"},{"location":"AI/Paper_Reading/LM/Model_Analysis/Classifier/index.html","title":"Index","text":"<p>\u200b\u673a\u6784\u200b\uff1a</p> <ul> <li>\u200b\u5317\u4eac\u5927\u5b66\u200bCS\u3001WeChat AI</li> </ul> <p>\u200b\u8bba\u6587\u200b\u5730\u5740\u200b\uff1a  </p> <ul> <li>LabelWords are Anchors: An Information Flow Perspective for Understanding In-Context Learning (2023 EMNLP Best Paper)</li> </ul> <p>Github\u200b\u5730\u5740\u200b\uff1a  </p> <ul> <li>https://github.com/lancopku/label-words-are-anchors</li> </ul>"},{"location":"AI/Paper_Reading/LM/Model_Analysis/Classifier/index.html#abstarct","title":"Abstarct","text":"<p>\u200b\u6587\u7ae0\u200b\u5148\u200b\u5047\u8bbe\u200bLM\u200b\u6a21\u578b\u200b\uff08AR\u200b\u6a21\u578b\u200b\uff09\u200b\u4e2d\u200b\u6837\u672c\u200b\u6807\u7b7e\u200b\u8bcd\u200b\u4f5c\u4e3a\u200b\u4fe1\u606f\u200b\u951a\u70b9\u200b\uff08Anchor\uff09\u200b\u5e76\u200b\u9a8c\u8bc1\u200b\u7ed3\u679c\u200b\uff0c\u200b\u5373\u200b\uff1a\u200b\u5728\u200b\u6d45\u5c42\u200b\u4e2d\u200b\u6837\u672c\u200b\u6807\u7b7e\u200b\u8bcd\u200b\u80fd\u591f\u200b\u805a\u96c6\u200b\u63d0\u53d6\u200b\u3001\u200b\u6536\u96c6\u200b\u8bed\u4e49\u200b\u4fe1\u606f\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u6df1\u5c42\u200b\u5c06\u200b\u63d0\u53d6\u200b\u7684\u200b\u8bed\u4e49\u200b\u6c47\u805a\u200b\u3001\u200b\u6d41\u5411\u200b\u6a21\u578b\u200b\u6700\u7ec8\u200b\u9884\u6d4b\u200b\u7684\u200b\u5206\u7c7b\u200b\u7c7b\u522b\u200b\u3002</p> <p>ICL\u200b\u4fe1\u606f\u6d41\u200b\u793a\u610f\u56fe\u200b</p>"},{"location":"AI/Paper_Reading/LM/Model_Analysis/Classifier/index.html#result","title":"Result","text":"<ol> <li>\u200b\u5b9e\u9a8c\u200b\u53d1\u73b0\u200b\u6837\u672c\u200b\u6807\u7b7e\u200b\u8bcd\u200b\u8d77\u5230\u200b\u4fe1\u606f\u200b\u951a\u70b9\u200b\u7684\u200b\u4f5c\u7528\u200b  <ul> <li>\u200b\u5728\u200b\u6d45\u5c42\u200b\u4e2d\u200b\u6837\u672c\u200b\u6807\u7b7e\u200b\u8bcd\u200b\u80fd\u591f\u200b\u805a\u96c6\u200b\u63d0\u53d6\u200b\u3001\u200b\u6536\u96c6\u200b\u8bed\u4e49\u200b\u4fe1\u606f\u200b</li> <li>\u200b\u5728\u200b\u6df1\u5c42\u200b\u6807\u7b7e\u200b\u8bcd\u200b\u5c06\u200b\u63d0\u53d6\u200b\u7684\u200b\u8bed\u4e49\u200b\u6c47\u805a\u200b\u3001\u200b\u6d41\u5411\u200b\u6a21\u578b\u200b\u6700\u7ec8\u200b\u9884\u6d4b\u200b\u7684\u200b\u5206\u7c7b\u200b\u7c7b\u522b\u200b\u3002</li> </ul> </li> <li>\u200b\u57fa\u4e8e\u200b\u6807\u7b7e\u200b\u8bcd\u200b\u8d77\u5230\u200b\u4fe1\u606f\u200b\u951a\u70b9\u200b\u4f5c\u7528\u200b\u7684\u200b\u73b0\u8c61\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u5206\u7c7b\u200b\u4efb\u52a1\u200b\u8bbe\u8ba1\u200b\u5e76\u200b\u5b9e\u73b0\u200b  <ul> <li>anchor re-weighting method\uff0c\u200b\u8fdb\u4e00\u6b65\u200b\u63d0\u5347\u200bICL\u200b\u6548\u679c\u200b</li> <li>AR\u200b\u6a21\u578b\u200b\u8f93\u5165\u200b\u538b\u7f29\u200b\uff0c\u200b\u52a0\u5feb\u200binference\u200b\u6027\u80fd\u200b</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/LM/Model_Analysis/Classifier/index.html#limitation","title":"Limitation","text":"<ol> <li>\u200b\u6682\u65f6\u200b\u53ea\u200b\u5c40\u9650\u4e8e\u200b\u5206\u7c7b\u200b\u4efb\u52a1\u200b\u6682\u65f6\u200b\u65e0\u6cd5\u200b\u6cdb\u5316\u200b\u81f3\u200b\u751f\u6210\u200b\u4efb\u52a1\u200b</li> <li>\u200b\u76ee\u524d\u200b\u53ea\u200b\u5728\u200b\u4f20\u7edf\u200bICL\u200b\u6a21\u5f0f\u200b\u4e0a\u200b\u8fdb\u884c\u200b\u8bd5\u9a8c\u200b\uff0c\u200b\u5176\u4ed6\u200bICL\uff08\u200b\u5982\u200bchaio-of-thought prompt\u200b\u94fe\u5f0f\u200b\u601d\u7ef4\u200b\uff09\u200b\u6682\u672a\u200b\u63a2\u7d22\u200b</li> <li>\u200b\u76ee\u524d\u200b\u53ea\u200b\u5728\u200bGPT-XL\u200b\u548c\u200bGPT-J\u200b\u6a21\u578b\u200b\u4e0a\u200b\u5b9e\u73b0\u200b\uff0c\u200b\u66f4\u200b\u5927\u89c4\u6a21\u200b\u7684\u200bLLM\u200b\u6a21\u578b\u200b\u6548\u679c\u200b\u672a\u77e5\u200b</li> </ol>"},{"location":"AI/Paper_Reading/LM/Model_Analysis/Classifier/index.html#motivation","title":"Motivation","text":"<p>ICL\uff08In-Context Learning\uff09\u200b\u5728\u200b\u8bad\u7ec3\u200bLM\u200b\u65f6\u200b\u6548\u679c\u200b\u660e\u663e\u200b\uff0c\u200b\u4f46\u662f\u200b\u9488\u5bf9\u200b\u5176\u200b\u4e3a\u4f55\u200b\u594f\u6548\u200b\u7684\u200b\u5de5\u4f5c\u200b\u6682\u672a\u200b\u88ab\u200b\u8f83\u200b\u597d\u200b\u5730\u200b\u7814\u7a76\u200b\u63a2\u660e\u200b\u3002\u200b\u63d0\u51fa\u200b\u4e86\u200b\u4ee5\u4e0b\u200b\u6807\u7b7e\u200b\u8bcd\u200b\u4f5c\u4e3a\u200b\u4fe1\u606f\u200b\u951a\u70b9\u200b\u7684\u200b\u5047\u8bbe\u200b\uff0c\u200b\u5177\u4f53\u200b\u4e3a\u200b\uff1a</p> <ul> <li>\\(\\mathcal{H_1}\\)\uff1a\u200b\u5728\u200b\u6d45\u5c42\u200b\u4e2d\u200b\uff0c\u200b\u6807\u7b7e\u200b\u8bcd\u200b\u6536\u96c6\u200b\u6f14\u793a\u200b\u6837\u672c\u200b\u4fe1\u606f\u200b\u4ee5\u200b\u5f62\u6210\u200b\u66f4\u200b\u6df1\u5c42\u200b\u7684\u200b\u8bed\u4e49\u200b\u8868\u793a\u200b\u3002  </li> <li>\\(\\mathcal{H_2}\\)\uff1a\u200b\u5728\u200b\u6df1\u5c42\u200b\u4e2d\u200b\uff0c\u200b\u6a21\u578b\u200b\u4ece\u200b\u6807\u7b7e\u200b\u8bcd\u4e2d\u200b\u63d0\u53d6\u200b\u4fe1\u606f\u200b\u4ee5\u200b\u5f62\u6210\u200b\u6700\u7ec8\u200b\u7684\u200b\u9884\u6d4b\u200b\u3002</li> </ul>"},{"location":"AI/Paper_Reading/LM/Model_Analysis/Classifier/index.html#details","title":"Details","text":""},{"location":"AI/Paper_Reading/LM/Model_Analysis/Classifier/index.html#prompt-construction","title":"Prompt Construction","text":"<p>prompt template=(Num*C) demonstrations + input_to_be_predicted\u3002Num\u200b\u8868\u793a\u200b\u6bcf\u4e2a\u200b\u7c7b\u522b\u200b\u6837\u672c\u6570\u200b\uff0c\u200b\u4e00\u822c\u200b\u4e3a\u200b1\uff1bC\u200b\u8868\u793a\u200b\u7c7b\u522b\u200b\u6570\u200b\uff1bdemonstration\u200b\u8868\u793a\u200b\u76f8\u5e94\u200b\u7c7b\u522b\u200b\u7684\u200b\u968f\u673a\u6837\u672c\u200b\uff1b</p>"},{"location":"AI/Paper_Reading/LM/Model_Analysis/Classifier/index.html#_1","title":"\u6307\u6807","text":"<ol> <li> <p>\u200b\u663e\u8457\u6027\u200b\u5206\u6570\u200b\uff08Attention\u200b\u77e9\u9635\u200b\u7684\u200b\u4e00\u9636\u200b\u6cf0\u52d2\u200b\u5c55\u5f00\u200b\uff09</p> \\[I_l=\\sum_h\\lvert A^T_{h,l}\\frac{\\partial \\mathcal{L}(x)}{\\partial A_{h,l}} \\rvert\\] <p>\\(l\\) \u200b\u8868\u793a\u200bTransformer \u200b\u5177\u4f53\u200b\u7684\u200b\u5c42\u200b \\(h\\) \u200b\u8868\u793a\u200b <code>attention</code> \u200b\u7684\u200b <code>#heads</code> \\(I_l(i, j)\\) \u200b\u8868\u793a\u200b \\(l\\text{-th}\\) \u200b\u5c42\u4e2d\u200b\u4f4d\u7f6e\u200b \\(j\\) \u200b\u81f3\u200b\u4f4d\u7f6e\u200b \\(i\\) \u200b\u7684\u200b\u4fe1\u606f\u6d41\u200b\u91cd\u8981\u6027\u200b</p> </li> <li> <p>\u200b\u6587\u672c\u200b\u5185\u5bb9\u200b\u81f3\u200b\u6807\u7b7e\u200b\u8bcd\u200b\u4fe1\u606f\u6d41\u200b\u91cd\u8981\u6027\u200b\u5747\u503c\u200b \\(S_{wp}\\)</p> \\[ \\begin{aligned}     &amp; S_{wp}=\\frac{\\sum_{(i, j) \\in C_{wp}} I_l{(i, j)}}{\\lvert C_{wp} \\rvert} \\\\     &amp; C_{wp} = \\{(p_k, j): k \\in [1, C], j &lt; p_k\\} \\end{aligned} \\] </li> <li> <p>\u200b\u6807\u7b7e\u200b\u8bcd\u81f3\u200b\u5206\u7c7b\u200b\u6807\u7b7e\u200b\u4fe1\u606f\u6d41\u200b\u91cd\u8981\u6027\u200b\u5747\u503c\u200b \\(S_{pq}\\)</p> \\[ \\begin{aligned}     &amp; S_{pq} = \\frac{\\sum_{(i, j) \\in C_{pq}} I_l{(i, j)}}{\\lvert C_{pq} \\rvert} \\\\     &amp; C_{pq}= \\{(q, p_k): k \\in [1, C]\\}  \\end{aligned} \\] </li> <li> <p>\u200b\u9664\u53bb\u200b\u4e0a\u8ff0\u200b\u4e24\u79cd\u200b\u5916\u200b\u6240\u6709\u200b\u8bcd\u200b\u4fe1\u606f\u6d41\u200b\u91cd\u8981\u6027\u200b\u5747\u503c\u200b \\(S_{ww}\\)</p> \\[ \\begin{aligned}     &amp; S_{ww} = \\frac{\\sum_{(i, j) \\in C_{ww}} I_l{(i, j)}}{\\lvert C_{ww} \\rvert} \\\\     &amp; C_{ww} = \\{(i, j):j \\lt i\\} - C_{wp} - C_{pq} \\end{aligned} \\] </li> </ol>"},{"location":"AI/Paper_Reading/LM/Model_Analysis/Classifier/index.html#h1h2","title":"\u9a8c\u8bc1\u200b\u5047\u8bbe\u200bH1\u3001H2","text":"<ul> <li>\\(S_{wp}\\) \u200b\u5728\u200b\u6d45\u5c42\u200b\u91cd\u8981\u6027\u200b\u9ad8\u200b\uff0c\\(S_{pq}\\) \u200b\u5728\u200b\u6df1\u5c42\u200b\u91cd\u8981\u6027\u200b\u9ad8\u200b</li> <li>\\(S_{wp}\\) \u200b\u548c\u200b \\(S_{pq}\\) \u200b\u91cd\u8981\u6027\u200b\u90fd\u200b\u6bd4\u200b \\(S_{ww}\\) \u200b\u9ad8\u200b</li> </ul>"},{"location":"AI/Paper_Reading/LM/Model_Analysis/Classifier/index.html#h1","title":"\u8fdb\u4e00\u6b65\u200b\u9a8c\u8bc1\u200b\u5047\u8bbe\u200bH1","text":"<p>\u200b\u622a\u65ad\u200b\u524d\u200b/\u200b\u540e\u200b5\u200b\u5c42\u200b\u4fe1\u606f\u6d41\u200b\u524d\u540e\u200b\u6548\u679c\u200b\u524d\u540e\u200b\u5bf9\u6bd4\u200b</p> <ul> <li>isolate label words: \\(A_l(p, i)=0, i\\lt p\\)</li> <li>isolate random non-label: \u200b\u622a\u65ad\u200b#C\u200b\u4e2a\u200b\u975e\u200b\u6807\u7b7e\u200b\u8bcd\u95f4\u200b\u7684\u200b\u4fe1\u606f\u6d41\u200b\uff0c\u200b\u7c7b\u4f3c\u200b\u4e8e\u200bMASK</li> <li>label loyality: \u200b\u524d\u540e\u200b\u8f93\u51fa\u200b\u6807\u7b7e\u200b\u4e00\u81f4\u6027\u200b</li> <li>word loyality: \u200b\u524d\u540e\u200b\u8f93\u51fa\u200btop-5\u200b\u7684\u200bJaccard similarity \\(J(A, B)=\\lvert A \\cap B \\rvert / \\lvert A \\cup B \\rvert\\)</li> </ul> <ul> <li>\u200b\u6d88\u878d\u200b\u5b9e\u9a8c\u200b\u8868\u660e\u200b\u622a\u65ad\u200b\u6d45\u5c42\u200b\u4fe1\u606f\u6d41\u200b\u6a21\u578b\u200b\u6548\u679c\u200b\u6709\u200b\u660e\u663e\u200b\u5f71\u54cd\u200b\uff0c\u200b\u4e14\u200b\u5728\u200b\u968f\u7740\u200b\u622a\u65ad\u200b\u5c42\u6570\u200b\u589e\u52a0\u200b\uff0c\u200b\u6548\u679c\u200b\u6301\u7eed\u200b\u4e0b\u964d\u200b</li> <li>\u200b\u6d88\u878d\u200b\u5b9e\u9a8c\u200b\u8868\u660e\u200b\u622a\u65ad\u200b\u6df1\u5c42\u200b\u4fe1\u606f\u6d41\u200b\u6a21\u578b\u200b\u6548\u679c\u200b\u5f71\u54cd\u200b\u4e0d\u200b\u5927\u200b\uff0c\u200b\u5373\u4f7f\u200b\u622a\u65ad\u200b\u7684\u200b\u5c42\u6570\u200b\u76f8\u5bf9\u200b\u8f83\u200b\u591a\u200b</li> <li>\u200b\u622a\u65ad\u200b\u6807\u7b7e\u200b\u8bcd\u200b\u7684\u200b\u4fe1\u606f\u63d0\u53d6\u200b\u6d41\u6bd4\u975e\u200b\u6807\u7b7e\u200b\u8bcd\u200b\u7684\u200b\u4fe1\u606f\u6d41\u200b\u5f71\u54cd\u200b\u66f4\u5927\u200b</li> </ul>"},{"location":"AI/Paper_Reading/LM/Model_Analysis/Classifier/index.html#h2","title":"\u8fdb\u4e00\u6b65\u200b\u9a8c\u8bc1\u200b\u5047\u8bbe\u200bH2","text":"<p>\u200b\u52a8\u673a\u200b\uff1a\u200b\u53d1\u73b0\u200b\u73b0\u8c61\u200b\u5e76\u200b\u63d0\u51fa\u200b\u5148\u9a8c\u200b\u6027\u200b\u5047\u8bbe\u200b \\(A_L=\\sum_h {A_{hl}}\\) \u200b\u4e2d\u200b\u7684\u200b\u6807\u7b7e\u200b\u8bcd\u200b\u4f4d\u7f6e\u200b\u81f3\u200b\u5206\u7c7b\u200b\u7c7b\u522b\u200b\u4f4d\u7f6e\u200b\u5904\u200b\u7684\u200b\u4fe1\u606f\u6d41\u200b\u4e0e\u200b\u8f93\u51fa\u200b\u6807\u7b7e\u200b\u5f3a\u200b\u76f8\u5173\u200b\uff0c\u200b\u5373\u200b \\(A_l(q, p_1), ..., A_l(q, p_C) \\backsim p_{f1}, ..., p_{fC}\\) \u3002</p> <p>GPT-XL\u200b\u4e0a\u200b\u7684\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\uff1a$\\text{AUCORC}_l$ \u200b\u548c\u200b $R_l$ </p> <p>GPT-J\u200b\u4e0a\u200b\u7684\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\uff1a$\\text{AUCORC}_l$ \u200b\u548c\u200b $R_l$ </p> <ul> <li>\\(\\text{AUCORC}_l\\)\uff1a\\(l\\text{-th}\\) \u200b\u5c42\u200b \\(A_l(q, p_i)\\) \u200b\u4e0e\u200b\u8f93\u51fa\u200b\u6807\u7b7e\u200b\u7684\u200b\u76f8\u5173\u6027\u200b\u7684\u200bROC\u200b\u503c\u200b</li> <li>\\(R_l=\\frac{\\sum_{i=1}^{l}(\\text{AUCROC}_i - 0.5)}{\\sum_{i=1}^{N}(\\text{AUCROC}_i - 0.5)}\\) \u200b\u8868\u793a\u200b\u524d\u200b \\(l\\) \u200b\u5c42\u200b\u5bf9\u6a21\u578b\u200b\u8f93\u51fa\u200b\u5f71\u54cd\u200b\u5360\u200b\u6bd4\u200b</li> </ul> <p>\u200b\u7ed3\u8bba\u200b\uff1a</p> <ul> <li>\u200b\u6d45\u5c42\u200b\u5bf9\u6a21\u578b\u200b\u8f93\u51fa\u200b\u5f71\u54cd\u200b\u5360\u200b\u6bd4\u8f83\u200b\u5c0f\u200b</li> <li>\u200b\u968f\u7740\u200b\u5c42\u6570\u200b\u589e\u52a0\u200b\uff08&gt;middle\uff09\uff0c\\(R_l\\)\u200b\u589e\u5927\u200b\u8f83\u4e3a\u200b\u660e\u663e\u200b\uff0c\u200b\u8868\u73b0\u200b\u4e3a\u200b\u6df1\u5c42\u200b\u5bf9\u6a21\u578b\u200b\u8f93\u51fa\u200b\u5f71\u54cd\u200b\u8f83\u5927\u200b</li> <li>\u200b\u9a8c\u8bc1\u200b\u7ed3\u8bba\u200b\uff1a\\(A_L=\\sum_h {A_{hl}}\\) \u200b\u4e2d\u200b\u7684\u200b\u6807\u7b7e\u200b\u8bcd\u200b\u4f4d\u7f6e\u200b\u81f3\u200b\u5206\u7c7b\u200b\u7c7b\u522b\u200b\u4f4d\u7f6e\u200b\u5904\u200b\u7684\u200b\u4fe1\u606f\u6d41\u200b\u4e0e\u200b\u8f93\u51fa\u200b\u6807\u7b7e\u200b\u5f3a\u200b\u76f8\u5173\u200b\uff0c\u200b\u5373\u200b \\(A_l(q, p_1), ..., A_l(q, p_C) \\backsim p_{f1}, ..., p_{fC}\\) </li> </ul>"},{"location":"AI/Paper_Reading/LM/Model_Analysis/Classifier/index.html#application","title":"Application","text":"<p>\u200b\u57fa\u4e8e\u200b\u7ed3\u8bba\u200b\uff0c\\(A_L=\\sum_h {A_{hl}}\\) \u200b\u4e2d\u200b\u7684\u200b\u6807\u7b7e\u200b\u8bcd\u200b\u4f4d\u7f6e\u200b\u81f3\u200b\u5206\u7c7b\u200b\u7c7b\u522b\u200b\u4f4d\u7f6e\u200b\u5904\u200b\u7684\u200b\u4fe1\u606f\u6d41\u200b\u4e0e\u200b\u8f93\u51fa\u200b\u6807\u7b7e\u200b\u5f3a\u200b\u76f8\u5173\u200b\uff0c\u200b\u5373\u200b \\(A_l(q, p_1), ..., A_l(q, p_C) \\backsim p_{f1}, ..., p_{fC}\\) \uff0c\u200b\u8fdb\u884c\u200b\u4e86\u200b\u4ee5\u4e0b\u200b\u6df1\u5165\u7814\u7a76\u200b</p>"},{"location":"AI/Paper_Reading/LM/Model_Analysis/Classifier/index.html#anchor-reweighting-method","title":"Anchor Reweighting Method","text":"<p>\u200b\u52a8\u673a\u200b\uff1a</p> \\[ \\begin{aligned} \\text{P}_f(Y=i|X=x) &amp;\\approx A(q, p_i) \\\\  &amp;=\\frac{\\text{exp}(q_qk_{p_i}^T/\\sqrt{d})}{\\sum_{j=1}^{seq\\_len}\\text{exp}(q_qk_{j}^T/\\sqrt{d})}  \\\\ \\end{aligned} \\] \\[ \\begin{aligned}  \\log \\frac{\\text{P}_f(Y=i|X=x)}{\\text{P}_f(Y=C|X=x)} &amp;= (k_{p_i} - k_{p_C})^Tq_q/\\sqrt{d} \\\\  &amp;\\Rightarrow \\beta_0^i + (k_{p_i} - k_{p_C})^Tq_q/\\sqrt{d} \\\\  \\hat{A}(q, p_i)&amp;=\\exp(\\beta_0^i)A(q, p_i) \\end{aligned} \\] <p>Attention Variant\uff1a\u200b\u5bf9\u4e8e\u200b\u6bcf\u5c42\u200b\u6bcf\u4e2a\u200bhead\uff0c\u200b\u8bbe\u8ba1\u200b\u4e00\u4e2a\u200blearnable\u200b\u53c2\u6570\u200b \\(\\beta_{hl} \\in \\mathbb{R}^C\\)</p> <p>\u200b\u9664\u200bcross-entropy\u200b\u5916\u200b\uff0c\u200b\u65b0\u589e\u200b\u4ee5\u4e0b\u200b\u8f85\u52a9\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u6765\u200b\u7ebf\u6027\u200b\u8c03\u6574\u200b\u5404\u200b\u6837\u672c\u200b\u6807\u7b7e\u200b\u91cd\u8981\u6027\u200b</p> \\[ \\beta^* = \\arg \\min_{\\beta}\\mathcal{L}(X_{train}, Y_{train}) \\] <p>few-shot\u200b\u573a\u666f\u200b\u4e0b\u200b\u6548\u679c\u200b\u4f18\u5316\u200b\u660e\u663e\u200b</p>"},{"location":"AI/Paper_Reading/LM/Model_Analysis/Classifier/index.html#demonstrations-compression","title":"Demonstrations Compression","text":"<p>AR\u200b\u6a21\u578b\u200b\u662f\u200b\u5355\u5411\u200b\u7684\u200b\uff0c\u200b\u5bf9\u4e8e\u200bPrompt\uff1a(Num*C) demonstrations + input_to_be_predicted\u200b\u7684\u200b\u524d\u534a\u90e8\u200b\u5206\u200b \u200b\u5176\u5b9e\u200b\u662f\u200b\u56fa\u5b9a\u200b\u7684\u200b\uff0c\u200b\u6ca1\u6709\u200b\u5fc5\u8981\u200b\u91cd\u590d\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u5904\u4e8e\u200b\u6027\u80fd\u200b\u8003\u91cf\u200b\uff0c\u200b\u8fdb\u884c\u200b\u4e86\u200b\u538b\u7f29\u200b\u3002\u200b\u5b9e\u9a8c\u200b\u5bf9\u6bd4\u200b\u5305\u62ec\u200b</p> <ul> <li>\\(\\text{Hidden}_{anchor}\\)\uff1a\u200b\u4e0d\u200b\u9700\u8981\u200b(Num*C) demonstrations\uff0c\u200b\u5728\u200b\u6bcf\u5c42\u200b\u7684\u200bhidden state\u200b\u524d\u200b\u8fde\u63a5\u200b\u5df2\u200b\u8ba1\u7b97\u200b\u597d\u200b\u7684\u200bC\u200b\u4e2a\u200b \"formating + label\" \u200b\u7684\u200bhidden state\uff0c\u200b\u5176\u4e2d\u200bformating\uff08\u200b\u5982\u200bSST-2\u200b\u4e2d\u200b\u7684\u200bSentiment:\uff09\u200b\u4fe1\u606f\u200b\u80fd\u591f\u200b\u5e2e\u52a9\u200b\u6a21\u578b\u200b\u786e\u5b9a\u200b\u8f93\u51fa\u200b\u7a7a\u95f4\u200b</li> <li>\\(\\text{Text}_{anchor}\\)\uff1a\u200b\u5c06\u200b(Num*C) demonstrations\u200b\u6539\u4e3a\u200b\u5bf9\u5e94\u200b\u7684\u200bC\u200b\u4e2a\u200b\"formating + label\"</li> <li>\\(\\text{Hidden}_{random}\\)\uff1a\u200b\u4e0e\u200b\\(\\text{Hidden}_{anchor}\\) \u200b\u7684\u200b\u533a\u522b\u200b\u5728\u4e8e\u200b\u8be5\u200b\u65b9\u6848\u200b\u8fde\u63a5\u200b\u7684\u200b\u662f\u200bC\u200b\u4e2a\u200b\"formatting + random non-label word\"</li> <li>\\(\\text{Hidden}_{random-top}\\)\uff1a\u200b\u968f\u673a\u200b\u4e86\u200b20\u200b\u4e2a\u200b\\(\\text{Hidden}_{random}\\)\u200b\u5e76\u53d6\u200b\u4e86\u200b\u6700\u597d\u200b\u7684\u200b\u7ed3\u679c\u200b</li> </ul> <ul> <li>\u200b\u8fdb\u4e00\u6b65\u200b\u786e\u8bc1\u200b\u6807\u7b7e\u200b\u8bcd\u200b\u63d0\u53d6\u200b\u4e86\u200b\u91cd\u8981\u200b\u7684\u200b\u8bed\u4e49\u200b\u4fe1\u606f\u200b                     </li> <li>\u200b\u6a21\u578b\u200b\u8d8a\u5927\u200b\uff0c\u200b\u52a0\u901f\u200b\u6548\u679c\u200b\u8d8a\u200b\u660e\u663e\u200b\uff1b\u200b\u88ab\u200b\u538b\u7f29\u200b\u7684\u200b\u6587\u672c\u200b\u957f\u5ea6\u200b\u8d8a\u957f\u200b\uff0c\u200b\u52a0\u901f\u200b\u6548\u679c\u200b\u8d8a\u200b\u660e\u663e\u200b</li> <li>demonstartion compression\u200b\u65b9\u6cd5\u200b\u80fd\u591f\u200b\u63d0\u5347\u200b\u6a21\u578b\u200b\u6027\u80fd\u200b\u4e14\u200b\u6548\u679c\u200b\u4e0b\u964d\u200b\u5f71\u54cd\u200b\u4e0d\u200b\u5927\u200b</li> </ul>"},{"location":"AI/Paper_Reading/LM/Model_Category/index.html","title":"\u6a21\u578b\u200b\u79cd\u7c7b","text":""},{"location":"AI/Paper_Reading/LM/Model_Category/index.html#ae","title":"AE","text":"<p>Auto-Encoder\u200b\u662f\u200b\u4e00\u79cd\u200b \u200b\u5bf9\u200b\u672a\u200b\u6807\u6ce8\u200b\u6570\u636e\u200b\u8fdb\u884c\u200b\u65e0\u200b\u76d1\u7763\u200b\u5b66\u4e60\u200b \u200b\u5f97\u5230\u200b\u76f8\u5e94\u200b\u7f16\u7801\u8868\u793a\u200b\u7684\u200b\u795e\u7ecf\u7f51\u7edc\u200b\u3002\u200b\u6574\u4f53\u200b\u662f\u200b\u4e00\u4e2a\u200b\u52a0\u5bc6\u200b\u518d\u200b\u91cd\u6784\u200b\u7684\u200b\u8fc7\u7a0b\u200b\uff0c\u200b\u5373\u200b\\(p,q=\\arg \\min_{p,q} \\Vert X - p[q(X)]\\Vert\\)\uff0c\u200b\u5305\u542b\u200b\u4e24\u4e2a\u200b\u90e8\u5206\u200b\uff1a</p> <ol> <li>encoder\uff1a\u200b\u5bf9\u200b\u8f93\u5165\u200b\u6570\u636e\u200b\u8fdb\u884c\u200b\u52a0\u5bc6\u200b\u8f6c\u6362\u200b\uff08\u200b\u9ad8\u7eac\u5ea6\u200b \u2192 \u200b\u4f4e\u7eac\u5ea6\u200b\u7684\u200bbottleneck\uff09</li> <li>decoder\uff1a\u200b\u5bf9\u200b\u52a0\u5bc6\u200b\u8f6c\u6362\u200b\u7684\u200b\u6570\u636e\u200b\u8fdb\u884c\u200b\u89e3\u7801\u200b\u8fd8\u539f\u200b\uff08\u200b\u4f4e\u7eac\u5ea6\u200b\u7684\u200bbottleneck \u2192 \u200b\u9ad8\u7eac\u5ea6\u200b\uff09</li> </ol> <p>AE\u200b\u7f51\u7edc\u200b\u793a\u610f\u200b</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/index.html#dae","title":"DAE","text":"<p>Denoising Auto-Encoder \u200b\u5728\u200bAE\u200b\u6a21\u578b\u200b\u57fa\u7840\u200b\u4e0a\u200b\u52a0\u5165\u200b\u566a\u58f0\u200b\u8fdb\u884c\u200b\u8fd8\u539f\u200b\uff0c\u200b\u8d1f\u91cd\u200b\u8bad\u7ec3\u200b\u63d0\u5347\u200b\u6a21\u578b\u200b\u9c81\u68d2\u6027\u200b</p> <ol> <li> <p>replace\uff1a\u200b\u5bf9\u200b\u8f93\u5165\u200b\u8fdb\u884c\u200b\u52a0\u566a\u200b</p> <ul> <li>MASK\uff1atoken sequence \u200b\u6216\u200b char image pixel</li> <li>ELECTRA\u200b\u6a21\u5f0f\u200b <p>ELECTRA\u200b\u7f51\u7edc\u200b\u793a\u610f\u200b</p> </li> <li>token sentnece repentation + white noise\uff1a\u200b\u5c06\u200b\u79bb\u6563\u200b\u7684\u200btoken\u200b\u589e\u52a0\u200b\u8fde\u7eed\u200b\u7684\u200b\u6270\u52a8\u200b</li> <li>char image + perturbations\uff1ae.g., \u200b\u767d\u200b\u566a\u58f0\u200b, \u200b\u51e0\u4f55\u53d8\u6362\u200b (\u200b\u65cb\u8f6c\u200b, \u200b\u7f29\u653e\u200b, \u200b\u5e73\u79fb\u200b\uff0c\u200b\u7578\u53d8\u200b\uff0c\u200b\u7b49\u200b)\uff0c\u200b\u5176\u4e2d\u200b\u5e38\u7528\u200b\u7684\u200b\u7578\u53d8\u200b\u64cd\u4f5c\u200b\u6709\u200b\u2460\u200b\u540c\u4e00\u200b\u5b57\u7b26\u200b\u7684\u200b\u4e0d\u540c\u200b\u5b57\u4f53\u200b\u8868\u8ff0\u200b\uff1b\u2461\u200b\u76f8\u4f3c\u200b\u5b57\u7b26\u200b\uff0c\u200b\u5982\u200bE\u200b\u548c\u200b\u03b5\uff1b\u2462\u200b\u4f7f\u7528\u200b\u6a21\u578b\u200b\u76f4\u63a5\u200b\u5bf9\u200b\u5b57\u7b26\u200b\u8fdb\u884c\u200b\u7578\u53d8\u200b</li> </ul> </li> <li> <p>insert\uff1a\u200b\u5bf9\u200b\u8f93\u5165\u200b\u8fdb\u884c\u200b\u52a0\u566a\u200b</p> <ul> <li>token sequence\u200b\u4e2d\u200b\u63d2\u5165\u200b\u6807\u70b9\u200b\u3001\u200b\u5b57\u7b26\u200b\u3001\u200b\u7a7a\u683c\u200b\u3001\u200b\u8868\u60c5\u200b\u7b49\u200b \u200b\u4e0d\u200b\u5f71\u54cd\u200b\u8bed\u4e49\u200b \u200b\u7684\u200b\u7279\u6b8a\u5b57\u7b26\u200b</li> </ul> </li> <li> <p>Dropout\uff1a\u200b\u5bf9\u6a21\u578b\u200b\u4e2d\u95f4\u200b\u7684\u200b\u6f5c\u5728\u200b\u8868\u793a\u200b\u8fdb\u884c\u200b\u52a0\u566a\u200b</p> <ul> <li>standard dropout\uff1a[seq_len, dim] \u200b\u6240\u6709\u200b\u503c\u200b\u72ec\u7acb\u200bdropout</li> <li>spatial dropout\uff1a[seq_len, dim] \u200b\u4ee5\u200bchannel\u200b\u7ef4\u5ea6\u200b\u7684\u200b\u503c\u200b\u4e3a\u200b\u5355\u4f4d\u200b\u8fdb\u884c\u200bdropout</li> </ul> </li> </ol> <p>standard dropout</p> <p>spatial dropout</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/index.html#vae","title":"VAE","text":"<p>AE\u200b\u6a21\u578b\u200b\u867d\u7136\u200b\u80fd\u591f\u200b\u5b66\u4e60\u200b\u5230\u200b\u8f93\u5165\u200b\u5185\u5bb9\u200b\u7684\u200brepresentation\uff0c\u200b\u4f46\u662f\u200b\u5176\u200b\u5404\u81ea\u200b\u7684\u200b\u7f16\u7801\u200b\u7a7a\u95f4\u200b\u8f83\u4e3a\u200b\u79bb\u6563\u200b\uff08\u200b\u5982\u200b\u6587\u672c\u200b\u201c\u200b\u4e2d\u56fd\u200b\u201d\u200b\u548c\u200b\u201c\u200b\u4e2d\u200b\uff0c\uff0c\uff0c\uff0c\u200b\u56fd\u200b\u201d\u200b\u7684\u200b\u5411\u91cf\u200b\u7a7a\u95f4\u200b\u8ddd\u79bb\u200b\u53ef\u80fd\u200b\u8f83\u5927\u200b\uff0c\u200b\u53c8\u200b\u6216\u200b\u3010\u200b\u534a\u6708\u200b\u3011\u200b\u548c\u200b\u3010\u200b\u6ee1\u6708\u200b\u3011\u200b\u7684\u200b\u56fe\u7247\u200b\u5411\u91cf\u200b\u7a7a\u95f4\u200b\u8ddd\u79bb\u200b\u4e5f\u200b\u53ef\u80fd\u200b\u8f83\u5927\u200b\uff09\u3002</p> <p>\u200b\u800c\u200b\u53d8\u5206\u200b\u81ea\u200b\u7f16\u7801\u5668\u200bVariational Auto-Encoder\u200b\u901a\u8fc7\u200bencoder\u200b\u5b66\u4e60\u200b\u8f93\u5165\u200b\u7684\u200b\u4e2d\u95f4\u200b\u8868\u793a\u200b\u5206\u5e03\u200b \\((\\mu, \\sigma)\\)\uff0c\u200b\u968f\u540e\u200b\u57fa\u4e8e\u200b\u5206\u5e03\u200b\u8fdb\u884c\u200b\u91c7\u6837\u200b\\(\\mu + \\sigma*e\\)\u200b\u518d\u200b\u8f93\u5165\u200b\u5230\u200bdecoder\u200b\u8fdb\u884c\u200b\u89e3\u7801\u200b\uff0c\u200b\u6700\u7ec8\u200b\u5b66\u4e60\u200b\u5230\u200b\u66f4\u52a0\u200b\u590d\u6742\u200b\u4e14\u200b\u4e30\u5bcc\u200b\u7684\u200brepresentation</p> <p>VAE\u200b\u7f51\u7edc\u200b\u793a\u610f\u200b</p> <ul> <li>\\(m\\)\uff1a\u200b\u9884\u6d4b\u200b\u7684\u200b\u4e2d\u95f4\u200b\u5411\u91cf\u200b\u8868\u793a\u200b\u7684\u200b\u5747\u503c\u200b\\(\\mu\\)</li> <li>\\(\\sigma\\)\uff1a\u200b\u9884\u6d4b\u200b\u7684\u200b\u4e2d\u95f4\u200b\u5411\u91cf\u200b\u8868\u793a\u200b\u7684\u200b\u6807\u51c6\u5dee\u200b\u53d6\u200b\u5bf9\u6570\u200b\\(\\log\\sigma\\)</li> <li>\\(e\\)\uff1a\u200b\u4ece\u200b\u6807\u51c6\u200b\u6b63\u6001\u5206\u5e03\u200b\u4e2d\u200b\u91c7\u6837\u200b\u7684\u200b\u968f\u673a\u6570\u200b</li> <li>\\(L_1\\)\uff1a\\(D_{KL}( q(z|x)\\Vert \\mathcal{N})\\)\uff0c\u200b\u7528\u4e8e\u200b\u89c4\u8303\u200b\u9884\u6d4b\u200b\u7684\u200b\u566a\u58f0\u200b\u5e94\u200b\u8d8b\u8fd1\u200b\u4e8e\u200b\u52a0\u5165\u200b\u7684\u200b\u566a\u58f0\u200b\u5206\u5e03\u200b\uff08\u200b\u767d\u200b\u566a\u58f0\u200b\uff09</li> <li>\\(L_2\\)\uff1a\u200b\u91cd\u6784\u200b\u635f\u5931\u200b\uff0c\u200b\u5982\u200bCross-Entropy</li> <li>\u200b\u672c\u8d28\u200b\u4e0a\u200b\u4e5f\u200b\u662f\u200b\u5bf9\u6a21\u578b\u200b\u4e2d\u95f4\u200b\u7684\u200b\u6f5c\u5728\u200b\u8868\u793a\u200b\u8fdb\u884c\u200b\u52a0\u566a\u200b</li> </ul> <p>https://arxiv.org/pdf/1312.6114v10</p> <ul> <li>VAE in nlp</li> </ul>"},{"location":"AI/Paper_Reading/LM/Model_Category/index.html#cvae","title":"CVAE","text":"<p>VAE\u200b\u5b58\u5728\u200b\u4e00\u4e2a\u200b\u95ee\u9898\u200b\uff0c\u200b\u5373\u200b\u65e0\u6cd5\u200b\u6307\u5b9a\u200b\u751f\u6210\u200b\u6307\u5b9a\u200b\u7684\u200b\u76ee\u6807\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5c31\u200b\u4ea7\u751f\u200b\u4e86\u200b\u6761\u4ef6\u200b\u53d8\u5206\u200b\u81ea\u200b\u7f16\u7801\u5668\u200bConditional Variational Auto-Encoder\uff0c\u200b\u5176\u200bencoder\u200b\u548c\u200bdecoder\u200b\u6709\u200b\u989d\u5916\u200b\u7684\u200b\u8f93\u5165\u200b\u2014\u2014\u200b\u6807\u7b7e\u200b \\(one\\_hot\\_y\\)</p> <p>CVAE\u200b\u7f51\u7edc\u200b\u793a\u610f\u200b</p> <p>infer\u200b\u65f6\u200b encoder\u200b\u8f93\u5165\u200b\u4e3a\u200b[randn(dim, ), label]</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/index.html#vqvae","title":"VQVAE","text":"<p>\u200b\u901a\u5e38\u200b\u5728\u200bAE \\(p[q(x)]=p(z)\\) \u200b\u4e2d\u200b\uff0c\u200b\u6211\u4eec\u200b\u53ea\u80fd\u200b\u770b\u5230\u200b\u539f\u59cb\u6570\u636e\u200b \\(x\\)\uff0c\u200b\u65e0\u6cd5\u200b\u77e5\u6653\u200b \\(z\\)\uff0c\u200b\u8fd9\u200b\u4e5f\u200b\u662f\u200b\u5176\u200b\u4e3a\u4ec0\u4e48\u200b\u79f0\u4e3a\u200b\u6570\u636e\u200b\u7684\u200b\u6f5c\u5728\u200b\u8868\u793a\u200b\u3002\u200b\u7136\u800c\u200b\u6211\u4eec\u200b\u5e0c\u671b\u200b\u5f97\u5230\u200b \\(z\\)\uff0c\u200b\u56e0\u4e3a\u200b\u5b83\u200b\u662f\u200b\u6570\u636e\u200b\u66f4\u200b\u57fa\u7840\u200b\u4e14\u200b\u538b\u7f29\u200b\u7684\u200b\u8868\u793a\u200b\u3002\u200b\u53e6\u5916\u200b\uff0c\u200b\u6f5c\u5728\u200b\u8868\u793a\u200b \\(z\\) \u200b\u662f\u200b\u5f88\u591a\u200b\u7b97\u6cd5\u200b\u5f88\u200b\u6709\u7528\u200b\u7684\u200b\u8f93\u5165\u200b\u3002</p> <p>\u200b\u7406\u60f3\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u6211\u4eec\u200b\u5e0c\u671b\u200b\u9690\u200b\u7a7a\u95f4\u200b\u4e2d\u200b\u8bed\u4e49\u200b\u76f8\u4f3c\u200b\u7684\u200b\u6570\u636e\u200b\u70b9\u200b\u5f7c\u6b64\u200b\u76f8\u90bb\u200b\uff0c\u200b\u800c\u200b\u8bed\u4e49\u200b\u4e0d\u540c\u200b\u7684\u200b\u70b9\u200b\u5f7c\u6b64\u200b\u8fdc\u79bb\u200b\u3002\u200b\u6700\u597d\u200b\u7684\u200b\u60c5\u51b5\u200b\u662f\u200b\uff0c\u200b\u5927\u90e8\u5206\u200b\u6570\u636e\u5206\u5e03\u200b\u5728\u200b\u9690\u200b\u7a7a\u95f4\u200b\u4e2d\u200b\u6784\u6210\u200b\u7d27\u51d1\u200b\u7684\u200b\u7a7a\u95f4\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u65e0\u9650\u5927\u200b\u3002\u200b\u53d8\u200b\u5206\u91cf\u200b\u5316\u81ea\u200b\u7f16\u7801\u5668\u200bVector Quantized Variational Auto-Encoder \u200b\u901a\u8fc7\u200b\u5411\u200b\u7f51\u7edc\u200b\u6dfb\u52a0\u200b\u79bb\u6563\u200b\u7684\u200b codebook \u200b\u7ec4\u4ef6\u200b\u6765\u200b\u6269\u5c55\u200b\u6807\u51c6\u200b\u81ea\u200b\u7f16\u7801\u5668\u200b\u3002</p> <p>VQ-VAE\u200b\u7f51\u7edc\u200b\u793a\u610f\u200b</p> <p>\u200b\u901a\u8fc7\u200b\u5c06\u200b\u8fde\u7eed\u200b\u7684\u200b\u4e2d\u95f4\u200b\u6f5c\u5728\u200b\u8868\u793a\u200b\u79bb\u6563\u200b\u5316\u200b</p> <ol> <li>encoder\u200b\u8f93\u51fa\u200b\\(z_{e}(x) \\in (H, W, dim)\\)</li> <li>\\(z_{e}(x)\\) \u200b\u4e0e\u200b\\(codebook \\in (codebook\\_size, dim)\\) \u200b\u8fdb\u884c\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u5e76\u200b \u200b\u9009\u53d6\u200b\u540e\u8005\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\u6700\u9ad8\u200b\u7684\u200b\u7279\u5f81\u200b\u8fdb\u884c\u200b\u66ff\u200b \u200b\u6362\u200b\u5f97\u5230\u200b \\(z_q(x)\\in (H, W, dim)\\)</li> <li>\u200b\u8f93\u5165\u200bdecoder\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u91cd\u6784\u200b</li> </ol> <p>\u200b\u635f\u5931\u200b\u51fd\u6570\u200b \\(\\mathcal{L}=\\log{(p(x|q(x)))} + \\Vert \\text{sg}[z_e(x)]-e\\Vert^2_2 + \\beta\\Vert z_e(x)-\\text{sg}[e] \\Vert^2_2\\)</p> <ul> <li>\\(\\text{sg}\\) \u200b\u8868\u793a\u200bstop gradient\uff0c\u200b\u5373\u200b\u53cd\u5411\u200b\u68af\u5ea6\u200b\u8ba1\u7b97\u200b\u5230\u6b64\u4e3a\u6b62\u200b</li> <li>\u200b\u7b2c\u4e00\u9879\u200b\u4e3a\u200b\u91cd\u6784\u200b\u635f\u5931\u200b</li> <li>\u200b\u7b2c\u4e8c\u9879\u200b\u4e3a\u200bcodebook\u200b\u7684\u200b\u5bf9\u9f50\u200b\u635f\u5931\u200b\uff0c\u200b\u53ea\u200b\u66f4\u65b0\u200bcodebook</li> <li>\u200b\u7b2c\u4e09\u9879\u200b\u4e3a\u200bencoder\u200b\u5411\u200bcodebook\u200b\u9760\u8fd1\u200b\u7684\u200b\u635f\u5931\u200b\uff0c\u200b\u53ea\u200b\u66f4\u65b0\u200bencoder</li> </ul> <p>https://arxiv.org/pdf/1711.00937'</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/index.html#ar","title":"AR","text":"<p>Auto-Regressive\u200b\u6a21\u578b\u200b\u7684\u200b\u8f93\u51fa\u200b\u7ed3\u679c\u200b\u4f9d\u8d56\u4e8e\u200b\u5176\u81ea\u751f\u200b\u7684\u200b\u5148\u524d\u200b\u503c\u200b\uff08\u200b\u5982\u200bNLP\u200b\u4e2d\u200b\\(X_{1,...,t-1}\\)\uff09\u200b\u548c\u200b\u4e00\u4e9b\u200b\u5176\u5b83\u200b\u73af\u5883\u56e0\u7d20\u200b\u786e\u5b9a\u200b\u7684\u200b\uff0c\u200b\u6574\u4f53\u200b\u662f\u200b\u4e00\u4e2a\u200b\u8fed\u4ee3\u200b\u8f93\u51fa\u200b\u7684\u200b\u8fc7\u7a0b\u200b\u3002</p> <p>\u200b\u72ed\u4e49\u200b\u4e0a\u200b\u7684\u200bAR\u200b\u6a21\u578b\u200b\u8f93\u51fa\u200b\u7684\u200b\u662f\u200b\u7ebf\u6027\u200b\u7ed3\u679c\u200b\uff0c\u200b\u6240\u4ee5\u200bLLM\u200b\u7684\u200bAR\u200b\u6a21\u578b\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5e7f\u4e49\u200b\u7684\u200b\u79f0\u547c\u200b\u6982\u5ff5\u200b</p> <p>AR\u200b\u7f51\u7edc\u200b\u793a\u610f\u200b</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/index.html#difussion","title":"Difussion","text":""},{"location":"AI/Paper_Reading/LM/Model_Category/index.html#gan","title":"GAN","text":""},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/index.html","title":"Index","text":"<p>Diffusion \u200b\u6269\u6563\u200b\u6a21\u578b\u200b</p> <p>\u200b\u6269\u6563\u200b\u6a21\u578b\u200b\uff1a\u200b\u53c8\u200b\u903c\u771f\u200b\u53c8\u200b\u591a\u6837\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u662f\u200b\u5206\u5e03\u200b\u6a21\u578b\u200b\uff0c\u200b\u57fa\u4e8e\u200b\u91c7\u6837\u200b\u5448\u73b0\u200b\u591a\u6837\u6027\u200b</p> <ul> <li>\u200b\u9690\u200b\u53d8\u91cf\u200b</li> </ul> <p>GAN\uff1a\u200b\u903c\u771f\u200b\uff08\u200b\u4f18\u5316\u200b\u76ee\u6807\u200b\u4e3a\u200b\u4ee5\u5047\u4e71\u771f\u200b\uff09\u200b\u4f46\u200b\u4e0d\u200b\u591a\u6837\u200b</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/index.html#_1","title":"\u6269\u6563\u200b\u6a21\u578b","text":""},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/index.html#ddpm","title":"DDPM","text":"<ol> <li>DDPM</li> </ol>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/index.html#dall-e","title":"DALL-E","text":"<ol> <li>DALL-E-1</li> <li>DALL-E-2</li> <li>DALL-E-3</li> </ol>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/index.html#noise-scheduler","title":"Noise Scheduler","text":"<ol> <li>cosine</li> <li>linear</li> <li>quadratic</li> <li>jsd</li> <li>sigmoid</li> </ol> <p>DDPM\uff08Denoising Diffusion Probabilistic Models\uff09\uff0c\u200b\u5355\u6b65\u200b\uff0c\u200b\u5373\u200bx_t = f(x_{t-1})\uff0c\u200b\u65f6\u95f4\u200b\u6b65\u200bt-1\u200b\u65f6\u523b\u200b\u7684\u200b\u56fe\u50cf\u200b\u5206\u5e03\u200b\uff0c\u200b\u91c7\u6837\u200b\u5f97\u5230\u200bx_{t-1}</p> <p>DDIM\uff1a\u200b\u76f4\u63a5\u200b\u03b5_{t-1} = f(x_0, x_t)</p> <p>spherical interpolation\uff1a\u200b\u7403\u9762\u200b\u7ebf\u6027\u63d2\u503c\u200b</p> <p>improved DDPM</p> <p>diffusion beats gan</p> <p>glide\u200b\u6a21\u578b\u200b\u3001classifier guided diffusion\u3001classifier free guidence</p> <p>\uff08\u200b\u9884\u6d4b\u200b\u65f6\u200b\u53ea\u200b\u9700\u8981\u200b\uff09Dalle-2\u200b\u4e24\u200b\u9636\u6bb5\u200b\uff08\u200b\u6d4b\u8bd5\u200b\u53d1\u73b0\u200b\u4e24\u200b\u9636\u6bb5\u200b\u6bd4\u200b\u76f4\u63a5\u200b\u751f\u6210\u200b\u6548\u679c\u200b\u597d\u200b\u5f88\u591a\u200b\uff09\uff1a 1. prior\u200b\u6a21\u578b\u200b\uff0c\u200b\u901a\u8fc7\u200b \\(y\\) \u200b\u7684\u200b \\(z_t\\) \u200b\u6765\u200b\u5b66\u4e60\u200b\u9884\u6d4b\u200b\u5bf9\u5e94\u200b\u7684\u200b \\(z_i\\)    - text_eocoding + text_representation + noise_image_representation + learn_query(\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b[CLS]) -- predict --&gt; image_representation 2. decoder\uff0c\u200b\u6839\u636e\u200b \\(z_i\\)\uff08\u200b\u53ef\u200b\u9009\u62e9\u200b\u662f\u5426\u200b\u4f7f\u7528\u200b\u6587\u672c\u200b\u4fe1\u606f\u200b \\(y\\) or \\(z_t\\)\uff09\uff0c\u200b\u7ea7\u8054\u200b\u5f0f\u200b\u5730\u200b\u8fd8\u539f\u200b\u751f\u6210\u200b\u9ad8\u6e05\u200b\u56fe\u7247\u200b \\(x\\)    - embedding \u200b\u5206\u5272\u200b\uff0c\u200b\u5c06\u200b1d\u200b\u5206\u5272\u200b\u4e3a\u200bhd/h\uff08\u200b\u76f8\u5f53\u4e8e\u200b\u4e00\u4e2a\u200btoken\u200b\u7ec6\u5316\u200b\u4e3a\u200b\u591a\u4e2a\u200btoken\uff09\u200b\u53c2\u4e0e\u200bTransformer\uff0c\u200b\u66f4\u597d\u200b\u5730\u200b\u5bf9\u200b\u6bcf\u4e2a\u200b\u7ef4\u5ea6\u200b\u7ec6\u5316\u200b\u6743\u91cd\u200b</p> <p>AE\uff1amask x\u200b\u540e\u200b\u8f93\u5165\u200b\u81f3\u200b\u6a21\u578b\u200b\uff0c\u200b\u518d\u200b\u6839\u636e\u200b\u4e2d\u95f4\u200b\u7279\u5f81\u200b\u8fdb\u884c\u200bx\u200b\u7684\u200b\u8fd8\u539f\u200b</p> <p>DAE\uff1a\u200b\u8f83\u200bAE\u200b\u5728\u200bmasked_x\u200b\u4e0a\u52a0\u200b\u4e86\u200b\u566a\u58f0\u200b</p> <p>V(ariational)AE\uff1a\u200b\u4e0d\u518d\u200b\u662f\u200b\u5b66\u4e60\u200b\u7279\u5f81\u200b\uff0c\u200b\u800c\u662f\u200b\u5b66\u4e60\u200b\u9884\u6d4b\u200b\u6982\u7387\u200b\u7684\u200b\u5747\u503c\u200b\u548c\u200b\u65b9\u5dee\u200b\uff0c\u200b\u5f97\u5230\u200b\u5747\u503c\u200b\u548c\u200b\u65b9\u5dee\u200b\u91c7\u6837\u200b\u4e00\u4e2a\u200b\u4e2d\u95f4\u200b\u7279\u5f81\u200b\uff0c\u200b\u4ee5\u200b\u5b9e\u73b0\u200bx\u200b\u7684\u200b\u8fd8\u539f\u200b</p> <p>V(ector)Q(uantised)VAE\uff1aVAE\u200b\u91cf\u5316\u200b\uff0c\u200b\u5c06\u200b\u8fde\u7eed\u200b\u5206\u5e03\u200b\u79bb\u6563\u200b\u5316\u200b\uff08\u200b\u6bd4\u5982\u200b\u4e00\u4e2a\u200bcodebook \\(\\in K\\times D\\)\uff0c\u200b\u53ea\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b\u76ee\u6807\u200b\u5411\u91cf\u200b\uff08\u200b\u6bd4\u5982\u200b\u6700\u200b\u76f8\u4f3c\u200b\uff09\u200b\u4f5c\u4e3a\u200b\u8f93\u5165\u200b</p> <p>pixel cnn: \u200b\u7528\u200bcnn\u200b\u6765\u200b\u5b66\u4e60\u200b\u7279\u5f81\u200b,\u200b\u7136\u540e\u200b\u7528\u200bVAE\u200b\u6765\u200b\u751f\u6210\u200b\u56fe\u7247\u200b</p> <p>beta\u200b\u7684\u200bschedule\uff0c\u200b\u7ebf\u6027\u200b\u3001cosine\u200b\u7b49\u200b</p> <p>UNet    - \u200b\u53f3\u4e0b\u89d2\u200b\u548c\u200b\u56fe\u4f8b\u200b\uff1a\u200b\u5377\u79ef\u200b\u3001\u200b\u4e0a\u4e0b\u200b\u91c7\u6837\u200b\u3001skip connect concat    - down sample\uff0c\u200b\u7ed3\u679c\u200b\u56fe\u5c42\u200b\u901a\u9053\u200b\u53d8\u591a\u200b\u3001\u200b\u56fe\u200b\u53d8\u5c0f\u200b\uff1a22\u200b\u6700\u5927\u200b\u6c60\u5316\u200b\uff0c\u200b\u4e3a\u200b\u4fdd\u7559\u200b\u66f4\u200b\u591a\u200b\u7279\u5f81\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u7528\u200b33\u200b\u5377\u79ef\u200b    - up sample\uff0c\u200b\u7ed3\u679c\u200b\u56fe\u5c42\u200b\u901a\u9053\u200b\u53d8\u5c0f\u200b\u3001\u200b\u56fe\u53d8\u200b\u591a\u200b\uff1a\u200b\u8f6c\u7f6e\u200b\u5377\u79ef\u200b\uff08\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b\u586b\u5145\u200b\u4e86\u200b\u7a7a\u6d1e\u200b\u5377\u79ef\u200b\u7684\u200b\u5f62\u5f0f\u200b\u8ba9\u200b\u56fe\u7247\u200b\u53d8\u200b\u5927\u200b\uff09\uff0c\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u63d2\u503c\u6cd5\u200b\uff08\u200b\u6bd4\u5982\u200b\u586b\u5145\u200b\u90bb\u8fd1\u200b\u50cf\u7d20\u200b\u6216\u200b\u5468\u56f4\u200b\u50cf\u7d20\u200b\u5747\u503c\u200b\u7b49\u200b\uff09</p> <p>pad=reflect\uff0c\u200b\u586b\u5145\u200b\u7684\u200b\u50cf\u7d20\u200b\u4ee5\u200b\u8fb9\u754c\u200b\u4e3a\u200b\u5bf9\u79f0\u8f74\u200b\u5bf9\u79f0\u200b\uff0c\u200b\u7531\u4e8e\u200b\u662f\u975e\u200b\u96f6\u200b\uff0c\u200b\u56e0\u6b64\u200bpad\u200b\u540e\u200b\u6574\u5f20\u200b\u56fe\u200b\u6240\u6709\u200b\u50cf\u7d20\u200b\u90fd\u200b\u6709\u200b\u7279\u5f81\u200b</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/noise_scheduler.html","title":"Noise scheduler","text":""},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/DDPM/DDPM.html","title":"DDPM","text":""},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/DDPM/DDPM.html#_1","title":"\u524d\u5411\u200b\u52a0\u566a\u200b\u8fc7\u7a0b","text":""},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/DDPM/DDPM.html#_2","title":"\u524d\u5411\u200b\u6269\u6563","text":"<p>\u200b\u8868\u793a\u200b\u901a\u8fc7\u200b\u5bf9\u200b\u4e00\u4e2a\u200b\u56fe\u7247\u200b\u4e0d\u65ad\u200b\u5730\u200b\u589e\u52a0\u200b\uff08\u200b\u9ad8\u65af\u200b\uff09\u200b\u566a\u58f0\u200b\u7684\u200b\u6743\u91cd\u200b\uff0c\u200b\u5728\u200b\u8db3\u591f\u200b\u7684\u200btime_step\u200b\u540e\u200b\u5c06\u200b\u83b7\u5f97\u200b\u8d8b\u8fd1\u200b\u4e8e\u200b\u4e00\u4e2a\u200b\u566a\u58f0\u200b\u7684\u200b\u56fe\u7247\u200b\uff0c\u200b\u7ed3\u679c\u200b\u6ee1\u8db3\u200b\u4ee5\u4e0b\u200b\u516c\u5f0f\u200b\uff1a</p> \\[ \\begin{aligned}     x_{t} &amp;= \\sqrt{\\alpha_t}x_{t-1=} + \\sqrt{1-\\alpha_t}\\epsilon \\\\     &amp;= \\sqrt{\\bar\\alpha_t}x_0 + \\sqrt{1-\\bar\\alpha_t}\\epsilon \\end{aligned} \\] <p>\u200b\u6bcf\u200b\u4e00\u6b65\u200b\u52a0\u5165\u200b\u7684\u200b\u9ad8\u65af\u200b\u566a\u58f0\u200b\u4e92\u76f8\u200b\u72ec\u7acb\u200b\uff0c\u200b\u56e0\u6b64\u200b\u6b63\u6001\u5206\u5e03\u200b\u53ef\u4ee5\u200b\u8fdb\u884c\u200b\u53e0\u52a0\u200b</p> <p>\u200b\u5176\u4e2d\u200b\\(\\beta_t\\)\u200b\u8868\u793a\u200bt\u200b\u65f6\u523b\u200b\u52a0\u5165\u200b\u7684\u200b\u566a\u58f0\u200b\u6743\u91cd\u200b\uff0c\\(\\alpha_t=1-\\beta_t\\)\u200b\u8868\u793a\u200b\u56fe\u50cf\u200b\\(x_t\\)\u200b\u4e2d\u4e0a\u200b\u4e00\u200b\u65f6\u523b\u200b\u56fe\u50cf\u200b\\(x_{t-1}\\)\u200b\u7684\u200b\u6743\u91cd\u200b\uff0c\\(\\bar\\alpha_t=\\prod_{i=1}^{t-1}\\alpha_i\\)\uff0c\u200b\u5373\u200b</p> <p>\u200b\u524d\u5411\u200b\u6269\u6563\u200b\u793a\u610f\u56fe\u200b</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/DDPM/DDPM.html#train-model","title":"train model","text":"<ol> <li>\u200b\u968f\u673a\u200b\u9009\u5b9a\u200b\u67d0\u4e00\u200b\u65f6\u523b\u200b\\(t\\in [1, T]\\)\uff0c\u200b\u5bf9\u200b\u539f\u59cb\u200b\u56fe\u7247\u200b \\(x_0\\) \u200b\u52a0\u5165\u200b\u566a\u58f0\u200b \\(\\epsilon \\in \\mathcal{N}(0, I)\\) \u200b\u751f\u6210\u200b \\(x_t\\)</li> <li>\u200b\u5c06\u200b \\(time\\_embedding_t\\) \uff08\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b<code>position_embedding</code>\uff09\u200b\u4ee5\u53ca\u200b \\(x_t\\) \u200b\u8f93\u5165\u200b\u6a21\u578b\u200b\uff08e.g., <code>UNet</code>\u3001Transformer\uff09\u200b\u4e2d\u200b\uff0c\u200b\u751f\u6210\u200b\u5bf9\u200b\u52a0\u5165\u200b\u566a\u58f0\u200b\u7684\u200b\u9884\u6d4b\u200b\u7ed3\u679c\u200b \\(\\hat\\epsilon\\)</li> <li>\u200b\u8ba1\u7b97\u200b\u4e24\u4e2a\u200b\u6b63\u6001\u5206\u5e03\u200b\u7684\u200b \\(D_{KL}(\\mathcal{N}\\Vert \\mathcal{N}_\\theta)\\) \u200b\u4f5c\u4e3a\u200b\u76ee\u6807\u200b\u51fd\u6570\u200b \\(loss\\) \u200b\u4ee5\u200b\u4f7f\u200b\u6a21\u578b\u200b\u62df\u5408\u200b\u5148\u9a8c\u200b\u5047\u8bbe\u200b \u200b\u901a\u8fc7\u200b\u5bf9\u200b\u4e00\u4e2a\u200b\u56fe\u7247\u200b\u4e0d\u65ad\u200b\u5730\u200b\u589e\u52a0\u200b\uff08\u200b\u9ad8\u65af\u200b\uff09\u200b\u566a\u58f0\u200b\u7684\u200b\u6743\u91cd\u200b\uff0c\u200b\u5728\u200b\u8db3\u591f\u200b\u7684\u200btime_step\u200b\u540e\u200b\u5c06\u200b\u83b7\u5f97\u200b\u8d8b\u8fd1\u200b\u4e8e\u200b\u4e00\u4e2a\u200b\u566a\u58f0\u200b\u7684\u200b\u56fe\u7247\u200b</li> </ol> \\[ \\begin{aligned}     D_{KL}(\\mathcal{N}_1\\Vert \\mathcal{N}_2) &amp;= \\log\\frac{\\sigma_2}{\\sigma_1} + \\frac{\\sigma_1^2+(\\mu_1-\\mu_2)^2}{2\\sigma_2^2} - \\frac{1}{2} \\\\     \\mathcal{L} &amp;= E_{q(x_0:T)}\\Big[ \\frac{1}{2\\Vert \\Sigma_\\theta(x_t, t)\\Vert^2}\\Vert \\mu(x_t, t) - \\mu_\\theta(x_t, t) \\Vert^2\\Big] + C \\\\     &amp;= E_{q(x_0:T), \\epsilon\\in\\mathcal{N}(0, I)}\\Big[ \\frac{1}{2\\Vert \\Sigma_\\theta(x_t, t)\\Vert^2}\\Vert \\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{\\beta_t}{1-\\bar\\alpha_t}\\epsilon) - \\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{\\beta_t}{1-\\bar\\alpha_t}\\epsilon_\\theta(x_t,t)) \\Vert^2\\Big] + C \\\\     \\mathcal{L}_{simple} &amp;= E_{q(x_0:T), \\epsilon\\in\\mathcal{N}(0, I)}\\Big[\\Vert \\epsilon - \\epsilon_\\theta(\\sqrt{\\bar\\alpha_t}x_0 + \\sqrt{1-\\bar\\alpha_t\\epsilon}), t)\\Vert^2\\Big] \\end{aligned} \\] <p>\u200b\u6700\u7ec8\u200bloss\u200b\u4e3a\u200b\u52a0\u5165\u200b\u566a\u58f0\u200b $\\epsilon$ \u200b\u548c\u200b\u9884\u6d4b\u200b\u7684\u200b\u566a\u58f0\u200b $\\hat\\epsilon$ \u200b\u95f4\u200b\u7684\u200bMSE</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/DDPM/DDPM.html#ddpm","title":"DDPM\u200b\u9006\u5411\u200b\u53bb\u200b\u566a\u200b\u8fc7\u7a0b","text":""},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/DDPM/DDPM.html#_3","title":"\u9006\u5411\u200b\u6269\u6563","text":"<p>DDPM (Denoising Diffusion Probabilistic Model)\uff0c\u200b\u8ba4\u4e3a\u200b\u76ee\u6807\u200b\u56fe\u7247\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u5bf9\u200b\u566a\u58f0\u200b\u56fe\u7247\u200b\u9010\u6b65\u200b\u5730\u200b\u8fdb\u884c\u200b\u53bb\u200b\u566a\u200b\u64cd\u4f5c\u200b\u5b9e\u73b0\u200b\u56fe\u7247\u200b\u7684\u200b\u6062\u590d\u200b\u91cd\u73b0\u200b\uff0c\u200b\u5b9e\u73b0\u200b\u7684\u200b\u6570\u5b66\u200b\u7406\u8bba\u200b\u5982\u4e0b\u200b\uff1a</p> \\[ \\begin{aligned}     q(x_{t-1}|x_t, x_0)&amp;=q(x_t|x_{t-1}, x_0)\\frac{q(x_{t-1}|x_0)}{q(x_t|x_0)} &amp;&amp;\u200b\u8d1d\u53f6\u65af\u200b\u516c\u5f0f\u200b \\\\     q(x_t|x_{t-1}, x_0)&amp;=\\sqrt{\\alpha_t}x_{t-1} + \\sqrt{1-\\alpha_t}\\epsilon &amp;&amp;\\sim\\mathcal{N}(\\sqrt{\\alpha_t}x_{t-1}, 1-\\alpha_t I) \\\\     q(x_{t-1}|x_0)&amp;=\\sqrt{\\bar\\alpha_{t-1}}x_0 + \\sqrt{1-\\bar\\alpha_{t-1}}\\epsilon &amp;&amp;\\sim\\mathcal{N}(\\sqrt{\\bar\\alpha_{t-1}}x_0, 1-\\bar\\alpha_{t-1} I) \\\\     q(x_{t}|x_0)&amp;=\\sqrt{\\bar\\alpha_{t}}x_0 + \\sqrt{1-\\bar\\alpha_{t}}\\epsilon&amp;&amp;\\sim\\mathcal{N}(\\sqrt{\\bar\\alpha_{t}}x_0, 1-\\bar\\alpha_{t} I) \\end{aligned} \\] <p>\u200b\u82e5\u200b\u968f\u673a\u53d8\u91cf\u200b \\(x\\) \u200b\u670d\u4ece\u200b\u4e00\u4e2a\u200b\u4f4d\u7f6e\u200b\u53c2\u6570\u200b\u4e3a\u200b \\(\\mu\\)\u3001\u200b\u5c3a\u5ea6\u200b\u53c2\u6570\u200b\u4e3a\u200b \\(\\sigma\\) \u200b\u7684\u200b\u6982\u7387\u5206\u5e03\u200b\uff0c\u200b\u4e14\u200b\u5176\u200b\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u200b\u4e3a\u200b\\(f(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})\\)\uff0c\u200b\u56e0\u6b64\u200b\u4e0a\u5f0f\u200b\u53ef\u200b\u8868\u793a\u200b\u4e3a\u200b\uff1a</p> \\[ \\begin{aligned}     q(x_{t-1}|x_t, x_0)&amp;=\\exp\\bigg(-\\frac{1}{2}(\\Big(\\frac{\\alpha_t}{\\beta_t}+\\frac{1}{1-\\bar\\alpha_{t-1}}\\Big)x_{t-1}^2 - 2\\Big(\\frac{\\sqrt{\\alpha_t}}{\\beta_t}x_t + \\frac{\\sqrt{\\bar\\alpha_{t-1}}}{1-\\bar\\alpha_{t-1}}x_0\\Big)x_{t-1} + C(x_t, x_0))\\bigg) \\\\     \\frac{1}{\\sigma_{t-1}^2}&amp;= \\frac{\\alpha_t}{\\beta_t}+\\frac{1}{1-\\bar\\alpha_{t-1}} \\\\     \\sigma_{t-1} &amp;= \\sqrt{\\frac{1-\\bar\\alpha_{t-1}}{1-\\bar\\alpha_t}\\beta_t} \\\\     \\mu_{t-1} &amp;= \\frac{\\sqrt{\\alpha_t}(1-\\bar\\alpha_{t-1})}{1-\\bar\\alpha_t}x_t + \\frac{\\sqrt{\\bar\\alpha_{t-1}}\\beta_t}{1-\\bar\\alpha_t}x_0 \\\\     &amp;= \\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{\\beta_t}{1-\\bar\\alpha_t}\\epsilon) \\end{aligned} \\\\ \\]"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/DDPM/DDPM.html#sample-image","title":"sample image","text":"<ol> <li>\u200b\u521d\u59cb\u5316\u200b \\(x_T\\sim\\mathcal{N}\\text{(}0, \\text{I}\\text{)}\\)</li> <li>\u200b\u901a\u8fc7\u200b \\(x_{t}\\) \u200b\u548c\u200b \\(time\\_embedding_t\\) \u200b\u9884\u6d4b\u200b\u589e\u52a0\u200b\u7684\u200b\u566a\u58f0\u200b \\(\\hat\\epsilon \\sim \\mathcal{N} \\text{(}\\mu_{t-1}, \\sigma_{t-1}^2\\text{)}\\)</li> <li>\u200b\u57fa\u4e8e\u200b \\(\\hat\\epsilon\\) \u200b\u5f97\u5230\u200b\u7684\u200b\u5206\u5e03\u200b\u91c7\u6837\u200b \\(t-1\\) \u200b\u65f6\u523b\u200b\u7684\u200b\u56fe\u50cf\u200b\\(x_{t-1}\\)</li> <li>\u200b\u91cd\u590d\u200b2-3\u200b\u6b65\u200b\u76f4\u81f3\u200b\u5f97\u5230\u200b\\(x_0\\)</li> </ol> <p>\u200b\u7531\u4e8e\u200b\u6bcf\u4e2a\u200btime_step\u200b\u7684\u200b\u56fe\u50cf\u200b\u90fd\u200b\u662f\u200b\u91c7\u6837\u200b\u5f97\u5230\u200b\u7684\u200b\uff0c\u200b\u56e0\u6b64\u200bdiffusion\u200b\u6a21\u578b\u200b\u5177\u6709\u200b\u5f88\u200b\u597d\u200b\u7684\u200b\u591a\u6837\u6027\u200b\u8868\u73b0\u200b</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/Dalle/dalle.html","title":"Dalle","text":"<p>DALLE\uff0c\u200b\u540d\u79f0\u200b\u6765\u6e90\u4e8e\u200b\u8457\u540d\u753b\u5bb6\u200b\u8fbe\u5229\u200b\uff08Dal\u00ed\uff09\u200b\u548c\u200b\u673a\u5668\u4eba\u200b\u603b\u52a8\u5458\u200b\uff08Wall-E\uff09\uff0c\u200b\u662f\u200bOpen AI\u200b\u63a8\u51fa\u200b\u7684\u200b\u4e00\u4e2a\u200b\u53ef\u4ee5\u200b\u6839\u636e\u200b\u4e66\u9762\u200b\u6587\u5b57\u200b\u751f\u6210\u200b\u56fe\u50cf\u200b\u7684\u200b\u4eba\u5de5\u667a\u80fd\u200b\u7cfb\u7edf\u200b\u3002</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/Dalle/dalle.html#dall-e-1","title":"DALL-E-1","text":""},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/Dalle/dalle.html#dall-e-2","title":"DALL-E-2","text":"<p>\u200b\u4e5f\u200b\u79f0\u4f5c\u200bunCLIP\uff0c\u200b\u5373\u200bCLIP\u200b\u7684\u200b\u9006\u200b\u8fc7\u7a0b\u200b\uff1a\u200b\u901a\u8fc7\u200b\u7ed9\u5b9a\u200bimge_hidden_state\u200b\u751f\u6210\u200b\u56fe\u7247\u200b\u3002\u200b\u5c42\u7ea7\u200b\u5f0f\u200b\u5730\u200b\u751f\u6210\u200b64*64 -&gt; 256*256 -&gt; 1024*1024\u200b\u5206\u8fa8\u7387\u200b\u7684\u200b\u56fe\u7247\u200b\uff0c\u200b\u9010\u6e10\u200b\u9ad8\u6e05\u200b</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/Dalle/dalle.html#framework","title":"Framework","text":"<p>unCLIP\u200b\u6982\u7565\u200b\u56fe\u200b</p> <p>DALLE-2\u200b\u6a21\u578b\u200b\u5305\u542b\u200bprior\u200b\u548c\u200bdecoder\u200b\u4e24\u4e2a\u200b\u6a21\u5757\u200b\uff0c\u200b\u524d\u8005\u200b\u57fa\u4e8e\u200b\u8f93\u5165\u200b\u7684\u200b\u6587\u672c\u200b\u751f\u6210\u200b\u76f8\u5e94\u200b\u7684\u200b\u56fe\u7247\u200b\u7279\u5f81\u200b\uff0c\u200b\u540e\u8005\u200b\u5219\u200b\u6839\u636e\u200b\u56fe\u200b-\u200b\u6587\u200b\u7279\u5f81\u200b\u751f\u6210\u200b\u56fe\u7247\u200b\uff0c\u200b\u6a21\u578b\u200b\u5305\u542b\u200b\u7684\u200b\u4e3b\u8981\u200b\u6280\u672f\u200b\u6709\u200b\uff1a</p> <ol> <li>\u200b\u5bf9\u6bd4\u200b\u5b66\u4e60\u200b\uff08CLIP\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u4f7f\u7528\u200b\u7684\u200b\u65b9\u6cd5\u200b\uff09</li> <li>\u200b\u591a\u200b\u6a21\u6001\u200b\uff08\u200b\u56fe\u200b-\u200b\u6587\u200b\u6a21\u6001\u200b\u4fe1\u606f\u200b\u4fe1\u606f\u200b\u4ea4\u4e92\u200b\u3001\u200b\u8f6c\u6362\u200b\uff09</li> <li>\u200b\u6269\u6563\u200b\u6a21\u578b\u200b\uff08prior\u200b\u4ee5\u53ca\u200bdecoder\u200b\u6a21\u5757\u200b\u4e3b\u8981\u200b\u601d\u8def\u200b\uff09</li> </ol>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/Dalle/dalle.html#prior","title":"prior","text":"<p>\u200b\u8f93\u5165\u200b\u63cf\u8ff0\u200b\u6587\u672c\u200b\uff0c\u200b\u8f93\u51fa\u200b\u76f8\u5e94\u200b\u7684\u200bclip imgae hidden state\u200b\u7279\u5f81\u200b</p> <ul> <li> <p>train</p> <ol> <li>\u200b\u8f93\u5165\u200b\u56fe\u6587\u200b\u5bf9\u200b (\\(x, y\\)) \u200b\u81f3\u200b frozen CLIP \u200b\u4e2d\u200b\u83b7\u53d6\u200b\u5bf9\u5e94\u200b\u7684\u200b\u56fe\u7247\u200b\u7279\u5f81\u200b \\(z_x\\) \u200b\u548c\u200b \u200b\u6587\u672c\u200b\u63cf\u8ff0\u200b\u7279\u5f81\u200b \\(z_y\\)</li> <li>\u200b\u4ee5\u200b\u6587\u672c\u200b\u4fe1\u606f\u200b \\(y\\) \u200b\u548c\u200b \\(z_y\\) \u200b\u4f5c\u4e3a\u200b\u8f93\u5165\u200b\uff0c\u200b\u8bad\u7ec3\u200bprior\u200b\u4f7f\u200b\u5176\u200b\u80fd\u591f\u200b\u5c06\u200b\u6587\u672c\u200b\u4fe1\u606f\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u5bf9\u5e94\u200b\u7684\u200b\u56fe\u7247\u200b\u7279\u5f81\u200b \\(z_x\\) (\u200b\u4f5c\u4e3a\u200b\u8bad\u7ec3\u200b\u7684\u200bground-truth)\uff0cprior\u200b\u6709\u200b\u4e24\u79cd\u200b\u5b9e\u73b0\u200b\u65b9\u6848\u200b<ul> <li>autoregressive prior\uff1a\\(\\text{gpt}_\\theta(y, z_y)=\\hat{z_x}\\)</li> <li>diffusion prior\uff1a\u200b\u6269\u6563\u200b\u6a21\u578b\u200b\u53bb\u200b\u566a\u200b\u8fd8\u539f\u200b\u5f97\u5230\u200b \\(z_x\\)\uff0c\\(f_\\theta(y, z_y, t, z_x^{(t)})=\\hat{z_x}\\) \uff0c\u200b\u6bcf\u4e2a\u200b\u9636\u6bb5\u200b\u4e0d\u200b\u9884\u6d4b\u200b\u52a0\u5165\u200b\u7684\u200b\u566a\u58f0\u200b\u800c\u662f\u200b\u76f4\u63a5\u200b\u9884\u6d4b\u200b\u6587\u672c\u200b\u63cf\u8ff0\u200b\u5bf9\u5e94\u200b\u7684\u200b\u56fe\u7247\u200b\u7279\u5f81\u200b</li> </ul> </li> <li>\\(\\mathcal{L}=\\mathbb{E}_{t\\sim[1,T], z_i^{(t)}\\sim q(t)}\\Big[\\Vert f_\\theta(z_i^{(t)}, t, y) - z_i\\Vert^2\\Big]\\)</li> </ol> <ul> <li>10%\u200b\u7684\u200b\u8bad\u7ec3\u200b\u65f6\u95f4\u200b\u5bf9\u200b \\(z_y\\) \u200b\u8fdb\u884c\u200bdrop\uff0c50%\u200b\u7684\u200b\u65f6\u95f4\u200b\u5bf9\u200b\u6587\u672c\u200b\u63cf\u8ff0\u200b\u8fdb\u884c\u200bmask</li> <li>\u200b\u4e0d\u540c\u4e8e\u200b\u56fe\u7247\u200b\u6269\u6563\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u56fe\u7247\u200b \u200b\u7279\u5f81\u200b\u7684\u200b\u6269\u6563\u200b\u8fd8\u539f\u200b\u9009\u7528\u200b\u4e86\u200bTransformer\u200b\u6a21\u578b\u200b \u200b\u800c\u200b\u4e0d\u662f\u200bUNet \uff0c\u200b\u5373\u200b\u8f93\u5165\u200b[<code>encoding_y</code>, <code>clip_text_embedding_y</code>, <code>time_embedding_of_t</code>, <code>x_t</code>, <code>noised_image_embedding</code>, <code>[IMG]</code>]\uff0c\u200b\u6a21\u578b\u200b\u6700\u540e\u200b\u5c42\u200b <code>[IMG]</code> \u200b\u7684\u200b\u503c\u200b\u5373\u200b\u4e3a\u200b\u9884\u6d4b\u200b\u7684\u200b\\(\\hat{z_x}\\)</li> </ul> </li> <li> <p>infer</p> <ol> <li>\u200b\u8f93\u5165\u200b\u6587\u672c\u200b \\(y\\) \u200b\u81f3\u200b frozen CLIP\u200b\u5f97\u5230\u200b \\(z_y\\)</li> <li>\u200b\u521d\u59cb\u5316\u200b \\(z_x^{(T)}\\sim\\mathcal{N}\\text{(}0, \\text{I}\\text{)}\\)</li> <li>\\(f_\\theta(y, z_y, t, z_x^{(t)})=\\hat{z_x}\\)\uff0c\u200b\u901a\u8fc7\u200b \\(\\hat{z_x}\\) \u200b\u548c\u200b \\(z_x^{(t)}\\) \u200b\u5f97\u5230\u200b \\(t-1\\) \u200b\u65f6\u523b\u200b\u7684\u200b\u56fe\u50cf\u200b\u5206\u5e03\u200b\uff0c\u200b\u5e76\u200b\u91c7\u6837\u200b\u5f97\u5230\u200b \\(z_x^{(t-1)}\\)</li> <li>\u200b\u91cd\u590d\u200b\u7b2c\u200b3\u200b\u6b65\u200b\u76f4\u81f3\u200b\u83b7\u53d6\u200b \\(z_x^{(0)}\\)</li> </ol> <p>autogressive prior \u200b\u76f4\u63a5\u200b\u4e00\u6b65\u200b\u9884\u6d4b\u200b\u5f97\u5230\u200b \\(\\hat{z_x}\\)</p> </li> </ul>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/Dalle/dalle.html#decoder","title":"decoder","text":"<ul> <li>train &amp; sample<ol> <li>\u200b\u6b63\u5e38\u200b\u7684\u200b\u56fe\u50cf\u200bdiffusion\u200b\u8fc7\u7a0b\u200b\uff0c\\(f_\\theta(y, z_y, \\hat{z_x}, t, x_t)=\\hat\\epsilon\\)</li> <li>\u200b\u6a21\u578b\u200b\u4e3a\u200bUNet</li> </ol> <ul> <li>\u200b\u8bad\u7ec3\u200b\u65f6\u200b5%\u200b\u7684\u200b\u8bad\u7ec3\u200b\u65f6\u95f4\u200b\u5bf9\u200b \\(z_x\\) \u200b\u8fdb\u884c\u200b\u4e86\u200bdrop</li> </ul> </li> </ul>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/Dalle/dalle.html#result","title":"Result","text":""},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/Dalle/dalle.html#importance-of-prior","title":"Importance of prior","text":"<p>\u200b\u7b2c\u4e00\u884c\u200b\uff1a$decoder(y)$\uff1b\u200b\u7b2c\u4e8c\u884c\u200b\uff1a$decode(y,z_y)$\uff1b\u200b\u7b2c\u4e09\u884c\u200b\uff1a$decoder(ar\\_piror(y, z_y))$ </p> <p>ar_prior \u200b\u548c\u200b diffusion_prior \u200b\u6548\u679c\u200b\u5bf9\u6bd4\u200b\uff08\u200b\u4eba\u5de5\u200b\u8bc4\u5ba1\u200b\u7ed3\u679c\u200b\uff09</p> <p>\u200b\u6bd4\u8d77\u200b\u76f4\u63a5\u200b\u8f93\u5165\u200b\u6587\u672c\u200b\u7279\u5f81\u200b\u8fdb\u884c\u200b\u56fe\u50cf\u200b\u8fd8\u539f\u200b\uff0cprior\u200b\u80fd\u591f\u200b\u589e\u5f3a\u200b\u6587\u672c\u200b\u751f\u6210\u200b\u56fe\u50cf\u200b\u7684\u200b\u6548\u679c\u200b\uff0c\u200b\u4e14\u200b diffusion_prior \u200b\u6bd4\u200b ar_prior \u200b\u5f97\u5230\u200b\u7684\u200b\u56fe\u7247\u200b\u7279\u5f81\u200b\u5728\u200b\u751f\u6210\u200b\u56fe\u7247\u200b\u8868\u73b0\u200b\u66f4\u52a0\u200b\u4f18\u8d8a\u200b</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/Dalle/dalle.html#_1","title":"\u6548\u679c\u200b\u5bf9\u6bd4","text":"<p>unCLIP &amp; GLIDE\u200b\u4e0d\u540c\u200b\u5c3a\u5ea6\u200b\u4e0b\u200b\u751f\u6210\u200b\u56fe\u7247\u200b\u53d7\u4eba\u200b\u559c\u7231\u200b\u6bd4\u4f8b\u200b</p> <p>unCLIP &amp; GLIDE\u200b\u4e0d\u540c\u200b\u5c3a\u5ea6\u200b\u4e0b\u200b\u751f\u6210\u200b\u56fe\u7247\u200bFID</p> <p>unCLIP\u200b\u4e0e\u200b\u540c\u7c7b\u200b\u5de5\u4f5c\u200b\u6548\u679c\u200b\u5bf9\u6bd4\u200b</p> <p>unCLIP \u200b\u5728\u200b\u6548\u679c\u200b\u548c\u200b\u6570\u503c\u200b\u6d4b\u8bd5\u200b\u8868\u73b0\u200b\u4e2d\u5747\u200b\u53d6\u5f97\u200b\u6700\u597d\u200b\u7ed3\u679c\u200b</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/Dalle/dalle.html#application","title":"Application","text":"<ul> <li>\u200b\u6587\u672c\u200b\u751f\u6210\u200b\u56fe\u7247\u200b</li> </ul> <ul> <li>\u200b\u5236\u4f5c\u200b\u52a8\u753b\u200b\u3001\u200b\u6e10\u53d8\u200b</li> </ul> <ul> <li>\u200b\u56fe\u7247\u200b\u91cd\u6784\u200b\uff08\u200b\u5c06\u200b\u56fe\u7247\u200b\u7684\u200bclip image embedding\u200b\u4f5c\u4e3a\u200bdecoder\u200b\u8f93\u5165\u200b\uff09</li> </ul> <ul> <li>\u200b\u56fe\u7247\u200b\u98ce\u683c\u200b\u878d\u5408\u200b\uff08\u200b\u5c06\u200b\u4e24\u5f20\u200b\u56fe\u7247\u200b\u7684\u200bclip image embedding\u200b\u52a0\u6743\u200b\u4f5c\u4e3a\u200bdecoder\u200b\u8f93\u5165\u200b\uff09</li> </ul>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/Dalle/dalle.html#limitation","title":"Limitation","text":"<ul> <li>\u200b\u5c40\u9650\u6027\u200b</li> </ul> <p>\u200b\u7531\u4e8e\u200b\u4ee5\u200bCLIP\u200b\u4e3a\u200b\u5b66\u4e60\u200b\u76ee\u6807\u200b\uff0c\u200b\u96c6\u6210\u200b\u4e86\u200b\u5176\u200b\u53ea\u200b\u5173\u6ce8\u200b\u7269\u4f53\u200b\u662f\u5426\u200b\u5b58\u5728\u200b\u800c\u200b\u4e0d\u200b\u5173\u6ce8\u200b\u7269\u4f53\u200b\u5c5e\u6027\u200b\uff08e.g., \u200b\u4f4d\u7f6e\u200b\uff0c\u200b\u89d2\u5ea6\u200b\uff0c\u200b\u5927\u5c0f\u200b\uff0c\u200b\u989c\u8272\u200b\u7b49\u200b\uff09\u200b\u7684\u200b\u5c40\u9650\u6027\u200b</p> <p>CLIP embedding\u200b\u65e0\u6cd5\u200b\u51c6\u786e\u200b\u5730\u200b\u89e3\u6790\u200b\u6587\u672c\u200b\u7684\u200b\u62fc\u5199\u200b\u4fe1\u606f\u200b\uff08\u200b\u5927\u200b\u6982\u7387\u200b\u662f\u56e0\u4e3a\u200bBPE\u200b\u7f16\u7801\u200b\u57fa\u4e8e\u200b\u7edf\u8ba1\u200b\u800c\u200b\u4e0d\u662f\u200b\u57fa\u4e8e\u200b\u8bed\u4e49\u200b\u5b9e\u73b0\u200b\u7684\u200b\uff09</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/Dalle/dalle.html#discovering","title":"Discovering","text":""},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/Dalle/dalle.html#hidden-vocabulary","title":"Hidden Vocabulary","text":"<ul> <li>prompt\uff1a\u200b\u63cf\u8ff0\u200b\u4e24\u4e2a\u200b\u8001\u519c\u200b\u8ba8\u8bba\u200b\u5728\u200b\u852c\u83dc\u200b\u5e76\u200b\u751f\u6210\u200b\u6807\u9898\u200b</li> <li>\u200b\u751f\u6210\u200b\u56fe\u7247\u200b\uff1a\u200b\u6807\u9898\u200b\u4e3a\u200b\u852c\u83dc\u200b\uff0c\u200b\u8c08\u8bdd\u200b\u5185\u5bb9\u200b\u4e3a\u200b\u9e1f\u200b</li> </ul> <ul> <li>prompt(\u200b\u4e00\u5806\u200b\u9e1f\u8bed\u200b)\uff1a\u201cApoploe vesrreaitais eating Contarra ccetnxniams luryca tanniounons\u201d</li> <li>\u200b\u751f\u6210\u200b\u56fe\u7247\u200b\uff1a\u200b\u9e1f\u200b\u5403\u200b\u866b\u200b</li> </ul> <ul> <li>prompt(\u200b\u4e00\u5806\u200b\u9e1f\u8bed\u200b)\uff1a\u201cWa ch zod ahaakes rea.\u201d</li> <li>\u200b\u751f\u6210\u200b\u56fe\u7247\u200b\uff1a\u200b\u6d77\u9c9c\u200b</li> </ul> <p>\u200b\u7531\u4e8e\u200b\u81ea\u7136\u8bed\u8a00\u200b\u7ec6\u8282\u200b\u7684\u200b\u8868\u8fbe\u200b\u65e0\u6cd5\u200b\u4fdd\u8bc1\u200b\uff0cDALLE\u200b\u8bed\u8a00\u200b\u5b58\u5728\u200b\u88ab\u200b\u201c\u200b\u7834\u89e3\u200b\u201d\u200b\u7528\u4f5c\u200b\u975e\u6cd5\u200b\u7528\u9014\u200b\u7684\u200b\u98ce\u9669\u200b</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/Diffusion/Dalle/dalle.html#dall-e-3","title":"DALL-E-3","text":"<ol> <li>predict_start_from_noise\uff0c\u200b\u6c42\u200b\\(x_0\\)\uff0c\\(x_t = ax_0 + b\\epsilon\\)</li> <li>predict_noise_from_start\uff0c\u200b\u6c42\u200b\\(\\epsilon\\)\uff0c\\(x_t = ax_0 + b\\epsilon\\)</li> <li>q_sample\uff0c\u200b\u6c42\u200b\\(x_t\\)\uff0c\\(x_t = ax_0 + b\\epsilon\\)</li> <li>q_posterior\uff0c\u200b\u6c42\u200b\\(\\mu_{t-1}\\)\uff0c\\(\\sigma_{t-1}\\)</li> <li>predict_start_from_v\uff0c</li> <li>calculate_v</li> </ol>"},{"location":"AI/Paper_Reading/LM/Model_Category/GAN/gan.html","title":"Gan","text":"<p>Generative Adversarial Network\u200b\u5bf9\u6297\u200b\u751f\u6210\u200b\u6a21\u578b\u200b\uff0c\u200b\u5305\u542b\u200b\u751f\u6210\u5668\u200b\u548c\u200b\u5224\u65ad\u200b\u5668\u200b\u4e24\u200b\u90e8\u5206\u200b</p> GeneratorDiscriminator <p>\u200b\u76ee\u7684\u200b\u662f\u200b\u4f7f\u200b\u751f\u6210\u200b\u7684\u200b\u7ed3\u679c\u200b\u66f4\u200b\u8d8b\u8fd1\u200b\u771f\u5b9e\u200b\u7ed3\u679c\u200b\uff0c\u200b\u53ea\u200b\u66f4\u65b0\u200b\u751f\u6210\u5668\u200b\u6a21\u578b\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c\\(\\mathcal{L}_G = \\text{D}\\big(\\text{G}(noise), y\\_real\\big)\\)</p> <pre><code>x_gen = G(z)\nD_G_z = D(x_gen)\nlossG = criterion(D_G_z, lab_real)\n</code></pre> <p>\u200b\u7531\u4e8e\u200b\u751f\u6210\u5668\u200b\u7684\u200b\u8f93\u5165\u200b\u4e3a\u200b\u566a\u58f0\u200b\uff0c\u200b\u6240\u4ee5\u200b\u4f1a\u200b\u968f\u673a\u200b\u751f\u6210\u200b\u53c2\u4e0e\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6240\u6709\u200b\\(x\\_real\\)\uff08\u200b\u5b9a\u5411\u751f\u200b\u6210\u200b\u9700\u8981\u200b\u56fa\u5b9a\u200bseed\uff09</p> <p>\u200b\u76ee\u7684\u200b\u662f\u200b\u80fd\u591f\u200b\u51c6\u786e\u200b\u8bc6\u522b\u200b\u751f\u6210\u200b\u7684\u200b\u7ed3\u679c\u200b\u548c\u200b\u771f\u5b9e\u200b\u7ed3\u679c\u200b\uff0c\u200b\u53ea\u200b\u66f4\u65b0\u200b\u5224\u522b\u200b\u5668\u200b\u6a21\u578b\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c\\(\\mathcal{L}_D = \\text{D}\\big(\\text{G}(x\\_real), y\\_real\\big) + \\text{D}\\big(\\text{G}(noise), y\\_fake\\big)\\)</p> <pre><code>D_x = D(x_real)\nlossD_real = criterion(D_x, lab_real)\n\nx_gen = G(z).detach()\nD_G_z = D(x_gen)\nlossD_fake = criterion(D_G_z, lab_fake)\n\nlossD = lossD_real + lossD_fake\n</code></pre>"},{"location":"AI/Paper_Reading/LM/Model_Category/VAE/VAE_in_nlp.html","title":"VAE in nlp","text":""},{"location":"AI/Paper_Reading/LM/Model_Category/VAE/VAE_in_nlp.html#vanilla-vae-in-nlp","title":"Vanilla VAE in nlp","text":"<p>\u200b\u8bba\u6587\u200b\uff1aGenerating Sentences from a Continuous Space Google Brain, CoNLL, 2016</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/VAE/VAE_in_nlp.html#_1","title":"\u6a21\u578b\u200b\u67b6\u6784","text":"<p>pipeline: encoder + VAE + decoder</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/VAE/VAE_in_nlp.html#_2","title":"\u5de5\u4f5c\u200b\u8981\u70b9","text":"<ol> <li>introduce <code>KL cost annealing</code> to deal with posterior collapse (also named KL-vanishing) \u3010\\(qp(z|x)\\rightarrow p(z)\\)\u3011</li><ul> <li>\u200b\u6563\u5ea6\u200b\u6d88\u5931\u200b\uff0c\u200b\u6b64\u65f6\u200b\u4ece\u200b\u7b80\u5355\u200b\u7684\u200b\u5148\u9a8c\u200bp(z)\u200b\u4e2d\u200b\u91c7\u6837\u200b\u6f5c\u200b\u53d8\u91cf\u200bz,\u200b\u4e5f\u200b\u80fd\u200b\u5f88\u200b\u597d\u200b\u5730\u200b\u91cd\u6784\u200b\u51fa\u200b\u8f93\u5165\u200bx\uff0c\u200b\u5bfc\u81f4\u200bz\u200b\u643a\u5e26\u200b\u7684\u200b\u4fe1\u606f\u200b\u5f88\u5c11\u200b</li> </ul> </ol> <p>\u200b\u5b9e\u9a8c\u200b\u53d1\u73b0\u200b\uff0cVAE\u200b\u8bad\u7ec3\u200b\u524d\u671f\u200b\\(\\mathcal{L}_{KL}\\)\u200b\u6fc0\u589e\u200b\uff0c\u200b\u82e5\u200b\u65e0\u200b\u5bf9\u5e94\u200b\u52a0\u6743\u200b\u65b9\u6848\u200b\u5c06\u200b\u4f7f\u200bdecoder\u200b\u62df\u5408\u200b\\(p(z)\\)\u200b\u800c\u200b\u4e0d\u662f\u200b\\(q(z|x)\\)\uff0c\u200b\u9020\u6210\u200b\u540e\u9a8c\u200b\u574d\u584c\u200b\uff0c\u200b\u53ef\u200b\u901a\u8fc7\u200b\u589e\u52a0\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b\u8fdb\u884c\u200b\u52a0\u6743\u200b \\(\\beta*\\mathcal{L}_{KL}\\)\uff0c\u200b\u4f8b\u5982\u200b\uff1a</p> <ul> <li>0 -&gt; linear/exp increase -&gt; 1</li> <li>learnable \\(\\beta\\)</li> </ul> <p> 2. latent space learned by VAE is more informative</p> <p>Penn Treebank language modeling results. NLL: negative log likelihood; Inputless: decoder($x_i|z,t_i$) without $x_{i-1}$</p> <p> 3. latent space learned by VAE is much smoother</p> <ul> <li>enable homotopy (linear interpolation \\(z=z_1*(1-t)+z_2*t\\))</li> </ul> <p>\u200b\u7531\u200binterpolation\u200b\u73b0\u8c61\u200b\u53ef\u77e5\u200b\uff0c\u200b\u4f20\u7edf\u200bAE\u200b\u6a21\u578b\u200b\u751f\u6210\u200b\u53e5\u200b\u5411\u91cf\u200b\u8fc7\u4e8e\u200b\u5c16\u9510\u200b\u4e0e\u200b\u79bb\u6563\u200b\uff0c\u200b\u800c\u200bVAE\u200b\u751f\u6210\u200b\u7684\u200b\u53e5\u200b\u5411\u91cf\u200b\u66f4\u52a0\u200b\u5e73\u6ed1\u200b\u4e14\u200b\u66f4\u200b\u4fdd\u7559\u200b\u66f4\u200b\u591a\u200b\u7684\u200b\u8bed\u6cd5\u200b\u3001\u200b\u4e3b\u9898\u200b\u4ee5\u53ca\u200b\u53e5\u6cd5\u200b\u7279\u5f81\u200b\u4fe1\u606f\u200b\u3002</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/VAE/VAE_in_nlp.html#optimus","title":"Optimus","text":"<p>\u200b\u8bba\u6587\u200b\uff1aOPTIMUS: Organizing Sentences via Pre-trained Modeling of a Latent Space Organizing sentences via Pre-Trained Modeling of a Universal Space MSR, EMNLP 2020</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/VAE/VAE_in_nlp.html#_3","title":"\u6a21\u578b\u200b\u67b6\u6784","text":"<ol> <li>\\(W_Mz=h_{memory}\\in \\mathbb{R}^{L\\times H}\\)\uff0c\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b\u8fde\u7eed\u578b\u200bprompt\u200b\u5206\u522b\u200b\u4e0e\u200btransformer\u200b\u6bcf\u5c42\u200b\u7684\u200bhidden state\u200b\u8fdb\u884c\u200bconcate</li> <li>\\(W_Dz=h_{embedding}\\in \\mathbb{R}^H\\)\uff0c\u200b\u53ea\u200b\u5728\u200bembedding layer\u200b\u751f\u6548\u200b\uff0c\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b\\(Emb_{token}, Emb_{pos}\\)</li> </ol>"},{"location":"AI/Paper_Reading/LM/Model_Category/VAE/VAE_in_nlp.html#_4","title":"\u5de5\u4f5c\u200b\u8981\u70b9","text":"<ol> <li>bridge the gap between pretrained encoder(e.g., BERT) and decoder(e.g., GPT-2)</li> </ol> <p> 2. \\(\\beta\\)-schedule</p> <ul> <li>train AE(\\(\\beta\\)=0) for 0.5 proportion</li> <li>anneal \\(\\beta\\) from 0 to 1 for 0.25 proportion</li> <li>fix \\(\\beta\\)=1 for 0.25 proportion</li> <li>when \\(\\beta\\)&gt;0, \\(\\mathcal{L_R}=\\sum_i\\max[\\lambda, \\text{KL}(q_\\varPhi(z_i|x)||p(z_i))], where \\lambda\\in[0, 1]\\)</li> </ul> <p> 3. OPTIMUS outperforms and adapts faster than BERT</p> <p> 4. OPTIMUS learns a smoother and more structured latent space</p> <p> 5. sentence transfer and interpolation abilities</p> <p>OPTIMUS\u200b\u5728\u200b\u53e5\u5b50\u200b\u98ce\u683c\u200b\u8fc1\u79fb\u200b\u6539\u5199\u200b\u4efb\u52a1\u200b\u4e2d\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u4f18\u8d8a\u200b</p> <p>OPTIMUS\u200b\u5728\u200b\u5185\u5bb9\u200b\u4e3b\u4f53\u200b\u5355\u590d\u6570\u200b\u3001\u200b\u957f\u77ed\u53e5\u200b\u3001\u200b\u76f8\u4f3c\u200b\u8bed\u8a00\u200b\u7b49\u200b\u4ea4\u7ec7\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u51fa\u200b\u5e73\u6ed1\u200b\u7684\u200b\u6548\u679c\u200b</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/VAE/VAE_in_nlp.html#bn-vae","title":"BN-VAE","text":"<p>\u200b\u8bba\u6587\u200b\uff1aA Batch Normalized Inference Network Keeps the KL Vanishing Away Tencent AI, ACL, 2020</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/VAE/VAE_in_nlp.html#_5","title":"\u6a21\u578b\u200b\u67b6\u6784","text":"<p>pipeline: encoder + VAE_distribution + BN + VAE_sample + decoder</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/VAE/VAE_in_nlp.html#_6","title":"\u5de5\u4f5c\u200b\u8981\u70b9","text":"<ol> <li>BN-VAE guarantee a positive lower bound of E[KL]</li> </ol> <p>\u200b\u6700\u4f4e\u200b\u4e0b\u9650\u200b\u53d7\u200bdimension \\(n\\)\u200b\u548c\u200b\u5747\u503c\u200b\\(\\mu\\)\u200b\u7684\u200b\u5f71\u54cd\u200b\uff0c\u200b\u524d\u8005\u200b\u8d85\u53c2\u200b\u56fa\u5b9a\u200b\uff0c\u200b\u540e\u8005\u200b\u53ef\u200b\u901a\u8fc7\u200bbatch norm \\(\\mu \\in \\mathbb{R}^n\\) \u200b\u8fdb\u884c\u200b\u7ea6\u675f\u200b\u3010\u200b\u5373\u4f7f\u200b\u5728\u200bNLP\u200b\u4efb\u52a1\u200b\u4e2d\u200b\uff0c\u200b\u4e5f\u200b\u4e0d\u53d7\u200b(padded_)seq\u200b\u7ef4\u5ea6\u200b\u5f71\u54cd\u200b\u3011</p> <p>\\(\\gamma\\) and \\(\\beta\\) in batch norm are fixed</p> <p> 2. BN-VAE possesses high accuracy and coverage speed</p> <p> 3. the model posterior \\(p_\\theta(z|x)\\) is well learned with the help of the BN-VAE decoder.</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/VAE/VAE_in_nlp.html#ceve","title":"CEVE","text":"<p>\u200b\u8bba\u6587\u200b\uff1aContrastive Deterministic Autoencoders For Language Modeling EMNLP, 2023</p>"},{"location":"AI/Paper_Reading/LM/Model_Category/VAE/VAE_in_nlp.html#_7","title":"\u6a21\u578b\u200b\u67b6\u6784","text":"<p>\u200b\u57fa\u4e8e\u200bVAE\u200b\u6bcf\u6b21\u200b\u91c7\u6837\u200b\u7ed3\u679c\u200b\u4e0d\u540c\u200b\u7684\u200b\u7279\u6027\u200b\uff0cCEVE\u200b\u8fdb\u4e00\u6b65\u200b\u5e94\u7528\u200b\u4e86\u200b\u5bf9\u6bd4\u200b\u5b66\u4e60\u200b\u7684\u200b\u601d\u60f3\u200b\u3002</p>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/index.html","title":"\u5f3a\u5316\u200b\u5b66\u4e60","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/index.html#_1","title":"\u5f3a\u5316\u200b\u5b66\u4e60\u200b\u6982\u5ff5","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/index.html#_2","title":"\u76f8\u5173\u200b\u7ec4\u6210\u200b\u6a21\u578b","text":"<ul> <li>\u200b\u7b56\u7565\u200b\u6a21\u578b\u200b\uff1aActor Model\u3001Policy Model\u3001Active Model</li> <li>\u200b\u5956\u52b1\u200b\u6a21\u578b\u200b\uff1aReward Model\uff08RM\uff09<ul> <li>reward function: xmlcount_reward_func, soft_format_reward_func, strict_format_reward_func, int_reward_func, correctness_reward_func</li> <li>pair-wise loss\uff1a\u200b\u6bd4\u8f83\u200b\u5bf9\u8c61\u200b\u7684\u200b\u76f8\u5bf9\u200b\u504f\u597d\u200b\u6765\u200b\u4f18\u5316\u200b\u6a21\u578b\u200b\uff0c\u200b\u5982\u200b\\(\\log \\sigma(f(x_i) - f(x_j))\\)</li> <li>point-wise loss\uff1a\u200b\u5206\u7c7b\u200b\u6216\u200b\u56de\u5f52\u200b\u95ee\u9898\u200b</li> </ul> </li> <li>\u200b\u4ef7\u503c\u200b\u6a21\u578b\u200b\uff1aValue Model\u3001Critic Model</li> <li>\u200b\u53c2\u8003\u6a21\u578b\u200b\uff1aReference Model</li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/index.html#_3","title":"\u76f8\u5173\u200b\u6982\u5ff5","text":"<ul> <li>State: \u200b\u72b6\u6001\u200b\u5e8f\u5217\u200b \\(s= \\{s_0, s_1, \\cdots \\}\\) </li> <li>Agent\uff1a\u200b\u6267\u884c\u200b\u52a8\u4f5c\u200b\u7684\u200b\u7528\u6237\u200b\u4e3b\u4f53\u200b  </li> <li>Observation\uff1a\u200b\u7528\u6237\u200b\u5f53\u524d\u200b\u89c6\u89d2\u200b\u80fd\u200b\u89c2\u6d4b\u200b\u5230\u200b\u7684\u200b\u72b6\u6001\u200b \\(s_t\\)</li> <li> <p>Action\uff1aAgent\u200b\u7684\u200b\u52a8\u4f5c\u200b\u5e8f\u5217\u200b \\(a = \\{a_0, a_1, \\cdots \\}\\)\uff0c\u200b\u4e00\u822c\u200b\u53d6\u503c\u200b\u6e90\u4e8e\u200b\u6709\u9650\u200b\u7684\u200b\u52a8\u4f5c\u200b\u7a7a\u95f4\u200b Action Space  </p> <p>\u200b\u5982\u200b\u8d85\u7ea7\u739b\u4e3d\u200b\u4e2d\u200b\u7684\u200b\u52a8\u4f5c\u200b\u7a7a\u95f4\u200b\u6709\u200b <code>{\u200b\u5de6\u200b, \u200b\u53f3\u200b, \u200b\u8df3\u200b, \u200b\u653b\u51fb\u200b, \u200b\u9759\u6b62\u200b}</code> </p> </li> <li> <p>Reward\uff1aAgent\u200b\u5728\u200b\u5f53\u524d\u200b\u72b6\u6001\u200b \\(s_t\\) \u200b\u4e0b\u200b\u6267\u884c\u200b\u52a8\u4f5c\u200b \\(a_t\\) \u200b\u540e\u200b\u7684\u200b\u5956\u52b1\u200b \\(r_{t+1}(s_t, a_t)\\) </p> </li> <li> <p>Policy\uff1a\u200b\u7b56\u7565\u200b \\(\\pi(a_t \\vert s_t)\\)\uff0c\u200b\u8868\u793a\u200b\u5728\u200b\u5f53\u524d\u200b\u72b6\u6001\u200b\u4e0b\u200b\u6267\u884c\u200b\u7684\u200b\u52a8\u4f5c\u200b  </p> <p>\u200b\u786e\u5b9a\u200b\u72b6\u6001\u200b\u662f\u200b \\(s_{t+1}=f(s_t, a_t)\\)\uff0c\u200b\u6982\u7387\u200b\u72b6\u6001\u200b \\(s_{t+1}=P(s_{t+1}\\vert s_t, a_t)\\) </p> </li> <li> <p>Trajectory\uff1a\u200b\u8f68\u8ff9\u200b\uff0c\u200b\u5373\u200b\u72b6\u6001\u200b\u52a8\u4f5c\u200b\u5e8f\u5217\u200b \\(\\tau = \\{s_0,a_0,s_1,a_1, \\dots\\}\\)</p> </li> <li> <p>Return: \u200b\u56de\u62a5\u200b\uff0c\u200b\u5373\u200b\u4ece\u200b\u5f53\u524d\u200b\u72b6\u6001\u200b \\(s_t\\) \u200b\u5230\u200b\u8f68\u8ff9\u200b\u7ed3\u675f\u200b\u7684\u200b Reward \u200b\u603b\u548c\u200b \\(R_t\\)</p> </li> <li> <p>episodes: \u200b\u7b49\u4ef7\u200b\u4e8e\u200bsample</p> </li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/index.html#_4","title":"\u4f18\u52bf\u200b\u51fd\u6570","text":"<p>\u200b\u52a8\u4f5c\u200b\u4ef7\u503c\u200b\u51fd\u6570\u200b\u793a\u610f\u200b</p> <p>\u200b\u4f18\u52bf\u200b\u51fd\u6570\u200b\u793a\u610f\u200b</p> <p>\u200b\u5728\u200b\u597d\u200b\u7684\u200b\u72b6\u6001\u200b \\(s_t\\)\u200b\u4e0b\u200b\uff0c\u200b\u65e0\u8bba\u200b\u505a\u200b\u4ec0\u4e48\u200b\u52a8\u4f5c\u200b \\(a_t\\) \u200b\u90fd\u200b\u80fd\u200b\u5f97\u5230\u200b\u6b63\u200b\u7684\u200b\u56de\u62a5\u200b\uff1b\u200b\u800c\u200b\u5728\u200b\u574f\u200b\u7684\u200b\u72b6\u6001\u200b \\(s_t\\) \u200b\u4e0b\u200b\uff0c\u200b\u65e0\u8bba\u200b\u505a\u200b\u4ec0\u4e48\u200b\u52a8\u4f5c\u200b\u90fd\u200b\u4f1a\u200b\u5f97\u5230\u200b\u8d1f\u200b\u7684\u200b\u56de\u62a5\u200b\uff0c\u200b\u8fd9\u200b\u662f\u200b\u4e0d\u200b\u5408\u9002\u200b\u7684\u200b\u3002\u200b\u6211\u4eec\u200b\u9700\u8981\u200b\u8861\u91cf\u200b\u6267\u884c\u200b\u5f53\u524d\u200b\u52a8\u4f5c\u200b \\(a_t\\) \u200b\u76f8\u5bf9\u200b\u4e8e\u200b\u5176\u4ed6\u200b\u52a8\u4f5c\u200b\u7684\u200b\u4f18\u52bf\u200b\uff0c\u200b\u56e0\u6b64\u200b\u9700\u8981\u200b\u6211\u4eec\u200b\u5bf9\u200b\u56de\u62a5\u200b\u51cf\u53bb\u200b\u4e00\u4e2a\u200b\u57fa\u51c6\u503c\u200b</p> <ul> <li>Action-Value Function\uff0c\u200b\u52a8\u4f5c\u200b\u4ef7\u503c\u200b\u51fd\u6570\u200b\uff0c\u200b\u5728\u200b\u5f53\u524d\u200b\u72b6\u6001\u200b \\(s_t\\) \u200b\u4e0b\u200b\uff0c\u200b\u505a\u51fa\u200b\u52a8\u4f5c\u200b \\(a_t\\) \u200b\u5e76\u200b\u9075\u5faa\u200b\u7b56\u7565\u200b \\(\\pi\\) \u200b\u540e\u200b\u7684\u200b\u56de\u62a5\u200b \\(Q^{\\pi}(s_t, a_t)\\) </li> <li>State-Value Function\uff0c\u200b\u72b6\u6001\u200b\u4ef7\u503c\u200b\u51fd\u6570\u200b\uff0c\u200b\u5728\u200b\u5f53\u524d\u200b\u72b6\u6001\u200b \\(s_t\\) \u200b\u4e0b\u200b\uff0c\u200b\u9075\u5faa\u200b\u7b56\u7565\u200b \\(\\pi\\) \u200b\u540e\u200b\u83b7\u5f97\u200b\u7684\u200b\u671f\u671b\u200b\u56de\u62a5\u200b \\(V^{\\pi}(s_t)\\) </li> <li> <p>Advantage Function\uff0c\u200b\u4f18\u52bf\u200b\u51fd\u6570\u200b\uff0c\u200b\u5728\u200b\u5f53\u524d\u200b\u72b6\u6001\u200b \\(s_t\\) \u200b\u4e0b\u200b\uff0c\u200b\u8861\u91cf\u200b\u52a8\u4f5c\u200b \\(a_t\\) \u200b\u76f8\u5bf9\u200b\u4e8e\u200b\u9075\u5faa\u200b\u7b56\u7565\u200b \\(\\pi\\) \u200b\u7684\u200b\u5e73\u5747\u200b\u8868\u73b0\u200b\uff0c\u200b\u5373\u200b\\(A^{\\pi}(s_t, a_t) = Q^{\\pi}(s_t, a_t) - V^{\\pi}(s_t)\\)</p> <ul> <li>\\(A^{\\pi}(s_t, a_t) \\gt 0\\) \u200b\u8868\u793a\u200b\u52a8\u4f5c\u200b \\(a_t\\) \u200b\u6bd4\u200b\u7b56\u7565\u200b \\(\\pi\\) \u200b\u7684\u200b\u5e73\u5747\u200b\u9009\u62e9\u200b\u66f4\u597d\u200b  </li> <li>\u200b\u7531\u4e8e\u200b\u76ee\u6807\u200b\u662f\u200b\u6700\u5927\u5316\u200b \\(A^{\\pi}(s_t, a_t)\\)\uff0c\u200b\u56e0\u6b64\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b\u68af\u5ea6\u200b\u4e0a\u5347\u200b\u65b9\u6cd5\u200b\u8fdb\u884c\u200b\u53c2\u6570\u200b\u66f4\u65b0\u200b</li> </ul> </li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/index.html#_5","title":"\u4f18\u5316\u200b\u7b56\u7565","text":"<p>\u200b\u6838\u5fc3\u200b\u533a\u522b\u200b\u5728\u4e8e\u200b\u6570\u636e\u200b\u53ef\u4e0d\u53ef\u4ee5\u200b\u91cd\u590d\u200b\u5229\u7528\u200b\uff0chttps://zhuanlan.zhihu.com/p/26603719923</p> <ol> <li> <p>On-Policy \u200b\u540c\u200b\u7b56\u7565\u200b\uff0c\u200b\u5fc5\u987b\u200b\u4f7f\u7528\u200b\u5f53\u524d\u200b\u7b56\u7565\u200b\u751f\u6210\u200b\u7684\u200b\u6570\u636e\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b  </p> <ul> <li>\\(E_{\\tau \\sim p_{\\theta}(\\tau) }[R(\\tau)\\nabla \\log p_{\\theta}(\\tau)]\\) </li> <li>\u200b\u8fb9\u200b\u5b66\u4e60\u200b\u6570\u636e\u200b\u8fb9\u200b\u66f4\u65b0\u200b\u72b6\u6001\u200b\uff0c\u200b\u6b64\u65f6\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b\u65b0\u200b\u72b6\u6001\u200b\u4e0b\u200b\u7684\u200b\u6570\u636e\u200b\uff0c\u200b\u6570\u636e\u200b\u5229\u7528\u7387\u200b\u4f4e\u200b\uff0c</li> </ul> </li> <li> <p>Off-Policy \u200b\u5f02\u200b\u7b56\u7565\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u5386\u53f2\u200b\u7b56\u7565\u200b\u751f\u6210\u200b\u7684\u200b\u6570\u636e\u200b  </p> <ul> <li>\\(E_{\\tau \\sim p_{\\theta}^{'}(\\tau) }[\\frac{p_\\theta(\\tau)}{p_{\\theta}^{'}(\\tau)}R(\\tau)\\nabla \\log p_{\\theta}(\\tau)]\\) </li> <li>\u200b\u89c2\u5bdf\u200b\u4ed6\u4eba\u200b\u5b66\u4e60\u200b\uff0c\u200b\u6570\u636e\u200b\u5229\u7528\u7387\u200b\u9ad8\u200b</li> </ul> </li> <li> <p>IS: importance sampling  </p> </li> <li>\\(\\frac{p_\\theta(\\tau)}{p_{\\theta}^{'}(\\tau)}\\) \u200b\u4e3a\u200b\u91cd\u8981\u6027\u200b\u6743\u91cd\u200b importance weight</li> </ol>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/index.html#rl","title":"RL\u200b\u7b97\u6cd5","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/index.html#_6","title":"\u8bc4\u4f30\u200b\u52a8\u4f5c\u200b\u4ef7\u503c","text":"<ol> <li>Q-Learning</li> <li>DQN\uff08Deep Q-Network\uff09</li> </ol>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/index.html#_7","title":"\u8bc4\u4f30\u200b\u72b6\u6001\u200b\u4ef7\u503c","text":"<ol> <li>Policy Gradient\uff08PG\uff09</li> </ol>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/index.html#_8","title":"\u8bc4\u4f30\u200b\u4f18\u52bf\u200b\u51fd\u6570","text":"<ol> <li>A3C\uff08Asynchronous Advantage Actor-Critic\uff09\uff1aAsynchronous Methods for Deep Reinforcement Learning</li> <li>A2C\uff08Advantage Actor-Critic\uff09</li> <li>TRPO\uff08Trust Region Policy Optimization\uff09\uff1ausing only first-order optimization</li> <li>PPO\uff08Proximal Policy Optimization\uff09</li> <li> <p>ppo  </p> <ul> <li>Generalized Advantage Estimation, GAE\uff0c\u200b\u591a\u200b\u6b65\u200b\u91c7\u6837\u200b\u65b9\u5f0f\u200b\u7ed3\u5408\u200b\uff0c\u200b\u6b65\u6570\u200b\u8d8a\u200b\u591a\u200b\u6743\u91cd\u200b\u8d8a\u5c0f\u200b</li> </ul> <p></p> <p></p> </li> <li> <p>SAC\uff08Soft Actor-Critic\uff09\uff1aSoft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor</p> </li> <li>dpo</li> <li>grpo<ul> <li>Approximating kl divergence, seq-all-token prob</li> <li>tokne-level \u200b\u8f93\u51fa\u200b</li> </ul> </li> <li>DAPO</li> </ol>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/index.html#llm-sft","title":"llm sft","text":"<ul> <li> \u200b\u5927\u200b\u6a21\u578b\u200b\u76d1\u7763\u200b\u5fae\u8c03\u200bSFT<ul> <li>chat template</li> <li>completion only\uff0c\u200b\u53ea\u200b\u5bf9\u200b\u8f93\u51fa\u200b\u7ed3\u679c\u200b\u8ba1\u7b97\u200bloss\uff0c\u200b\u4e0d\u200b\u8ba1\u7b97\u200b\u901a\u7528\u200bchat template\u200b\u7684\u200bloss\uff08\u200b\u5982\u200b\u901a\u8fc7\u200bcompletion mask\u200b\u8fdb\u884c\u200b\u6807\u8bb0\u200b\uff09</li> <li>NEFTune, noisy embeddings finetuning: \u200b\u5bf9\u200b\u8f93\u5165\u200bembedding\u200b\u52a0\u200b\u4e86\u200b\u4e00\u70b9\u200b\u566a\u97f3\u200b\uff0csqrt(seq_len * dim) \u200b\u662f\u200b\u4e3a\u4e86\u200b\u5f52\u4e00\u5316\u200b\uff0c\u200b\u9632\u6b62\u200b\u7531\u4e8e\u200b\u6bcf\u6b21\u200binput\u200b\u957f\u5ea6\u200b\u4e0d\u540c\u200b\u5bfc\u81f4\u200b\u7684\u200b\u6b27\u5f0f\u200b\u8ddd\u79bb\u200b\u4e0d\u540c\u200b\uff0c\u200b\u53ef\u200b\u4e0e\u200battention\u200b\u6743\u91cd\u200b\u5206\u6570\u200b\u7c7b\u6bd4\u200b</li> </ul> </li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/index.html#llm-rl","title":"llm rl","text":"<ul> <li>question\uff0c\u200b\u95ee\u9898\u200b</li> <li>chosen\uff0c\u200b\u66f4\u597d\u200b\u7684\u200b\u56de\u7b54\u200b</li> <li>rejected\uff0c\u200b\u76f8\u5bf9\u200b\u4e0d\u597d\u200b\u7684\u200b\u56de\u7b54\u200b</li> <li>grpo trainer</li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/critic_model.html","title":"Critic model","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dapo.html","title":"Dapo","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dapo.html#dapo","title":"DAPO","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDAPO: An Open-Source LLM Reinforcement Learning System at Scale Project Page\uff1adapo-sia.github.io DAPO\uff1aDecoupled clip Dynamic sAmpling Policy Optimization ByteDance Seed &amp; Tsinghua University &amp; The University of Hong Kong, 2025 Mar</p>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dapo.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>https://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&amp;mid=2247571337&amp;idx=2&amp;sn=ca7ed117c5f5534bc4299ca5f166f9f0&amp;chksm=ea4791a30d92493bfc6f54ff44bcc1d4c6f5185b73dc1f94d804baeac25f909978fd2facb516&amp;scene=27</li> <li>Qwen2.5-32B as the pretrained model for RL</li> <li>GRPO baseline suffers from several key issues such as 1) entropy collapse; 2) reward noise; 3) training instability</li> <li>DAPO introduces 4 key techniques to make RL shine in long-CoT RL schenario<ol> <li>clip-higher</li> <li>dynamic sampling</li> <li>token-level policy gradient loss</li> <li>overlong reward shaping</li> </ol> </li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dapo.html#ppo-in-llm","title":"PPO in LLM","text":"\\[ \\begin{aligned}     \\mathcal{L}_\\text{PPO} =&amp; \\mathbb{E}_{(q, a) \\sim D, o\\le t \\sim \\pi_{\\theta_\\text{old}}(\\cdot \\vert q)} \\bigg[ \\min \\Big( r_t(\\theta)\\hat{A}_t, \\text{clip}\\big(r_t(\\theta), 1-\\epsilon, 1+\\epsilon \\big)\\hat{A_t}\\Big) \\bigg] \\\\     r_t(\\theta) =&amp; \\frac{\\pi_{\\theta}(o_t\\vert q, o_{\\lt t})}{\\pi_{\\theta_\\text{old}}(o_t\\vert q, o_{\\lt t})} \\end{aligned} \\] <p>\\((q, a)\\) \u200b\u4e3a\u200bquestion-answer pair \\(o\\) \u200b\u8868\u793a\u200breference model\u200b\u7684\u200boutput</p>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dapo.html#grpo-in-llm","title":"GRPO in LLM","text":"\\[ \\begin{aligned}     \\mathcal{L}_\\text{GRPO} = &amp;\\mathbb{E}_{(q, a) \\sim D, \\{o_i\\}_{i=1}^{G} \\sim \\pi_{\\theta_\\text{old}}(\\cdot \\vert q)} \\\\      &amp; \\bigg[ \\frac{1}{G} \\sum_{i=1}^{G}\\frac{1}{\\vert o_i \\vert} \\sum_{t=1}^{\\vert o_i \\vert} \\bigg( \\min \\Big(  r_{i, t}(\\theta)\\hat{A}_{i,t},  \\text{clip}\\big(  r_{i, t}(\\theta), 1-\\epsilon, 1+\\epsilon \\big)\\hat{A_{i, t}}\\Big) -\\beta D_\\text{KL}(\\pi_{\\theta} \\Vert \\pi_\\text{old}) \\bigg)\\bigg] \\\\     \\hat{A}_{i, t} =&amp; \\frac{r_i - \\text{avg}(\\{r_j\\}_{j=1}^G)}{\\text{std}(\\{r_j\\}_{j=1}^G)} \\\\     r_{i, t}(\\theta) =&amp; \\frac{\\pi_{\\theta}(o_{i, t}\\vert q, o_{i, \\lt t})}{\\pi_{\\theta_\\text{old}}(o_{i, t}\\vert q, o_{i, \\lt t})} \\end{aligned} \\] <ul> <li>remove KL divergence: In the RLHF scenario, the goal of RL is to align the model behavior without diverging too far from the initial model. However, during training the long-CoT reasoning model, the model distribution can diverge significantly from the initial model, thus this restriction is not necessary. Therefore, we will exclude the KL term from our proposed algorithm.</li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dapo.html#rule-based-reward-modeling","title":"Rule-based Reward Modeling","text":"<ul> <li>reward model usually suffers from the reward hacking problem [24-29]</li> <li> <p>we directly use final accuracy of a verifiable task as the outcome reward as below</p> \\[ r(\\hat{y}, y) = \\begin{cases}     1, &amp; \\text{is_equivalent}(\\hat{y}, y) \\\\     -1, &amp; \\text{otherwise} \\end{cases} \\] <p>\\(y\\) ground-truth answer, \\(\\hat{y}\\) is the predicted answer  </p> </li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dapo.html#clip-higher","title":"Clip-Higher","text":"<p>PPO\u200b\u548c\u200bGRPO\u200b\u4f1a\u200b\u5f15\u53d1\u200b\u71b5\u200b\u584c\u7f29\u200bentropy collapse\u200b\u73b0\u8c61\u200b\uff0c\u200b\u8868\u73b0\u200b\u4e3a\u200b\u71b5\u200b\u503c\u200b\u4e0b\u964d\u200b\u8fc7\u5feb\u200b\uff08\u200b\u5feb\u901f\u200b\u5230\u8fbe\u200b\u76ee\u6807\u200b\u72b6\u6001\u200b\uff0c\u200b\u76f4\u63a5\u200b\u7ed3\u675f\u200b\u5b66\u4e60\u200b\u8fc7\u7a0b\u200b\uff09\uff0c\u200b\u5bfc\u81f4\u200bgroup sampled responses\u200b\u7684\u200b\u7ed3\u679c\u200b\u8fc7\u4e8e\u200b\u96f7\u540c\u200b\uff0cpolicy model\u200b\u6709\u9650\u200b\u63a2\u7d22\u200b\u963b\u788d\u200bLLM\u200b\u7684\u200b\u62d3\u5c55\u200b\uff08get stuck in a narrow range of outputs\uff09</p> <ul> <li>low fixed clipping range prevents policy model from making large updates, which is good for stability but not for diversity exploration</li> <li>upper clipping threshold indeed restricts the probability increase of low-probability tokens, thereby potentially constraining the diversity of the system.</li> <li>\u200b\u5047\u5b9a\u200b\\(\\epsilon=0.2\\)\u200b\u6709\u200b \\(\\pi_{\\theta_\\text{old}}(o_i\\vert q)\\) \u200b\u5206\u522b\u200b\u4e3a\u200b0.01\u200b\u548c\u200b0.9\uff0c\u200b\u5bf9\u5e94\u200bPPO-clip\u200b\u7684\u200b\u6700\u5927\u200b\u4f18\u5316\u200b\u6982\u7387\u200b \\(\\pi_{\\theta}(o_i\\vert q)\\) \u200b\u4e3a\u200b0.012\u200b\u548c\u200b1.08\uff0c\u200b\u8868\u73b0\u200b\u4e3a\u200b\u5bf9\u200b\u4f4e\u200b\u6982\u7387\u200btoken\u200b\u7684\u200b\u53d1\u6398\u200b\u96be\u5ea6\u200b\u589e\u52a0\u200b\uff0c\u200b\u4ece\u800c\u200b\u9650\u5236\u200bpolicy model\u200b\u7684\u200b\u591a\u6837\u6027\u200b</li> <li>\u200b\u56e0\u6b64\u200b\u91c7\u7528\u200bDecouple Clip, \u200b\u5176\u4e2d\u200blow \\(\\epsilon_\\text{low}\\) for maintaining stability, high \\(\\epsilon_\\text{high}\\) for exploration</li> </ul> <p></p> <ul> <li>maximum probability of clipped tokens is approximately \\(\\pi_{\\theta}(o_i \\vert q) &lt; 0.2\\)\uff0c\u200b\u8868\u73b0\u200b\u4e3a\u200b\u4f4e\u200b\u6982\u7387\u200b\u7684\u200btoken\u200b\u9884\u88ab\u200b\u63a2\u7d22\u200b\u65f6\u200b\u63d0\u524d\u200b\u88ab\u200bclip\uff0c\u200b\u9002\u5f53\u200b\u653e\u5927\u200b\\(1+\\epsilon\\) \u200b\u53ef\u200b\u63d0\u9ad8\u200b\u63a2\u7d22\u200b\u8303\u56f4\u200b</li> <li>\u200b\u6b64\u65f6\u200b\u4fdd\u6301\u200b\\(\\epsilon_\\text{low}=0.2, \\epsilon_\\text{high}=0.28\\) </li> </ul> <p></p> <ul> <li>\\(\\text{clip}\\big(  r_{i, t}(\\theta), 1-\\epsilon_\\text{low}, 1+\\epsilon_\\text{high} \\big)\\)</li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dapo.html#dynamic-sampling","title":"Dynamic Sampling","text":"<ul> <li>Existing RL algorithm suffers from the gradient-decreasing problem when some prompts have accuracy equal to 1. \u200b\u5f53\u200breference model\u200b\u5bf9\u4e8e\u200b\u67d0\u4e2a\u200bprompt\u200b\u7684\u200b \\(G\\) \u200b\u4e2a\u200boutputs\u200b\u7684\u200breward\u200b\u503c\u200b\u90fd\u200b\u76f8\u7b49\u200b\u65f6\u200b\uff0c\u200b\u6b64\u65f6\u200b\u4f18\u52bf\u200b\u503c\u4e3a\u200b0\uff0c\u200b\u68af\u5ea6\u200b\u4e3a\u200b0\uff0cpolicy model\u200b\u65e0\u6548\u200b\u66f4\u65b0\u200b\uff0c\u200b\u964d\u4f4e\u200b\u6709\u6548\u200b\u91c7\u6837\u200b\u6548\u7387\u200b</li> </ul> <ul> <li>number of samples with accuracy equal to 1 continues to increase, \u200b\u65e0\u6548\u200b\u91c7\u6837\u7387\u200b\u4f1a\u200b\u968f\u7740\u200b\u8bad\u7ec3\u200b\u7684\u200b\u8fdb\u884c\u200b\u4e0d\u65ad\u200b\u79ef\u7d2f\u200b\u63d0\u5347\u200b</li> <li> <p>\u200b\u8fc7\u200b\u91c7\u6837\u200bover-sample + filter out prompts outputs accuracy \u200b\u7b49\u4e8e\u200b1\u200b\u6216\u200b0\u200b\u7684\u200b\u90e8\u5206\u200b\uff08until fulfill each batch\uff09</p> </li> <li> <p>\\(\\text{s.t.  } 0 \\lt \\Big\\vert \\{o_i \\vert \\text{is_equivalent}(a, o_i)\\} \\Big\\vert \\lt G\\)</p> </li> <li>dynamic sampling the experiment achieves the same performance faster as shown in Figure 6.</li> <li>When applying Dynamic Sampling, although more data needs to be sampled due to the filtering out of zero-gradient data, the overall training time is not significantly affected. </li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dapo.html#token-level-policy-gradient-loss","title":"Token-Level Policy Gradient Loss","text":"<ul> <li>GRPO algorithm employs a sample-level loss calculation, each sample is assigned an equal weight in the final loss computation </li> <li>\u200b\u5bf9\u4e8e\u200blong output\uff0c\u200b\u5355\u7eaf\u200bavg sample loss\u200b\u540e\u200b\u6bcf\u4e2a\u200btoken\u200b\u7684\u200bloss\u200b\u8d21\u732e\u200b\u4f1a\u200b\u5f88\u5c0f\u200b\uff0c\u200b\u5bfc\u81f4\u200b\uff1a1) \u200b\u963b\u6b62\u200bpolicy model\u200b\u5b66\u4e60\u200b\u9ad8\u8d28\u91cf\u200blong output\u200b\u7684\u200b\u63a8\u7406\u200b\uff1b2) \u200b\u8fc7\u957f\u200b\u7684\u200boutput\u200b\u901a\u5e38\u200b\u4f1a\u200b\u51fa\u73b0\u200b\u4f4e\u8d28\u91cf\u200b\u7684\u200bpatterns\uff08\u200b\u5982\u200b\u4e71\u7801\u200b\u548c\u200b\u91cd\u590d\u200brepeat\u200b\u5355\u8bcd\u200b\uff09\u3002\u200b\u56e0\u6b64\u200bavg token loss\u200b\u65e0\u6cd5\u200b\u6709\u6548\u200b\u60e9\u7f5a\u200blong output\u200b\u7684\u200b\u4e0d\u4f73\u200bpattern\u3001\u200b\u5956\u52b1\u200blong output\u200b\u7684\u200b\u7406\u60f3\u200bpattern\uff0c\u200b\u5bfc\u81f4\u200b\u71b5\u200b\u548c\u200b\u54cd\u5e94\u200b\u957f\u5ea6\u200b\u4e0d\u200b\u5065\u5eb7\u200b\u5730\u200b\u589e\u52a0\u200b</li> <li>\u200b\u4f18\u5316\u200b\uff1aavg sample loss \u2192 avg token loss</li> <li>longer sequences can have more influence on the overall gradient update compared to shorter sequences.</li> <li> <p>from the perspective of individual tokens, if a particular generation pattern can lead to an increase or decrease in reward, it will be equally prompted or suppressed, regardless of the length of the response in which it appears. </p> </li> <li> <p>\\(\\frac{1}{ \\sum_{i=1}^{G} \\vert o_i \\vert} \\sum_{i=1}^G\\sum_{t=1}^{\\vert o_i \\vert}\\)</p> </li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dapo.html#overlong-reward-shaping","title":"Overlong Reward Shaping","text":"<ul> <li>improper reward shaping for truncated samples can introduce reward noise and significantly disrupt the training process.</li> <li>a punitive reward to truncated samples may introduce noise into the training process which can potentially confuse the model regarding the validity of its reasoning process</li> <li>Overlong Filtering strategy which masks the loss of truncated samples (corresponding_loss * 0), significantly stabilizes training and enhances performance</li> </ul> <ul> <li> <p>Soft Overlong Punishment, the penalty is added to the original rule-based correctness reward</p> \\[ r_\\text{length}(y) = \\begin{cases}     0 &amp; \\vert y \\vert \\le L_\\text{max} - L_\\text{cache} \\\\     \\frac{(L_\\text{max} - L_\\text{cache}) - \\vert y \\vert }{L_\\text{cache}} &amp; L_\\text{max} - L_\\text{cache} \\lt \\vert y \\vert \\le L_\\text{max} \\\\     -1 &amp; \\vert y \\vert \\gt L_\\text{max}  \\end{cases} \\] <p>\\(L_\\text{max} = 20480, L_\\text{cache} = 4096\\)</p> </li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dapo.html#dapo_1","title":"DAPO","text":"\\[ \\begin{aligned}     \\mathcal{L}_\\text{GRPO} =&amp; \\mathbb{E}_{(q, a) \\sim D, \\{o_i\\}_{i=1}^{G} \\sim \\pi_{\\theta_\\text{old}}(\\cdot \\vert q)} \\\\     &amp; \\bigg[ \\frac{1}{ \\sum_{i=1}^{G} \\vert o_i \\vert} \\sum_{i=1}^G\\sum_{t=1}^{\\vert o_i \\vert}  \\min \\Big(  r_{i, t}(\\theta)\\hat{A}_{i,t},  \\text{clip}\\big(  r_{i, t}(\\theta), 1-\\epsilon_\\text{low}, 1+\\epsilon_\\text{high} \\big)\\hat{A_{i, t}}\\Big)\\bigg] \\\\     \\text{s.t.  } &amp; 0 \\lt \\Big\\vert \\{o_i \\vert \\text{is_equivalent}(a, o_i)\\} \\Big\\vert \\lt G \\\\     \\hat{A}_{i, t} =&amp; \\frac{r_i - \\text{avg}(\\{r_j\\}_{j=1}^G)}{\\text{std}(\\{r_j\\}_{j=1}^G)} \\\\     r_{i, t}(\\theta) =&amp; \\frac{\\pi_{\\theta}(o_{i, t}\\vert q, o_{i, \\lt t})}{\\pi_{\\theta_\\text{old}}(o_{i, t}\\vert q, o_{i, \\lt t})} \\end{aligned} \\]"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dapo.html#monitoring-indicators","title":"Monitoring Indicators","text":"<p> monitoring of key intermediate results during experimentation is essential for swiftly identifying the sources of discrepancies and, ultimately, for refining the system.</p> <ol> <li>The Length of Generated Responses is a metric closely related to training stability and performance, The increase in length provides the model with a larger space for exploration, allowing more complex reasoning behaviors to be sampled and gradually reinforced through training  </li> <li>The Dynamics of Reward, final reward on the training set often exhibits little correlation with the accuracy on the validation set  </li> <li>The Entropy of the Actor Model and Generation Probability are related to the model\u2019s exploration capability. Intuitively, the model\u2019s entropy needs to be maintained within an appropriate range. An excessively low entropy indicates that the probability distribution is overly sharp, leading to a loss of exploration capability</li> <li>Generation Probability is exactly the opposite to the entropy</li> </ol>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dapo.html#abaltion-study","title":"Abaltion Study","text":"<ul> <li>For token-level loss, although it brings less performance improvement, we find it enhances training stability and makes the length increase more healthily.</li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dapo.html#case-study","title":"Case Study","text":"<ul> <li>During the RL training process, we observe an interesting phenomenon: the reasoning patterns of the actor model evolve dynamically over time. Specifically, the RL algorithm not only reinforces existing reasoning patterns that facilitate correct problem-solving but also gradually gives rise to entirely new modes of reasoning that were initially absent. \u200b\u5373\u200b\u524d\u671f\u200b\u5229\u7528\u200b + \u200b\u540e\u671f\u200b\u63a2\u7d22\u200b</li> <li>in the early stages of model training, there was virtually no occurrence of checking and reflecting on previous reasoning steps</li> <li>as training progresses, the model exhibits distinct behaviors of reflection and backtracking</li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dpo.html","title":"Dpo","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dpo.html#dpo","title":"DPO","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDirect Preference Optimization: Your Language Model is Secretly a Reward Model  </p> <p>Stanford University 2023 May, NeruIPS 2023  </p>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/dpo.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li> <p>Bradley-Terry\u200b\u504f\u597d\u200b\u6a21\u578b\u200b\uff0cpair-loss\uff0c\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b\u8d1f\u200b\u91c7\u6837\u200b</p> \\[ P(y_1 \\gt y_2 \\vert x) = \\frac{\\exp(r(x,y_1))}{\\exp(r(x, y_1)) + \\exp(r(x, y_2))} \\] </li> <li> <p>\u200b\u7b56\u7565\u200b\u4e0e\u200b\u5956\u52b1\u200b\u7684\u200b\u9690\u5f0f\u200b\u5173\u7cfb\u200b\uff0c\u200b\u901a\u8fc7\u200bKL\u200b\u7ea6\u675f\u200b\u7b56\u7565\u200b\u4f18\u5316\u200b\u95ee\u9898\u200b</p> \\[ r(x, y) = \\beta \\log \\frac{\\pi(y\\vert x)}{\\pi_\\text{ref}(y \\vert x)} + c \\] <p>\\(\\beta\\) \u200b\u4e3a\u200b\u6e29\u5ea6\u200b\u7cfb\u6570\u200b</p> </li> <li> <p>loss function\uff0c\u200b\u6700\u5c0f\u5316\u200b\u504f\u597d\u200b\u6570\u636e\u200b\u7684\u200b\u8d1f\u200b\u5bf9\u6570\u200b\u4f3c\u7136\u200b</p> \\[ \\mathcal{L}_\\text{DPO}(\\pi_{\\theta}) = -\\mathbb{E}_{(x, y_w, y_l) \\sim D} \\bigg[ \\log \\sigma \\Big(\\beta \\log \\frac{\\pi(y_w\\vert x)}{\\pi_\\text{ref}(y_w \\vert x)} - {\\beta \\log \\frac{\\pi(y_l\\vert x)}{\\pi_\\text{ref}(y_l \\vert x)} - {\\pi(y_l\\vert x)}} \\Big) \\bigg] \\] </li> <li> <p>https://zhuanlan.zhihu.com/p/681559204  </p> </li> <li>https://zhuanlan.zhihu.com/p/642569664</li> <li>IPO\uff08Identity Preference Optimization\uff09</li> <li>KTO\uff08Kahneman-Tversky Optimization\uff09</li> <li>Reword Model \u200b\u9636\u6bb5\u200b </li> <li>https://zhuanlan.zhihu.com/p/15578845927</li> <li>RL \u200b\u9636\u6bb5\u200b\uff0c\u200b\u6700\u5927\u5316\u200b\u751f\u6210\u200b\u7684\u200b\u7b54\u6848\u200b\u80fd\u591f\u200b\u83b7\u5f97\u200b\u7684\u200breward\u200b\u4e4b\u200b\u548c\u200b\uff0c\u200b\u540c\u65f6\u200b\u4e3a\u4e86\u200b\u786e\u4fdd\u200b\u548c\u200bSFT\u200b\u8868\u73b0\u200b\u76f8\u5dee\u200b\u4e0d\u592a\u8fdc\u200b\uff0c\u200b\u6dfb\u52a0\u200b\u4e86\u200bKL\u200b\u6563\u5ea6\u200b\u4f5c\u4e3a\u200b\u7ea6\u675f\u200b</li> <li></li> <li></li> <li></li> <li></li> <li></li> <li></li> <li></li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/gae.html","title":"Gae","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/gae.html#gae","title":"GAE","text":"<p>\u200b\u8bba\u6587\u200b\uff1aHigh-Dimensional Continuous Control Using Generalized Advantage Estimation University of California Berkeley 2015 Jun, ICLR 2016</p>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/gae.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>reduce bias\uff1a\\(\\hat{V}(s_t) = r_t + \\gamma V(s_{t+1})\\)</li> <li>reduce variance\uff1a\\(\\hat{V}(s_t) = r_t + \\gamma r_{t+1} + \\dots + \\gamma^{T-t+1}r_{T-1} + \\gamma^{T-t}V_{s_t}\\)</li> <li>policy gradient estimators that significantly reduce variance while maintaining a tolerable level of bias  </li> <li>\u200b\u901a\u8fc7\u200b\u8870\u51cf\u200b\u53c2\u6570\u200b \\(\\gamma\\) \u200b\u964d\u4f4e\u200b\u4e0e\u200b\u5ef6\u8fdf\u200b\u540e\u7eed\u200b\u6b65\u9aa4\u200b\u7684\u200b\u76f8\u5e94\u200b\u5956\u52b1\u200b\u6765\u200b\u51cf\u5c11\u200b\u65b9\u5dee\u200b\uff0c\u200b\u4f46\u200b\u4ee3\u4ef7\u200b\u662f\u200b\u5f15\u5165\u200b\u4e86\u200b\u504f\u5dee\u200b\uff08\u200b\u8870\u51cf\u200b\u540e\u503c\u200b\u4e0e\u200b\u539f\u200b\u771f\u5b9e\u200b\u5956\u52b1\u200b\u503c\u200b\u5b58\u5728\u200b\u5dee\u5f02\u200b\uff09</li> <li>\u200b\u6709\u200b\u6298\u6263\u200b\u4f18\u52bf\u200b\u51fd\u6570\u200b\\(A^{\\pi, \\gamma}\\)\uff0c\u200b\u65e0\u200b\u6298\u6263\u200b\u4f18\u52bf\u200b\u51fd\u6570\u200b\\(A^{\\pi}\\)</li> <li>trust region optimization for the value function  </li> <li>bias-variance tradeoff  </li> </ul> <pre><code>We\u2019ve described an advantage estimator with two separate parameters and \u0015, both of which contribute to the bias-variance tradeoff when using an approximate value function. However, they serve different purposes and work best with different ranges of values. most importantly determines the scale of the value function V \u0019; , which does not depend on \u0015. Taking  &lt; 1 introduces bias into the policy gradient estimate, regardless of the value function\u2019s accuracy. On the other hand, \u0015 &lt; 1 introduces bias only when the value function is inaccurate. Empirically, we find that the best value of \u0015 is much lower than the best value of , likely because \u0015 introduces far less bias than  for a reasonably accurate value function.\n</code></pre>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/gspo.html","title":"Gspo","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/gspo.html#gspo","title":"GSPO","text":"<p>\u200b\u8bba\u6587\u200b\uff1aGSPO: Group Sequence Policy Optimization BQwen Team, 2025 Jul</p>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/gspo.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/pg.html","title":"Pg","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/pg.html#pg","title":"PG","text":"<p>\u200b\u7b56\u7565\u200b\u68af\u5ea6\u200b Policy Gradient \u200b\u662f\u200b\u5f3a\u5316\u200b\u5b66\u4e60\u200b\u4e2d\u200b\u4e00\u7c7b\u200b\u76f4\u63a5\u200b\u4f18\u5316\u200b\u7b56\u7565\u200b\u7684\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u901a\u8fc7\u200b\u68af\u5ea6\u200b\u4e0a\u5347\u200b\u76f4\u63a5\u200b\u8c03\u6574\u200b\u7b56\u7565\u200b\u53c2\u6570\u200b\uff0c\u200b\u9002\u7528\u200b\u4e8e\u200b\u8fde\u7eed\u200b\u52a8\u4f5c\u200b\u7a7a\u95f4\u200b\u548c\u200b\u968f\u673a\u200b\u7b56\u7565\u200b\u7684\u200b\u573a\u666f\u200b\u3002</p>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/pg.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<p>PG \u200b\u7684\u200b\u6838\u5fc3\u601d\u60f3\u200b\u4e3a\u200b\u6700\u5927\u5316\u200b\u8f68\u8ff9\u200b\uff08\u200b\u6298\u6263\u200b\u6216\u975e\u200b\u6298\u6263\u200b\uff09\u200b\u56de\u62a5\u200b</p> \\[ J(\\theta) = \\mathbb{E}_{\\tau \\sim  \\pi_{\\theta}} \\bigg[ \\sum_{t=0}^\\infty \\gamma^{t}r_t \\bigg] \\]"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/pg.html#_2","title":"\u68af\u5ea6\u200b\u63a8\u5bfc","text":"\\[ \\begin{aligned}     \\nabla_{\\theta} J(\\theta) =&amp; \\mathbb{E}_{\\tau \\sim \\pi_{\\theta}} \\bigg[ \\sum_{t=0}^{T_n} \\Psi_t \\nabla_{\\theta} \\log \\pi_{\\theta}(a_t\\vert s_t) \\bigg] \\end{aligned} \\] <ul> <li>\u200b\u6bcf\u200b\u4e00\u6b65\u200b\u90fd\u200b\u8fdb\u884c\u200b\u4e86\u200b\u4e0a\u8ff0\u200b\u4f18\u5316\u200b</li> </ul> <p>\\(\\Psi_t\\) \u200b\u6709\u200b\u4ee5\u4e0b\u200b\u591a\u79cd\u200b\u9009\u62e9\u200b\uff1a</p> <ul> <li>\\(Q^{\\pi}(s_t, a_t)\\)\uff0c\u200b\u52a8\u4f5c\u200b\u4ef7\u503c\u200b\u51fd\u6570\u200b</li> <li>\\(A^{\\pi}(s_t, a_t)\\)\uff0c\u200b\u4f18\u52bf\u200b\u51fd\u6570\u200b\uff0c\u2192 \u200b\u6700\u5c0f\u200b\u65b9\u5dee\u200b</li> <li>\\(\\sum_{t=0}^{\\infty} r_t\\)\uff0c\u200b\u8f68\u8ff9\u200b\uff08\u200b\u6298\u6263\u200b\u6216\u975e\u200b\u6298\u6263\u200b\uff09\u200b\u603b\u200b\u56de\u62a5\u200b</li> <li>\\(\\sum_{k=0}^{\\infty} r_{t+k}\\)\uff0c\u200b\u540e\u7eed\u200b\u8f68\u8ff9\u200b\uff08\u200b\u6298\u6263\u200b\u6216\u975e\u200b\u6298\u6263\u200b\uff09\u200b\u56de\u62a5\u200b</li> <li>\\(\\sum_{k=0}^{\\infty} r_{t+k} - b_{t+k}\\)\uff0c\u200b\u51cf\u53bb\u200b\u57fa\u7ebf\u200b\u7684\u200b\u540e\u7eed\u200b\u8f68\u8ff9\u200b\uff08\u200b\u6298\u6263\u200b\u6216\u975e\u200b\u6298\u6263\u200b\uff09\u200b\u56de\u62a5\u200b</li> <li> <p>\\(r_t + V^{\\pi}(s_{t+1}) - V^{\\pi}(s_t)\\)\uff0c\u200b\u65f6\u5e8f\u200b\u5dee\u5206\u200b\u6b8b\u5dee\u200bTemporal Difference residual\uff0c\u200b\u524d\u200b\u4e24\u9879\u200b\u53ef\u200b\u7406\u89e3\u200b\u4e3a\u200b\u52a8\u4f5c\u200b\u4ef7\u503c\u200b\u77e9\u9635\u200b \\(Q^{\\pi}(s_t, a_t) = r_t + V^{\\pi}(s_{t+1})\\)\uff0c\u200b\u53ea\u4e0d\u8fc7\u200b\u524d\u8005\u200b\u53ea\u200b\u9700\u8981\u200b\u4e00\u4e2a\u200b\u6a21\u578b\u200b\uff0c\u200b\u540e\u8005\u200b\u9700\u8981\u200b\u4e24\u4e2a\u200b\u6a21\u578b\u200b\uff0c\u200b\u4f18\u4e8e\u200b\u91c7\u7528\u200b\u4e86\u200b\u52a8\u4f5c\u200b\u4e5f\u200b\u4f1a\u200b\u6709\u200b\u5404\u79cd\u200b\u72b6\u6001\u200b\u8f6c\u79fb\u200b\u7ed3\u679c\u200b\uff0c\u200b\u6b64\u65f6\u200b\u9700\u8981\u200b\u5bf9\u200b\u6240\u6709\u200b\\(V(s_{t+1})\\)\u200b\u7684\u200b\u53d6\u200b\u5747\u503c\u200b\uff0c\u200b\u5373\u200b\\(\\mathbb{E}_{s_{t+1}}[r_t + \\gamma V^{\\pi, \\gamma}(s_{t+1}) - V^{\\pi, \\gamma}(s_t)]\\)</p> </li> <li> <p>\u200b\u8499\u7279\u5361\u6d1b\u200b\uff08\u200b\u901a\u8fc7\u200b\u91c7\u6837\u200b\u4f30\u8ba1\u200b\uff09\u200b\u7b56\u7565\u200b\u68af\u5ea6\u200b</p> \\[ \\nabla_{\\theta} J(\\theta) \\approx \\frac{1}{N}\\sum_{i=1}^{N}\\sum_{t=0}^{T_n} \\nabla_{\\theta} \\log \\pi_{\\theta}(a_t^i\\vert s_t^i)\\cdot G_{t}^i  \\] <p>\u200b\u8499\u7279\u5361\u6d1b\u200b\u56de\u62a5\u200b \\(G_{t} = \\sum_{t^{'}=t}^{T_n} \\gamma^{t^{'} - t}\\cdot r_{t}\\)</p> </li> <li> <p>Actor-Critic</p> \\[ \\nabla_{\\theta} J(\\theta) \\approx \\mathbb{E} \\big[  \\nabla_{\\theta} \\log \\pi_{\\theta}(a_t\\vert s_t)\\cdot A^{\\pi_\\theta}(s_t, a_t) \\big] \\] <p>\u200b\u901a\u8fc7\u200b\u4f30\u8ba1\u200b\u6bcf\u200b\u4e00\u6b65\u200b\u7684\u200b\u4f18\u52bf\u200b\u503c\u200b\u66ff\u4ee3\u200b\u8499\u7279\u5361\u6d1b\u200b\u56de\u62a5\u200b \\(G_t\\)</p> </li> <li> <p>vanilla policy gradient with adaptive stepsize</p> </li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/ppo.html","title":"Ppo","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/ppo.html#ppo","title":"PPO","text":"<p>\u200b\u8bba\u6587\u200b\uff1aProximal Policy Optimization Algorithms OpenAI, 2017 Aug</p>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/ppo.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/ppo.html#truncated-gae","title":"Truncated GAE","text":"<p>\u200b\u622a\u65ad\u200b\u7248\u200bGAE\uff0c\u200b\u8003\u91cf\u200b\u4e86\u200b\u540e\u7eed\u200b \\(T\\) \u200b\u6b65\u200b\u7684\u200b\u6298\u6263\u200b\u4f18\u52bf\u200b</p> \\[ \\begin{aligned}     \\hat{A}_t =&amp; \\delta_t + (\\gamma\\lambda)\\delta_{t+1} + \\dots + (\\gamma\\lambda)^{T-t+1}\\delta_{T-1} \\\\     \\delta_t =&amp; r_t  + \\gamma V(s_{t+1}) - V(s_t) \\end{aligned} \\]"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/ppo.html#clipped-surrogate-objective","title":"Clipped Surrogate Objective","text":"<p>\u200b\u88c1\u526a\u200b\u7b56\u7565\u200b\u7ea6\u675f\u200bpolicy model\u200b\u66f4\u65b0\u200b\u5e45\u5ea6\u200b\uff0c\u200b\u9632\u6b62\u200b\u4e0e\u200breference model\u200b\u5dee\u5f02\u200b\u8fc7\u5927\u200b\u3001\u200b\u91cd\u8981\u6027\u200b\u91c7\u6837\u200b\u6548\u679c\u200b\u4e0d\u200b\u5bf9\u9f50\u200b\u3002 </p> \\[ L^{CLIP}(\\theta) = \\hat{\\mathbb{E}}_t \\Big[ \\min\\big(r_t(\\theta) \\hat{A}_t, \\text{clip}(r_t(\\theta), 1-\\epsilon, 1+\\epsilon)\\hat{A}_t\\big) \\Big] \\] <ul> <li>\u200b\u65b0\u65e7\u200b\u7b56\u7565\u200b\u6982\u7387\u200b\u6bd4\u200b \\(r_t(\\theta)=\\frac{\\pi_{\\theta}(a_t\\vert s_t)}{\\pi_{\\theta_{old}}(a_t\\vert s_t)}\\) </li> <li>\\(\\epsilon\\) \u200b\u4e3a\u200b\u88c1\u526a\u200b\u53c2\u6570\u200b\uff0c\u200b\u901a\u5e38\u200b\u53d6\u200b0.1 ~ 0.3\uff0c\u200b\u5f3a\u5236\u200b \\(r_t(\\theta)\\approx 1\\)\uff0c\u200b\u907f\u514d\u200b\u8fc7\u5927\u200b\u66f4\u65b0\u200b</li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/ppo.html#adaptive-kl-penalty","title":"Adaptive KL Penalty","text":"\\[ L^{KL}(\\theta) = \\beta \\hat{\\mathbb{E}}_t\\Big[  \\text{KL}[\\pi_{\\theta_\\text{old}}(\\cdot \\vert s_t), \\pi_{\\theta}(\\cdot \\vert s_t)] \\Big] \\] <p>\u200b\u5176\u4e2d\u200b \\(\\beta\\) \u200b\u4e3a\u200bKL\u200b\u6563\u5ea6\u200b\u635f\u5931\u200b\u60e9\u7f5a\u200b\u7cfb\u6570\u200b\uff0c\u200b\u5f53\u200bpolicy model\u200b\u4e0e\u200breference\u200b\u5dee\u5f02\u200b\u8fc7\u5927\u65f6\u200b\uff0c\u200b\u589e\u5927\u200b\u60e9\u7f5a\u200b\u7cfb\u6570\u200b\uff0c\u200b\u53cd\u4e4b\u200b\u51cf\u5c11\u200b\u60e9\u7f5a\u200b\u7cfb\u6570\u200b\uff08\u200b\u56e0\u6b64\u200b\u5bf9\u200b \\(\\beta\\) \u200b\u7684\u200b\u521d\u59cb\u5316\u200b\u4e0d\u200b\u654f\u611f\u200b\uff09\uff1a</p> \\[ \\beta = \\begin{cases}  \\frac{\\beta}{2} &amp; \\text{if }d \\lt d_\\text{targ}/1.5 \\\\  \\beta &amp; \\text{others} \\\\ \\beta \\times 2 &amp; \\text{if }d \\gt d_\\text{targ}\\times 1.5 \\end{cases} \\] <ul> <li>\\(d\\) \u200b\u4e3a\u200b \\(L^{KL}(\\theta)\\) \u200b\u7684\u200b\u540e\u200b\u534a\u200b\u90e8\u5206\u200b  </li> <li>\u200b\u542f\u53d1\u5f0f\u200b\u5730\u200b\u9009\u62e9\u200b\u5e38\u6570\u200b 1.5\u200b\u548c\u200b2\uff0c\u200b\u4e14\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u5bf9\u200b\u5e38\u6570\u200b\u9009\u62e9\u200b\u4e0d\u200b\u654f\u611f\u200b</li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/ppo.html#ppo-algorithm","title":"PPO Algorithm","text":"<p>PPO on-policy\u200b\u7b97\u6cd5\u200b\uff08policy model\u200b\u8bad\u7ec3\u200b\u4f9d\u8d56\u4e8e\u200b\u5f53\u524d\u200bpolicy\u200b\u751f\u6210\u200b\u7684\u200b\u6570\u636e\u200b\uff09  </p> <ul> <li><code>line 2-5</code>\uff1a\\(N\\)\u200b\u4e2a\u200bpolicy model\u200b\u5e76\u884c\u200b\u91c7\u6837\u200b \\(NT\\) \u200b\u4e2a\u200b\u6837\u672c\u200b\u5e76\u200b\u8ba1\u7b97\u200b\u5bf9\u5e94\u200b\u4f18\u52bf\u200b\u503c\u200b\\(\\hat{A}_t\\) </li> <li><code>line 6</code>\uff1a\u200b\u57fa\u4e8e\u200b\u91c7\u6837\u200b\u6837\u672c\u200b\uff0c\u200b\u4f7f\u7528\u200b\\(\\text{batch_size}=M\\le NT\\)\uff0c\u200b\u5bf9\u200bpolicy model\u200b\u8bad\u7ec3\u200b\u5e76\u200b\u66f4\u65b0\u200b \\(K\\) epochs  </li> <li><code>line 7</code>\uff1a\u200b\u66f4\u65b0\u200breference model</li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/ppo.html#ablation-study","title":"Ablation Study","text":"<ul> <li><code>Clipped Surrogate Objective</code> \u200b\u548c\u200b <code>KL Penalty</code> \u200b\u5747\u200b\u5bf9\u200b\u5f3a\u5316\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u6709\u200b\u63d0\u5347\u200b\uff0c\u200b\u4e14\u200b\u524d\u8005\u200b\u63d0\u5347\u200b\u6548\u679c\u200b\u66f4\u4f18\u200b  </li> <li><code>Adaptative KL Penalty</code> \u200b\u8f83\u200b <code>Fixed KL Penalty</code> \u200b\u5bf9\u200b\u5f3a\u5316\u200b\u6a21\u578b\u200b\u63d0\u5347\u200b\u6548\u679c\u200b\u66f4\u4f18\u200b</li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/q_learning.html","title":"Q learning","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/q_learning.html#q-learning","title":"Q-Learning","text":"<p>Q-Learning \u200b\u662f\u200b\u5f3a\u5316\u200b\u5b66\u4e60\u200b\uff08Reinforcement Learning, RL\uff09\u200b\u4e2d\u200b\u6700\u200b\u7ecf\u5178\u200b\u7684\u200b\u65e0\u200b\u6a21\u578b\u200b\uff08model-free\uff09\u200b\u57fa\u4e8e\u200b\u503c\u200b\u51fd\u6570\u200b\u7684\u200b\u65b9\u6cd5\u200b\u7b97\u6cd5\u200b\u4e4b\u4e00\u200b\uff0c\u200b\u7531\u200b Chris Watkins \u200b\u5728\u200b 1989 \u200b\u5e74\u200b\u63d0\u51fa\u200b\uff0c\u200b\u9002\u7528\u200b\u4e8e\u200b\u79bb\u6563\u200b\u72b6\u6001\u200b\u548c\u200b\u52a8\u4f5c\u200b\u7a7a\u95f4\u200b\u7684\u200b\u95ee\u9898\u200b\u3002</p>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/q_learning.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<p>Q-Learning \u200b\u901a\u8fc7\u200b\u76f4\u63a5\u200b\u4f18\u5316\u200b\u66f4\u65b0\u200b\u52a8\u4f5c\u200b\u4ef7\u503c\u200b\u51fd\u6570\u200b\u6216\u200b\u72b6\u6001\u200b\u4ef7\u503c\u200b\u51fd\u6570\u200b\uff0c\u200b\u9009\u62e9\u200b\u6700\u4f18\u200b\u52a8\u4f5c\u200b\uff0c\u200b\u627e\u5230\u200b\u6700\u4f73\u200b\u7b56\u7565\u200b</p> \\[ \\pi(s) =\\text{arg} \\mathop{\\text{ max }}\\limits_{a} Q(s, a) \\]"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/q_learning.html#bellman-equation","title":"Bellman Equation","text":"<p>\u200b\u8d1d\u5c14\u66fc\u200b\u65b9\u7a0b\u200b\u7684\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\uff1a<code>\u200b\u5f53\u524d\u200b\u72b6\u6001\u200b\u7684\u200b\u4ef7\u503c\u200b=\u200b\u5373\u65f6\u200b\u5956\u52b1\u200b + \u200b\u672a\u6765\u200b\u72b6\u6001\u200b\u7684\u200b\u6298\u6263\u200b\u4ef7\u503c\u200b</code>\u3002\u200b\u6839\u636e\u200b\u4e0d\u540c\u200b\u7684\u200b\u4ef7\u503c\u200b\u51fd\u6570\u200b\uff0c\u200b\u5206\u4e3a\u200b\u4ee5\u4e0b\u200b\u4e24\u79cd\u200b\u5f62\u5f0f\u200b\uff1a</p> <ol> <li> <p>\u200b\u52a8\u4f5c\u200b\u4ef7\u503c\u200b\u51fd\u6570\u200b \\(Q\\) \u200b\u7684\u200b\u8d1d\u5c14\u66fc\u200b\u65b9\u7a0b\u200b\uff0c</p> \\[ \\begin{aligned}     Q^{\\pi}(s_t, a_t)      =&amp; \\mathbb{E}_{\\pi} [r_{t+1} + \\gamma Q^{\\pi}(s_{t+1}, a_{t+1})\\vert s_t, a_t]  \\end{aligned} \\] <ul> <li>\\(\\gamma \\in [0, 1]\\) \u200b\u4e3a\u200b\u6298\u6263\u200b\u56e0\u5b50\u200b\uff0c\u200b\u7528\u4e8e\u200b\u5e73\u8861\u200b\u5f53\u524d\u200b\u4e0e\u200b\u672a\u6765\u200b\u5956\u52b1\u200b\u7684\u200b\u91cd\u8981\u6027\u200b\uff08\u200b\u65f6\u5e8f\u200b\u8d8a\u200b\u8fdc\u200b\u5f71\u54cd\u200b\u8d8a\u5c0f\u200b\uff09  </li> <li>\\(\\mathbb{E}\\) \u200b\u8868\u793a\u200b\u5bf9\u200b\u6240\u6709\u200b\u6982\u7387\u200b\u4e0b\u200b\u72b6\u6001\u200b\u671f\u671b\u200b\u5316\u200b\uff0c\u200b\u5373\u200b \\(\\sum_{s_{t+1}^{'}} p(s_{t+1}^{'}\\vert s_t, a_t)\\)</li> </ul> </li> <li> <p>\u200b\u72b6\u6001\u200b\u4ef7\u503c\u200b\u51fd\u6570\u200b \\(V\\) \u200b\u7684\u200b\u8d1d\u5c14\u66fc\u200b\u65b9\u7a0b\u200b</p> \\[ V^{\\pi}(s_t) = \\mathbb{E}_{\\pi} [r_{t+1} + \\gamma V^{\\pi}(s_{t+1})\\vert s_t] \\] <ul> <li>\\(\\mathbb{E}\\) \u200b\u8868\u793a\u200b\u5bf9\u200b\u6240\u6709\u200b\u52a8\u4f5c\u200b\u6982\u7387\u200b\u4e0b\u200b\u72b6\u6001\u200b\u671f\u671b\u200b\u5316\u200b\uff0c\u200b\u5373\u200b \\(\\sum_{a_{t}^{'}} p_{\\pi}(a_{t}^{'}\\vert s_t)\\sum_{s_{t+1}^{'}}p(s_{t+1}^{'}\\vert s_t, a_{t}^{'})\\)</li> </ul> </li> <li> <p>Bellman residual</p> </li> </ol>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/q_learning.html#_2","title":"\u7b56\u7565\u200b\u6c42\u53d6\u200b\u6b65\u9aa4","text":"<p>\u200b\u901a\u8fc7\u200b\u9012\u5f52\u200b\u6c42\u89e3\u200b \\(Q\\) \u200b\u6216\u200b \\(V\\) \u200b\u5373\u53ef\u200b\u5f97\u5230\u200b\u6700\u4f18\u200b\u7b56\u7565\u200b \\(\\pi^*\\)</p>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/q_learning.html#dqn","title":"DQN","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/q_learning.html#double-dqn","title":"Double DQN","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/q_learning.html#dueling-dqn","title":"Dueling DQN","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/reward_model.html","title":"Reward model","text":"<ul> <li>https://github.com/RLHFlow/RLHF-Reward-Modeling</li> </ul>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/trpo.html","title":"Trpo","text":""},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/trpo.html#trpo","title":"TRPO","text":"<p>\u200b\u8bba\u6587\u200b\uff1aTrust Region Policy Optimization University of California, 2015 Feq, ICML 2015</p>"},{"location":"AI/Paper_Reading/LM/Reinforcement_Learning/trpo.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<p>TRPO\u200b\u53ea\u200b\u5728\u200b\u7f6e\u4fe1\u533a\u95f4\u200b\u5185\u200b\u8fdb\u884c\u200b\u7b56\u7565\u200b\u4f18\u5316\u200b\uff0c\u200b\u5373\u200b\u901a\u8fc7\u200bclip\u200b\u64cd\u4f5c\u200b\u7ea6\u675f\u200b\u7b56\u7565\u200b\u4f18\u5316\u200b\u533a\u95f4\u200b</p> \\[ \\max_{\\theta} \\hat{\\mathbb{E}}_t\\bigg[  \\frac{\\pi_{\\theta}(a_t\\vert s_t)}{\\pi_{old}(a_t\\vert s_t)} \\hat{A}_t\\bigg] \\\\ \\text{subject to } \\hat{\\mathbb{E}}_t[D_{KL}\\big(\\pi_{old}(\\cdot \\vert s_t), \\pi_{\\theta}(\\cdot \\vert s_t)\\big)] \\le \\delta \\] <p>\u200b\u5728\u200bSGA\u200b\u7684\u200b\u540c\u65f6\u200b\u8981\u6c42\u200b\u9075\u5faa\u200b\u4e24\u4e2a\u200b\u6a21\u578b\u200b\u7684\u200b\u7b56\u7565\u200b\u5206\u5e03\u200b\u5dee\u8ddd\u200b\u5904\u4e8e\u200b\u8f83\u200b\u9ad8\u200b\u7684\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\u7684\u200b\u786c\u200b\u7ea6\u675f\u200b\uff08\\(\\le \\delta\\)\uff09</p> \\[ \\max_{\\theta} \\hat{\\mathbb{E}}_t\\bigg[  \\frac{\\pi_{\\theta}(a_t\\vert s_t)}{\\pi_{old}(a_t\\vert s_t)} \\hat{A}_t -\\beta D_{KL}\\big(\\pi_{old}(\\cdot \\vert s_t), \\pi_{\\theta}(\\cdot \\vert s_t)\\big)\\bigg] \\\\ \\] <p>\u200b\u6574\u5408\u200b\u4e3a\u200b\u60e9\u7f5a\u200b\u9879\u200b\uff0cSGA - D_{KL}</p>"},{"location":"AI/Paper_Reading/LM/Search_Recommender/index.html","title":"\u641c\u7d22\u200b\u63a8\u8350","text":"<ul> <li>\u200b\u63a8\u8350\u200b\u3001\u200b\u5e7f\u544a\u200b\u3001\u200b\u56fe\u200b\u63a8\u8350\u200b\u3001\u200b\u641c\u7d22\u200b\u3001CTR\u200b\u9884\u4f30\u200b</li> </ul>"},{"location":"AI/Paper_Reading/LM/Search_Recommender/index.html#_1","title":"\u53ec\u56de","text":"<ol> <li>Content-based\u200b\u57fa\u4e8e\u200b\u53ec\u56de\u200b\uff1a\u200b\u5229\u7528\u200b\u5df2\u6709\u200b\u7528\u6237\u7fa4\u200b\u8fc7\u53bb\u200b\u7684\u200b\u884c\u4e3a\u200b\u6216\u200b\u610f\u89c1\u200b\u9884\u6d4b\u200b\u5f53\u671f\u200b\u7528\u6237\u200b\u6700\u200b\u53ef\u80fd\u200b\u559c\u6b22\u200b\u7684\u200b\u5185\u5bb9\u200b\uff0c\u200b\u5177\u6709\u200b\u9ad8\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\u503e\u5411\u200b\u6216\u200b\u504f\u597d\u200b\u7684\u200b\u6837\u672c\u200b\u95f4\u200b\u9690\u5f0f\u200b\u5730\u200b\u4e92\u76f8\u200b\u534f\u4f5c\u200b\u63a8\u8350\u200b(\u200b\u5bf9\u65b9\u200b\u6ca1\u6709\u200b\u7684\u200b\u63a5\u89e6\u200b\u7684\u200b)</li> <li> <p>Collaborative filtering\u200b\u534f\u540c\u200b\u8fc7\u6ee4\u200b\u53ec\u56de\u200b</p> </li> <li> <p>Knowledge-based\u200b\u57fa\u4e8e\u200b\u77e5\u8bc6\u200b\u7684\u200b\u53ec\u56de\u200b</p> </li> <li>Product Similarity-based\u200b\u4ea7\u54c1\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\u63a8\u8350\u200b\uff0c\u200b\u63a8\u8350\u200b\u67e5\u8be2\u200b\u8fc7\u200b\u7684\u200b\u76f8\u4f3c\u200b\u7269\u54c1\u200b</li> </ol>"},{"location":"AI/Paper_Reading/LM/Search_Recommender/index.html#_2","title":"\u8bc4\u5206","text":"<ol> <li>\u200b\u663e\u5f0f\u200b\u8bc4\u5206\u200b\uff1a\u200b\u8ba9\u200b\u7528\u6237\u200b\u624b\u52a8\u200b\u6253\u5206\u200b</li> <li>\u200b\u9690\u5f0f\u200b\u8bc4\u5206\u200b\uff1a\u200b\u7528\u6237\u200b\u8bc4\u8bba\u200b\u503e\u5411\u200b\uff0c\u200b\u7528\u6237\u200b\u505c\u7559\u200b\u67d0\u4e2a\u200b\u9875\u9762\u200b\u6216\u200b\u5185\u5bb9\u200b\u65f6\u957f\u200b\u7b49\u200b</li> <li>\u200b\u6570\u636e\u200b\u7a00\u758f\u200b\u51b7\u542f\u52a8\u200b\uff1a\u200b\u7528\u6237\u200b\u8bc4\u5206\u200b\u8f83\u5c11\u200b\u6216\u200b\u57fa\u6570\u200b\u8f83\u200b\u5c11\u200b\uff0c\u200b\u6570\u636e\u200b\u7a00\u758f\u200b\u65e0\u6cd5\u200b\u5f88\u200b\u597d\u200b\u5730\u200b\u5b9e\u73b0\u200b\u9884\u6d4b\u200b<ul> <li>user\u200b\u51b7\u542f\u52a8\u200b\uff1a\u200b\u65b0\u200b\u7528\u6237\u200b\u63a8\u8350\u200b\u4ec0\u4e48\u200b\u4ea7\u54c1\u200b</li> <li>item\u200b\u51b7\u542f\u52a8\u200b\uff1a\u200b\u65b0\u200b\u4ea7\u54c1\u200b\u63a8\u8350\u200b\u7ed9\u200b\u54ea\u4e9b\u200b\u7528\u6237\u200b</li> <li>query\u200b\u51b7\u542f\u52a8\u200b/\u200b\u957f\u5c3e\u200bquery </li> </ul> </li> </ol> <p>exploration and exploitation - \u200b\u7c97\u6392\u200b\u3001\u200b\u7cbe\u6392\u200b\u3001\u200b\u91cd\u6392\u200b - AB\u200b\u5b9e\u9a8c\u200bA/B testing - factorization machine</p> <ul> <li>\u200b\u963f\u91cc\u200bDIN</li> </ul>"},{"location":"AI/Paper_Reading/LM/Search_Recommender/bert4rec.html","title":"Bert4rec","text":""},{"location":"AI/Paper_Reading/LM/Search_Recommender/bert4rec.html#bert4rec","title":"BERT4Rec","text":"<p>\u200b\u8bba\u6587\u200b\uff1aBERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer BERT4Rec: BERT for Recommendation Github: DeepInterestNetwork Alibaba Inc, CIKM 2019</p>"},{"location":"AI/Paper_Reading/LM/Search_Recommender/cl4srec.html","title":"Cl4srec","text":""},{"location":"AI/Paper_Reading/LM/Search_Recommender/cl4srec.html#din","title":"DIN","text":"<p>\u200b\u8bba\u6587\u200b\uff1aCL4SRec: Contrastive Learning for Sequential Recommendation   Github: DeepInterestNetwork PKU &amp; Alibaba Group, SIGIR 2021</p>"},{"location":"AI/Paper_Reading/LM/Search_Recommender/din.html","title":"Din","text":""},{"location":"AI/Paper_Reading/LM/Search_Recommender/din.html#din","title":"DIN","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDIN: Deep Interest Network for Click-Through Rate Prediction Github: DeepInterestNetwork Alibaba Group, KDD 2018  </p> <ul> <li>cost-per-click (CPC)\u200b\u70b9\u51fb\u200b\u4ed8\u8d39\u200b</li> <li>eCPM (effective cost per mille)\u200b\u6bcf\u200b\u5343\u6b21\u200b\u5c55\u793a\u200b\u6709\u6548\u200b\u6210\u672c\u200b</li> <li> <p>\\(v_{U}(A) = \\mathbb{R}^{1*d}\\mathbb{R}^{d*H}\\mathbb{R}^{H*d}\\)</p> </li> <li> <p>https://zhuanlan.zhihu.com/p/54085498</p> </li> <li>out product</li> </ul>"},{"location":"AI/Paper_Reading/LM/Search_Recommender/ple.html","title":"Ple","text":""},{"location":"AI/Paper_Reading/LM/Search_Recommender/ple.html#ple","title":"PLE","text":"<p>\u200b\u8bba\u6587\u200b\uff1aProgressive Layered Extraction: A Novel Multi-Task Learning Model for Personalized Recommendations PLE: Progressive Layered Extraction Github: DeepInterestNetwork Tencent PCG, RecSys 2020  </p> <ul> <li>Multi-Task Learning in Recommender Systems</li> <li>An MTL Ranking System for Video Recommendation</li> <li>Seesaw Phenomenon in MTL</li> </ul>"},{"location":"AI/Paper_Reading/Trick/trick.html","title":"\u70bc\u4e39\u200b\u6280\u5de7","text":""},{"location":"AI/Paper_Reading/Trick/trick.html#_1","title":"\u591a\u200b\u6a21\u6001\u200b\u878d\u5408","text":"<ul> <li>token</li> <li>sound</li> <li>shape</li> <li>fusion</li> <li>\u200b\u89c6\u89c9\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff1a\u200b\u5bf9\u200b\u9875\u9762\u200b\u5185\u5bb9\u200b\u8fdb\u884c\u200b\u8bed\u4e49\u200b\u8fdb\u884c\u200b\u5206\u6790\u200b</li> <li>ali cosyvoice\u3001f5-tts</li> </ul>"},{"location":"AI/Paper_Reading/Trick/trick.html#_2","title":"\u8bad\u7ec3\u200b\u6570\u636e\u200b\u5229\u7528","text":""},{"location":"AI/Paper_Reading/Trick/trick.html#_3","title":"\u96c6\u6210\u200b\u5b66\u4e60","text":"<ol> <li>Boosting</li> <li>Model Merging</li> <li>Bagging<ul> <li>[Random Forests]</li> </ul> </li> <li>Stacking</li> <li>Voting</li> <li>MoE</li> </ol>"},{"location":"AI/Paper_Reading/Trick/trick.html#_4","title":"\u6570\u636e\u200b\u589e\u5f3a","text":"<ol> <li>Dropout</li> <li>Label Smoothing</li> <li>\u200b\u52a0\u566a\u81ea\u200b\u7f16\u7801\u5668\u200b<ul> <li>DAE\u3001VAE</li> <li>\u200b\u5bf9\u6297\u200b\u8bad\u7ec3\u200b</li> </ul> </li> <li>\u200b\u6570\u636e\u200b\u589e\u5f3a\u200b  <ul> <li>flipping  </li> <li>rotating  </li> <li>transforming the color  </li> <li>text_image + mask</li> </ul> </li> <li>Subword Regularization\u3001BPE-Dropout</li> </ol>"},{"location":"AI/Paper_Reading/Trick/trick.html#_5","title":"\u5bf9\u6bd4\u200b\u5b66\u4e60","text":""},{"location":"AI/Paper_Reading/Trick/trick.html#_6","title":"\u5927\u200b\u6a21\u578b\u200b\u76f8\u5173","text":""},{"location":"AI/Paper_Reading/Trick/trick.html#scaling-laws","title":"Scaling Laws","text":""},{"location":"AI/Paper_Reading/Trick/trick.html#pre-training","title":"Pre-training","text":"<ul> <li>scaling law\u200b\u5931\u6548\u200b https://arxiv.org/pdf/2001.08361</li> <li>multitask learning</li> <li>batch train\u200b\u65f6\u200b\uff0cnext token \u200b\u4e3a\u200bpad\u200b\u65f6\u200b\uff0c\u200b\u53ef\u4ee5\u200bignore\u200b\u6b64\u200bPAD token\u200b\u7684\u200bloss\u200b\u4ee5\u200b\u5b8c\u5168\u200b\u5ffd\u7565\u200bPAD\u200b\u7684\u200b\u5f71\u54cd\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/trick.html#sft","title":"SFT","text":"<ul> <li>prefix tuning</li> <li>Instrument Finetune</li> <li>Prompt Finetune</li> <li>RAdam</li> <li>hallucination\u200b\u5e7b\u89c9\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/trick.html#prompt-engineering","title":"Prompt Engineering","text":""},{"location":"AI/Paper_Reading/Trick/trick.html#rlhf","title":"RLHF","text":""},{"location":"AI/Paper_Reading/Trick/trick.html#peft","title":"PEFT","text":"<ul> <li>ULMFit, Universal language model fine-tuning for text classification</li> <li>AdaLoRA\u200b\u5947\u5f02\u200b\u503c\u200b\u91cd\u8981\u6027\u200b\u8861\u91cf\u200b(equation 11)</li> </ul>"},{"location":"AI/Paper_Reading/Trick/trick.html#_7","title":"\u8f7b\u91cf\u5316","text":""},{"location":"AI/Paper_Reading/Trick/trick.html#_8","title":"\u84b8\u998f\u200b\u3001\u200b\u538b\u7f29","text":"<ul> <li>\u200b\u8f6f\u200b\u6807\u7b7e\u200b &amp; \u200b\u786c\u200b\u6807\u7b7e\u200b</li> <li>\u200b\u6e29\u5ea6\u200b\u7cfb\u6570\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/trick.html#_9","title":"\u6a21\u578b\u200b\u538b\u7f29","text":"<ul> <li>dim \u200b\u538b\u7f29\u200b\uff1aMRL</li> <li>\u200b\u7f51\u7edc\u200b\u7626\u8eab\u200b\uff1aSlimmable Neural Networks</li> </ul>"},{"location":"AI/Paper_Reading/Trick/trick.html#attention","title":"Attention\u200b\u53d8\u79cd","text":"<ul> <li>MQA\u3001GQA\u3001MLA</li> </ul>"},{"location":"AI/Paper_Reading/Trick/trick.html#attention_1","title":"Attention\u200b\u6548\u7387\u200b\u4f18\u5316","text":"<ul> <li>KV Cache</li> <li>flash attention</li> <li>vLLM</li> <li>ollama</li> </ul>"},{"location":"AI/Paper_Reading/Trick/trick.html#_10","title":"\u663e\u5b58\u200b\u4f18\u5316","text":"<ul> <li>gradient checkpointing</li> <li>Reducing activation recomputation in large transformer models</li> </ul>"},{"location":"AI/Paper_Reading/Trick/trick.html#_11","title":"\u5e76\u884c\u200b\u8bad\u7ec3","text":"<ul> <li>\u200b\u6570\u636e\u200b\u5e76\u884c\u200b DP(Data Pparallelism)<ul> <li>DP\uff0c\u200b\u6570\u636e\u200b\u5e76\u884c\u200b</li> <li>DDP, Distributed Data Parallelism</li> <li>FSDP, Fully Sharded Data Parallel\uff0c\u200b\u5168\u200b\u5207\u7247\u200b\u6570\u636e\u200b\u5e76\u884c\u200b</li> </ul> </li> <li>\u200b\u6a21\u578b\u200b\u5e76\u884c\u200b MP(Model Parallelism)<ul> <li>TP(Tensor Parallelism)\uff0c\u200b\u5982\u200bGEMM</li> <li>PP(Pipeline Parallelism)</li> <li>EP(Expert Parallelism)</li> </ul> </li> <li>SP(Sequence Parallel)</li> <li>CP(Context Parallelism)</li> <li>\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b<ul> <li>[generate config]</li> <li>DeepSpeed: ZeRO: Zero Redundancy Optimizer</li> <li>Megatron-LM</li> <li>HAI-LLM framework\uff08higher flyer\uff09</li> </ul> </li> </ul>"},{"location":"AI/Paper_Reading/Trick/trick.html#_12","title":"\u63a8\u7406\u200b\u4f18\u5316","text":"<ul> <li>\u200b\u91cf\u5316\u200b</li> <li>onnx\uff1aopen neural network exchange</li> <li>TensorRT\uff1a</li> </ul> <p>\u200b\u76ee\u6807\u200b\u91cd\u8981\u6027\u200b\u8861\u91cf\u200b  </p> <pre><code>- \u200b\u6bd4\u8f83\u200b\u53bb\u9664\u200b\u76ee\u6807\u200b\u7684\u200b\u524d\u540e\u200b\u53d8\u5316\u200b\uff0c\u200b\u4e00\u822c\u200b\u5dee\u5f02\u200b\u503c\u8d8a\u200b\u5927\u200b\u8868\u793a\u200b\u76ee\u6807\u200b\u8d8a\u200b\u91cd\u8981\u200b\n</code></pre>"},{"location":"AI/Paper_Reading/Trick/Denoising/dropout.html","title":"Dropout","text":""},{"location":"AI/Paper_Reading/Trick/Denoising/dropout.html#spatial_dropout","title":"spatial_dropout","text":"<p>\u200b\u968f\u673a\u200b\u5bf9\u200b\u6ca1\u4e2a\u200b channel \u200b\u7684\u200b\u6240\u6709\u200b\u503c\u200b\u8fdb\u884c\u200b <code>dropout</code></p> TF 1.x <pre><code>def spatial_dropout_2d(input_tensor, keep_prob=1):\n    if keep_prob == 1:\n        return input_tensor\n    elif keep_prob &lt;= 0 or keep_prob &gt; 1:\n        raise ValueError(f\"keep_prob should in (0, 1], keep_prob=={keep_prob} is invalid!!!\")\n\n    if input_tensor.shape.ndims != 3:\n        raise ValueError(f\"input_tensor should equal 3, but not {input_tensor.shape.ndims}\")\n\n    bs, seq, dim = input_tensor.shape.as_list()\n    mask = tf.tile(tf.expand_dims(tf.random_uniform(shape=[bs, dim]) &lt; keep_prob,\n                                axis=1),\n                [1, seq, 1])\n    spatial_dropout_tensor = tf.where(mask, input_tensor, tf.zeros_like(input_tensor))\n    return tf.multiply(tf.constant(1/keep_prob), spatial_dropout_tensor)\n</code></pre>"},{"location":"AI/Paper_Reading/Trick/Denoising/dropout.html#max_pooling_dropout","title":"max_pooling_dropout","text":"<p>\u200b\u5728\u200b <code>max_pooling</code> \u200b\u524d\u200b\u6bcf\u4e2a\u200b\u503c\u200b\u8fdb\u884c\u200b <code>dropout</code></p> TF 1.x <pre><code># 2d \u200b\u7684\u200b\u5177\u4f53\u200b\u5b9e\u73b0\u200b\u7b49\u4ef7\u200b\u4e8e\u200b `tf.nn.dropout`\ndef max_pooling_dropout_2d(input_tensor, keep_prob=1, name=None):\n    return tf.nn.dropout(input_tenosr, keep_prob=keep_prob, name=name)\n</code></pre>"},{"location":"AI/Paper_Reading/Trick/Denoising/label_smoothing.html","title":"Label smoothing","text":""},{"location":"AI/Paper_Reading/Trick/Denoising/label_smoothing.html#label-smoothing","title":"Label Smoothing","text":"<p>\u200b\u6807\u7b7e\u200b\u5e73\u6ed1\u200b\u662f\u200b\u4e00\u79cd\u200b\u7528\u4e8e\u200b\u5206\u7c7b\u200b\u4efb\u52a1\u200b\u7684\u200b\u6b63\u5219\u200b\u5316\u200b\u6280\u672f\u200b\uff0c\u200b\u65e8\u5728\u200b\u7f13\u89e3\u200b\u6a21\u578b\u200b\u5bf9\u200b\u8bad\u7ec3\u200b\u6807\u7b7e\u200b\u7684\u200b\u8fc7\u5ea6\u200b\u81ea\u4fe1\u200b\uff08over-confidence\uff09\u200b\u95ee\u9898\u200b\uff0c\u200b\u5c06\u200b\u786c\u200b\u6807\u7b7e\u200b\u66ff\u6362\u200b\u4e3a\u200b\u8f6f\u200b\u6807\u7b7e\u200b\uff0c\u200b\u9632\u6b62\u200b\u8fc7\u200b\u62df\u5408\u200b\uff0c\u200b\u63d0\u5347\u200b\u6a21\u578b\u200b\u7684\u200b\u6cdb\u5316\u200b\u80fd\u529b\u200b\u3002</p> <ol> <li>\u200b\u771f\u5b9e\u200b\u7c7b\u522b\u200b\u7684\u200b\u6982\u7387\u200b\u4e3a\u200b \\(1-\\epsilon\\)\uff0c\u200b\u5176\u4e2d\u200b \\(\\epsilon\\) \u200b\u4e3a\u200b\u5e73\u6ed1\u200b\u7cfb\u6570\u200b  </li> <li>\u200b\u5176\u5b83\u200b\u7c7b\u522b\u200b\u7684\u200b\u6982\u7387\u200b\u5747\u5300\u200b\u5206\u914d\u200b \\(\\epsilon / (K-1)\\)\uff0c\u200b\u5176\u4e2d\u200b \\(K\\) \u200b\u4e3a\u200b\u7c7b\u522b\u200b\u6570\u200b  </li> </ol> <ul> <li>\u200b\u4e5f\u200b\u53ef\u200b\u5c06\u200b\u5e73\u6ed1\u200b\u7cfb\u6570\u200b\\(\\epsilon\\)\u200b\u5747\u5300\u200b\u5206\u914d\u200b\u7ed9\u200b\u6240\u6709\u200b\u7c7b\u522b\u200b\uff0c\u200b\u5373\u200b \\(y_\\text{LS}=(1-\\epsilon)\\cdot y + \\epsilon/K\\)</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Denoising/AdversarialTraining/vat.html","title":"Vat","text":""},{"location":"AI/Paper_Reading/Trick/Denoising/AdversarialTraining/vat.html#fgsm","title":"FGSM","text":"<p>\u200b\u8bba\u6587\u200b\uff1aExplaining and Harnessing Adversarial Examples FGSM\uff1aFast Gradient Sign Method Google, ICLR 2015</p>"},{"location":"AI/Paper_Reading/Trick/Denoising/AdversarialTraining/vat.html#_1","title":"\u5de5\u4f5c\u200b\u8981\u70b9","text":"<ul> <li> <p> \u200b\u5728\u200b\u68af\u5ea6\u65b9\u5411\u200b\u901a\u8fc7\u200b\u63a7\u5236\u200b\u8d85\u53c2\u200b\\(\\epsilon\\)\u200b\u589e\u52a0\u200b\u4e9b\u5fae\u200b\u6270\u52a8\u200b\uff08\u200b\u7279\u522b\u200b\u662f\u200b\u68af\u5ea6\u200b\u4e0a\u5347\u200b\u65b9\u5411\u200b\uff09\u200b\u5373\u53ef\u200b\u8f7b\u6613\u200b\u4f7f\u200b\u6a21\u578b\u200b\u4e25\u91cd\u200b\u8bef\u5224\u200b\uff0c</p> \\[ \\begin{aligned} f&amp;(x+r)\\ne f(x) \\\\ r&amp; = \\epsilon \\text{sign}\\big(\\nabla \\mathcal{L}_x(\\theta, x, y)\\big) \\end{aligned} \\] <p>\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b\u5bf9\u200b\u68af\u5ea6\u200b\u9644\u52a0\u200b\u4e86\u200b\u4e00\u4e2a\u200b\\(L_\\infty\\) norm\u200b\u7ea6\u675f\u200b\uff08\u200b\u6807\u51c6\u200b\\(L_\\infty\\)\u200b\u9664\u4ee5\u200b\u6700\u5927\u200b\u7edd\u5bf9\u503c\u200b\uff0c\u200b\u6b64\u5904\u200b\u989d\u5916\u200b\u589e\u52a0\u200b\u4e86\u200b\u53d6\u6574\u200b\u6b65\u9aa4\u200b\uff09</p> </li> <li> <p> \u200b\u5bf9\u6297\u200b\u8bad\u7ec3\u200b\u63d0\u5347\u200b\u6a21\u578b\u200b\u6cdb\u5316\u200b\u80fd\u529b\u200b\\(\\mathcal{L}(\\theta, x, y)=\\mathcal{L}_1(\\theta, x, y) + \\alpha\\mathcal{L}_1\\big(\\theta, x+\\epsilon\\text{sign}(\\nabla_x \\mathcal{L}_1(\\theta, x, y)\\big), y)\\)</p> <p>\\(\\alpha\\)\u200b\u4e00\u822c\u200b\u53d6\u200b1</p> </li> </ul>"},{"location":"AI/Paper_Reading/Trick/Denoising/AdversarialTraining/vat.html#_2","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ol> <li> <p>FGSM\u200b\u4e0d\u540c\u200b\\(\\epsilon\\)\u200b\u4e0b\u200b\u7684\u200b\u6548\u679c\u200b\u8868\u73b0\u200b </p> <p>-\\(0.01\\nabla_x\\): 0.98\u200b\u62c9\u200b\u591a\u200b</p> <p>\\(0\\nabla_x\\): 0.42\u200b\u62c9\u200b\u591a\u200b</p> <p>+\\(0.01\\nabla_x\\): 0.13\u200b\u6c99\u514b\u72ac\u200b</p> <p>+\\(0.1\\nabla_x\\): 0.15\u200b\u5a01\u739b\u200b\u730e\u72ac\u200b</p> <p>\u200b\u5728\u200b\u56fe\u50cf\u200b\u68af\u5ea6\u200b(\u200b\u4e0a\u5347\u200b/\u200b\u4e0b\u964d\u200b)\u200b\u65b9\u5411\u200b\u65bd\u52a0\u200b\u4e0d\u540c\u200b\u7a0b\u5ea6\u200b\u6270\u52a8\u200b\u5bf9\u6a21\u578b\u200b\u8bc6\u522b\u200b\u7ed3\u679c\u200b\u7684\u200b\u5f71\u54cd\u200b</p><p></p> <p>\u200b\u5728\u200b\u68af\u5ea6\u200b\u4e0a\u5347\u200b\u65b9\u5411\u200b\u589e\u52a0\u200b\u6270\u52a8\u200b\uff0c\u200b\u6a21\u578b\u200b\u7f6e\u4fe1\u200b\u964d\u4f4e\u200b\uff0c\u200b\u53cd\u4e4b\u200b\u589e\u52a0\u200b\uff1b</p> </li> <li> <p>FGSM\u200b\u5bf9\u6297\u200b\u8bad\u7ec3\u200b\u63d0\u5347\u200b\u6a21\u578b\u200b\u7a33\u5b9a\u6027\u200b \\(\\mathcal{L}(x, y, \\theta)=\\mathcal{L}_1(x, y, \\theta) + \\alpha\\mathcal{L}_1\\big(x+\\epsilon\\text{sign}(\\nabla_x \\mathcal{L}_1(\\theta, x, y)\\big), y, \\theta)\\)</p> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Denoising/AdversarialTraining/vat.html#approximation-of-lds","title":"approximation of LDS","text":"<p>LDS\uff1aLocal Distributional Smoothness \u200b\u8bba\u6587\u200b\uff1aDistributional Smoothing with Virtual Adversarial Training Kyoto University, ICLR 2016   </p> <p></p> <p>\u200b\u8bba\u6587\u200b\uff1aVirtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning Github: vat_pytorch Preferred Networks &amp; Kyoto University &amp; ATR Cognitive Mechanisms Laboratories &amp; Ritsumeikan University, TPAMI 2017</p>"},{"location":"AI/Paper_Reading/Trick/Denoising/AdversarialTraining/vat.html#_3","title":"\u5de5\u4f5c\u200b\u8981\u70b9","text":"<ul> <li> <p> \u200b\u865a\u62df\u200b\u5bf9\u6297\u200b\u8bad\u7ec3\u200b\u7684\u200b\u534a\u200b\u76d1\u7763\u200b\u7b97\u6cd5\u200b(VAT, Vitural Adversarial Training)\uff0c\u200b\u8fd0\u7528\u200b\u4e86\u200b\u5e73\u6ed1\u200b\u601d\u60f3\u200b\u65e8\u5728\u200b\u4f7f\u200b\u6a21\u578b\u200b\u5bf9\u200b\u5904\u4e8e\u200b\u4e00\u5b9a\u200b\u7684\u200b\u533a\u95f4\u200b\u8303\u56f4\u200b\u5185\u200b\u7684\u200b\u6570\u636e\u200b\u6837\u672c\u200b\u90fd\u200b\u6709\u200b\u8f83\u4e3a\u200b\u76f8\u4f3c\u200b\u7684\u200b\u5206\u7c7b\u200b\u7ed3\u679c\u200b\u3002</p> \\[ \\begin{aligned}     \\mathcal{L} &amp;= \\mathop{\\mathcal{L}_1}\\limits_{(x_1,y_1) \\in D_{label}}(x_1, y_1, \\theta) + \\alpha \\mathop{\\text{KL}}\\limits_{x_2 \\in D_{all}}[f(x_2)||f(x_2+r_{\\text{v-adv}})] \\\\     r_{\\text{v-adv-}2} &amp;= \\epsilon\\frac{g}{||g||_2}, \\text{where}\\ g=\\nabla_{r}\\text{KL}[p(y|x_2,\\theta)||p(y|x_2+r,\\theta)]\\Big\\vert_{r=\\epsilon d} \\\\     r_{\\text{v-adv-}\\infty} &amp;= \\epsilon \\text{sign}(g), \\text{where}\\ g=\\nabla_{r}\\text{KL}[p(y|x_2,\\theta)||p(y|x_2+r,\\theta)]\\Big\\vert_{r=\\epsilon d} \\end{aligned} \\] <ul> <li>\u200b\u5c40\u90e8\u200b\u5e73\u6ed1\u200b\u76ee\u6807\u200b\uff0c\u200b\u5373\u200b\u6270\u52a8\u200b\u8303\u56f4\u200b\\(||r||_{2/\\infty}\\le \\epsilon\\)\u200b\u5185\u200b\uff0c\\(f(x)\\approx f(x+r)\\) </li> <li>\u200b\u4e24\u4e2a\u200b\u8d85\u53c2\u200b \\(\\epsilon\\) \u200b\u548c\u200b \\(\\alpha\\)\uff0c\u200b\u4ee5\u53ca\u200b\u6307\u5b9a\u200bnorm\u200b\u65b9\u5f0f\u200b  </li> <li>\\((x_1,y_1)\\in D_{label}, x_2\\in D_{all}\\)\uff0c\u200b\u524d\u8005\u200b\u6709\u200b\u76d1\u7763\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u540e\u8005\u200b\u65e0\u200b\u76d1\u7763\u200b\u5c40\u90e8\u200b\u5206\u5e03\u200b\u5e73\u6ed1\u200b\uff0c\u200b\u56e0\u6b64\u200b\u4e3a\u200b\u534a\u200b\u76d1\u7763\u200b\u8bad\u7ec3\u200b</li> <li>\\(\\nabla_r\\)\u200b\u4e2d\u200b\u7684\u200b\\(r\\)\u200b\u8868\u793a\u200b\u7684\u200b\u662f\u200b<code>random_init_r</code></li> <li>\u200b\u5355\u6b21\u200b\u8bad\u7ec3\u200b\u9700\u8981\u200b3\u200b\u6b21\u524d\u200b\u5411\u200b\u8ba1\u7b97\u200b\uff1a<code>forward(x), forward(x2_update_r), forward(x2_get_final_kl)</code></li> <li>\u200b\u5355\u6b21\u200b\u540e\u200b\u5411\u200b\u9700\u8981\u200b2\u200b\u6b21\u540e\u200b\u5411\u200b\u8ba1\u7b97\u200b\uff1a<code>backward(x2_update_r), backward(update_\u03b8)</code></li> </ul> </li> <li> <p> VAT\u200b\u8f83\u200b\uff08\u200b\u4f7f\u7528\u200b\u4f2a\u200b\u6807\u7b7e\u200b\u7684\u200b\uff09\u200b\u5bf9\u6297\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u7684\u200b\u6cdb\u5316\u200b\u80fd\u529b\u200b\u4f18\u79c0\u200b\uff08AT\u200b\u65b0\u589e\u200b\u8bad\u7ec3\u200b\u70b9\u200b\uff0cVAT\u200b\u76f4\u63a5\u200b\u6cdb\u5316\u200b\u9762\u200b\uff09</p> </li> </ul>"},{"location":"AI/Paper_Reading/Trick/Denoising/AdversarialTraining/vat.html#_4","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ol> <li> <p>approximation of LDS</p> \\[ \\begin{aligned}     \\text{LDS}(r, x, \\theta) =&amp; \\text{KL}(r, x, \\theta)=\\text{KL}[f(x)||f(x+r)] \\\\     \\approx&amp; \\text{LDS}(0, x, \\theta) + \\nabla_r\\text{LDS}(0, x, \\theta)|_{r=0} + \\frac{1}{2}r^TH(x,\\theta)r \\\\     =&amp; \\frac{1}{2}r^TH(x,\\theta)r \\\\     r_{\\text{v-adv}} =&amp; \\mathop{\\text{arg max}}\\limits_{r;\\ ||r||_{2/\\infty}\\le \\epsilon} \\text{KL}(r, x, \\theta) \\\\     \\approx&amp; \\epsilon *\\overline{d(x, \\theta)} \\\\     \\text{power iteration method} \\\\     d\\leftarrow&amp; \\overline{Hd} \\\\     \\text{finite differce method} \\\\     Hd \\approx&amp; \\frac{\\nabla_r\\text{KL}(0, x+\\epsilon d,\\theta)\\big\\vert_{r=0} - \\nabla_r\\text{KL}(0, x,\\theta)\\big\\vert_{r=0}}{\\epsilon d}*d \\\\     =&amp; \\frac{\\nabla_r\\text{KL}(0, x+\\epsilon d,\\theta)\\big\\vert_{r=0}}{\\epsilon} \\\\     d=&amp;\\overline{\\nabla_r\\text{KL}(0, x+\\epsilon d,\\theta)\\big\\vert_{r=0}} \\end{aligned} \\] <ul> <li>\\(r=0\\) \u200b\u65f6\u200bKL\u200b\u6563\u5ea6\u503c\u200b\u4e3a\u200b0\u200b\u4e14\u200b\u5bf9\u5e94\u200b\u6781\u503c\u200b\u70b9\u200b\uff0c\u200b\u6240\u4ee5\u200b\u6cf0\u52d2\u200b\u5c55\u5f00\u5f0f\u200b\u524d\u200b\u4e24\u9879\u200b\u5747\u200b\u4e3a\u200b0  </li> <li>\\(\\text{arg max}\\text{ KL}\\) \u200b\u8868\u793a\u200b\u9009\u7528\u200b\\(r\\)\u200b\u4f7f\u5f97\u200bKL\u200b\u503c\u200b\u6700\u5927\u200b\u53c2\u4e0e\u200bVAT\u200b\u8bad\u7ec3\u200b\uff08\u200b\u6b64\u65f6\u200b\u8ba4\u4e3a\u200b\u5bf9\u6297\u200b\u6548\u679c\u200b\u6700\u597d\u200b\uff09  </li> <li>\\(\\overline{\\cdot}\\) \u200b\u4e3a\u200b L2 norm \u200b\u64cd\u4f5c\u200b\uff0c\\(u(x,\\theta)\\)\u200b\u8868\u793a\u200b\u4e3a\u6d77\u68ee\u200b\u77e9\u9635\u200b\\(H\\)\u200b\u7684\u200b\u6700\u200b\u4e3b\u8981\u200b\u7279\u5f81\u5411\u91cf\u200b  </li> <li>\u200b\u7279\u5f81\u503c\u200b\u5e42\u200b\u8fed\u4ee3\u200b\u8fd1\u4f3c\u7b97\u6cd5\u200b  <ol> <li>random_init \\(d\\); </li> <li>\u200b\u8fed\u4ee3\u200b\u8ba1\u7b97\u200bK\u200b\u6b21\u200b\uff08\u200b\u6b64\u5904\u200b1\u200b\u6b21\u200b\u6548\u679c\u200b\u5c31\u200b\u5f88\u200b\u7406\u60f3\u200b\uff09: \\(d = L_2\\text{-}norm(Hd)\\); </li> <li>return \\(d\\)</li> </ol> </li> </ul> </li> <li> <p>K=1\u200b\u5373\u53ef\u200b\u53d6\u5f97\u200b\u7406\u60f3\u200b\u6548\u679c\u200b     </p> <p></p> </li> <li> <p>VAT\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u7684\u200b\u6cdb\u5316\u200b\u80fd\u529b\u200b\u6548\u679c\u200b\u66f4\u5f3a\u200b\uff08AT\u200b\u65b0\u589e\u200b\u8bad\u7ec3\u200b\u70b9\u200b\uff0cVAT\u200b\u76f4\u63a5\u200b\u6cdb\u5316\u200b\u9762\u200b\uff09   </p> <p>VAT\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u7684\u200b\u6cdb\u5316\u200b\u80fd\u529b\u200b\u6548\u679c\u200b\u6f14\u5316\u200b</p> <p></p> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Denoising/AdversarialTraining/vat.html#fgm","title":"FGM","text":"<p>\u200b\u8bba\u6587\u200b\uff1aAdversarial Training Methods for Semi-supervised Text Classification FGM\uff1aFast Gradient Method Github\uff1aadversarial_text Preferred Networks &amp; Google &amp; OpenAI, ICLR 2017</p>"},{"location":"AI/Paper_Reading/Trick/Denoising/AdversarialTraining/vat.html#_5","title":"\u5de5\u4f5c\u200b\u8981\u70b9","text":"<ul> <li> \u200b\u7b2c\u4e00\u4e2a\u200b\u5c06\u200bAT\u200b\u548c\u200bVAT\u200b\u5e94\u7528\u200b\u81f3\u200b\u6587\u672c\u200b\u9886\u57df\u200b</li> <li> \u200b\u7ed3\u5408\u200b\u4e86\u200bFGSM\u200b\u548c\u200bapproximation of LDS\uff0c\u200b\u5176\u4e2d\u200b\u524d\u8005\u200b\\(L_\\infty\\)\u200b\u7ea6\u675f\u200b\u53d8\u4e3a\u200b\\(L_2\\)\u200b\u7ea6\u675f\u200b\uff0c\u200b\u5373\u200b\\(\\epsilon\\frac{g}{||g||_2}\\)</li> </ul> <ul> <li> dropout + FGM \u200b\u987a\u5e8f\u200b\u642d\u914d\u200b\u4f7f\u7528\u200b\u6548\u679c\u200b\u66f4\u597d\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Denoising/AdversarialTraining/vat.html#pgd","title":"PGD","text":"<p>\u200b\u8bba\u6587\u200b\uff1aTowards Deep Learning Models Resistant to Adversarial Attacks PGD\uff1aProjected Gradient Descent Github\uff1amnist_challenge\u3001cifar10_challenge MIT, ICLR 2018</p>"},{"location":"AI/Paper_Reading/Trick/Denoising/AdversarialTraining/vat.html#_6","title":"\u5de5\u4f5c\u200b\u8981\u70b9","text":"<ul> <li> <p>\u200b\u4e0d\u540c\u4e8e\u200bFG(S)M\u200b\u5148\u9a8c\u200b\u5730\u200b\u8ba4\u4e3a\u200b\u65e2\u6709\u200b\u6a21\u578b\u200b\u4e3a\u200b\u7b80\u5355\u200b\u7ebf\u6027\u200b\u5206\u7c7b\u5668\u200b\uff0c\u200b\u6b64\u7c7b\u200b\u5bf9\u6297\u200b\u8bad\u7ec3\u200b\u590d\u6742\u200b\u6a21\u578b\u200b\u6548\u679c\u200b\u4e0d\u591f\u200b\u9002\u7528\u200b\uff08\u200b\u5c40\u90e8\u200b\u6700\u4f18\u200b\u6216\u200b\u6548\u679c\u200b\u4e0d\u200b\u7406\u60f3\u200b\uff09\uff0c\u200b\u56e0\u6b64\u200b\u63d0\u51fa\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u4f18\u5316\u200b\u7684\u200b\u591a\u6b65\u200b\u53d8\u4f53\u200b\u65b9\u6848\u200b\u9002\u7528\u200b\u4e8e\u200b\u590d\u6742\u200b\u6a21\u578b\u200b\u7684\u200b\u5bf9\u6297\u200b\u8bad\u7ec3\u200b     </p> <p>PGM\u200b\u539f\u7406\u200b\u793a\u610f\u200b</p> <p></p> \\[ \\begin{aligned}     \\mathcal{L}(x, y, \\theta) &amp;= \\mathcal{L}_1(x, y, \\theta) + \\alpha\\mathcal{L}_1(x^S, y, \\theta) \\\\     x^{t+1} &amp;= x^0 + r^t \\\\     r^{t+1}_{\\infty}&amp; = \\epsilon\\text{sign}(\\nabla_x\\mathcal{L}_1(x^t, y, \\theta)) \\\\     r^{r+1}_{2}&amp; = \\epsilon\\frac{\\nabla_x\\mathcal{L}_1(x^t, y, \\theta)}{||\\nabla_x\\mathcal{L}_1(x^t, y, \\theta)||_2}  \\end{aligned} \\] <ul> <li>\u200b\u4e3a\u200b\u589e\u52a0\u200b\u6837\u672c\u200b\u968f\u673a\u6027\u200b\uff0c\u200b\u53ef\u200b\u521d\u59cb\u5316\u200b<code>x0=x+clip(random_r, delta)</code>\u200b\u4f5c\u4e3a\u200bPGD\u200b\u8d77\u59cb\u200b\u70b9\u200b  </li> <li>\\(S\\) \u200b\u8868\u793a\u200b\u8fed\u4ee3\u200b\u7684\u200b\u6b65\u6570\u200b\uff0c\u200b\u53ef\u200b\u901a\u8fc7\u200b<code>clip(r, delta)</code>\u200b\u65b9\u6848\u200b\u63a7\u5236\u200b\u6bcf\u6b65\u200b\u65b0\u589e\u200b\u7684\u200b\\(r\\)</li> </ul> </li> </ul>"},{"location":"AI/Paper_Reading/Trick/Denoising/AdversarialTraining/vat.html#smart","title":"SMART","text":"<p>\u200b\u8bba\u6587\u200b\uff1aSMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization SMAR\\(^3\\)T\\(^2\\)\uff1aSMoothness-inducing Adversarial Regularization and bRegman pRoximal poinT opTimization Github\uff1amt-dnn\uff0csmart_pytorch Microsoft Dynamics 365 AI, ACL 2020</p>"},{"location":"AI/Paper_Reading/Trick/Denoising/AdversarialTraining/vat.html#_7","title":"\u5de5\u4f5c\u200b\u8981\u70b9","text":"<ul> <li> <p> \u200b\u7ed3\u5408\u200bapproximation of LDS\u200b\u548c\u200bPGD\u200b\u601d\u60f3\u200b</p> \\[ \\begin{aligned}     \\mathcal{L} = \\mathcal{L}_1(x, y, \\theta) &amp;+ \\alpha \\big(\\text{KL}[f(x)||f(x^S)] + \\text{KL}[f(x^S)||f(x)]\\big) \\\\      x^{t+1} &amp;= x^0 + r^t \\\\     r^{t+1}_{\\text{v-adv-}2} &amp;= \\epsilon\\frac{g}{||g||_2}, \\text{where}\\ g=\\nabla_{r}\\text{KL}[f(x)||f(x^0 + r)] \\Big\\vert_{r=r^t} \\\\     r^{t+1}_{\\text{v-adv-}\\infty} &amp;= \\epsilon \\text{sign}(g), \\text{where}\\ g=\\nabla_{r}\\text{KL}[f(x)||f(x^0 + r)] \\Big\\vert_{r=r^t} \\end{aligned} \\] <ul> <li>\u200b\u6b64\u5904\u200bapproximation of LDS\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u4e86\u200b\u5bf9\u79f0\u200bKL\u200b\u6563\u5ea6\u200b</li> <li>\\(\\nabla_r\\)\u200b\u4e2d\u200b\u7684\u200b\\(r\\)\u200b\u8868\u793a\u200b\u7684\u200b\u662f\u200b<code>random_init_r</code></li> </ul> </li> <li> <p> SMART\u200b\u8f83\u200b\u6b63\u5e38\u200bBERT\u200b\u8bad\u7ec3\u200b\u6548\u679c\u200b\u63d0\u5347\u200b</p> </li> </ul> <p>1 TextBugger</p> <p>\u200b\u8bba\u6587\u200b\uff1aTextBugger: Generating Adversarial Text Against Real-world Applications Zhejiang University &amp; Alibaba-Zhejiang University Joint Research, NDSS 2019</p> <p>1 \u200b\u5de5\u4f5c\u200b\u8981\u70b9\u200b - general attack framework for generating adversarial texts - \u200b\u767d\u76d2\u200b\u73af\u5883\u200b\uff1a     - \u200b\u57fa\u4e8e\u200b\u96c5\u200b\u53ef\u6bd4\u200b\u77e9\u9635\u200b\uff0c\u200b\u5e76\u200b\u6309\u7167\u200b\u68af\u5ea6\u200b\u964d\u5e8f\u200bargidx\u200b\u6392\u5e8f\u200btoken\u200b\u5e8f\u5217\u200b     - \u200b\u904d\u5386\u200b\u6709\u5e8f\u200btoken\u200b\u5e8f\u5217\u200b\uff0c\u200b\u5f53\u200b\u6270\u52a8\u200b(char-level\u200b\u6216\u200bword-level)\u200b\u540e\u200b\\(S(x, x^{'})\\gt \\epsilon\\ \\text{and} \\ F(x^{'})\\ne y\\)\uff0c\u200b\u8fd4\u56de\u200b\\(x^{'}\\)         - insert\u3001delete\u3001swap\u3001subsitute-char and subsitute-word         - algorithm 2 - \u200b\u9ed1\u76d2\u200b\u73af\u5883\u200b\uff1a\u200b\u9009\u62e9\u200b\u91cd\u8981\u6027\u200b\u6700\u9ad8\u200b\u7684\u200b\u53e5\u5b50\u200b\uff0c\u200b\u5229\u7528\u200b\u6253\u5206\u200b\u51fd\u6570\u200b\u5b9a\u4f4d\u200b\u5e76\u200b\u64cd\u7eb5\u200b\u91cd\u8981\u200btokens         - algorithm 3</p> <p>1 TextAttack TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP</p> <ul> <li>Reliable Evaluation of Adversarial Robustness with an Ensemble of Diverse Parameter-free Attacks</li> </ul> <p>1 FreeAT Adversarial Training for Free! - https://zhuanlan.zhihu.com/p/103593948</p> <p>1 YOPO You Only Propagate Once</p> <p>1 FreeLB Free Large-Batch</p>"},{"location":"AI/Paper_Reading/Trick/Denoising/DAE/dae.html","title":"Dae","text":""},{"location":"AI/Paper_Reading/Trick/Denoising/DAE/dae.html#dae","title":"DAE","text":"<ul> <li>mask\u200b\u90e8\u5206\u200binput_token\u200b\u8fdb\u884c\u200b\u5206\u7c7b\u200b\u8bad\u7ec3\u200b</li> <li>\u200b\u90e8\u5206\u200binput_token\u200b\u52a0\u5165\u200b\u6270\u52a8\u200b\u566a\u58f0\u200b -&gt; \u200b\u5c06\u200b\u79bb\u6563\u200b\u7684\u200btoken embedding\u200b\u901a\u8fc7\u200b\u52a0\u5165\u200b\u566a\u58f0\u200b\u5b9e\u73b0\u200b\u5411\u91cf\u200b\u8fde\u7eed\u200b\u5316\u200b\uff0c\u200b\u52a0\u5f3a\u200b\u5bf9\u6297\u6027\u200b</li> <li>\u200b\u4e00\u4e2a\u200bd\u200b\u7ef4\u200btoken\u200b\u5212\u5206\u200b\u4e3a\u200bk\u200b\u4e2a\u200bd/k\u200b\u7ef4\u200btoken\uff0c\u200b\u518d\u200b\u5f15\u5165\u200b\u5c40\u90e8\u6027\u200b\u9020\u6210\u200b\uff0c\u200b\u5e38\u89c1\u4e8e\u200b\u56fe\u50cf\u200bpatch\u200b\u6216\u8005\u200b\u6216\u8005\u200b\u5411\u91cf\u200b\u8868\u793a\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Denoising/VAE/vae.html","title":"Vae","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/index.html","title":"Index","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/index.html#_1","title":"\u5e95\u5c42\u200b\u4f18\u5316\u200b\u65b9\u6848","text":"<ul> <li>Flash Attention<ul> <li>v1\uff1a\u200b\u901a\u8fc7\u200b\u5206\u5757\u200b\u7684\u200b\u65b9\u5f0f\u200b\u8282\u7701\u200b\u4e86\u200bHBM\u200b\u7684\u200b\u8bbf\u5b58\u200b\u6b21\u6570\u200b\uff1b\u200b\u5728\u200b<code>batch_size</code>\u200b\u7ef4\u5ea6\u200b\u4e0a\u200b\u5e76\u884c\u200b</li> <li>v2\uff1a\u200b\u51cf\u5c11\u200b\u4e86\u200b\u975e\u200b\u77e9\u9635\u200b\u4e58\u6cd5\u200b\u8fd0\u7b97\u200b\uff1b\u200b\u4fee\u6539\u200b<code>batch_size</code>\u200b\u7ef4\u5ea6\u200b\u5e76\u200b\u884c\u81f3\u200b<code>seq_len</code>\u200b\u7ef4\u5ea6\u200b\u4e0a\u200b\u5e76\u884c\u200b\uff1b\u200b\u5c06\u200b\u5206\u5757\u200b\u7684\u200bK\u3001V\u200b\u77e9\u9635\u200b\u5feb\u200b\u653e\u5165\u200b\u540c\u4e00\u4e2a\u200bthread block\u200b\u7684\u200b\u4e0d\u540c\u200bwarp\u200b\u4e2d\u200b\uff0c\u200b\u901a\u8fc7\u200b\u5171\u4eab\u5185\u5b58\u200b\u7684\u200b\u7279\u6027\u200b\u51cf\u5c11\u200b\u901a\u4fe1\u200b\u5f00\u9500\u200b</li> <li>v3\uff1a\u200b\u5728\u200bKey\u200b\u548c\u200bValue\u200b\u7684\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b<code>seq_len</code>\u200b\u4e0a\u200b\u5206\u5757\u200b\uff0c\u200b\u8fdb\u4e00\u6b65\u200b\u8bbe\u7f6e\u200b\u4e86\u200b\u591a\u200b\u8d77\u70b9\u200b\uff0c\u200b\u4ece\u800c\u200b\u65b0\u589e\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u5e76\u884c\u200b\u5316\u200b\u64cd\u4f5c\u200b\u3002Q\u200b\u8fd8\u662f\u200b\u6309\u7167\u200bblock\u200b\u987a\u5e8f\u200b\u6267\u884c\u200b</li> </ul> </li> </ul> Flash Attention v1, v2\u200b\u8fd0\u884c\u200b\u539f\u7406\u56fe\u200b Flash Attention v3\u200b\u8fd0\u884c\u200b\u539f\u7406\u56fe"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/batch_strategy.html","title":"Batch strategy","text":"<ul> <li>https://mp.weixin.qq.com/s?__biz=MzU3Mzg5ODgxMg==&amp;mid=2247489116&amp;idx=1&amp;sn=0f2771e71f2c3e020ab8e86684df0093&amp;chksm=fd3bff0fca4c7619db3f3dc800df858150a12c7f192234625b871a4f15cfc699c5746846c5b8&amp;token=1935281044&amp;lang=zh_CN#rd</li> <li>left_pad: \u200b\u4f7f\u540c\u200b\u6279\u6b21\u200b\u5185\u200b\u6570\u636e\u200b\u7b49\u200b\u957f\u200b\uff0c\u200b\u4e14\u200b\u6709\u6548\u200b\u6570\u636e\u200b\u9760\u53f3\u200b\uff0cright_pad\u200b\u4f1a\u200b\u5bfc\u81f4\u200bprompt\u200b\u548c\u200b\u751f\u6210\u200b\u7684\u200btoken\u200b\u95f4\u200b\u5b58\u5728\u200bmask\uff0c\u200b\u589e\u52a0\u200b\u590d\u6742\u6027\u200b</li> <li>\u200b\u9759\u6001\u200b\u6279\u5904\u7406\u200b\uff08static batching\uff09\uff1a\u200b\u8f93\u5165\u200b\u901a\u8fc7\u200bleft_pad\u200b\u5c06\u200b\u6240\u6709\u200b\u8f93\u5165\u200b\u586b\u5145\u200b\u81f3\u200b\u76f8\u540c\u200b\u957f\u5ea6\u200b\u8fdb\u884c\u200b\u751f\u6210\u200b\uff0c\u200b\u7531\u4e8e\u200b\u90e8\u5206\u200bPrompt\u200b\u5728\u200b\u6279\u5904\u7406\u200b\u4e2d\u8f83\u200b\u65e9\u200b\u201c\u200b\u5b8c\u6210\u200b\u201d\uff0c\u200b\u4f46\u200b\u9700\u200b\u7b49\u5f85\u200b\u8fd9\u4e00\u200b\u6279\u6b21\u200b\u4e2d\u200bPrompt\u200b\u6700\u957f\u200b\u7684\u200b\u751f\u6210\u200b\u7ed3\u675f\u200b\uff0c\u200b\u56e0\u6b64\u200bGPU \u200b\u672a\u200b\u5f97\u5230\u200b\u5145\u5206\u5229\u7528\u200b\u3002batch_size\u200b\u4fdd\u6301\u200b\u4e0d\u53d8\u200b</li> <li></li> <li>\u200b\u52a8\u6001\u200b\u6279\u5904\u7406\u200b\uff08Dynamic batching\uff09\uff1a\u200b\u5c06\u200b\u53d7\u5230\u200b\u7684\u200b\u670d\u52a1\u200b\u7ec4\u6210\u200b\u6279\u6b21\u200b\u8fdb\u884c\u200b\u5904\u7406\u200b\uff08\u200b\u4e00\u822c\u200b\u5927\u200b\u6279\u6b21\u200b\u7684\u200b\u541e\u5410\u200b\u7387\u200b\u8f83\u200b\u5c0f\u200b\u6279\u6b21\u200b\u7684\u200b\u66f4\u200b\u9ad8\u200b\uff09</li> <li></li> <li>\u200b\u53d8\u200b\u957f\u200b\u8f93\u5165\u200b\u6279\u5904\u7406\u200b\uff08Ragged Batching\uff09\uff1adynamic shape + dynamic batching\uff0c\u200b\u5982\u200b\u4e0d\u540c\u200b\u5c3a\u5bf8\u200btensor padding\u200b\u81f3\u200b\u76f8\u540c\u200b\u5c3a\u5bf8\u200b\uff0c<code>[1, 3, 768, 932]</code> \u200b\u548c\u200b <code>[1, 3, 1024, 168]</code> \u200b\u6bd4\u5982\u200bpadding\u200b\u4e3a\u200b <code>[1, 3, 1024, 1024]</code>\uff0cNLP\u200b\u4e2d\u200b\u8868\u73b0\u200b\u4e3a\u200bleft_pad</li> <li>\u200b\u8fde\u7eed\u200b\u6279\u5904\u7406\u200b\uff08Continuous/Inflight Batching\uff09\uff1a\u200b\u4e0d\u540c\u4e8e\u200bstatic batching\uff0c\u200b\u5f53\u200b\u4e00\u4e2a\u200b\u8f93\u5165\u200b\u7684\u200b\u751f\u6210\u200b\u7ed3\u675f\u200b\u4e86\u200b\uff0c\u200b\u5c31\u200b\u5c06\u200b\u65b0\u200b\u7684\u200b\u8f93\u5165\u200b\u63d2\u8fdb\u6765\u200b\uff0c\u200b\u6240\u4ee5\u200bbatch size\u200b\u662f\u200b\u52a8\u6001\u200b\u7684\u200b\u3002<ul> <li></li> <li>\u200b\u6bcf\u4e2a\u200b\u8bf7\u6c42\u200b\u7684\u200bKV Cache\u200b\u72ec\u7acb\u200b\u521d\u59cb\u5316\u200b\u3002</li> <li>\u200b\u901a\u8fc7\u200battention mask\u200b\u9694\u79bb\u200b\u4e0d\u540c\u200b\u8bf7\u6c42\u200b\u7684\u200b\u53ef\u89c1\u200b\u8303\u56f4\u200b(\u200b\u5177\u4f53\u200b\u4e3a\u200bclear kv cache\uff0c\u200b\u7136\u540e\u200b\u8bbf\u95ee\u200b\u65b0\u200b\u4fdd\u5b58\u200b\u7684\u200bkv cache\u200b\u5185\u5bb9\u200b)</li> <li>\u200b\u65b0\u200b\u8bf7\u6c42\u200b\u7684\u200bprompt\u200b\u4e00\u822c\u200b\u4e0d\u9010\u200btoken\u200b\u751f\u6210\u200b\uff08\u200b\u56e0\u200bprompt\u200b\u662f\u200b\u5df2\u77e5\u200b\u5e8f\u5217\u200b\uff0c\u200b\u8be5\u200b\u65b9\u5f0f\u200b\u8fc7\u4e8e\u200b\u4f4e\u6548\u200b\uff09\uff0c\u200b\u800c\u662f\u200b\u4f1a\u200b\u91c7\u7528\u200b\u4e00\u6b21\u6027\u200b\u8ba1\u7b97\u200b\u65b9\u6848\u200b\u5f97\u5230\u200b\u65b0\u200b\u8bf7\u6c42\u200bprompt\u200b\u7684\u200bkv cache\uff0c\u200b\u5f53\u200b\u8ba1\u7b97\u200b\u5b8c\u200bprompt \u200b\u7684\u200bkv cache\u200b\u540e\u200b\uff0c\u200b\u53ef\u200b\u52a8\u6001\u200b\u8c03\u5ea6\u200b\u65b0\u200b\u8bf7\u6c42\u200b\uff08kv cache\uff09\u200b\u8fdb\u884c\u200bnext token prediction\uff08\u200b\u5177\u6709\u200bkv cache\u200b\u7b56\u7565\u200b\u7684\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u53ea\u200b\u9700\u8981\u200b\u8f93\u5165\u200b\u5355\u4e2a\u200btoken\uff0c\u200b\u5373\u200bcurrent token\uff09</li> </ul> </li> <li>FasterTransformer</li> <li>Orca: A Distributed Serving System for Transformer-Based Generative Models</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/flash_attention.html","title":"Flash attention","text":"<p><code>Flash Attention</code> \u200b\u662f\u200b\u7531\u200bStanford AI Lab\u200b\u53d1\u8868\u200b\u5e76\u200b\u5b9e\u73b0\u200b\u7684\u200b\u4e00\u4e9b\u200b\u57fa\u4e8e\u200bGPU\u200b\u5e95\u5c42\u200b\u67b6\u6784\u200b\u5b9e\u73b0\u200bAttention\u200b\u8fd0\u7b97\u200b\u4f18\u5316\u200b\u65b9\u6848\u200b (\u200b\u975e\u200b\u8fd1\u4f3c\u7b97\u6cd5\u200b)\uff0c\u200b\u5176\u200b\u5229\u7528\u200b\u66f4\u5c11\u200b\u7684\u200bGPU\u200b\u663e\u5b58\u200b\u5f97\u5230\u200b\u66f4\u5feb\u200b\u7684\u200b\u8fd0\u7b97\u200b\u7684\u200b\u901f\u7387\u200b\u88ab\u200b\u8bb8\u591a\u200b\u4f01\u4e1a\u200b\u548c\u200b\u7814\u7a76\u5ba4\u200b\u91c7\u7528\u200b\uff0c\u200b\u5e7f\u6cdb\u5e94\u7528\u200b\u4e8e\u200b\u5927\u591a\u6570\u200bLLM\u200b\u5e93\u200b</p> <ul> <li>Flash Attention v1</li> <li>Flash Attention v2</li> <li>Flash Attention v3</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/flash_attention.html#standard-attention","title":"Standard Attention","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/flash_attention.html#_1","title":"\u7b97\u6cd5\u200b\u5b9e\u73b0","text":"<p>\u200b\u6807\u51c6\u200battention\u200b\u7b97\u6cd5\u200b\u5b9e\u73b0\u200b</p> <ol> <li>\u200b\u4ece\u200bHBM\u200b\u5206\u5757\u200b\u52a0\u8f7d\u200b\\(Q\\)\u3001\\(K\\)\uff0c\u200b\u8ba1\u7b97\u200b\\(S = QK^T\\)\uff0c\u200b\u5c06\u200b \\(S\\) \u200b\u5199\u56de\u200bHBM</li> <li>\u200b\u4ece\u200bHBM\u200b\u8bfb\u53d6\u200b\\(S\\)\uff0c\u200b\u8ba1\u7b97\u200b \\(P=\\text{softmax}(S)\\)\uff0c\u200b\u5c06\u200b \\(P\\) \u200b\u5199\u56de\u200bHBM</li> <li>\u200b\u4ece\u200bHBM\u200b\u5206\u5757\u200b\u52a0\u8f7d\u200b\\(P\\)\u3001\\(V\\)\uff0c\u200b\u8ba1\u7b97\u200b\\(O=PV\\)\uff0c\u200b\u5c06\u200b \\(O\\) \u200b\u5199\u56de\u200bHBM</li> </ol> <ul> <li>\u200b\u5f53\u524d\u200b\u4e3b\u6d41\u200b\u7684\u200bAttention\u200b\u52a0\u901f\u200b\u7b97\u6cd5\u200b\u90fd\u200b\u662f\u200b\u8fd1\u4f3c\u7b97\u6cd5\u200b\uff08\u200b\u5982\u200b\u7a00\u758f\u200bAttention\uff09\uff0c\u200b\u4ee5\u200b\u51cf\u5c11\u200b\u590d\u6742\u5ea6\u200b\u4e3a\u200b\\(O(N^2d)\\) Attention\u200b\u8ba1\u7b97\u200b\u5f00\u9500\u200b\uff0c\u200b\u4f46\u200b\u5f53\u524d\u200bGPU\u200b\u7684\u200b\u6d6e\u70b9\u6570\u200b\u8ba1\u7b97\u200b\u6548\u7387\u200b\u6bd4\u200bIO\u200b\u8bbf\u5b58\u200b\u6548\u7387\u200b\u5feb\u5f97\u591a\u200b\uff0c\u200b\u8fc7\u5206\u200b\u7684\u200b\u4f18\u5316\u200bFLOPS\u200b\u6548\u679c\u200b\u4e0d\u200b\u660e\u663e\u200b</li> <li>\u200b\u6807\u51c6\u200bHBM IO\u200b\u8bbf\u5b58\u200b\u590d\u6742\u5ea6\u200b=\\(O(Nd + N^2)\\)\uff0c\u200b\u74f6\u9888\u200b\u5728\u200bHBM IO\u200b\u8bbf\u5b58\u200b\u3002</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/flash_attention.html#flashattention-1","title":"FlashAttention-1","text":"<p>\u200b\u901a\u8fc7\u200b<code>Q</code>\u3001<code>K</code>\u3001<code>V</code>\u200b\u5206\u5757\u200btiling\u200b\u548c\u200b\u91cd\u200b\u8ba1\u7b97\u200b\uff08\u200b\u4e0d\u200b\u4fdd\u5b58\u200bAttention\u200b\u7684\u200b\u90e8\u5206\u200b\u4e2d\u95f4\u200b\u7ed3\u679c\u200b\uff09\u200b\u7684\u200b\u65b9\u5f0f\u200b\u8282\u7701\u200b\u4e86\u200bHBM\u200b\u7684\u200bIO\u200b\u8bbf\u5b58\u200b\u6b21\u6570\u200b</p> <ul> <li> Attention\u200b\u90e8\u5206\u200b\u663e\u5b58\u200b\u4f7f\u7528\u200b\u6570\u91cf\u7ea7\u200b\u4ece\u200b\u5e73\u65b9\u200b\u964d\u200b\u4e3a\u200b\u7ebf\u6027\u200b</li> <li> \u200b\u6700\u7ec8\u200b\u4ee5\u8f83\u200b\u5c11\u200b\u7684\u200bGPU\u200b\u8d44\u6e90\u200b\u548c\u200b\u66f4\u200b\u5feb\u200b\u7684\u200b\u901f\u5ea6\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u4e0e\u200b\u6807\u51c6\u200bAttention\u200b\u4e00\u6837\u200b\u7684\u200b\u6548\u679c\u200b</li> <li> \u200b\u76f8\u540c\u200b\u7684\u200bGPU\u200b\u8d44\u6e90\u200b\u4e0b\u200b\u80fd\u591f\u200b\u8bad\u7ec3\u200b\u66f4\u5927\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u53d6\u5f97\u200b\u66f4\u4f73\u200b\u7684\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/flash_attention.html#_2","title":"\u52a8\u673a","text":"Attention\u200b\u5b58\u50a8\u200b\u8bbf\u95ee\u200b\u793a\u610f\u56fe\u200b\u3002\uff08HBM\uff1ahigh bandwith memory\uff09 <p>===&gt; \u200b\u901a\u8fc7\u200b\u4fee\u6539\u200bPyTorch\u200b\u6216\u200bTensorflow\u200b\u66f4\u200b\u5e95\u5c42\u200bCUDA\u200b\u903b\u8f91\u200b\u5b9e\u73b0\u200bIO\u200b\u8bbf\u5b58\u200b\u7684\u200b\u4f18\u5316\u200b</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/flash_attention.html#_3","title":"\u57fa\u672c\u539f\u7406","text":"<ol> <li> <p>\u200b\u5206\u5757\u200b</p> <ul> <li>\u200b\u5c06\u200b <code>Q</code>\u200b\u5206\u5757\u200b\u4e3a\u200b\\(T_r\\)\u200b\u4e2a\u5757\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u5757\u200b\u7ef4\u5ea6\u200b\\(\\in R^{B_r \\times d}\\) <p>\\(N=B_r*T_r\\)</p> </li> <li>\u200b\u5c06\u200b <code>K</code>, <code>V</code>\u200b\u5206\u5757\u200b\u4e3a\u200b\\(T_c\\)\u200b\u4e2a\u5757\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u5757\u200b\u7ef4\u5ea6\u200b\\(\\in R^{B_c \\times d}\\) <p>\\(N=B_c*T_c\\)</p> </li> <li>\u200b\u4e2d\u95f4\u200b\u503c\u200b \\(S_{i, j}=Q_iK_j^T \\in \\mathbb{R}^{B_r\\times B_c}\\)</li> <li>\u200b\u65b0\u589e\u200b\u989d\u5916\u200b\u5b58\u50a8\u7a7a\u95f4\u200b\\(m_i \\in \\mathbb{R}^{B_r}\\) \u200b\u8868\u793a\u200b\u5b9e\u65f6\u200b\u5b58\u50a8\u200bi-th S\u200b\u5757\u200b\u6574\u5408\u200b\u540e\u200b\u5404\u884c\u200b\u6700\u5927\u503c\u200b\uff0c\u200b\u4e34\u65f6\u200b\u53d8\u91cf\u200b\\(m_{i, j} \\in \\mathbb{R}^{T_r}\\) \u200b\u8868\u793a\u200b\u5f53\u524d\u200b{i, j} S\u200b\u5757\u200b\u7684\u200b\u5404\u884c\u200b\u6700\u5927\u503c\u200b</li> <li>\u200b\u4e2d\u95f4\u200b\u503c\u200b\\(P_{i, j} = \\exp(S_{i,j} - \\bar{m}_{i,j})\\)\u200b\u7684\u200b\u5c40\u90e8\u200b\u6307\u6570\u200b\u51cf\u53bb\u200b\u5f53\u524d\u200b\u5757\u200b\u6700\u5927\u503c\u200b\u7684\u200b<code>exp</code>\u200b\u7ed3\u679c\u200b</li> <li>\u200b\u8f93\u51fa\u200b <code>O</code> \u200b\u5206\u5757\u200b\u4e3a\u200b\\(T_r\\) \u200b\u4e2a\u5757\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u5757\u200b\u7ef4\u5ea6\u200b\\(\\in R^{B_r \\times d}\\)</li> <li>\u200b\u65b0\u589e\u200b\u989d\u5916\u200b\u5b58\u50a8\u7a7a\u95f4\u200b\\(\\ell \\in \\mathbb{R}^{T_r}\\) \u200b\u8868\u793a\u200b\u5b9e\u65f6\u200b\u5b58\u50a8\u200bi-th P\u200b\u5757\u200b\u6574\u5408\u200b\u540e\u200b\u7684\u200bexp_sum\uff08\u200b\u9664\u4ee5\u200b\u4e86\u200b\u5f53\u524d\u200b\u6574\u5408\u200b\u72b6\u6001\u200b\u4e0b\u200b\u6700\u5927\u503c\u200b\u800c\u200b\u5f52\u4e00\u5316\u200b\uff0c\u200b\u9632\u6b62\u200b\u7d2f\u4e58\u200b\u7206\u70b8\u200b\uff09\uff0c\u200b\u4e34\u65f6\u200b\u53d8\u91cf\u200b\\(\\ell_{i, j} \\in \\mathbb{R}^{T_r}\\) \u200b\u8868\u793a\u200b\u5f53\u524d\u200b{i, j} P\u200b\u5757\u200b\u7684\u200bexp_sum\uff08\u200b\u9664\u4ee5\u200b\u4e86\u200b\u5f53\u524d\u200b\u5757\u200b\u72b6\u6001\u200b\u4e0b\u200b\u6700\u5927\u503c\u200b\u800c\u200b\u5f52\u4e00\u5316\u200b\uff0c\u200b\u9632\u6b62\u200b\u7d2f\u4e58\u200b\u7206\u70b8\u200b\uff09</li> <li>\\(O_i\\)\u200b\u8868\u793a\u200b<code>Q</code>\u200b\u5206\u5272\u200b\u5f97\u5230\u200b\\(i \\text{-} th\\)\u200b\u4e2a\u5757\u200b\uff08\u200b\u5373\u200b<code>Q_i</code>\uff09\u200b\u7684\u200bAttention\u200b\u5206\u6570\u200b</li> </ul> </li> <li> <p>\u200b\u91cd\u200b\u8ba1\u7b97\u200b\uff08\u200b\u4e0d\u200b\u4fdd\u5b58\u200bAttention\u200b\u7684\u200b\u90e8\u5206\u200b\u4e2d\u95f4\u200b\u7ed3\u679c\u200b\uff09</p> <ul> <li>\u200b\u4e0d\u200b\u4fdd\u5b58\u200b\\(S\\)\u200b\u81f3\u200bHBM\uff0c\u200b\u51cf\u5c11\u200bIO</li> <li>\u200b\u4e0d\u200b\u4fdd\u5b58\u200b\\(P\\)\u200b\u81f3\u200bHBM\uff0c\u200b\u51cf\u5c11\u200bIO</li> </ul> </li> </ol> <p>\u200b\u5916\u200b\u5faa\u73af\u200b\u662f\u200bK\u3001V\uff0c\u200b\u5185\u200b\u5faa\u73af\u200b\u662f\u200bQ\uff0c\u200b\u524d\u8005\u200b\u53ea\u200b\u9700\u8981\u200b\u8bfb\u200b2+T_r\u200b\u6b21\u200b\uff0c\u200b\u540e\u8005\u200b\u9700\u8981\u200b\u8bfb\u200b1+2*T_c\u200b\u6b21\u200b</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/flash_attention.html#flashattention-2","title":"FlashAttention-2","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/flash_attention.html#_4","title":"\u52a8\u673a","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/flash_attention.html#_5","title":"\u57fa\u672c\u539f\u7406","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/flash_attention.html#flashattention-3","title":"FlashAttention-3","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/flash_attention.html#_6","title":"\u65b9\u6cd5\u200b\u4ecb\u7ecd","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/flash_attention.html#_7","title":"\u57fa\u672c\u539f\u7406","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/flash_attention.html#_8","title":"\u5e95\u5c42\u200b\u4f18\u5316\u200b\u65b9\u6848","text":"<ul> <li>Flash Attention<ul> <li>v1\uff1a\u200b\u901a\u8fc7\u200b\u5206\u5757\u200b\u7684\u200b\u65b9\u5f0f\u200b\u8282\u7701\u200b\u4e86\u200bHBM\u200b\u7684\u200b\u8bbf\u5b58\u200b\u6b21\u6570\u200b\uff1b\u200b\u5728\u200b<code>batch_size</code>\u200b\u7ef4\u5ea6\u200b\u4e0a\u200b\u5e76\u884c\u200b</li> <li>v2\uff1a\u200b\u51cf\u5c11\u200b\u4e86\u200b\u975e\u200b\u77e9\u9635\u200b\u4e58\u6cd5\u200b\u8fd0\u7b97\u200b\uff1b\u200b\u4fee\u6539\u200b<code>batch_size</code>\u200b\u7ef4\u5ea6\u200b\u5e76\u200b\u884c\u81f3\u200b<code>seq_len</code>\u200b\u7ef4\u5ea6\u200b\u4e0a\u200b\u5e76\u884c\u200b\uff1b\u200b\u5c06\u200b\u5206\u5757\u200b\u7684\u200bK\u3001V\u200b\u77e9\u9635\u200b\u5feb\u200b\u653e\u5165\u200b\u540c\u4e00\u4e2a\u200bthread block\u200b\u7684\u200b\u4e0d\u540c\u200bwarp\u200b\u4e2d\u200b\uff0c\u200b\u901a\u8fc7\u200b\u5171\u4eab\u5185\u5b58\u200b\u7684\u200b\u7279\u6027\u200b\u51cf\u5c11\u200b\u901a\u4fe1\u200b\u5f00\u9500\u200b</li> <li>v3\uff1a\u200b\u5728\u200bKey\u200b\u548c\u200bValue\u200b\u7684\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b<code>seq_len</code>\u200b\u4e0a\u200b\u5206\u5757\u200b\uff0c\u200b\u8fdb\u4e00\u6b65\u200b\u8bbe\u7f6e\u200b\u4e86\u200b\u591a\u200b\u8d77\u70b9\u200b\uff0c\u200b\u4ece\u800c\u200b\u65b0\u589e\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u5e76\u884c\u200b\u5316\u200b\u64cd\u4f5c\u200b\u3002Q\u200b\u8fd8\u662f\u200b\u6309\u7167\u200bblock\u200b\u987a\u5e8f\u200b\u6267\u884c\u200b</li> </ul> </li> </ul> Flash Attention v1, v2\u200b\u8fd0\u884c\u200b\u539f\u7406\u56fe\u200b Flash Attention v3\u200b\u8fd0\u884c\u200b\u539f\u7406\u56fe"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/kv_cache.html","title":"Kv cache","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/kv_cache.html#kv-cache","title":"KV Cache","text":"<p>\u200b\u5e94\u7528\u200b KV Cache \u200b\u4f18\u5316\u200b\u7684\u200b\u751f\u6210\u200b\u5927\u200b\u6a21\u578b\u200b\u5728\u200b\u63a8\u7406\u200b\u8fc7\u7a0b\u200b\u5305\u542b\u200b\u4e86\u200b\u4e24\u4e2a\u200b\u9636\u6bb5\u200b\uff1a</p> <ol> <li>Prompt\u200b\u9884\u200b\u586b\u5145\u200b\uff1a\u200b\u4e00\u6b21\u6027\u200b\u5c06\u200bPrompt Input\uff08Full Attention\uff09\u200b\u8f93\u5165\u200b\u81f3\u200bLLM\u200b\u4e2d\u200b\u751f\u6210\u200b\u6bcf\u5c42\u200b\u7684\u200b KV Cache</li> <li>\u200b\u89e3\u7801\u200b\uff1a\u200b\u65f6\u5e8f\u200b\u66f4\u65b0\u200b\u5e76\u200b\u4f7f\u7528\u200bKV Cache\uff0c\u200b\u6267\u884c\u200b<code>next_token_prediction</code>\uff08Causal Attention\uff09\u200b\u64cd\u4f5c\u200b</li> </ol>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/kv_cache.html#_1","title":"\u89e3\u7801\u200b\u9636\u6bb5","text":"<p>KV cache \u200b\u5c06\u200b\u5404\u5c42\u200b \\(k^n_{1:t-1}\\) \u200b\u4e0e\u200b \\(v^n_{1:t-1}\\)\uff0c\u200b\u5176\u4e2d\u200bper-head\u200b\u7f13\u5b58\u200b <code>K/V.shape = (seq_len, head_dim)</code>\uff0c\u200b\u63a8\u7406\u200b\u89e3\u7801\u200b\u65f6\u200bper-head\u200b\u57fa\u4e8e\u200b\\(h_t^n\\)\u200b\u7684\u200b\\(q_t^n, k_t^n, v_t^n\\) \u200b\u8ba1\u7b97\u200b\u4ee5\u53ca\u200b\u7f13\u5b58\u200b\u8bfb\u53d6\u200b\u3001\u200b\u66f4\u65b0\u200b\u540e\u200b\u6267\u884c\u200b </p> \\[ \\text{Attention}(q^n_t, K^n_{1:t}, V^n_{1:t}) = \\text{Softmax}\\left(\\frac{\\left(q_t^n\\right)^T \\left(K^n_{1:t}\\right)^T}{\\sqrt{d_h}}\\right) V^n_{1:t} \\] <p>\u200b\u53ea\u200b\u9700\u8981\u200b\u57fa\u4e8e\u200b \\(q^n_t\\) \u200b\u4e0e\u200b \\(K^n_{1:t}\\) \u200b\u4fbf\u200b\u53ef\u200b\u8ba1\u7b97\u200b1~t\u200b\u7684\u200b\u6ce8\u610f\u529b\u200b\u6743\u91cd\u200b\u5411\u91cf\u200b\uff0c\u200b\u65e0\u9700\u200b\u7f13\u5b58\u200b\u6216\u91cd\u200b\u8ba1\u7b97\u200b\u5386\u53f2\u200b\\(q^n_{\\lt t}\\)</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/kv_cache.html#flops","title":"FLOPs\u200b\u5206\u6790","text":"\u64cd\u4f5c\u200b\u9879\u200b w/o KV Cache w/ KV Cache \\(Q, K, V\\) \\(3*2*ld^2\\) \\(3*2*d^2\\) \\(QK^T\\) \\(2*l^2d\\) \\(2*ld\\) \\(score\\cdot V\\) \\(2*l^2d\\) \\(2*ld\\) \\(O\\) \\(2*ld^2\\) \\(2*d^2\\) Attention \\(l*(8d^2 + 4ld)\\) \\(8d^2 + 4ld\\) FFN \\(2*2*ldd_{ff}\\) \\(2*2*dd_{ff}\\) block \\(l*(24d^2 + 4ld)\\) \\(24d^2 + 4ld\\) <ul> <li>FLPOs\u200b\u77e9\u9635\u200b\u64cd\u4f5c\u200b\u5305\u62ec\u200bmultiply + add\u200b\u4e24\u200b\u90e8\u5206\u200b\uff0c\u200b\u56e0\u6b64\u200b\u9700\u8981\u200b\u4e58\u4ee5\u200b2</li> <li>\u200b\u901a\u5e38\u200b\u60c5\u51b5\u200b\u4e0b\u200b\\(d_{ff}=4d\\)</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/kv_cache.html#_2","title":"\u91cf\u5316","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/linear_attention.html","title":"Linear attention","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/linear_attention.html#fast-ar-transformers","title":"Fast AR Transformers","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/linear_attention.html#linformer","title":"Linformer","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/mqa.html","title":"Mqa","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/mqa.html#mqa","title":"MQA","text":"<p>\u200b\u8bba\u6587\u200b\uff1aMQA: Fast Transformer Decoding: One Write-Head is All You Need MQA\uff1aMulti-Query Attention Google Noam Shazeer 2019 Nov</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/mqa.html#_1","title":"\u5de5\u4f5c\u200b\u8981\u70b9","text":"<ol> <li>\u200b\u6240\u6709\u200b\u7684\u200bheads\u200b\u4f7f\u7528\u200b\u540c\u4e00\u4e2a\u200bK\u200b\u548c\u200bV\uff0c\u200b\u5373\u200b\u3010\\(h\\ \\text{Q} + 1\\ \\text{K} + 1\\ \\text{V}\\)\u3011</li> <li>\u200b\u662f\u200b\u4e00\u4e2a\u200b\u6027\u80fd\u200b\u4e0e\u200b\u6548\u679c\u200b\u7684\u200btrade-off\uff0c\u200b\u901a\u8fc7\u200b\u727a\u7272\u200b\u4e00\u70b9\u70b9\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\uff0c\u200b\u63d0\u5347\u200b\u901f\u5ea6\u200b\u7684\u200b\u540c\u65f6\u200b\u51cf\u5c11\u200bGPU\u200b\u4f7f\u7528\u91cf\u200b      </li> <li>\u200b\u52a0\u901f\u200b\u539f\u56e0\u200b<ul> <li> \u200b\u5c11\u200b\u4e86\u200b\\(h-1\\)\u200b\u6b21\u200bK\u3001V\u200b\u7ed3\u679c\u200b\u8ba1\u7b97\u200b\uff1b</li> <li> K\u3001V\u200b\u7f13\u5b58\u200b\u51cf\u5c11\u200b\uff0c\u200b\u4e3a\u200b\u66f4\u200b\u9ad8\u901f\u200bSRAM\u200b\u817e\u51fa\u200b\u4e86\u200b\u7a7a\u95f4\u200b\u7528\u4ee5\u200b\u52a0\u901f\u200b\u8ba1\u7b97\u200b\u3002</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/mqa.html#gqa","title":"GQA","text":"<p>\u200b\u8bba\u6587\u200b\uff1aGQA: training generalized multi-query transformer models from multi-head checkpoints GQA\uff1aGrouped-Query Attention Google Research 2023 May, EMNLP 2023</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/mqa.html#_2","title":"\u5de5\u4f5c\u200b\u8981\u70b9","text":"<ol> <li> <p>\\(\\frac{h}{g}\\)\u200b\u4e2a\u200bheads\u200b\u5171\u4eab\u200b\u4e00\u4e2a\u200bK\u200b\u548c\u200bV\uff0c\u200b\u5373\u200b\u3010\\(GQA_g=h\\ \\text{Q} + g\\ \\text{K} + g\\ \\text{V}\\)\u3011</p> <ul> <li>MHA\u200b\u4e0e\u200bMQA\u200b\u7684\u200btrade-off\u200b\u4ea7\u7269\u200b\uff0c\\(g=h\\)\u200b\u4e3a\u200bMHA\uff0c\\(g=1\\)\u200b\u4e3a\u200bMQA</li> <li>\u200b\u5982\u679c\u200b\u8981\u200b\u517c\u5bb9\u200bMHA\u200b\u6216\u200bMQA\uff0c\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u5404\u7ec4\u200bK,V\u200b\u6c42\u200b\u5e73\u5747\u200b\u6216\u200b\u590d\u5236\u200b\u7684\u200b\u65b9\u5f0f\u200b\u5feb\u901f\u200b\u5b9e\u73b0\u200b  </li> </ul> </li> <li> <p>\u200b\u662f\u200b\u4e00\u4e2a\u200b\u6027\u80fd\u200b\u4e0e\u200b\u6548\u679c\u200b\u7684\u200btrade-off\uff0c\u200b\u901a\u8fc7\u200b\u727a\u7272\u200b\u4e00\u70b9\u70b9\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\uff0c\u200b\u63d0\u5347\u200b\u901f\u5ea6\u200b\u7684\u200b\u540c\u65f6\u200b\u51cf\u5c11\u200bGPU\u200b\u4f7f\u7528\u91cf\u200b</p> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/nsa.html","title":"Nsa","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/nsa.html#nsa","title":"NSA","text":"<p>\u200b\u8bba\u6587\u200b\uff1aNative Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention DeepSeek-AI &amp; Peking University &amp; University of Washington, 2025 Feb, ACL 2025</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/nsa.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>\u200b\u672c\u8d28\u200b\u4e0a\u200b\u4e3a\u200bhierarchical attention</li> <li>NSA employs a dynamic hierarchical sparse strategy, combining coarse-grained token compression with fine-grained token selection to preserve both global context awareness and local precision</li> <li>attention computation with softmax architectures accounts for 70-80% of total latency when decoding 64k-length contexts, underscoring the urgent need for more efficient attention mechanisms</li> <li>Hardware-aligned inference speedup\uff1bTraining-aware algorithm design</li> <li>To achieve more effective and efficient sparse attention</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/vllm.html","title":"Vllm","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/vllm.html#vllm","title":"vLLM","text":"<p>\u200b\u8bba\u6587\u200b\uff1aEfficient Memory Management for Large Language Model Serving with PagedAttention vLLM: virtual Large Language Model inference engine Github\uff1avllm UC Berkeley &amp; Stanford University &amp; Independent Researcher &amp; UC San Diego 2023 Sep, SIGOPS 2023</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/vllm.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<p>vLLM\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5f00\u6e90\u200b\u7684\u200b\u63a8\u7406\u200b\u5f15\u64ce\u200b\uff0c\u200b\u4e13\u200b\u4e3a\u200bLLM\u200b\u7684\u200b\u63a8\u7406\u200b\u548c\u200b\u90e8\u7f72\u200b\u800c\u200b\u8bbe\u8ba1\u200b\uff0c\u200b\u6838\u5fc3\u200b\u7279\u6027\u200b\u5305\u62ec\u200b\u9ad8\u6548\u200b\u7684\u200b\u670d\u52a1\u200b\u541e\u5410\u91cf\u200b\u3001\u200b\u4f18\u5316\u200b\u7684\u200b\u5185\u5b58\u200b\u7ba1\u7406\u200b\u548c\u200b\u591a\u79cd\u200b\u89e3\u7801\u200b\u7b97\u6cd5\u200b\u652f\u6301\u200b\u3002</p> <ul> <li> \u200b\u89e3\u51b3\u200b\u5185\u5b58\u200b\u788e\u7247\u200b\u5316\u200b\u95ee\u9898\u200b</li> <li> \u200b\u5b9e\u73b0\u200b\u5e76\u884c\u200b\u91c7\u6837\u200b\u6216\u200bbeam search\u200b\u751f\u6210\u200b\u7684\u200b\u591a\u4e2a\u200b\u8f93\u51fa\u200b\u5e8f\u5217\u200b\u95f4\u200b\u90e8\u5206\u200bKV\u200b\u7f13\u5b58\u200b\u53ef\u80fd\u200b\u5171\u4eab\u200b</li> </ul> <p>https://blog.csdn.net/m0_59164520/article/details/141869967</p> <ul> <li>only 20.4% - 38.2% of the KV cache memory is used to store the actual token states in the existing systems.</li> <li>existing LLM serving systems fall short of managing the KV cache memory efficiently. This is mainly because they store the KV cache of a request in contiguous memory space</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/vllm.html#pagedattention","title":"PagedAttention","text":"<p>\u200b\u5c06\u200bKey/Value\u200b\u4ee5\u200bblock\u200b\u4e3a\u200b\u5355\u4f4d\u200b\u7f13\u5b58\u200b\u81f3\u975e\u200b\u8fde\u7eed\u200b\u5b58\u50a8\u7a7a\u95f4\u200b\u5185\u200b</p> <ul> <li>\u200b\u6bcf\u4e2a\u200bblock\u200b\u4e2d\u200b\u56fa\u5b9a\u200b\u5b58\u653e\u200b \\(B\\) \u200b\u4e2a\u200btoken\u200b\u5bf9\u5e94\u200b\u7684\u200bKey/Value\u200b\u5411\u91cf\u200b\uff0c\u200b\u6d6e\u70b9\u200b\u6570\u91cf\u200b\u4e3a\u200b<code>2*N*L*d</code></li> <li>i-th block\u200b\u7684\u200bKey\u200b\u5411\u91cf\u200b \\(K_i = \\left(k_{(i-1)B + 1}, \\dots, k_{iB}\\right)\\)\u3001Value\u200b\u5411\u91cf\u200b \\(V_i = \\left(v_{(i-1)B + 1}, \\dots, v_{iB}\\right)\\)</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/vllm.html#kv-cache-manager","title":"KV Cache Manager","text":"<ul> <li> <p>KV cache has unique characteristics: it dynamically grows and shrinks over time as the model generates new tokens, and its lifetime and length are not known a priori.</p> </li> <li> <p>PagedAttention divides the request\u2019s KV cache into blocks, each of which can contain the attention keys and values of a fixed number of tokens, the blocks for the KV cache are not necessarily stored in contiguous space(\u200b\u53d7\u200b\u542f\u53d1\u200b\u4e8e\u200bOS\u200b\u4e2d\u200b\u7684\u200b\u865a\u62df\u5185\u5b58\u200b)</p> </li> </ul> <ul> <li> <p>When managed inefficiently, this memory can be significantly wasted by fragmentation and redundant duplication, limiting the batch size.</p> </li> <li> <p>Moreover, physical memory space needs not to be fully reserved in advance, enabling the OS to dynamically allocate physical pages as needed</p> </li> <li>The last KV block\u2019s unfilled positions are reserved for future generations</li> <li>The KV block manager also maintains block tables\u2014the mapping between logical and physical KV blocks of each request. Each block table entry records the corresponding physical blocks of a logical block and the number of filled positions.</li> <li>Separating logical and physical KV blocks allows vLLM to dynamically grow the KV cache memory without reserving it for all positions in advance</li> <li>As all the blocks are filled from left to right and a new physical block is only allocated when all previous blocks are full, vLLM limits all the memory wastes for a request within one block, \u200b\u6700\u5dee\u200b(B-1)/B</li> </ul> <p>\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\u5c06\u200bKV cache\u200b\u7ec4\u7ec7\u200b\u4e3a\u200b\u56fa\u5b9a\u200b\u5927\u5c0f\u200b\u5757\u200b(block)\u200b\u4e2d\u200b\u7c7b\u4f3c\u200b\u865a\u62df\u5185\u5b58\u200b\u4e2d\u200b\u7684\u200b\"\u200b\u9875\u200b\"\u3002\u200b\u5173\u952e\u6280\u672f\u200b\u7279\u70b9\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li>\u200b\u975e\u200b\u8fde\u7eed\u200b\u5b58\u50a8\u200b\uff1a\u200b\u5141\u8bb8\u200b\u5c06\u200b\u8fde\u7eed\u200b\u7684\u200bK\u200b\u548c\u200bV\u200b\u5b58\u50a8\u200b\u5728\u200b\u4e0d\u200b\u8fde\u7eed\u200b\u7684\u200b\u7269\u7406\u200b\u5185\u5b58\u200b\u4e2d\u200b\uff08\u200b\u901a\u8fc7\u200b\u7ef4\u62a4\u200bblock table\u200b\u6620\u5c04\u200b\uff09\uff0c\u200b\u6bcf\u4e2a\u200bKV\u200b\u5757\u200b\u5305\u542b\u200b\u56fa\u5b9a\u200b\u6570\u91cf\u200btoken\u200b\u7684\u200bKV\u200b\u5411\u91cf\u200b  </li> <li>\u200b\u5757\u5f0f\u200b\u6ce8\u610f\u529b\u200b\u8ba1\u7b97\u200b\uff1a\u200b\u6ce8\u610f\u529b\u200b\u8ba1\u7b97\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u5bf9\u200b\u5757\u200b\u7684\u200b\u8ba1\u7b97\u200b\u5f62\u5f0f\u200b\uff0cPagedAttention\u200b\u5185\u6838\u200b\u80fd\u591f\u200b\u5206\u522b\u200b\u8bc6\u522b\u200b\u548c\u200b\u83b7\u53d6\u200b\u4e0d\u540c\u200bKV\u200b\u5757\u200b\u8fdb\u884c\u200b\u8ba1\u7b97\u200b  </li> <li>\u200b\u7075\u6d3b\u200b\u7684\u200b\u5185\u5b58\u200b\u7ba1\u7406\u200b\uff1a\u200b\u53ef\u200b\u5c06\u200b\u5757\u200b\u89c6\u4e3a\u200b\u9875\u200b\u3001token\u200b\u89c6\u4e3a\u200b\u5b57\u8282\u200b\u3001\u200b\u8bf7\u6c42\u200b\u89c6\u4e3a\u200b\u8fdb\u7a0b\u200b\uff0c\u200b\u5b9e\u73b0\u200b\u7c7b\u4f3c\u200b\u64cd\u4f5c\u7cfb\u7edf\u200b\u7684\u200b\u5185\u5b58\u200b\u7ba1\u7406\u200b</li> </ol>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/vllm.html#_2","title":"\u5185\u5b58\u200b\u5171\u4eab","text":"<ol> <li>prompt\u200b\u90e8\u5206\u200bKV cache\u200b\u5171\u4eab\u200b  </li> <li>\u200b\u5176\u4f59\u200b\u975e\u200b\u76f8\u5173\u200b\u90e8\u5206\u200b\u72ec\u7acb\u200b\u5b58\u50a8\u200b</li> </ol>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/vllm.html#muitiple-decoding-scenarios","title":"Muitiple Decoding Scenarios","text":"<ol> <li> <p>Parallel sampling, one-prompt, multiple-response, share the same input prompt KV cache</p> <ul> <li>prompt\u200b\u5171\u4eab\u200b\uff08\u200b\u4e0b\u200b\u91c7\u6837\u200bblock\u200b\u4e3a\u200b\u5355\u4f4d\u200b\uff09</li> <li>\u200b\u5bf9\u4e8e\u200bnon-full last block\uff0c\u200b\u5728\u200bgeneration\u200b\u6b65\u9aa4\u200b\u4e2d\u200b\uff0c\u200b\u5f53\u200b\u53d1\u73b0\u200blast prompt block reference count &gt; 1\u200b\u65f6\u200b\uff0c\u200b\u590d\u5236\u200blast block\u200b\u5185\u5bb9\u200b\u81f3\u200b\u65b0\u200bphysical block\u200b\u8fdb\u884c\u200b\u5b58\u50a8\u200b\uff0c\u200b\u5e76\u200b\u5c06\u200blast prompt block reference count -=1, \u200b\u8be5\u200b\u65b9\u6cd5\u200b\u53eb\u505a\u200bcopy-on-write</li> </ul> <p></p> <p></p> </li> <li> <p>Beam search, not only share the initial prompt blocks but also other blocks across different candidates, and the sharing patterns dynamically change as the decoding process advances</p> <ul> <li>\u200b\u6bcf\u200b\u4e00\u6b65\u200b\u4ece\u200bk*k\u200b\u4e2a\u200bcondidate\u200b\u4e2d\u200b\u9009\u62e9\u200btop-k\u200b\u4e2a\u200b\u5e8f\u5217\u200b\uff0c\u200b\u5bf9\u4e8e\u200bcurrent-block reference count=0\uff0c\u200b\u91ca\u653e\u200b\u5f53\u524d\u200b\u7a7a\u95f4\u200b</li> <li>\u200b\u4ee5\u200bblock\u200b\u4e3a\u200b\u5355\u4f4d\u200b\u5171\u4eab\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u4ee5\u200btoken\u200b\u4e3a\u200b\u5355\u4f4d\u200b</li> </ul> <p></p> <p></p> </li> <li> <p>Shared prefix, description of the task including instructions and example inputs and outputs, also known as system prompt</p> <p></p> <p></p> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Attention_Speedup/vllm.html#scheduling-and-preemption","title":"Scheduling and Preemption","text":"<ul> <li>first-come-first-serve (FCFS) scheduling policy for all requests, ensuring fairness and preventing starvation</li> <li>block eviction policy: <ul> <li>Since in our case we know that all blocks of a sequence are accessed together, we implement an all-or-nothing eviction policy, i.e., either evict all or none of the blocks of a sequence.</li> <li>Furthermore, multiple sequences within one request (e.g., beam candidates in one beam search request) are gang-scheduled as a sequence group.</li> </ul> </li> <li> <p>evicted block recover policy: </p> <ul> <li>Swapping. GPU \u27f7 CPU \u27f7 Disk</li> <li>Recomputation. drop + recompute(\u200b\u7531\u4e8e\u200b\u5386\u53f2\u200btoken\u200b\u5df2\u200b\u786e\u5b9a\u200b\uff0c\u200b\u6bd4\u200bcausal\u200b\u89e3\u7801\u200b\u901f\u5ea6\u200b\u5feb\u5f97\u591a\u200b\uff0c\u200b\u5355\u6b21\u200b\u5c31\u200b\u5b8c\u6210\u200b\u91cd\u200b\u8ba1\u7b97\u200b)</li> </ul> <p></p> <p></p> </li> </ul>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/context_parallelism.html","title":"Context parallelism","text":"<p>attention\u200b\u8ba1\u7b97\u200b\u590d\u6742\u5ea6\u200b\u4e0e\u200bseq_len\u200b\u5e73\u65b9\u200b\u6210\u6b63\u6bd4\u200b\uff0c\u200b\u76f4\u63a5\u200b\u8d85\u957f\u200b\u8bad\u7ec3\u200bcontext window\u200b\u538b\u529b\u200b\u8fc7\u5927\u200b\uff0c\u200b\u53ef\u200b\u901a\u8fc7\u200bcontext parallelism\u200b\u63d0\u5347\u200b\u8ba1\u7b97\u200b\u6027\u80fd\u200b</p> <ol> <li> <p>CP\uff1a\u200b\u8ba1\u7b97\u200b\u6d41\u7a0b\u56fe\u200b     </p> <p>CP communication pipeline. (AG: all gather; RS: reduce scatter)</p> <p></p> </li> <li> <p>ring CP\uff1akey-value blocks traverse through a ring of hosts\u200b\u793a\u610f\u56fe\u200b</p> </li> </ol> <p>P2P\u200b\u53ea\u200b\u4f20\u9012\u200bK,V\uff08\u200b\u4e00\u822c\u200b\u642d\u914d\u200bGQA\u200b\u4e00\u8d77\u200b\u4f7f\u7528\u200b\uff0c\u200b\u6b64\u65f6\u200b$\\#K,\\#V \\ll \\#Q$\uff09\u200b\u7ed9\u200b\u4e34\u8fd1\u200b\u7684\u200b\u4e0b\u200b\u4e00\u5f20\u200bGPU</p> <ol> <li>ring CP\uff1aring attention calculation\u200b\u793a\u610f\u56fe\u200b</li> </ol> <p>ring attention calculation</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/data_parallelism.html","title":"Data parallelism","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/data_parallelism.html#dp","title":"DP","text":"<p>https://www.cnblogs.com/gzyatcnblogs/articles/17946484#dataparallel</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/data_parallelism.html#dp_1","title":"DP","text":"<ul> <li>https://www.cnblogs.com/CircleWang/p/15620825.html</li> <li> <p>https://www.cnblogs.com/gzyatcnblogs/articles/17946484#dataparallel</p> </li> <li> <p>\u200b\u5c06\u200b\u6a21\u578b\u200b\u590d\u5236\u5230\u200b\u5404\u4e2a\u200bGPU\u200b\u4e2d\u200b\uff0c\u200b\u5e76\u200b\u5c06\u200b\u4e00\u4e2a\u200bbatch\u200b\u7684\u200b\u6570\u636e\u200b\u5212\u5206\u200b\u4e3a\u200b\u591a\u4e2a\u200bmini_batch\u200b\u5e76\u5206\u200b\u53d1\u7ed9\u200b\u591a\u4e2a\u200bGPU</p> </li> <li>\u200b\u5404\u4e2a\u200bGPU\u200b\u72ec\u81ea\u200b\u5b8c\u6210\u200bmini_batch\u200b\u7684\u200bforward\uff0c\u200b\u5e76\u200b\u628a\u200b\u83b7\u5f97\u200b\u7684\u200boutput\u200b\u4f20\u9012\u200b\u7ed9\u200bGPU_0\uff08\u200b\u4e3b\u200bGPU\uff09</li> <li>GPU_0\u200b\u6574\u5408\u200b\u5404\u4e2a\u200bGPU\u200b\u4f20\u9012\u200b\u8fc7\u6765\u200b\u7684\u200boutput\uff0c\u200b\u5e76\u200b\u8ba1\u7b97\u200bloss\uff08\u200b\u6b64\u65f6\u200bGPU_0\u200b\u53ef\u4ee5\u200b\u5bf9\u200b\u6240\u6709\u200bloss\u200b\u8fdb\u884c\u200b\u4e00\u4e9b\u200b\u805a\u5408\u200b\u64cd\u4f5c\u200b\uff09</li> <li>GPU_0\u200b\u5f52\u5e76\u200bloss\u200b\u540e\u200b\uff0c\u200b\u8fdb\u884c\u200bbackward\u200b\u4ee5\u53ca\u200b\u68af\u5ea6\u200b\u4e0b\u964d\u200b\u540e\u200b\u5b8c\u6210\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u66f4\u65b0\u200b\uff0c\u200b\u968f\u540e\u200b\u5c06\u200b\u66f4\u65b0\u200b\u540e\u200b\u6a21\u578b\u200b\u4f20\u9012\u200b\u7ed9\u200b\u5176\u5b83\u200bGPU</li> </ul> <p>\u200b\u4ee5\u4e0a\u200b\u5c31\u662f\u200bDP\u200b\u6a21\u5f0f\u200b\u4e0b\u591a\u5361\u200bGPU\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u7684\u200b\u65b9\u5f0f\u200b\u3002\u200b\u5176\u5b9e\u200b\u53ef\u4ee5\u200b\u770b\u5230\u200bGPU_0\u200b\u4e0d\u4ec5\u200b\u627f\u62c5\u200b\u4e86\u200b\u524d\u200b\u5411\u200b\u4f20\u64ad\u200b\u7684\u200b\u4efb\u52a1\u200b\uff0c\u200b\u8fd8\u200b\u627f\u62c5\u200b\u4e86\u200b\u6536\u96c6\u200bloss\uff0c\u200b\u5e76\u200b\u8fdb\u884c\u200b\u68af\u5ea6\u200b\u4e0b\u964d\u200b\u3002\u200b\u56e0\u6b64\u200b\u5728\u200b\u4f7f\u7528\u200bDP\u200b\u6a21\u5f0f\u200b\u8fdb\u884c\u200b\u5355\u673a\u200b\u591a\u5361\u200bGPU\u200b\u8bad\u7ec3\u200b\u7684\u200b\u65f6\u5019\u200b\u4f1a\u200b\u6709\u200b\u4e00\u5f20\u200b\u5361\u200b\u7684\u200b\u663e\u5b58\u200b\u5229\u7528\u200b\u4f1a\u200b\u6bd4\u200b\u5176\u4ed6\u200b\u5361\u200b\u66f4\u200b\u591a\u200b\uff0c\u200b\u90a3\u200b\u5c31\u662f\u200b\u4f60\u200b\u8bbe\u7f6e\u200b\u7684\u200bGPU_0\u3002 \u200b\u91c7\u7528\u200b\u4e86\u200bGPU_0\u200b\u4f5c\u4e3a\u200b\u4e3b\u200bGPU\u200b\u8d1f\u8d23\u200b\u68af\u5ea6\u200b\u805a\u5408\u200b\u548c\u200b\u53c2\u6570\u200b\u66f4\u65b0\u200b \u200b\u6bcf\u5f20\u200bGPU\u200b\u90fd\u200b\u4fdd\u7559\u200b\u4e86\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u526f\u672c\u200b</p> <pre><code>import torch.nn as nn\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = '2,3,1' # GPU_0\u200b\u4e3a\u200b\u5361\u200b2\uff0cGPU_1\u200b\u4e3a\u200b\u5361\u200b3\uff0cGPU_3\u200b\u4e3a\u200b\u5361\u200b1\ndevice_ids = [0, 1, 2]\n\nmodel = nn.DataParallel(model, device_ids=device_ids)\nmodel = nn.DataParallel(model)               # \u200b\u5728\u200b\u6267\u884c\u200b\u8be5\u200b\u8bed\u53e5\u200b\u4e4b\u524d\u200b\u6700\u597d\u200b\u52a0\u4e0a\u200bmodel.cuda(),\u200b\u4fdd\u8bc1\u200b\u6a21\u578b\u200b\u5b58\u5728\u200bGPU\u200b\u4e0a\u200b\n                                             # \u200b\u5185\u90e8\u200bbatch\u200b\u7684\u200b\u62c6\u5206\u200b\u88ab\u200b\u5c01\u88c5\u200b\u5728\u200b\u4e86\u200bDataParallel\u200b\u6a21\u5757\u200b\u4e2d\u200b\n</code></pre> <p>\u200b\u7531\u4e8e\u200b\u6211\u4eec\u200b\u7684\u200bmodel\u200b\u88ab\u200b<code>nn.DataParallel()</code>\u200b\u5305\u88f9\u200b\u4f4f\u200b\u4e86\u200b\uff0c\u200b\u6240\u4ee5\u200b\u5982\u679c\u200b\u60f3\u8981\u200b\u50a8\u5b58\u200b\u6a21\u578b\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c\u200b\u9700\u8981\u200b\u4f7f\u7528\u200bmodel.module.state_dict()\u200b\u7684\u200b\u65b9\u5f0f\u200b\u624d\u80fd\u200b\u53d6\u51fa\u200b\uff0c\u200b\u4e0d\u80fd\u200b\u76f4\u63a5\u200b\u662f\u200bmodel.state_dict()  </p> <p>\u200b\u53ea\u6709\u200b\u4e00\u4e2a\u200b\u4e3b\u200b\u8fdb\u7a0b\u200b\uff0c\u200b\u4e3b\u200b\u8fdb\u7a0b\u200b\u4e0b\u200b\u6709\u200b\u591a\u4e2a\u200b\u7ebf\u7a0b\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u7ebf\u7a0b\u200b\u7ba1\u7406\u200b\u4e00\u4e2a\u200bdevice\u200b\u7684\u200b\u8bad\u7ec3\u200b\u3002\u200b\u56e0\u6b64\u200bDP\u200b\u5185\u5b58\u200b\u4e2d\u200b\u53ea\u200b\u5b58\u5728\u200b\u4e00\u4efd\u200b\u6570\u636e\u200b\uff0c\u200b\u5404\u4e2a\u200b\u7ebf\u7a0b\u200b\u95f4\u200b\u5171\u4eab\u200b\u8be5\u200b\u6570\u636e\u200b\u3002  </p> <p>\u200b\u4ec5\u9650\u200b\u5355\u673a\u200b\u591a\u5361\u200b</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/data_parallelism.html#ddp","title":"DDP","text":"<p>\u200b\u5206\u5e03\u5f0f\u200b\u6570\u636e\u200b\u5e76\u884c\u200bDistributed Data Pparallelism\uff0c\u200b\u591a\u4e2a\u200b\u8fdb\u7a0b\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u8fdb\u7a0b\u200b\u4f1a\u200b\u72ec\u7acb\u200b\u52a0\u8f7d\u200b\u5b8c\u6574\u200b\u7684\u200b\u6570\u636e\u200b\u5e76\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b</p> <ul> <li>all reduce\u200b\u548c\u200ball gather\u200b\u8fdb\u884c\u200b\u6570\u636e\u200b\u4ea4\u4e92\u200b</li> <li>\u200b\u652f\u6301\u200b\u8de8\u200b\u673a\u5668\u200b</li> </ul> <pre><code>import argparse\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.distributed as dist\nfrom torch.nn.parallel import DistributedDataParallel as DDP\n\n\n# 1. \u200b\u57fa\u7840\u200b\u6a21\u5757\u200b ### \nclass SimpleModel(nn.Module):\n    def __init__(self, input_dim):\n        super(SimpleModel, self).__init__()\n        self.fc = nn.Linear(input_dim, 1)\n        cnt = torch.tensor(0)\n        self.register_buffer('cnt', cnt)\n\n    def forward(self, x):\n        self.cnt += 1\n        # print(\"In forward: \", self.cnt, \"Rank: \", self.fc.weight.device)\n        return torch.sigmoid(self.fc(x))\n\nclass SimpleDataset(Dataset):\n    def __init__(self, data, target):\n        self.data = data\n        self.target = target\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx], self.target[idx]\n\n# 2. \u200b\u521d\u59cb\u5316\u200b\u6211\u4eec\u200b\u7684\u200b\u6a21\u578b\u200b\u3001\u200b\u6570\u636e\u200b\u3001\u200b\u5404\u79cd\u200b\u914d\u7f6e\u200b  ####\n## DDP\uff1a\u200b\u4ece\u200b\u5916\u90e8\u200b\u5f97\u5230\u200blocal_rank\u200b\u53c2\u6570\u200b\u3002\u200b\u4ece\u200b\u5916\u9762\u200b\u5f97\u5230\u200blocal_rank\u200b\u53c2\u6570\u200b\uff0c\u200b\u5728\u200b\u8c03\u7528\u200bDDP\u200b\u7684\u200b\u65f6\u5019\u200b\uff0c\u200b\u5176\u4f1a\u200b\u81ea\u52a8\u200b\u7ed9\u51fa\u200b\u8fd9\u4e2a\u200b\u53c2\u6570\u200b\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--local_rank\", default=-1, type=int)\nFLAGS = parser.parse_args()\nlocal_rank = FLAGS.local_rank\n\n## DDP\uff1aDDP backend \u200b\u901a\u4fe1\u200b\u540e\u200b\u7aef\u200b\u521d\u59cb\u5316\u200b\ntorch.cuda.set_device(local_rank)\ndist.init_process_group(backend='nccl')\n\n## \u200b\u5047\u8bbe\u200b\u6211\u4eec\u200b\u6709\u200b\u4e00\u4e9b\u200b\u6570\u636e\u200b\nn_sample = 100\nn_dim = 10\nbatch_size = 25\nX = torch.randn(n_sample, n_dim)  # 100\u200b\u4e2a\u200b\u6837\u672c\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u6837\u672c\u200b\u6709\u200b10\u200b\u4e2a\u200b\u7279\u5f81\u200b\nY = torch.randint(0, 2, (n_sample, )).float()\n\ndataset = SimpleDataset(X, Y)\nsampler = torch.utils.data.distributed.DistributedSampler(dataset)\ndata_loader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n\n## \u200b\u6784\u9020\u200b\u6a21\u578b\u200b\nmodel = SimpleModel(n_dim).to(local_rank)\n## DDP: Load\u200b\u6a21\u578b\u200b\u8981\u200b\u5728\u200b\u6784\u9020\u200bDDP\u200b\u6a21\u578b\u200b\u4e4b\u524d\u200b\uff0c\u200b\u4e14\u200b\u53ea\u200b\u9700\u8981\u200b\u5728\u200bmaster\u200b\u4e0a\u200b\u52a0\u8f7d\u200b\u5c31\u884c\u4e86\u200b\u3002\nckpt_path = None\nif dist.get_rank() == 0 and ckpt_path is not None:\n    model.load_state_dict(torch.load(ckpt_path))\n\n## DDP: \u200b\u6784\u9020\u200bDDP model \u2014\u2014\u2014\u2014\u2014\u2014 \u200b\u5fc5\u987b\u200b\u5728\u200b init_process_group \u200b\u4e4b\u540e\u200b\u624d\u200b\u53ef\u4ee5\u200b\u8c03\u7528\u200b DDP\nmodel = DDP(model, device_ids=[local_rank], output_device=local_rank)\n\n## DDP: \u200b\u8981\u200b\u5728\u200b\u6784\u9020\u200bDDP model\u200b\u4e4b\u540e\u200b\uff0c\u200b\u624d\u80fd\u200b\u7528\u200bmodel\u200b\u521d\u59cb\u5316\u200boptimizer\u3002\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001)\nloss_func = nn.BCELoss().to(local_rank)\n\n# 3. \u200b\u7f51\u7edc\u200b\u8bad\u7ec3\u200b  ###\nmodel.train()\nnum_epoch = 100\niterator = tqdm(range(100))\nfor epoch in iterator:\n    # DDP\uff1a\u200b\u8bbe\u7f6e\u200bsampler\u200b\u7684\u200bepoch\uff0c\n    # DistributedSampler\u200b\u9700\u8981\u200b\u8fd9\u4e2a\u200b\u6765\u200b\u6307\u5b9a\u200bshuffle\u200b\u65b9\u5f0f\u200b\uff0c\n    # \u200b\u901a\u8fc7\u200b\u7ef4\u6301\u200b\u5404\u4e2a\u200b\u8fdb\u7a0b\u200b\u4e4b\u95f4\u200b\u7684\u200b\u76f8\u540c\u200b\u968f\u673a\u6570\u200b\u79cd\u5b50\u200b\u4f7f\u200b\u4e0d\u540c\u200b\u8fdb\u7a0b\u200b\u80fd\u200b\u83b7\u5f97\u200b\u540c\u6837\u200b\u7684\u200bshuffle\u200b\u6548\u679c\u200b\u3002\n    data_loader.sampler.set_epoch(epoch)\n    # \u200b\u540e\u9762\u200b\u8fd9\u90e8\u5206\u200b\uff0c\u200b\u5219\u200b\u4e0e\u200b\u539f\u6765\u200b\u5b8c\u5168\u4e00\u81f4\u200b\u4e86\u200b\u3002\n    for data, label in data_loader:\n        data, label = data.to(local_rank), label.to(local_rank)\n        optimizer.zero_grad()\n        prediction = model(data)\n        loss = loss_func(prediction, label.unsqueeze(1))\n        loss.backward()\n        iterator.desc = \"loss = %0.3f\" % loss\n        optimizer.step()\n\n    # DDP:\n    # 1. save\u200b\u6a21\u578b\u200b\u7684\u200b\u65f6\u5019\u200b\uff0c\u200b\u548c\u200bDP\u200b\u6a21\u5f0f\u200b\u4e00\u6837\u200b\uff0c\u200b\u6709\u200b\u4e00\u4e2a\u200b\u9700\u8981\u200b\u6ce8\u610f\u200b\u7684\u200b\u70b9\u200b\uff1a\u200b\u4fdd\u5b58\u200b\u7684\u200b\u662f\u200bmodel.module\u200b\u800c\u200b\u4e0d\u662f\u200bmodel\u3002\n    #    \u200b\u56e0\u4e3a\u200bmodel\u200b\u5176\u5b9e\u200b\u662f\u200bDDP model\uff0c\u200b\u53c2\u6570\u200b\u662f\u200b\u88ab\u200b`model=DDP(model)`\u200b\u5305\u200b\u8d77\u6765\u200b\u7684\u200b\u3002\n    # 2. \u200b\u53ea\u200b\u9700\u8981\u200b\u5728\u200b\u8fdb\u7a0b\u200b0\u200b\u4e0a\u200b\u4fdd\u5b58\u200b\u4e00\u6b21\u200b\u5c31\u884c\u4e86\u200b\uff0c\u200b\u907f\u514d\u200b\u591a\u6b21\u200b\u4fdd\u5b58\u200b\u91cd\u590d\u200b\u7684\u200b\u4e1c\u897f\u200b\u3002\n    if dist.get_rank() == 0 and epoch == num_epoch - 1:\n        torch.save(model.module.state_dict(), \"%d.ckpt\" % epoch)\n</code></pre>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/data_parallelism.html#fsdp","title":"FSDP","text":"<p>Fully Sharded Data Parallel\uff0c\u200b\u5168\u200b\u5207\u7247\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\uff0c\u200b\u7ed3\u5408\u200b\u4e86\u200bZeRO\u200b\u601d\u8def\u200b\u8fdb\u884c\u200b\u4e86\u200b\u53c2\u6570\u200b\u3001\u200b\u68af\u5ea6\u200b\u548c\u200b\u4f18\u5316\u200b\u671f\u200b\u72b6\u6001\u200b\u5206\u7247\u200b</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/distbelief.html","title":"Distbelief","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/distbelief.html#distbelief","title":"DistBelief","text":"<p>\u200b\u8bba\u6587\u200b\uff1aLarge Scale Distributed Deep Networks Google Inc, NISP 2012</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/distbelief.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/distbelief.html#model-parallelism","title":"Model Parallelism","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/gpipe.html","title":"Gpipe","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/gpipe.html#gpipe","title":"GPipe","text":"<p>\u200b\u8bba\u6587\u200b\uff1aGPipe: Easy Scaling with Micro-Batch Pipeline Parallelism \u200b\u4ee3\u7801\u200b\uff1agpipe.py Google, 2018 Nov, NeurIPS 2019</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/gpipe.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/model_parallelism.html","title":"Model parallelism","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/model_parallelism.html#mp","title":"MP","text":"<p>intra-layer model parallel</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/model_parallelism.html#tp","title":"TP","text":"<ul> <li>Distributed Tensor Model Parallelism</li> <li>more general distributed tensor computation</li> </ul> <p>\u200b\u5f20\u91cf\u200b\u5e76\u884c\u200bTensor Parallel\u200b\u5c06\u200b\u5927\u578b\u200b\u5f20\u91cf\u200b\u64cd\u4f5c\u200b\uff08\u200b\u5982\u200b\u77e9\u9635\u200b\u4e58\u6cd5\u200b\uff09\u200b\u62c6\u5206\u200b\u5230\u200b\u591a\u4e2a\u200b\u8ba1\u7b97\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u6267\u884c\u200b\uff0c\u200b\u4f7f\u5f97\u200b\u5355\u4e2a\u200b\u8bbe\u5907\u200b\u53ea\u200b\u9700\u200b\u5904\u7406\u200b\u5f20\u91cf\u200b\u7684\u200b\u4e00\u4e2a\u200b\u5b50\u96c6\u200b\uff0c\u200b\u4ece\u800c\u200b\u89e3\u51b3\u200b\u5927\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u4e2d\u200b\u7684\u200b\u5185\u5b58\u200b\u548c\u200b\u8ba1\u7b97\u200b\u74f6\u9888\u200b\u95ee\u9898\u200b\u3002</p> <ol> <li>Row-wise Parallelism\uff0c<code>A=[A1; A2], AB=[A1B; A2B]</code></li> <li>Column-wise Parallelism\uff0c<code>B=[B1, B2], AB=[AB1, AB2]</code></li> <li>all parallelism, <code>A=[A1; A2], B=[B1, B2], AB=[A1B1, A1B2; A2B1, A2B2]</code></li> </ol>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/model_parallelism.html#sp","title":"SP","text":"<p> sequence parallel\uff0c\u200b\u5c06\u200b\u5e8f\u5217\u200b\u5747\u200b\u5206\u4e3a\u200bk\u200b\u6bb5\u200b\u5206\u914d\u200b\u81f3\u200bk\u200b\u4e2a\u200bworker\uff0c\u200b\u6bcf\u200b\u6bb5\u957f\u5ea6\u200b\u4e3a\u200bn/k\uff0c\u200b\u53ea\u200b\u6cbf\u7740\u200b\u5e8f\u5217\u200b\u7ef4\u5ea6\u200b\u5212\u5206\u200b\u6fc0\u6d3b\u200b\u503c\u200b\uff0c\u200b\u5982\u200bLN\u200b\u548c\u200bdropout</p> <ul> <li>\u200b\u91cd\u53e0\u200b\u5207\u5206\u200b\uff08\u200b\u53ef\u200b\u9009\u200b\uff09\uff1a\u200b\u4e3a\u200b\u4fdd\u6301\u200b\u5c40\u90e8\u200b\u4e0a\u4e0b\u6587\u200b\u8fde\u7eed\u6027\u200b\uff0c\u200b\u5b50\u200b\u5e8f\u5217\u200b\u95f4\u200b\u53ef\u200b\u91cd\u53e0\u200b\u5c11\u91cf\u200bTokens\uff08\u200b\u5982\u200b\u6ed1\u52a8\u200b\u7a97\u53e3\u200b\uff09\u3002</li> <li>\u200b\u8d1f\u8f7d\u200b\u5747\u8861\u200b\uff1a\u200b\u82e5\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b\u4e0d\u5747\u200b\uff08\u200b\u5982\u53d8\u957f\u200b\u8f93\u5165\u200b\uff09\uff0c\u200b\u9700\u200b\u52a8\u6001\u200b\u8c03\u5ea6\u200b\u3002</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/model_parallelism.html#cp","title":"CP","text":"<p>context parallel\uff0c\u200b\u589e\u5f3a\u7248\u200bsp\uff0c\u200b\u6cbf\u200b\u6240\u6709\u200b\u5c42\u200b\u7684\u200b\u8f93\u5165\u200b\u5f20\u91cf\u200b\u8fdb\u884c\u200b\u5212\u5206\u200b\uff0c\u200b\u5305\u62ec\u200b\u8f93\u5165\u200b\u548c\u200b\u6fc0\u6d3b\u200b\u503c\u200b - context parallelism - attention \u200b\u77e9\u9635\u200b\u8ba1\u7b97\u200b\\(QK^TV\\)\uff1aall_gather\u200b\u83b7\u53d6\u200bV - attention softmax\uff1aall_reduce\u200b\u540c\u6b65\u200b\u5206\u6bcd\u200b - FFN\u200b\u72ec\u7acb\u200b\u8ba1\u7b97\u200b - LN\uff1aall_recue\u200b\u540c\u6b65\u200b\u5747\u503c\u200b\u4e0e\u200b\u65b9\u5dee\u200b</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/parallelism.html","title":"Parallelism","text":"<ul> <li>https://zhuanlan.zhihu.com/p/368828844</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/parallelism.html#_1","title":"\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u67b6\u6784","text":"<p>\u200b\u5206\u5e03\u5f0f\u8ba1\u7b97\u200b\u4e2d\u200b\u7684\u200b\u5173\u952e\u200b\u96c6\u4f53\u200b\u901a\u4fe1\u200b\uff08Collective Communication\uff09\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u7528\u4e8e\u200b\u5728\u200b\u591a\u4e2a\u200b\u8ba1\u7b97\u200b\u8282\u70b9\u200b/\u200b\u8bbe\u5907\u200b\u95f4\u200b\u540c\u6b65\u200b\u6570\u636e\u200b</p> <ul> <li>All-Reduce\uff08\u200b\u5168\u200b\u89c4\u7ea6\u200b\uff09\uff1a\u200b\u5c06\u200b\u591a\u4e2a\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u7684\u200b\u6570\u636e\u200b\u901a\u8fc7\u200b\u67d0\u79cd\u200b\u64cd\u4f5c\u200b\u805a\u5408\u200b\uff08\u200b\u5982\u200b\u6c42\u548c\u200breduce_sum\u3001\u200b\u6c42\u200bloss\u200b\u5e73\u5747\u200breduce_mean\u200b\u7b49\u200b\uff09\uff0c\u200b\u5e76\u200b\u5c06\u200b\u7ed3\u679c\u200b\u5206\u53d1\u200b\u5230\u200b\u6240\u6709\u200b\u8bbe\u5907\u200b</li> <li>All-Gather\uff08\u200b\u5168\u200b\u6536\u96c6\u200b\uff09\uff1a\u200b\u6bcf\u4e2a\u200b\u8bbe\u5907\u200b\u63d0\u4f9b\u200b\u4e00\u90e8\u5206\u200b\u6570\u636e\u200b\uff0c\u200b\u6700\u7ec8\u200b\u6240\u6709\u200b\u8bbe\u5907\u200b\u83b7\u5f97\u200b\u6240\u6709\u200b\u6570\u636e\u200b\u7684\u200b\u5b8c\u6574\u200b\u62fc\u63a5\u200b\u96c6\u5408\u200b\uff08\u200b\u5982\u200bconcat\u200b\u7b49\u200b\uff09</li> <li> <p>Reduce-Scatter\uff08\u200b\u5206\u6563\u200b\u6536\u96c6\u200b\uff09\uff1a\u200b\u6bcf\u4e2a\u200b\u8bbe\u5907\u200b\u63d0\u4f9b\u200b\u4e00\u90e8\u5206\u200b\u6570\u636e\u200b\u8fdb\u884c\u200b\u89c4\u7ea6\u200b\uff0c\u200b\u968f\u540e\u200b\u5c06\u200b\u89c4\u7ea6\u200b\u7ed3\u679c\u200b\u5206\u7247\u200b\u5206\u53d1\u200b\u5230\u200b\u5404\u4e2a\u200b\u8bbe\u5907\u200b\uff08\u200b\u5373\u200b\u6240\u6709\u200b\u8bbe\u5907\u200b\u7684\u200b\u7ed3\u679c\u200bconcat\u200b\u5373\u200b\u4e3a\u200ball-reduce, Reduce-Scatter + All-Gather = All-Reduce\uff09</p> </li> <li> <p>NCCL\uff0c\u200b\u7535\u8bdd\u200b\u7f51\u7edc\u200b</p> </li> <li>Gloo\uff0c\u200b\u7535\u5b50\u90ae\u4ef6\u200b</li> <li>MPI\uff0c\u200b\u53ca\u65f6\u200b\u901a\u4fe1\u8f6f\u4ef6\u200b</li> </ul> <p>\u200b\u89c1\u200b\u8bba\u6587\u200bCollective Communication\uff0cAccurate, Large Minibatch SGD: Training ImageNet in 1 Hour</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/parallelism.html#_2","title":"\u53c2\u6570\u200b\u66f4\u65b0\u200b\u7b56\u7565","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/parallelism.html#bsp","title":"BSP","text":"<p>Bulk\u200b\u540c\u6b65\u200b\u5e76\u884c\u200bBulk Synchronous Parallel\u200b\u662f\u200b\u4e00\u79cd\u200b\u7ecf\u5178\u200b\u7684\u200b\u5e76\u884c\u200b\u673a\u5236\u200b\uff0c\u200b\u6539\u200b\u6a21\u578b\u200b\u5c06\u200b\u8ba1\u7b97\u200b\u5212\u5206\u200b\u4e3a\u200b\u591a\u4e2a\u200b\u8d85\u6b65\u200b\uff08Supersteps\uff09\uff0c\u200b\u6bcf\u4e2a\u200b\u8d85\u6b65\u200b\u5305\u542b\u200b\u4e09\u4e2a\u200b\u9636\u6bb5\u200b</p> <ol> <li>\u200b\u672c\u5730\u200b\u8ba1\u7b97\u200b\uff08Computation\uff09\uff1a\u200b\u6240\u6709\u200bmachine\u200b\u5e76\u884c\u6267\u884c\u200b\u672c\u5730\u200b\u8ba1\u7b97\u200b</li> <li>\u200b\u5168\u5c40\u200b\u901a\u4fe1\u200b\uff08Communication\uff09\uff1amachine\u200b\u95f4\u200b\u4ea4\u4e92\u200b\u6570\u636e\u200b\uff08\u200b\u5982\u200b\u68af\u5ea6\u200b\u540c\u6b65\u200b\uff09</li> <li>\u200b\u540c\u6b65\u200b\u5c4f\u969c\u200b\uff08Barrier Synchronization\uff09\uff1a\u200b\u6240\u6709\u200b\u7684\u200bmachine\u200b\u7b49\u5f85\u200b\u901a\u4fe1\u200b\u5b8c\u6210\u200b\uff0c\u200b\u786e\u4fdd\u200b\u4e00\u81f4\u6027\u200b</li> </ol> <p>\u200b\u5173\u952e\u200b\u7279\u70b9\u200b\uff1a\"\u200b\u8ba1\u7b97\u200b-\u200b\u901a\u4fe1\u200b-\u200b\u540c\u6b65\u200b\" \u200b\u7684\u200b\u4e25\u683c\u200b\u4ea4\u66ff\u200b\u6267\u884c\u200b\uff0c\u200b\u786e\u4fdd\u200b\u6240\u6709\u200bmachine\u200b\u6b65\u8c03\u4e00\u81f4\u200b\u3002\u200b\u56e0\u6b64\u200b\u8d85\u6b65\u200b\u65f6\u95f4\u200b\u4e3a\u200b $$ T = T_\\text{compute} + T_\\text{communicatoin} + T_\\text{barrier} $$</p> <ul> <li>\\(T_\\text{compute}\\) \u200b\u6700\u6162\u200bmachine\u200b\u7684\u200b\u8ba1\u7b97\u200b\u65f6\u95f4\u200b  </li> <li>\\(T_\\text{communicatoin}\\) \u200b\u6700\u6162\u200b\u7684\u200b\u901a\u4fe1\u200b\u5ef6\u8fdf\u200b  </li> <li>\\(T_\\text{barrier}\\) \u200b\u540c\u6b65\u200b\u5f00\u9500\u200b  </li> </ul> <p>\u200b\u6728\u6876\u200b\u6548\u5e94\u200b\uff0c\u200b\u56e0\u6b64\u200b\u540c\u6b65\u200b\u5f00\u9500\u200b\u4f1a\u200b\u53d8\u5927\u200b</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/parallelism.html#asp","title":"ASP","text":"<p>\u200b\u5f02\u6b65\u200b\u5e76\u884c\u200bAsynchronous Parallel\u200b\u662f\u200b\u4e00\u79cd\u200b\u53bb\u200b\u4e2d\u5fc3\u5316\u200b\u3001\u200b\u65e0\u200b\u963b\u585e\u200b\u7684\u200b\u5e76\u884c\u200b\u673a\u5236\u200b\uff0cASP\u200b\u7684\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\u5141\u8bb8\u200b\u6240\u6709\u200b\u8ba1\u7b97\u200b\u8282\u70b9\u200bmachine\u200b\u72ec\u7acb\u200b\u8fd0\u884c\u200b\uff0c\u200b\u65e0\u9700\u200b\u7b49\u5f85\u200b\u5168\u5c40\u200b\u540c\u6b65\u200b\uff08\u200b\u5c40\u90e8\u200b\u4f18\u5148\u200b\uff0c\u200b\u5168\u5c40\u200b\u6ede\u540e\u200b\uff09\uff0c\u200b\u4ece\u800c\u200b\u6700\u5927\u5316\u200b\u786c\u4ef6\u200b\u5229\u7528\u7387\u200b\uff0c\u200b\u5c24\u5176\u200b\u9002\u5408\u200b\u5927\u89c4\u6a21\u200b\u5206\u5e03\u5f0f\u200b\u8bad\u7ec3\u200b\u548c\u200b\u5f02\u6784\u8ba1\u7b97\u200b\u73af\u5883\u200b\u3002</p> <p>\u200b\u4ee5\u200b\u53c2\u6570\u200b\u670d\u52a1\u5668\u200bParameter Server\uff08PS\uff09\u200b\u67b6\u6784\u200b\u4e3a\u4f8b\u200b\uff0cASP\u200b\u7684\u200b\u8ba1\u7b97\u200b\u6b65\u9aa4\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li>\u200b\u4ece\u200bPS\u200b\u5f02\u6b65\u200bPull\u200b\u53c2\u6570\u200b\uff08\u200b\u53ef\u80fd\u200b\u7531\u4e8e\u200b\u5ef6\u8fdf\u200b\u6216\u200b\u8ba1\u7b97\u901f\u5ea6\u200b\u56e0\u7d20\u200b\uff0c\u200b\u5f53\u524d\u200bmachine\u200b\u7684\u200b\u53c2\u6570\u200b\u662f\u200b\u8fc7\u65f6\u200b\u7248\u672c\u200b \\(W_{t-s_i}\\)\uff09</li> <li>\u200b\u57fa\u4e8e\u200b\u53c2\u6570\u200b\\(W_{t-s_i}\\)\uff0cmachine i\u200b\u4f7f\u7528\u200b\u672c\u5730\u200b\u6570\u636e\u200b\u8ba1\u7b97\u200b\u68af\u5ea6\u200b \\(\\nabla W_{t-s_i}\\)</li> <li>\u200b\u5c06\u200b\u68af\u5ea6\u200b\u5f02\u6b65\u200bPush\u200b\u68af\u5ea6\u200b\u5230\u200bPS\uff0cPS\u200b\u7acb\u5373\u200b\u66f4\u65b0\u200b\u5168\u5c40\u200b\u53c2\u6570\u200b \\(W_{t+1} = W_t - \\eta\\cdot\\nabla W_{t-s_i}\\)</li> </ol>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/parallelism.html#ssp","title":"SSP","text":"<p>\u200b\u65e7\u7248\u672c\u200b\u540c\u6b65\u200b\u5e76\u884c\u200bStale Synchronous Parallel\u200b\u662f\u200b\u4e00\u79cd\u200b\u4ecb\u4e8e\u200bBSP\u200b\u4e25\u683c\u200b\u540c\u6b65\u200b\u548c\u200bASP\u200b\u5b8c\u5168\u200b\u5f02\u6b65\u200b\u7684\u200b\u5206\u5e03\u5f0f\u200b\u5e76\u884c\u8ba1\u7b97\u200b\u673a\u5236\u200b\uff0c\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\u901a\u8fc7\u200b\u5bb9\u5fcd\u200b\u6709\u9650\u200b\u7684\u200b\u8ba1\u7b97\u200b\u5ef6\u8fdf\u200b\uff08Staleness Bound\uff09\uff0c\u200b\u5728\u200b\u4fdd\u8bc1\u200b\u8bad\u7ec3\u200b\u7a33\u5b9a\u6027\u200b\u7684\u200b\u540c\u65f6\u200b\uff0c\u200b\u663e\u8457\u200b\u63d0\u9ad8\u200b\u5206\u5e03\u5f0f\u7cfb\u7edf\u200b\u7684\u200b\u8d44\u6e90\u200b\u5229\u7528\u7387\u200b\u3002</p> <p>\u200b\u4ee5\u200b\u53c2\u6570\u200b\u670d\u52a1\u5668\u200bParameter Server\uff08PS\uff09\u200b\u67b6\u6784\u200b\u4e3a\u4f8b\u200b\uff0cSSP\u200b\u7684\u200b\u8ba1\u7b97\u200b\u6b65\u9aa4\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li>\u200b\u6bcf\u4e2a\u200bmachine\u200b\u4ece\u200bPS\u200b\u5f02\u6b65\u200bPull\u200b\u53c2\u6570\u200b\uff0c\u200b\u5e76\u200b\u8bb0\u5f55\u200b\u5404\u81ea\u200b\u62c9\u53d6\u200b\u7684\u200b\u5168\u5c40\u200b\u7248\u672c\u53f7\u200b \\(t_i\\)</li> <li>\u200b\u57fa\u4e8e\u200b\u672c\u5730\u200b\u53c2\u6570\u200b\\(W_{t_i}\\)\uff0cmachine i\u200b\u4f7f\u7528\u200b\u672c\u5730\u200b\u6570\u636e\u200b\u8ba1\u7b97\u200b\u68af\u5ea6\u200b \\(\\nabla W_{i_i}\\) </li> <li> <p>\u200b\u5c06\u200b\u68af\u5ea6\u200b\u5f02\u6b65\u200bPush\u200b\u5230\u200bPS\uff0c</p> <ul> <li>if \\(t_i - \\min \\{t_j\\}_{j=1}^N \\le S\\)\uff0c\u200b\u5219\u200b\u5141\u8bb8\u200b\u66f4\u65b0\u200b</li> <li>else machine i\u200b\u6682\u505c\u200b\u8ba1\u7b97\u200b\u5e76\u200b\u7b49\u5f85\u200b\u5176\u5b83\u200bmachine\u200b\u8ffd\u8d76\u200b</li> </ul> </li> <li> <p>PS\u200b\u805a\u5408\u200b\u6709\u6548\u200b\u68af\u5ea6\u200b\u5e76\u200b\u66f4\u65b0\u200b\u5168\u5c40\u200b\u53c2\u6570\u200b \\(W_{t+1} = W_t - \\eta\\cdot\\nabla W_{t_i}\\)</p> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/pipedream.html","title":"Pipedream","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/pipedream.html#pipedream","title":"PipeDream","text":"<p>\u200b\u8bba\u6587\u200b\uff1aPipeDream: Fast and Efficient Pipeline Parallel DNN Training MSR &amp; Carnegie Mellon University &amp; Stanford University, 2018 Jun</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/pipedream.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>https://zhuanlan.zhihu.com/p/715442799</li> <li>https://www.cnblogs.com/rossiXYZ/p/15212165.html#%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%B9%B6%E8%A1%8C%E4%B9%8Bpipedream1----profile%E9%98%B6%E6%AE%B5</li> <li>PipeDream aggressively pipelines minibatch processing, with different workers processing different inputs at any instant of time. This is accomplished by injecting multiple inputs into the worker with the first DNN layer, thereby keeping the pipeline full and ensuring concurrent processing on all workers  </li> <li>It also uses data parallelism for selected subsets of layers to balance computation load among workers.</li> <li>pipeline + MP + DP \u2192 PP</li> <li>PipeDream \u200b\u901a\u8fc7\u200b\u8fd0\u884c\u200b\u7b80\u77ed\u200b\u7684\u200b\u5206\u6790\u200b\u81ea\u52a8\u200b\u51b3\u5b9a\u200b\u5982\u4f55\u200b\u5212\u5206\u200bpipeline, using an algorithm that balances computation load among the different stages while minimizing communication</li> <li>PipeDream can use data parallelism for some stages\u2014multiple workers can be assigned to a given stage, processing different minibatches in parallel.</li> <li>PipeDream\u200b\u5728\u200b\u8fd0\u884c\u200b\u65f6\u4f1a\u200b\u4ea4\u7ec7\u200b\u8fd0\u884c\u200b\u524d\u5411\u200bforward\u200b\u548c\u200b\u540e\u200b\u5411\u200bbackward</li> <li>\u200b\u4fdd\u8bc1\u200b\u6d41\u6c34\u7ebf\u200b\u65f6\u523b\u200b\u8fd0\u884c\u200b\uff0c\u200b\u4e0d\u200b\u51fa\u73b0\u200b\u6d41\u6c34\u7ebf\u200b\u505c\u6ede\u200b\u73b0\u8c61\u200b while preventing excessive inprogress minibatches and ensuring model convergence</li> <li>asynchronous parallel or ASP, reduces GPU idle time</li> <li>pipeline parallel\u200b\u5c06\u200b\u6a21\u578b\u200b\u5212\u5206\u200b\u4e3a\u200b\u591a\u4e2a\u200b\u90e8\u5206\u200b\uff0c\u200b\u6bcf\u200b\u90e8\u5206\u200b\u53eb\u505a\u200bstage\uff0c\u200b\u6bcf\u4e2a\u200bstage\u200b\u5bf9\u5e94\u200b\u4e00\u4e2a\u200bgpu\uff0c\u200b\u5176\u4e2d\u200b\u8f93\u5165\u200b\u90e8\u5206\u200b\u662f\u200binput stage\uff0c\u200b\u8f93\u51fa\u200b\u90e8\u5206\u200b\u662f\u200boutput stage</li> <li>\u200b\u4f20\u7edf\u200b\u7684\u200bmodel-parallel DNN training results in severe under-utilization of GPU resources</li> <li></li> <li>\u200b\u4e3a\u200b\u4f7f\u200b\u6bcf\u200b\u4e00\u200b\u65f6\u523b\u200b\u6ca1\u6709\u200bgpu\u200b\u95f2\u7f6e\u200b\uff0c\u200b\u901a\u8fc7\u200binject multiple minibatches into the pipeline one after the other\u200b\u6765\u200b\u907f\u514d\u200b\u8be5\u200b\u95ee\u9898\u200b</li> <li></li> <li>\u200b\u7531\u4e8e\u200b\u901a\u4fe1\u200b\u65f6\u95f4\u200b\u4e3a\u200bforward\u200b\u6216\u200bbackward\u200b\u7684\u200b\u4e00\u5c0f\u90e8\u5206\u200b\uff0c\u200b\u53c8\u200b\u56e0\u4e3a\u200b\u5728\u200bpipeline\u200b\u4e2d\u200b\u8fde\u7eed\u200b\u6ce8\u5165\u200b\u4e86\u200b\u591a\u4e2a\u200bminibatch\uff0c\u200b\u56e0\u6b64\u200b\u53ef\u4ee5\u200b\u5b8c\u7f8e\u200b\u7684\u200b\u907f\u514d\u200b\u901a\u4fe1\u200b\u7b49\u5f85\u200b</li> <li></li> <li> <p>PipeDream\u200b\u5bf9\u200bDNN\u200b\u6a21\u578b\u200bpipeline\u200b\u52a8\u6001\u200b\u5212\u5206\u200b\uff0c\u200b\u671f\u671b\u200b\uff1a1\uff09\u200b\u6bcf\u4e2a\u200bstage\u200b\u7684\u200b\u8ba1\u7b97\u200b\u91cf\u200b\u5c3d\u53ef\u80fd\u200b\u76f8\u7b49\u200b\uff1b2\uff09\u200b\u4f7f\u200b\u5404\u200bstage\u200b\u95f4\u200b\u6570\u636e\u901a\u4fe1\u200b\u3001\u200b\u4f20\u8f93\u200b\u7684\u200b\u91cf\u200b\u8d8a\u5c11\u200b\u8d8a\u200b\u597d\u200b\u3002\u200b\u8d1f\u8f7d\u200b\u4e0d\u200b\u5747\u8861\u200b\u6216\u8005\u200b\u673a\u5668\u95f4\u200b\u8fc7\u591a\u200b\u7684\u200b\u901a\u4fe1\u200b\u4f1a\u200b\u964d\u4f4e\u200b\u6548\u7387\u200b\uff0c\u200b\u5f71\u54cd\u200b\u541e\u5410\u200b\u7387\u200b</p> </li> <li> <p>PipeDream\u200b\u8fc7\u7a0b\u200b\uff0c\u200b\u7ed9\u5b9a\u200b\\(N\\)\u200b\u5c42\u200b\uff0c\\(M\\)\u200b\u4e2a\u200b\u8bbe\u5907\u200b\uff0c\u200b\u9996\u5148\u200b\u5728\u200b\u5355\u4e2a\u200b\u673a\u5668\u200b\u4e0a\u200b\u8fd0\u884c\u200b\u4e00\u904d\u200bprofiler\uff0c\u200b\u968f\u540e\u200b\u5212\u5206\u200b\u6a21\u578b\u200b\uff08\u200b\u540c\u65f6\u200b\u786e\u5b9a\u200breplication factor\u200b\u4ee5\u200b\u5c3d\u53ef\u80fd\u200b\u5730\u8f83\u200b\u5c11\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u957f\u200b\uff09</p> <ol> <li>profiling the DNN model\uff1aDNN training shows little variance in the computation and communication time across minibatches (paper\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u4e86\u200b1000)\uff0c\u200b\u56e0\u6b64\u200b\u5bf9\u200b\u6bcf\u5c42\u200b\u8bb0\u5f55\u200b3\u200b\u4e2a\u200b\u6570\u503c\u200b{\\(T_l\\): l\u200b\u7684\u200bforward + backward\u200b\u8ba1\u7b97\u200b\u65f6\u95f4\u200b\u7efc\u5408\u200b\uff1b\\(a_l\\)\uff1alayer l\u200b\u8f93\u51fa\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u7684\u200bsize\uff1b\\(w_l\\)\uff1alayer l\u200b\u7684\u200b\u53c2\u6570\u200b\u7684\u200bsize\uff1b}</li> </ol> </li> <li>\u200b\u901a\u4fe1\u200b\u8fc7\u7a0b\u200b\uff1a1\uff09\u200b\u53d1\u9001\u200b\u65b9\u200bGPU\u2192CPU\uff1b2\uff09\u200b\u901a\u8fc7\u200b\u7f51\u7edc\u200b\u4f20\u8f93\u200b\u5230\u200b\u63a5\u6536\u200b\u65b9\u200b\uff1b3\uff09\u200b\u63a5\u6536\u200b\u65b9\u200bCPU\u2192GPU\u3002\u200b\u4ece\u200blayer l\u200b\u81f3\u200blayer l+1 \u200b\u6fc0\u6d3b\u200b\u503c\u200b\u4f20\u8f93\u200b\u901a\u4fe1\u200b\u8017\u65f6\u200b\u4e3a\u200b\\(C_l\\)\uff0c\u200b\u8ba1\u7b97\u200b\u65b9\u5f0f\u200b\u548c\u200b\u4e3a\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u6570\u636e\u91cf\u200b/\u200b\u5e26\u5bbd\u200b\uff0c\u200b\u53ef\u200b\u901a\u8fc7\u200b\\(a_l\\)\u200b\u4f30\u7b97\u200b\u3002\\(W_l^m\\) \u200b\u8868\u793a\u200blayer l \u200b\u5728\u200bm\u200b\u4e2a\u200b\u8bbe\u5907\u200b\u4e2d\u200bDP\u200b\u540c\u6b65\u200b\u53c2\u6570\u200b\u6743\u91cd\u200b\u7684\u200b\u901a\u4fe1\u200b\u65f6\u200b\u957f\u200b</li> <li>PipeDream's Partitioning Algorithm\uff1aOur partitioning algorithm takes the output of the profiling step, and computes: 1) a partitioning of layers into stages, 2) the replication factor for each stage, and 3) optimal number of minibatches to keep the training pipeline busy. <p>\u200b\u603b\u5171\u200bm\u200b\u4e2a\u200b\u8bbe\u5907\u200b\uff0c\u200b\u53ef\u200b\u7528\u4e8e\u200bPP\uff0c\u200b\u4e5f\u200b\u53ef\u200b\u7528\u4e8e\u200bDP\uff0c\u200b\u5373\u200b #DP + #PP = m</p> </li> <li> <p>\u200b\u52a8\u6001\u200b\u89c4\u5212\u200b\u7528\u4e8e\u200bstage\u200b\u5212\u5206\u200b\uff0c\\(A(j, m)\\) \u200b\u8868\u793a\u200b\u524d\u200bj\u200b\u5c42\u200b\u5728\u200bm\u200b\u4e2a\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u6700\u4f18\u200b\u5212\u5206\u200b\u4e2d\u200b\u7684\u200b\u65f6\u957f\u200b\u6700\u5927\u200bstage\u200b\u7684\u200b\u8017\u65f6\u200b\uff0c\\(T(i\\rightarrow j, m) = \\frac{1}{m} \\max \\left( \\sum_{l=i}^j T_l, \\sum_{l=i}^j W_l^m \\right)\\) \u200b\u8868\u793a\u5c42\u200blayer i \u200b\u81f3\u200b layer j\u200b\u5728\u200bm\u200b\u4e2a\u200b\u8bbe\u5907\u200b\u4e0a\u200bDP\u200b\u82b1\u8d39\u200b\u7684\u200b\u5e73\u5747\u200b\u65f6\u200b\u957f\u200b\uff0c\u200b\u56e0\u6b64\u200b\u4f1a\u200b\u5b58\u5728\u200b\u4ee5\u4e0b\u200b\u51e0\u79cd\u200b\u60c5\u51b5\u200b</p> <ol> <li> <p>\u200b\u53ea\u200b\u5305\u542b\u200b\u4e00\u4e2a\u200bstage\uff0cDP m\u200b\u6b21\u200b</p> \\[ A(j, m) = T(1\\rightarrow j, m) \\] </li> <li> <p>layer 1\u200b\u81f3\u200blayer i\u200b\u8fdb\u884c\u200b\\(m-m^{'}\\) PP\uff0clayer i+1 \u200b\u81f3\u200b layer j \u200b\u8fdb\u884c\u200b \\(m^{'}\\) DP</p> \\[ A(j, m) = \\min_{1 \\le i \\lt j} \\min_{1 \\le m^{'} \\lt m} \\max \\begin{cases}     A(i, m-m^{'}) \\\\     2\\cdot C_i \\\\     T(i+1 \\rightarrow j, m^{'}) \\end{cases} \\] <p>\\(2\\cdot C_i\\) \u200b\u4e2d\u200b\u7684\u200b2\u200b\u8868\u793a\u200b forward activations + backward gradients</p> </li> </ol> </li> <li> <p>Initialization\uff1a<code>A(1, m) = T(1 \u2192 1, m) for m in range(1, M+1)</code>, <code>A(i, 1) = T(1 \u2192 i, 1) for i in range(1, N+1)</code></p> </li> <li>Runtime Analysis\uff1aA\u200b\u6709\u200bN*M\u200b\u4e2a\u5b50\u200b\u7a7a\u95f4\u200b\uff0c\u200b\u56e0\u6b64\u200b\u4e3a\u200b\\(O(NM)\\)\uff0c\u200b\u6bcf\u4e2a\u200b\u5b50\u200b\u7a7a\u95f4\u200b\u9700\u8981\u200b\u5206\u522b\u200b\u5bf9\u5c42\u200bi\u200b\u548c\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u6570\u200bm\u200b\u8fdb\u884c\u200b\u5206\u5272\u200b\u904d\u5386\u200b\uff0c\u200b\u4e3a\u200b\\(O(NM)\\)\uff0c\u200b\u603b\u200b\u590d\u6742\u5ea6\u200b\u4e3a\u200b\\(O(N^2M^2)\\)</li> </ul> <p></p> <ul> <li>Work Scheduling\uff1ain the steady state, every machine is busy either doing the forward pass or backward pass for a minibatch\uff0c\u200b\u663e\u8457\u200b\u51cf\u5c11\u200b\u6d41\u6c34\u7ebf\u200b\u6c14\u6ce1\u200b\uff0c1F1B\uff0cforward\u3001backward\u200b\u4ea4\u66ff\u200b\u8fdb\u884c\u200b</li> <li> <p>Figure 8 illustrates this using a partitioning with no data parallelism</p> </li> <li> <p>in the backward pass for minibatch 5 on stage 1, the gradient is computed using a different set of weights than the ones used in the corresponding forward pass; this discrepancy in weight versions can prevent the model from converging.</p> </li> <li> <p>NOAM (NUM_OPT_ACTIVE_MINIBATCHES)\uff1a\\(\\lceil \\#\\text{machines}/(\\#\\text{machines in the input stage}) \\rceil\\)</p> </li> </ul> <p>naive pipelining does not achieve the same accuracy as data-parallel training. To address this problem, PipeDream uses two techniques:</p> <ul> <li> <p>Weight Stashing\u200b\u6743\u91cd\u200b\u5b58\u50a8\u200b: \u200b\u8ba1\u7b97\u200bminibatch i \u200b\u7684\u200bforward\u200b\u65f6\u200b\uff0c\u200b\u5f53\u524d\u200bmachine\u200b\u4fdd\u5b58\u200b\u4f7f\u7528\u200b\u7684\u200b\u6743\u91cd\u200b \\(W_i\\)\uff0c\u200b\u5728\u200b\u8ba1\u7b97\u200b\u6539\u200bminibatch\u200b\u7684\u200bbackward\u200b\u65f6\u200b\uff0c\u200b\u4ece\u200bstash\u200b\u4e2d\u200b\u53d6\u51fa\u200b\u4fdd\u5b58\u200b\u7684\u200b \\(W_i\\) \u200b\u8ba1\u7b97\u200b\u68af\u5ea6\u200b\u800c\u200b\u4e0d\u662f\u200b\u4f7f\u7528\u200b\u6700\u65b0\u200b\u72b6\u6001\u200b\u7684\u200b\u6743\u91cd\u200b\uff08\u200b\u68af\u5ea6\u200b\u8ba1\u7b97\u200b\u57fa\u4e8e\u200b\u524d\u5411\u200b\u4f20\u64ad\u200b\u65f6\u200b\u76f8\u540c\u200b\u7684\u200b\u6743\u91cd\u200b\u7248\u672c\u200b\uff1b\u200b\u907f\u514d\u200b\u6743\u91cd\u200b\u7248\u672c\u200b\u4e0d\u200b\u4e00\u81f4\u200b\u5bfc\u81f4\u200b\u7684\u200b\u8bad\u7ec3\u200b\u4e0d\u200b\u7a33\u5b9a\u200b\u95ee\u9898\u200b\u3002\uff09</p> <ul> <li> \u200b\u4fdd\u8bc1\u200b\u68af\u5ea6\u200b\u8ba1\u7b97\u200b\u7684\u200b\u6b63\u786e\u6027\u200b\uff0c\u200b\u786e\u4fdd\u200b\u5404\u200bminibatch\u200b\u7684\u200bforward\u200b\u548c\u200bbackward\u200b\u4f7f\u7528\u200b\u7684\u200b\u6743\u91cd\u200b\u76f8\u540c\u200b\uff0c\u200b\u907f\u514d\u200b\u7248\u672c\u200b\u6f02\u79fb\u200b\u95ee\u9898\u200b\u3002</li> <li> \u200b\u5141\u8bb8\u200b\u4e0d\u540c\u200bmachine\u200b\u540c\u65f6\u200b\u5904\u7406\u200b\u4e0d\u540c\u200b\u7684\u200bminibatch\uff0c\u200b\u63d0\u9ad8\u200b\u8bad\u7ec3\u200b\u6548\u7387\u200b</li> <li> \u200b\u4ec5\u200b\u9700\u200b\u5728\u200bmachine\u200b\u672c\u5730\u200b\u7f13\u5b58\u200b\u6743\u91cd\u200b\u7248\u672c\u200b\uff0c\u200b\u65e0\u9700\u200b\u5168\u5c40\u200b\u540c\u6b65\u200b</li> <li> \u200b\u5185\u5b58\u200b\u5f00\u9500\u200b\u589e\u52a0\u200b\uff0c\u200b\u6bcf\u4e2a\u200bmachine\u200b\u9700\u8981\u200b\u5b58\u50a8\u200b\u591a\u4e2a\u200b\u6743\u91cd\u200b\u526f\u672c\u200b\uff08\u200b\u4e00\u822c\u200b\u6d41\u6c34\u7ebf\u200bstage\u200b\u6570\u8d8a\u200b\u591a\u200b\uff0c\u200b\u5f00\u9500\u200b\u8d8a\u5927\u200b\uff09</li> <li> \u200b\u4e0d\u80fd\u200b\u5b8c\u5168\u200b\u6d88\u9664\u200b\u5ef6\u8fdf\u200b\uff0c\u200b\u4ecd\u200b\u5b58\u5728\u200b\u6d41\u6c34\u7ebf\u200b\u6ce1\u6cab\u200bbubble\uff08\u200b\u7a7a\u95f2\u200b\u65f6\u95f4\u200b\uff09\uff0c\u200b\u4f46\u200b\u76f8\u6bd4\u200b\u4f20\u7edf\u200b\u65b9\u6cd5\u200b\u66f4\u200b\u7a33\u5b9a\u200b <p>\u200b\u56e0\u6b64\u200bminibatch 5\uff0cforward [update_1, update_2, update_3, update_4]</p> </li> </ul> </li> <li> <p>Vertical Sync\u200b\u5782\u76f4\u200b\u540c\u6b65\u200b\uff1aminibatch 5 stage 1\u200b\u7684\u200b\u524d\u200b\u5411\u200b\u6743\u91cd\u200b\u53ea\u200b\u66f4\u65b0\u200b\u4e86\u200b1\uff0c\u200b\u800c\u200bstage 2\u200b\u524d\u5411\u200b\u6743\u91cd\u200b\u66f4\u65b0\u200b\u4e86\u200b1\u200b\u548c\u200b2\uff0c\u200b\u6743\u91cd\u200b\u7248\u672c\u200b\u4e0d\u200b\u4e00\u81f4\u200b\u3002\u200b\u4e3a\u4e86\u200b\u89e3\u51b3\u200b\u8be5\u200b\u95ee\u9898\u200b\u63d0\u51fa\u200b\u4e86\u200b\u5782\u76f4\u200b\u540c\u6b65\u200b</p> <ul> <li>\u200b\u5bf9\u4e8e\u200bminibatch 5\uff0c\u200b\u6240\u6709\u200bstage\u200b\u5747\u200b\u4f7f\u7528\u200b\u53ea\u200b\u7531\u200bminibatch 1\u200b\u66f4\u65b0\u200b\u7684\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b\uff0c\u200b\u5373\u200b\\(m_i\\)\u200b\u5168\u7a0b\u200b\u53ea\u7528\u200b \\(i-x\\) \u200b\u7248\u672c\u200b\u6743\u91cd\u200b\uff0c\u200b\u5728\u200bbackward\u200b\u540e\u200b\uff0c\\(w^{i-x}\\) \u200b\u66f4\u65b0\u200b\u4e3a\u200b \\(w^(i)\\) <p>impact of vertical sync is negligible. \u200b\u4fdd\u8bc1\u200bforward + backward\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u6743\u91cd\u200b\u4e00\u81f4\u200b\u66f4\u200b\u91cd\u8981\u200b</p> </li> </ul> </li> <li> <p>If the stage is replicated, the weight update is copied to host memory and then sent to the parameter server. When a newer version of the parameters becomes available, the prior version is not immediately discarded, as part of the weight stashing scheme. Parameter data is only discarded once a backward pass that uses fresher parameters is performed. (\u200b\u9636\u6bb5\u6027\u200bSP\uff0c\u200b\u5404\u200bminibatch\u200b\u66f4\u65b0\u200b\u5b8c\u200b\u5c31\u200bpush\u200b\u81f3\u200bPS)</p> </li> <li> <p>Effect of using faster compute (V100s)</p> </li> <li>Effect of varying number of machines</li> <li>Comparison to asynchronous parallel</li> <li>MP: \u200b\u6bcf\u200b\u4e00\u90e8\u5206\u200b\u987a\u5e8f\u200b\u6267\u884c\u200b</li> <li>PP\uff1a\u200b\u6bcf\u200b\u4e00\u90e8\u5206\u200b\u987a\u5e8f\u200b\u662f\u200b\u6267\u884c\u200b\uff0c\u200b\u4e14\u200b\u540c\u65f6\u200b\u5904\u7406\u200b\u4e0d\u540c\u200bminibatch</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/pipedream.html#pipedream-2bw","title":"PipeDream-2BW","text":"<p>\u200b\u8bba\u6587\u200b\uff1aMemory-Efficient Pipeline-Parallel DNN Training MSR &amp; Stanford University, 2020 Jun, ICML 2021</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/pipedream.html#_2","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>PipeDream-2BW</li> <li>PipeDream-Flush </li> </ul>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/pipeline_parallelism.html","title":"Pipeline parallelism","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/pipeline_parallelism.html#pp","title":"PP","text":"<ul> <li>layer-wise model parallelism</li> <li>https://fleet-x.readthedocs.io/en/latest/paddle_fleet_rst/collective/collective_mp/pipeline.html</li> </ul> <p>\u200b\u6d41\u6c34\u7ebf\u200b\u5e76\u884c\u200bPipeline Parallel\u200b\u5c06\u200b\u6a21\u578b\u200b\u6309\u5c42\u200b\u5206\u5272\u200b\u5230\u200b\u4e0d\u540c\u200b\u8bbe\u5907\u200b\uff0c\u200b\u5f62\u6210\u200b\u5904\u7406\u200b\u6d41\u6c34\u7ebf\u200b\u3002\u200b\u4f20\u7edf\u200bPP\u200b\u4e3a\u5355\u200bmini-batch\u200b\u65f6\u5e8f\u200b\u8fd0\u884c\u200b\uff0c\u200b\u540c\u4e00\u200b\u65f6\u523b\u200b\u53ea\u6709\u200b\u4e00\u4e2a\u200bstage\u200b\u5de5\u4f5c\u200b\uff0c\u200b\u6548\u7387\u200b\u4f4e\u4e0b\u200b</p> <ul> <li>PipeDream</li> <li>GPipe</li> </ul> <p></p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/zero_bubble.html","title":"Zero bubble","text":""},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/zero_bubble.html#zero-bubble","title":"Zero Bubble","text":"<p>\u200b\u8bba\u6587\u200b\uff1aZero Bubble Pipeline Parallelism Github\uff1azero-bubble-pipeline-parallelism Sea AI Lab, 2023 Nov, ICLR 2024</p>"},{"location":"AI/Paper_Reading/Trick/Efficiency_Speedup/Parallelism/zero_bubble.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>ZB1P</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Bagging/bagging.html","title":"Bagging","text":"<ul> <li> <p>Bootstrap Aggregating\uff0c\u200b\u901a\u8fc7\u200b\u81ea\u52a9\u200b\u91c7\u6837\u200b\uff08Bootstrap Sampling\uff09\u200b\u751f\u6210\u200b\u591a\u4e2a\u200b\u8bad\u7ec3\u200b\u96c6\u200b\uff0c\u200b\u7136\u540e\u200b\u5728\u200b\u6bcf\u4e2a\u200b\u8bad\u7ec3\u200b\u96c6\u4e0a\u200b\u8bad\u7ec3\u200b\u4e00\u4e2a\u200b\u57fa\u200b\u5b66\u4e60\u200b\u5668\u200b\uff0c\u200b\u6700\u540e\u200b\u5c06\u200b\u8fd9\u4e9b\u200b\u57fa\u200b\u5b66\u4e60\u200b\u5668\u200b\u7684\u200b\u9884\u6d4b\u200b\u7ed3\u679c\u200b\u8fdb\u884c\u200b\u5e73\u5747\u200b\uff08\u200b\u56de\u5f52\u200b\u4efb\u52a1\u200b\uff09\u200b\u6216\u200b\u6295\u7968\u200b\uff08\u200b\u5206\u7c7b\u200b\u4efb\u52a1\u200b\uff09\u3002</p> </li> <li> <p>\u200b\u4f7f\u7528\u200b\u968f\u673a\u200b\u6570\u636e\u200b\u5b50\u96c6\u200b\u5e76\u884c\u200b\u6784\u5efa\u200b\u4e0d\u540c\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u5e76\u200b\u805a\u5408\u200b\u6240\u6709\u200b\u9884\u6d4b\u200b\u53d8\u91cf\u200b\u7684\u200b\u9884\u6d4b\u200b\u7ed3\u679c\u200b\u3002</p> </li> </ul>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/adaboost.html","title":"Adaboost","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/adaboost.html#adaboost","title":"AdaBoost","text":"<p>\u200b\u8bba\u6587\u200b\uff1aA Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting AdaBoost: Adaptive Boosting AT&amp;T Labs, EuroCOLT 1997</p>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/adaboost.html#_1","title":"\u57fa\u672c\u539f\u7406","text":"<ol> <li> <p>\u200b\u521d\u59cb\u5316\u200b\uff0c\u200b\u8bad\u7ec3\u200b\u96c6\u200b\\(D=\\{(x^i, y^i)\\}_{i=1}^n\\)\uff0c\u200b\u6700\u5927\u200b\u8fed\u4ee3\u200b\u8f6e\u6570\u200b\\(T\\)\uff0c\u200b\u5404\u200b\u6837\u672c\u200b\u6743\u91cd\u200b\\(w_0^i=\\frac{1}{n}\\)</p> <p>\\(y_i\\in \\{-1, +1\\}\\) \u200b\u5206\u522b\u200b\u5bf9\u5e94\u200b\u8d1f\u200b\u3001\u200b\u6b63\u7c7b\u200b</p> </li> <li> <p>\u200b\u8fed\u4ee3\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u5f53\u524d\u200b\u8fed\u4ee3\u200b\u8f6e\u6b21\u200b\\(t\\)\uff1a</p> <ul> <li>\u200b\u57fa\u4e8e\u200b\u6837\u672c\u200b\u6743\u91cd\u200b \\(W_{t}\\) \u200b\u52a0\u6743\u200bloss\u200b\u6765\u200b\u8bad\u7ec3\u200b\u5f31\u200b\u5b66\u4e60\u200b\u5668\u200b\\(f_t(x)\\)</li> <li> <p>\u200b\u7ed3\u5408\u200b \\(W_{t}\\) \u200b\u8ba1\u7b97\u200b \\(f_t(x)\\) \u200b\u5728\u200b\u8bad\u7ec3\u200b\u96c6\u4e0a\u200b\u7684\u200b\u5206\u7c7b\u200b\u9519\u8bef\u7387\u200b(error rate) \\(e_t\\)</p> \\[ e_t = \\sum_{i=1}^n w_t^i*\\mathbb{I}\\big(f_t(x^i)\\ne y^i\\big) \\] <p>\\(\\mathbb{I}\\) \u200b\u4e3a\u200b\u6307\u793a\u200b\u51fd\u6570\u200b\uff0c\u200b\u5982\u679c\u200b\u6761\u4ef6\u200b\u6210\u7acb\u200b\u5219\u200b1\uff0c\u200b\u53cd\u4e4b\u200b\u5219\u200b0\u3002</p> </li> <li> <p>\u200b\u8ba1\u7b97\u200b\u5f31\u200b\u5b66\u4e60\u200b\u5668\u200b \\(f_t(x)\\) \u200b\u7684\u200b\u6743\u91cd\u200b \\(\\alpha_t\\)\uff0c\u200b\u9519\u8bef\u7387\u200b\u8d8a\u5c0f\u5f31\u200b\u5b66\u4e60\u200b\u5668\u200b\u6743\u91cd\u200b\u8d8a\u5927\u200b</p> \\[\\alpha_t=\\frac{1}{2}\\ln\\bigg(\\frac{1-e_t}{e_t}\\bigg)\\] </li> <li> <p>\u200b\u66f4\u65b0\u200b\u5404\u200b\u6837\u672c\u200b\u6743\u91cd\u200b\u5e76\u200b\u5f52\u4e00\u5316\u200b\uff0c\u200b\u9884\u6d4b\u200b\u6b63\u786e\u200b\u964d\u4f4e\u200b\u6743\u503c\u200b\uff0c\u200b\u9884\u6d4b\u200b\u9519\u8bef\u200b\u63d0\u5347\u200b\u6743\u503c\u200b</p> \\[ w_{t+1}^i=\\frac{w_t^i * \\exp^{-\\alpha_t*y_i*f_t(x_i)}}{\\sum_k^n w_t^k * \\exp^{-\\alpha_t*y_k*f_t(x_k)}} \\] </li> </ul> </li> <li> <p>\u200b\u7ec4\u5408\u200b\u5f31\u200b\u5b66\u4e60\u200b\u5668\u200b\uff0c\\(F(x)=\\text{sign}\\Big(\\sum_{t=1}^T\\alpha_t*f_t(x)\\Big)\\)</p> <p>\\(\\text{sign}\\) \u200b\u7528\u4e8e\u200b\u53d6\u200b\u6807\u7b7e\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u53bb\u9664\u200b\u8fd9\u90e8\u5206\u200b\u83b7\u53d6\u200blogit\u200b\u503c\u200b\u8fdb\u800c\u200b\u8c03\u6574\u200b\u9608\u503c\u200b</p> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/boosting.html","title":"Boosting","text":"<p>Boosting\u200b\u901a\u8fc7\u200b\u8fed\u4ee3\u200b\u5730\u200b\u8bad\u7ec3\u200b\u57fa\u200b(\u200b\u6216\u5f31\u200b)\u200b\u5b66\u4e60\u200b\u5668\u200b\uff0c\u200b\u6bcf\u6b21\u200b\u8fed\u4ee3\u200b\u90fd\u200b\u66f4\u200b\u5173\u6ce8\u200b\u5728\u200b\u4e0a\u200b\u4e00\u8f6e\u200b\u9884\u6d4b\u200b\u7ed3\u679c\u200b\u4e2d\u200b\u88ab\u200b\u9519\u8bef\u200b\u5206\u7c7b\u200b\u7684\u200b\u6837\u672c\u200b\u3002\u200b\u901a\u8fc7\u200b\u52a0\u6743\u200b\u7ec4\u5408\u200b\u591a\u8f6e\u200b\u57fa\u200b\u5b66\u4e60\u200b\u5668\u200b\uff0c\u200b\u6700\u7ec8\u200b\u5f97\u5230\u200b\u4e00\u4e2a\u200b\u5f3a\u200b\u5b66\u4e60\u200b\u5668\u200b\u3002  </p> <ul> <li>AdaBoost </li> <li> <p>GBM </p> <ul> <li>GBDT\uff1aGBM\u200b\u7684\u200b\u4e00\u79cd\u200b\u7279\u6b8a\u200b\uff08\u200b\u51b3\u7b56\u6811\u200b\uff09\u200b\u5b9e\u73b0\u200b<ul> <li>XGBoost </li> <li>LightGBM </li> <li>CatBoost</li> </ul> </li> </ul> </li> <li> <p>https://www.kaggle.com/code/faressayah/xgboost-vs-lightgbm-vs-catboost-vs-adaboost#6.-Scikit-Learn-vs-XGBoost-vs-LightGBM-vs-CatBoost  </p> </li> <li>https://neptune.ai/blog/when-to-choose-catboost-over-xgboost-or-lightgbm  </li> <li> <p>https://tech.deliveryhero.com/is-catboost-faster-than-lightgbm-and-xgboost/</p> </li> <li> <p>https://blog.csdn.net/u012856866/article/details/138860813  </p> </li> <li>https://zhuanlan.zhihu.com/p/678188301</li> <li>ID3\u200b\u7b97\u6cd5\u200b https://zhuanlan.zhihu.com/p/577638501</li> <li>C4.5\u3001C5.0\u200b\u7b97\u6cd5\u200b</li> <li>CART</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/catboost.html","title":"Catboost","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/catboost.html#catboost","title":"CatBoost","text":"<p>\u200b\u8bba\u6587\u200b: CatBoost: unbiased boosting with categorical features CatBoost: Categorical Boosting Yandex &amp; Moscow Institute of Physics and Technology, NIPS 2017  </p>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/catboost.html#_1","title":"\u57fa\u672c\u539f\u7406","text":"<ul> <li>https://mp.weixin.qq.com/s/iYumC_JlMHZpBuAd4ryWFw</li> <li>categrorical features processing\uff0c\u200b\u5904\u7406\u200b\u3010\u200b\u79bb\u6563\u200b\u3011\u200b\u7684\u200b\u7c7b\u522b\u200b\u578b\u200b\u7279\u5f81\u200b\u4e3a\u200b\u65b0\u200b\u7684\u200b\u6570\u503c\u200b\u578b\u200b\u7279\u5f81\u200b</li> <li>categrorical features \u200b\u662f\u200b\u4e00\u4e2a\u200b\u5305\u542b\u200b\u4e92\u76f8\u200b\u72ec\u7acb\u200b\u7684\u200b\u79bb\u6563\u200b\u7279\u5f81\u200b\u96c6\u200b\uff0c\u200b\u5e38\u89c1\u200b\u7684\u200b\u6709\u200bone-hot encoding\uff0c\u200b\u5bf9\u200b\u6bcf\u4e2a\u200b\u7279\u5f81\u200b\u65b0\u589e\u200b\u4e00\u4e2a\u200b\u4e8c\u5206\u200b\u7279\u5f81\u200b\u8fdb\u884c\u200b\u8868\u793a\u200b\uff0c\u200b\u4f46\u200b\u5bf9\u4e8e\u200b\u67d0\u4e9b\u200b\u5177\u6709\u200bid\u200b\u5c5e\u6027\u200b\u7684\u200b\u7279\u5f81\u200b\uff0c\u200b\u4e8c\u5206\u200b\u5c5e\u6027\u200b\u5f80\u5f80\u200b\u4e0d\u591f\u200b\uff0c\u200b\u800c\u662f\u200b\u9700\u8981\u200b\u5927\u91cf\u200b\u7684\u200b\u679a\u4e3e\u200b\u503c\u200b\u4f5c\u4e3a\u200b\u533a\u5206\u200b<ul> <li>\u200b\u907f\u514d\u200b\u9ad8\u7ef4\u200b\u7a00\u758f\u200b\u77e9\u9635\u200b\u6216\u200b\u4fe1\u606f\u200b\u4e22\u5931\u200b</li> </ul> </li> <li>drift: category feature \u200b\u5728\u200b\u8bad\u7ec3\u200b\u96c6\u200b\u548c\u200b\u6d4b\u8bd5\u200b\u96c6\u4e0a\u200b\u6c42\u5f97\u200b\u7684\u200b\u503c\u200b\u4e0d\u200b\u4e00\u81f4\u200b\uff08\u200b\u5982\u200b\u67d0\u200b\u4e00\u200b\u7279\u5f81\u200b\u53d6\u503c\u200b\u6240\u5c5e\u200b\u7c7b\u522b\u200b\u7684\u200b\u5360\u200b\u6bd4\u200b\uff09</li> <li> <p>TS (target statistics): greedy TS, Holdout TS[x], Leave-one-out TS, Ordered TS\uff0c\u200b\u57fa\u4e8e\u200b\u6bcf\u4e2a\u200b\u7c7b\u522b\u200b\u7684\u200b\u4fe1\u606f\u200b\u6765\u200b\u8ba1\u7b97\u200b\u76ee\u6807\u200b\u7279\u5f81\u503c\u200b</p> </li> <li> <p>greedy TS</p> <ul> <li>\\(\\hat{x}_i^k=\\frac{\\sum_{x^j \\in D_k} \\mathbb{1}_{\\{x^j_i = x^k_i\\}}\\cdot y^j + ap}{\\sum_{x^j \\in D_k} \\mathbb{1}_{\\{x^j_i = x^k_i\\}} + a}\\)<ul> <li>\\(D_k \\subset D \\backslash \\{x^k\\}\\), excluding \\(x^k\\) to avoid target leakage</li> </ul> </li> </ul> </li> <li> <p>row-wise ordered TS\uff0c\u200b\u5229\u7528\u200b\u4e4b\u524d\u200b\u7684\u200b\u5386\u53f2\u6570\u636e\u200b\u6765\u200b\u4f30\u8ba1\u200b\u8be5\u200b\u7c7b\u522b\u200b\u4e0e\u200b\u76ee\u6807\u200b\u7279\u5f81\u503c\u200b\u4e4b\u95f4\u200b\u7684\u200b\u76f8\u5173\u6027\u200b</p> </li> <li> <p>\\(\\hat{x}_i^k=\\frac{\\sum_{x^j \\in D_k} \\mathbb{1}_{\\{x^j_i = x^k_i\\}}\\cdot y^j + ap}{\\sum_{x^j \\in D_k} \\mathbb{1}_{\\{x^j_i = x^k_i\\}} + a}\\) </p> <ul> <li>train step: \\(D_k = \\{x_j: j\\lt k\\}\\), historical instances to avoid target leakage\u200b\u5e76\u200b\u51cf\u7f13\u200b\u8fc7\u200b\u62df\u5408\u200b</li> <li>infer step: \\(D_k = D\\)</li> </ul> </li> <li> <p>gradient bias</p> </li> <li>prediction shift\uff1a\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u6807\u7b7e\u200b\u4fe1\u606f\u200b\u6cc4\u9732\u200b\u4e86\u200b\uff0c\u200b\u4f7f\u7528\u200b\u4e86\u200b\u672c\u8be5\u200b\u88ab\u200b\u9884\u6d4b\u200b\u7684\u200b\u503c\u200b\uff1b\u200b\u6d4b\u8bd5\u200b\u6216\u200b\u9a8c\u8bc1\u200b\u65f6\u200b\u8f93\u5165\u200b\u7684\u200b\u662f\u200b\u672a\u200b\u53c2\u4e0e\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6570\u636e\u200b\u8fdb\u884c\u200b\u9884\u6d4b\u200b\uff0c\u200b\u4e24\u8005\u200b\u5b58\u5728\u200b\u5dee\u5f02\u200b\u3002\u200b\u6b64\u5916\u200b\u5c31\u662f\u200b\u6bcf\u6b21\u200b\u8fed\u4ee3\u200b\u65f6\u200b\uff0c\u200b\u4f7f\u7528\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b(\u200b\u6837\u672c\u200b\u987a\u5e8f\u200b\u548c\u200b\u5185\u5bb9\u200b)\u200b\u662f\u200b\u76f8\u540c\u200b\u7684\u200b</li> <li>Analysis of prediction shift</li> <li>Feature combinations</li> <li>plain boosting: ordered TS + gbdt</li> <li> <p>ordered boosting (Algorithm 1 &amp; Figure 1)</p> <ol> <li>\u200b\u6253\u7834\u200b\u6570\u636e\u200b\u56fa\u6709\u200b\u7684\u200b\u987a\u5e8f\u200b\u4f9d\u8d56\u6027\u200b\uff0crandom row/instance permutation</li> <li>\u200b\u5bf9\u200b\u6bcf\u200b\u4e00\u4e2a\u200b\u6837\u672c\u200b \u200b\u90fd\u200b\u8bad\u7ec3\u200b\u4e00\u4e2a\u200b\u5355\u72ec\u200b\u7684\u200b\u6a21\u578b\u200b </li> <li>\u200b\u8fd4\u56de\u200b\\(F_{n}^{T}\\)\uff08\u200b\u53ef\u7528\u200b\u52a8\u6001\u200b\u89c4\u5212\u200bdp\u200b\u7406\u89e3\u200b\u6216\u200bCausal mask\uff09</li> </ol> </li> <li> <p>catboost (Algorithm 2): combine ordered TS and ordered boosting</p> <ol> <li>\u200b\u5206\u5757\u200b\u5904\u7406\u200b\uff0c\u200b\u5c06\u200b\u968f\u673a\u200b\u6392\u5217\u200b\u540e\u200b\u7684\u200b\u6570\u636e\u200b\u5206\u6210\u200b\u591a\u4e2a\u200b\u4e0d\u200b\u76f8\u4ea4\u200b\u5c0f\u200b\u5757\u200b\\(B_1, B_2, \\dots\\)\uff0c\u200b\u6bcf\u4e2a\u200b\u5757\u200b\u57fa\u4e8e\u200b\u4e4b\u524d\u200b\u5386\u53f2\u200b\u5757\u200b\u4fe1\u606f\u200b\u8ba1\u7b97\u200bordered TS\uff0c\u200b\u987a\u5e8f\u200b\u66f4\u65b0\u200b</li> <li>\u200b\u4ece\u200b\u6392\u5217\u200b\\(\\sigma_1, \\dots, \\sigma_n\\) \u200b\u968f\u673a\u200b\u9009\u53d6\u200b\u4e00\u4e2a\u200b\u7528\u4e8e\u200b\u51b3\u5b9a\u200b\u51b3\u7b56\u6811\u200b\u4e2d\u200b\u5185\u90e8\u200b\u8282\u70b9\u200b\u7684\u200b\u5206\u88c2\u200b</li> <li>\u200b\u4f7f\u7528\u200b \\(\\sigma_0\\) \u200b\u6765\u200b\u786e\u5b9a\u200b\u51b3\u7b56\u6811\u200b\u5404\u200b\u53f6\u5b50\u200b\u8282\u70b9\u200b\u7684\u200b\u503c\u200b</li> <li>\u200b\u4f7f\u7528\u200b\u6392\u5217\u200b \\(\\sigma_1, \\dots, \\sigma_n\\) \u200b\u7684\u200b\u5e73\u5747\u200b\u68af\u5ea6\u200b\u503c\u4ee5\u200b\u68af\u5ea6\u200b\u4e0b\u964d\u200b\u66f4\u65b0\u200b\u6a21\u578b\u200b</li> </ol> </li> <li> <p>oblivious decision trees\uff0cdecision table</p> </li> <li>https://blog.csdn.net/Water8L/article/details/138172853</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/gbdt.html","title":"Gbdt","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/gbdt.html#gbdt","title":"GBDT","text":"<p>\u200b\u8bba\u6587\u200b\uff1aGreedy Function Approximation: A Gradient Boosting Machine GBDT: Gradient Boosting Decision Trees Stanford University, Annals of Statistics 2001</p>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/gbdt.html#_1","title":"\u57fa\u672c\u539f\u7406","text":"<p>\u200b\u4e5f\u200b\u79f0\u4e3a\u200b Gradient Boosted Regression Trees (GBRT) \u200b\u6216\u8005\u200b\u662f\u200b Gradient Tree Boosting\uff0c\u200b\u662f\u200bGBM\u200b\u7684\u200b\u4e00\u79cd\u200b\u7279\u4f8b\u200b\uff0c\u200b\u5176\u4e2d\u200b\uff1a  </p> <ul> <li>\u200b\u6bcf\u4e2a\u200b\u5f31\u200b\u5b66\u4e60\u200b\u5668\u200b \\(h_t(x)\\) \u200b\u90fd\u200b\u662f\u200bCART\u200b\u51b3\u7b56\u6811\u200b\u3002</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/gbm.html","title":"Gbm","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/gbm.html#gbm","title":"GBM","text":"<p>\u200b\u8bba\u6587\u200b\uff1aGreedy Function Approximation: A Gradient Boosting Machine GBM: Gradient Boosting Machines Stanford University, Annals of Statistics 2001</p>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/gbm.html#_1","title":"\u57fa\u672c\u539f\u7406","text":"<p>\u200b\u6bcf\u6b21\u200b\u8fed\u4ee3\u200b\u4e2d\u200b\uff0c\u200b\u65b0\u200b\u7684\u200b\u6a21\u578b\u200b\u88ab\u200b\u8bad\u7ec3\u200b\u6765\u200b\u62df\u5408\u200b\u5f53\u524d\u200b\u6a21\u578b\u200b\u9884\u6d4b\u503c\u200b\u4e0e\u200b\u771f\u5b9e\u200b\u503c\u200b\u4e4b\u95f4\u200b\u7684\u200b\u6b8b\u5dee\u200b\u3002\u200b\u8bad\u7ec3\u200b\u96c6\u200b \\(D=\\{(x^i, y^i)\\}_{i=1}^n\\)\uff0c\u200b\u6700\u5927\u200b\u8fed\u4ee3\u200b\u8f6e\u6570\u200b \\(T\\)</p> <ol> <li> <p>\u200b\u521d\u59cb\u6a21\u578b\u200b\uff0c\u200b\u4f7f\u7528\u200b\u4e00\u4e2a\u200b\u7b80\u5355\u200b\u6a21\u578b\u200b\u4f5c\u4e3a\u200b\u521d\u59cb\u6a21\u578b\u200b \\(f_0(x)\\) \uff0c\u200b\u901a\u5e38\u200b\u662f\u200b\u4e00\u4e2a\u200b\u5e38\u6570\u200b\u6a21\u578b\u200b </p> \\[ f_0(x)=\\text{arg }\\mathop{\\text{min}}\\limits_{\\gamma}\\sum_{i=1}^n L(y_i, \\gamma) \\] </li> <li> <p>\u200b\u8fed\u4ee3\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u4f7f\u7528\u200b\u65b0\u200b\u7684\u200b\u6a21\u578b\u200b\u6765\u200b\u4fee\u6b63\u200b\u4e0a\u200b\u4e00\u8f6e\u200b\u7684\u200b\u8bef\u5dee\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u5f53\u524d\u200b\u8fed\u4ee3\u200b\u8f6e\u6b21\u200b\\(t\\)\uff1a</p> <ul> <li> <p>\u200b\u8ba1\u7b97\u200b\u5f53\u524d\u200b\u6a21\u578b\u200b \\(f_{t-1}\\) \u200b\u4e0e\u200b\u76ee\u6807\u503c\u200b \\(y^i\\) \u200b\u6b8b\u5dee\u200b\u7684\u200b\u8d1f\u200b\u68af\u5ea6\u200b</p> \\[ \\tilde{y}^i = -\\frac{\\partial L\\big(y^i - f_{t-1}(x^i)\\big)}{\\partial f_{t-1}(x^i)} \\] </li> <li> <p>\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b \\(h_t(x)\\) \u200b\u6765\u200b\u62df\u5408\u200b\u6b8b\u5dee\u200b\u8d1f\u200b\u68af\u5ea6\u200b</p> </li> <li> <p>\u200b\u5c06\u200b\u6b8b\u5dee\u200b\u68af\u5ea6\u200b\u62df\u5408\u200b\u6a21\u578b\u200b\u6574\u5408\u200b\u5165\u200b\u73b0\u6709\u200b\u6a21\u578b\u200b\u4e2d\u200b (\u200b\u53ef\u200b\u89c6\u4f5c\u200b\u5bf9\u200b\u4e0a\u200b\u4e00\u8f6e\u200b\u6b21\u200b\u6a21\u578b\u200b\u8fdb\u884c\u200b\u68af\u5ea6\u200b\u4e0b\u964d\u200b)</p> \\[ f_t(x) =f_{t-1}(x) + \\eta_t * h_t(x) \\] <p>\\(\\eta_t\\) \u200b\u4e3a\u200b\u5b66\u4e60\u200b\u7387\u200b</p> </li> <li> <p>\u200b\u8bc4\u4f30\u200b\u662f\u5426\u200b\u8fbe\u5230\u200b\u67d0\u4e2a\u200b\u505c\u6b62\u200b\u51c6\u5219\u200b\uff0c\u200b\u5982\u200b\u6700\u5927\u200b\u8fed\u4ee3\u200b\u8f6e\u6b21\u200b\u3001\u200b\u6027\u80fd\u200b\u4e0d\u518d\u200b\u63d0\u5347\u200b\u3001\u200b\u6b8b\u5dee\u200b\u5c0f\u4e8e\u200b\u4e00\u5b9a\u200b\u9608\u503c\u200b\u3002</p> </li> </ul> </li> <li> <p>\u200b\u8f93\u51fa\u200b\u5f3a\u200b\u5206\u7c7b\u5668\u200b \\(F(x) = f_T(x) = \\sum_{i=0}^T \\eta_t * h_t(x)\\)\uff0c\u200b\u56e0\u6b64\u200b</p> </li> </ol> <p>\u200b\u76f4\u63a5\u200b\u5bf9\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u6c42\u5bfc\u200b\uff0c\u200b\u5982\u200b\\(\\mathcal{L} = -\\ln \\frac{1}{1+\\exp^{-x}}\\)    - \\(g=\\frac{-\\exp^{-x}}{1+ \\exp^{-x}} = 1-\\frac{1}{1+\\exp^{-x}} = 1-\\sigma(x)\\)    - \\(h=-\\frac{1}{1+\\exp^{-x}} + -\\frac{1}{(1+\\exp^{-x})^2} = -\\sigma(x) + \\sigma(x)^2 = -\\sigma(x)(1-\\sigma(x))\\) </p><pre><code>In XGBoost, the first-order and second-order gradients are used for optimization during the training process. While decision trees themselves don't have straightforward gradients, XGBoost approximates these gradients by using the Taylor expansion of the loss function.\n\nFor the first-order gradient (the gradient of the loss function), it is often approximated using the negative gradient of the loss function with respect to the current prediction.\n\nFor the second-order gradient, XGBoost approximates the Hessian matrix, which represents the second-order partial derivatives of the loss function with respect to the predictions. This approximation is used to update the leaf values in the tree.\n\nHere's a simple example to illustrate how these gradients are used in XGBoost:\n\nGiven a dataset with input features ( x ) and target ( y ), XGBoost starts with an initial prediction ( \\hat{y}_0 ) for each sample.\n\nFor a given loss function (e.g., squared error loss), XGBoost computes the first-order gradient (negative gradient) and the second-order gradient for each sample based on the current predictions.\n\nIt then fits a decision tree to the negative gradient values, and for the second-order gradient, it approximates the Hessian matrix to update the leaf values in the tree.\n\nThe new tree captures the residual between the true target and the current prediction, and the leaf values are updated based on the Hessian approximation.\n\nThe updated tree is added to the ensemble, and the predictions are improved by considering the ensemble's combined output.\n\nIn summary, XGBoost uses the first-order and second-order gradients to guide the process of fitting decision trees, effectively optimizing the model's parameters to minimize the loss function.\n</code></pre><p></p>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/lightgbm.html","title":"Lightgbm","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/lightgbm.html#lightgbm","title":"LightGBM","text":"<p>\u200b\u8bba\u6587\u200b\uff1aLightGBM: A Highly Efficient Gradient Boosting Decision Tree MSR &amp; Peking University, NIPS 2017</p>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/lightgbm.html#_1","title":"\u57fa\u672c\u539f\u7406","text":"<ul> <li>https://zhuanlan.zhihu.com/p/627313748  </li> <li>\u200b\u4e5f\u200b\u79f0\u4f5c\u200blgb</li> <li>GOSS\uff1agradient-based one-side sampling  </li> <li>EFB: exclusive feature bundling  </li> <li>Stochastic Gradient Boosting</li> <li>definition 3.1: \\(\\frac{1}{n}*(\\frac{(n_lg_l)^2}{n_l} + \\frac{(n_rg_r)^2}{n_r})=\\frac{n_lg_l^2 + n_rg_r^2}{n}\\)</li> <li>alg. 3 alg. 4</li> <li><code>for_col_wise=True</code>\uff0chttps://www.cnblogs.com/travel92/p/18824909\uff0c\u200b\u5217\u200bWISE\u200b\u51cf\u5c11\u200b\u5185\u5b58\u200b\u5360\u7528\u200b\uff0c\u200b\u9002\u5408\u200bCPU\u200b\u6838\u5fc3\u200b\u8d85\u591a\u200b\u7684\u200b\uff0c\u200b\u884c\u200bWISE\u200b\u4f1a\u200bDOUBLE\u200b\u5185\u5b58\u200b\u5360\u7528\u200b\uff0c\u200b\u9002\u5408\u200bCPU\u200b\u6838\u5fc3\u200b\u6ca1\u6709\u200b\u90a3\u4e48\u200b\u591a\u200b\u7684\u200b\u3002</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/lightgbm.html#pypi","title":"PyPI","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/lightgbm.html#_2","title":"\u5e93\u200b\u5b89\u88c5","text":"<ol> <li>\u200b\u81ea\u52a8\u200b\u517c\u5bb9\u200b<code>org.lightgbm.predict4j</code> <code>pip install lightgbm==2.0.4</code>\uff0c\u200b\u8f93\u51fa\u200b\u7684\u200bgbdt\u200b\u6587\u4ef6\u200b\u4f1a\u200b\u81ea\u52a8\u200b\u5305\u542b\u200b<code>default_value</code>\u200b\u5b57\u200b\u6bb5\u200b</li> <li> <p>\u200b\u624b\u52a8\u200b\u517c\u5bb9\u200b<code>org.lightgbm.predict4j</code> <code>pip install lightgbm</code>\uff0c\u200b\u8f93\u51fa\u200b\u7684\u200bgbdt\u200b\u6587\u4ef6\u200b\u5df2\u5f03\u200b\u7528\u200b<code>default_value</code>\u200b\u5b57\u200b\u6bb5\u200b\uff0c\u200b\u9700\u200b\u624b\u52a8\u200b\u517c\u5bb9\u200b     </p>compliant_org.lightgbm.predict4j<pre><code>for line in f_in:\n    f_out.write(line)\n    if line.startswith('decision_type'):\n        num = len(line.strip().split())\n        f_out.write(f'default_value={\" \".join([\"0\"]*num)}\\n')\n    f_out.flush()\n</code></pre><p></p> <p>\u200b\u65b0\u200b\u7248\u672c\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u66f4\u597d\u200b</p> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/lightgbm.html#_3","title":"\u6570\u636e\u200b\u52a0\u8f7d","text":"<ol> <li> <p><code>lgb.Dataset</code> </p><pre><code>def __init__(self,\n    data,                           # x, Union[numpy, array, scipy.sparse]\n    label=None,                     # y, Optional[list, 1-D array]\n    max_bin=255,                    # int, max number of discrete bin for features\n    reference=None,                 # used for dev_set referring to train_set\n    weight=None,                    # Optional[list, 1-D array], weight for each instance\n    group=None,                     # Optional[list, 1-D array]\n                                        # rank: \n                                        # regression and classification: \u200b\u4e00\u822c\u200b\u4e0d\u7528\u200b\n    silent=False,                   # bool, \u200b\u662f\u5426\u200b\u9009\u62e9\u200b\u9759\u9ed8\u200b\u6d01\u51c0\u200b\u6a21\u5f0f\u200b\uff0c\u200b\u4e0d\u200b\u8f93\u51fa\u200b\u6784\u5efa\u200b\u6a21\u578b\u200b\u4e2d\u200b\u7684\u200b\u7ec6\u8282\u200b\n    feature_name='auto',            # \u200b\u6307\u5b9a\u200b\u5404\u200b\u7279\u5f81\u200b\u540d\u5b57\u200b\n    categorial_feature='auto',      # \u200b\u6307\u5b9a\u200b\u5404\u200b\u5206\u7c7b\u200b\u7279\u5f81\u200b\u540d\u5b57\u200b\n    params=None,\n    free_raw_data=True              # bool, \u200b\u662f\u5426\u200b\u5728\u200b\u6784\u5efa\u200b\u5185\u90e8\u200b\u6570\u636e\u200b\u96c6\u540e\u200b\u91ca\u653e\u200b\u539f\u59cb\u6570\u636e\u200b\n)\n</code></pre><p></p> </li> <li> <p>\u200b\u4f2a\u200b\u4ee3\u7801\u200b </p><pre><code>import lightgbm as lgb\n\nmodel = None        # \u200b\u521d\u59cb\u5316\u200b F_{epoch-0} \u200b\u9636\u6bb5\u200b\u6a21\u578b\u200b\nfor epoch in range(1, epoch_num + 1):\n    for batch_samples in get_batch_samples(data=train_data_set, batch_size=batch_size, shuffle=True, noleft=True):\n        '''\n            1. get `train_tokens` and `y_labels` from batch_samples\n            2. build spare_vector `x_trains` from train_tokens\n        '''\n        train_data = lightgbm.Dataset(x_trains, label=np.array(y_trains))\n        '''\n            3. load or sample `valid_data` from `x_valids` and `y_valids`\n            4. set `valid_data` reference to `train_data`\n        '''\n        valid_data = lightgbm.Dataset(x_valids, label=np.array(y_valids), reference=train_data)\n</code></pre><p></p> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/lightgbm.html#params","title":"params","text":"<pre><code>params = {\n    'objective': 'binary',      # Union[str, callable], \u200b\u76ee\u6807\u200bloss\u200b\u51fd\u6570\u200b\n    'boosting': 'gbdt',         # \u200b\u9009\u62e9\u200bboost\u200b\u7c7b\u578b\u200b\n\n    'metric': 'binary',         # \n    'num_leaves': 31,           # \u200b\u6307\u5b9a\u200b\u6bcf\u9897\u200b\u6811\u200b\u6700\u5927\u200b\u53f6\u200b\u8282\u70b9\u200b\u6570\u200b\uff0c\u200b\u9ed8\u8ba4\u503c\u200b\u4e3a\u200b31\n    'max_depth': -1,            # \u200b\u6307\u5b9a\u200b\u6bcf\u68f5\u200b\u6811\u200b\u7684\u200b\u6700\u5927\u200b\u6df1\u5ea6\u200b\uff0c\u200b\u9ed8\u8ba4\u200b\u4e3a\u200b-1\uff0c\u200b\u8868\u793a\u200b\u65e0\u200b\u9650\u5236\u200b\n    'min_data_in_leaf': 20,     # \u200b\u6307\u5b9a\u200b\u6bcf\u4e2a\u200b\u53f6\u5b50\u200b\u8282\u70b9\u200b\u4e0a\u200b\u5fc5\u987b\u200b\u5305\u542b\u200b\u7684\u200b\u6700\u5c0f\u200b\u6837\u672c\u6570\u200b\uff0c\u200b\u9ed8\u8ba4\u503c\u200b\u4e3a\u200b20\n    'max_bin': 255,             # \u200b\u6700\u4f73\u200b\u5212\u5206\u200b\u70b9\u200b\u7b97\u6cd5\u200b\u65f6\u200b\u6bcf\u4e2a\u200b\u7279\u5f81\u200b\u6700\u5927\u200b\u5206\u6876\u200b\u6570\u91cf\u200b\uff0c\u200b\u9ed8\u8ba4\u200b\u4e3a\u200b255\n    'feature_fraction': 0.9,    # feature(column) subsampling fraction\uff0c\u200b\u9ed8\u8ba4\u503c\u200b\u4e3a\u200b1.0\n    'data_sample_strategy'='bagging', \n                                # instance(row) subsampling \u200b\u7b56\u7565\u200b\uff0c{**bagging**, goss}\n    'bagging_fraction': 0.9,    # instance(row) subsampling fraction\uff0c\u200b\u9ed8\u8ba4\u503c\u200b\u4e3a\u200b1.0\n    'bagging_freq': 5,          # \u200b\u6307\u5b9a\u200bbagging\u200b\u9891\u6b21\u200b\uff0c\u200b\u5373\u200b\u6267\u884c\u200b\u4e00\u6b21\u200bbagging\u200b\u64cd\u4f5c\u200b\u7684\u200b\u8f6e\u6b21\u200b\u5468\u671f\u200b\uff0c\u200b\u9ed8\u8ba4\u503c\u200b\u4e3a\u200b0\n    'device': 'cpu',            # \u200b\u6307\u5b9a\u200b\u8fd0\u884c\u200b\u8bbe\u5907\u200b\uff0c{**cpu**, gpu, cuda}\n    'learning_rate': 0.1,       # \u200b\u6bcf\u8f6e\u200b\u8fed\u4ee3\u200b\u7684\u200b\u5b66\u4e60\u200b\u7387\u200b\uff0c\u200b\u53ef\u200b\u901a\u8fc7\u200b\u6bcf\u6b21\u200bepoch\u200b\u6216\u200b\u6307\u5b9a\u200bstep\u200b\u65f6\u200b\u4fee\u6539\u200b\u5b57\u5178\u200b\u503c\u4ee5\u200b\u5b9e\u65f6\u200b\u66f4\u65b0\u200blr\n    'verbose': 0                # \u200b\u63a7\u5236\u200b\u65e5\u5fd7\u200b\u8f93\u51fa\u200b\u7b49\u7ea7\u200b\n}\n</code></pre> key aliases details objective objective_typeappapplicationloss <ol><li>\u200b\u56de\u5f52\u200b\u4efb\u52a1\u200b</li><ul><li>regression/regression_l2/mean_squared_error/mse</li><li>regiression_l1/mean_absolute_error/mae</li><li>huber </li><li>fair </li><li>possion </li><li>quanile </li><li>quanile_l2</li></ul> <li>\u200b\u5206\u7c7b\u200b\u4efb\u52a1\u200b</li> <ul><li>binary\uff0c\u200b\u8981\u6c42\u200b\u6807\u7b7e\u200b\u4e3a\u200b{0, 1}</li><li>multiclass/softmax</li><li>mlticlassova/multiclass_ova/ova/ovr</li></ul> <li>\u200b\u6392\u5e8f\u200b\u4efb\u52a1\u200b</li> <ul><li>lambdarank</li><li>rank_xendcg</li></ul> </ol> boosting boosting_typeboost <li>gbdt\uff0c\u200b\u68af\u5ea6\u200b\u51b3\u7b56\u200b\u63d0\u5347\u200b\u6811\u200b</li> <li>dart\uff0cDropouts meet Multiple Additive Regression Trees</li> <li>goss\uff0c\u200b\u57fa\u4e8e\u200b\u68af\u5ea6\u200b\u7684\u200b\u5355\u8fb9\u200b\u91c7\u6837\u200b</li> <li>rf\uff0crandom forest</li> num_leaf number_leavesmax_leavesmax_leafmax_leaf_nodes \u200b\u6307\u5b9a\u200b\u6bcf\u9897\u200b\u6811\u200b\u6700\u5927\u200b\u53f6\u200b\u8282\u70b9\u200b\u6570\u200b\uff0c31 min_data min_data_in_leafmin_data_per_leafmin_child_samplesmin_samples_leaf \u200b\u6307\u5b9a\u200b\u6bcf\u4e2a\u200b\u53f6\u5b50\u200b\u8282\u70b9\u200b\u4e2d\u200b\u6700\u5c0f\u200b\u6837\u672c\u6570\u200b\uff0c20 max_depth \u200b\u6307\u5b9a\u200b\u6bcf\u68f5\u200b\u6811\u200b\u7684\u200b\u6700\u5927\u200b\u6df1\u5ea6\u200b\uff0c-1 \u200b\u8868\u793a\u200b\u65e0\u200b\u9650\u5236\u200b max_bin max_bins \u200b\u6307\u5b9a\u200b\u83b7\u53d6\u200b\u6700\u4f73\u200b\u5212\u5206\u200b\u70b9\u65f6\u200b\u5404\u200b\u7279\u5f81\u200b\u6700\u5927\u200b\u5206\u6876\u200b\u6570\u200b\uff0c255 feature_fraction sub_featurecolsample_bytree \u200b\u7279\u5f81\u200b(\u200b\u5217\u200b)\u200b\u90e8\u5206\u200b\u91c7\u6837\u200b\u6bd4\u4f8b\u200b\uff0c1.0 bagging_fraction sub_rowsubsamplebagging \u200b\u6837\u672c\u200b(\u200b\u884c\u200b)\u200b\u90e8\u5206\u200b\u91c7\u6837\u200b\u6bd4\u4f8b\u200b\uff0c1.0 bagging_freq subsample_freq \u200b\u6837\u672c\u200b(\u200b\u884c\u200b)\u200b\u90e8\u5206\u200b\u91c7\u6837\u200b\u6267\u884c\u200b\u7684\u200b\u8f6e\u6b21\u200b\u95f4\u9694\u200b\u6570\u200b\uff0c0 \u200b\u8868\u793a\u200b\u4e0d\u200b\u8fdb\u884c\u200bbagging data_sample_strategy \u200b\u8f6e\u6b21\u200b\u8fed\u4ee3\u200b\u65f6\u200b\u6837\u672c\u200b\u91c7\u6837\u200b\u7b56\u7565\u200b<li>bagging\uff0c\u200b\u5f53\u4e14\u200b\u4ec5\u200b\u5f53\u200b<code>bagging_fraction &lt; 1.0 and bagging_freq &gt; 0</code> \u200b\u65f6\u200b\u751f\u6548\u200b</li><li>goss</li> learning_rate shrinkage_rateeta \u200b\u5b66\u4e60\u200b\u7387\u200b\uff0c0.1 device device_type \u200b\u6307\u5b9a\u200b\u8fd0\u884c\u200b\u8bbe\u5907\u200b\uff0c{cpu, gpu, cuda}\uff0c\u200b\u5728\u200blinux\u200b\u7cfb\u7edf\u200b\u4e0a\u80fd\u200b\u76f4\u63a5\u200b\u8fd0\u884c\u200bgpu verbose \u200b\u65e5\u5fd7\u200b\u8f93\u51fa\u200b\u7b49\u7ea7\u200b<li>0: \u200b\u65e0\u200b\u8f93\u51fa\u200b</li><li>1: \u200b\u6bcf\u68f5\u200b\u6811\u200b\u8bad\u7ec3\u200b\u5b8c\u65f6\u200b\u8f93\u51fa\u200b\u8fdb\u5ea6\u200b\u4fe1\u606f\u200b</li><li> 2: \u200b\u8f93\u51fa\u200b\u5305\u62ec\u200b\u6bcf\u68f5\u200b\u6811\u200b\u8bc4\u4f30\u200b\u7ed3\u679c\u200b\u7684\u200b\u8bad\u7ec3\u200b\u4fe1\u606f\u200b</li> <p>https://lightgbm.readthedocs.io/en/v4.4.0/GPU-Windows.html https://github.com/microsoft/LightGBM/issues/5989 https://juejin.cn/post/7362844486560137228</p>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/lightgbm.html#api","title":"API","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/lightgbm.html#data-structure-api","title":"Data Structure API","text":"<ol> <li>Booster <pre><code>bst = lightgbm.Booster(model_file=model_path + model_file_name)\nx_tests = get_sparse_vector(get_by_index(ngrams, batch_idx), feats, n_feats)\npreds = bst.predict(x_tests)\n</code></pre></li> <li>Dataset</li> </ol>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/lightgbm.html#training-api","title":"Training API","text":"<ul> <li>train</li> <li>cv <pre><code>```java\ntry {\n    LightGBMModelConvertor.convert(\n        txt_model_file,\n        dat_model_file\n    );\n} catch (Exception e) {\n    System.out.println(\"\");\n}\n</code></pre></li> </ul>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/lightgbm.html#utils","title":"Utils","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/lightgbm.html#prechecker_tokenization","title":"prechecker_tokenization","text":"prechecker_tokenization.py<pre><code>from wheel_utils.char_alpha_numeric import PyTokenizer\nimport random\nfrom tqdm import tqdm\nimport os\nimport json\n\n\ndef uni_label(label):\n    raise Exception(\"todo: \u200b\u81ea\u5b9a\u4e49\u200buni_label\u200b\u51fd\u6570\u200b\")\n    if label in {'0', 'normal', 'other'}:\n        return 0\n    elif label in {'1', '2', '3'} or 'tag_' in label:\n        return 1\n    else:\n        raise ValueError\n\n\ndef read_dataset(path, file_name):\n    ret = []\n    n0, n1 = 0, 0\n    with open(path + file_name, 'r', encoding='utf-8') as f:\n        for line in tqdm(f, desc=\"reading total dataset\"):\n            line = json.loads(line)\n            cnt = line.get('content')\n            lbl = uni_label(line.get('label'))\n            line['label'] = lbl\n            ret.append(line)\n            if lbl == 1:\n                n1 += 1\n            elif lbl == 0:\n                n0 += 1\n    print(f'in {file_name}:\\n  #label_0: {n0}\\n  #label_1: {n1}')\n    return ret\n\n\ndef split_train_valid_dataset(dataset, tokenize_types, pp, path, train_percent=0.9, rewrite=False):\n    \"\"\"\n        pp: \u200b\u6b63\u200b\u6837\u672c\u200b\u589e\u5f3a\u200b\u500d\u6570\u200b\n        train_percent: \u200b\u8bad\u7ec3\u200b\u96c6\u79cd\u200b\u6570\u636e\u200b\u5360\u200b\u6240\u6709\u200b\u6570\u636e\u200b\u7684\u200b\u6bd4\u4f8b\u200b\n    \"\"\"\n    if not rewrite and (os.path.exists(path + 'train.json') or os.path.exists(path + 'valid.json')):\n        raise ValueError(\"train.json or valid.json already exist and rewrite is unavailable!!!\")\n\n    random.shuffle(dataset)\n    n_train, n_valid = 0, 0\n    with open(path + 'train.json', 'w', encoding='utf-8') as f_train, \\\n            open(path + 'valid.json', 'w', encoding='utf-8') as f_valid:\n        for line in tqdm(dataset, desc=\"split train &amp; valid dataset\"):\n            lbl = int(line['label'])\n            cnt = line['content']\n            if random.uniform(0, 1) &lt; train_percent:\n                ret = {'label': lbl}\n                for tokenize_type in tokenize_types:\n                    # tokenized already\n                    if tokenize_type in line:\n                        tokens = line[tokenize_type]\n                    # tokenize now\n                    else:\n                        tokens = tokenize(cnt, tokenize_type)\n                    ret[tokenize_type] = tokens\n\n                for _ in range(1 if lbl == 0 else pp):\n                    f_train.write(json.dumps(ret, ensure_ascii=False) + '\\n')\n                    f_train.flush()\n                    n_train += 1\n            else:\n                ret = {'label': lbl}\n                for tokenize_type in tokenize_types:\n                    # tokenized already\n                    if tokenize_type in line:\n                        tokens = line[tokenize_type]\n                    # tokenize now\n                    else:\n                        tokens = tokenize(cnt, tokenize_type)\n                    ret[tokenize_type] = tokens\n                f_valid.write(json.dumps(ret, ensure_ascii=False) + '\\n')\n                f_valid.flush()\n                n_valid += 1\n    print(f'using tokenize_types: {tokenize_types} and with positive sample augment of \u3010{pp}\u3011, get'\n          f'  \\n#train_dataset: {n_train}  \\n#valid_dataset: {n_valid}')\n\n\ndef tokenize(text, tokenize_type):\n    if tokenize_type == 'char':\n        tokens = char_tokenize(text)\n    elif tokenize_type == 'sound':\n        tokens = sound_tokenize(text, py_tokenizer)\n    else:\n        raise ValueError(f\"{tokenize_type} is an invalid tokenize type!!!\")\n    return tokens\n\n\ndef char_tokenize(text):\n    return list(text)\n\n\ndef sound_tokenize(text, py_tokenizer):\n    sound = py_tokenizer.lazy_pinyin(text)\n    return [c if not c.startswith('##') else c[2:] for c in sound]\n\n\nif __name__ == \"__main__\":\n    tokenize_types = ['char', 'sound']\n    pp = 5  # \u200b\u6b63\u200b\u6837\u672c\u200b\u589e\u5f3a\u200b\n    train_percent = 0.9\n    rewrite = False\n    path = './../data/prechecker/dataset/'\n    file_name = \"data.json\"\n    sound_file = r'E:\\JAVA\\project_files\\text-classification\\textalg-check\\src\\main\\resources\\64_politics/char_meta.txt'\n\n    py_tokenizer = PyTokenizer(\n        sound_file,\n        file_type=\"csv_1_2\"\n    )\n\n    dataset = read_dataset(path, file_name)\n    split_train_valid_dataset(\n        dataset=dataset,\n        tokenize_types=tokenize_types,\n        pp=pp,\n        path=path,\n        train_percent=train_percent,\n        rewrite=rewrite\n    )\n</code></pre>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/lightgbm.html#prechecker_features","title":"prechecker_features","text":"prechecker_features.py<pre><code>import json\nfrom scipy.sparse import csr_matrix\nfrom math import log2\nfrom tqdm import tqdm\nfrom collections import Counter\n\n\ndef get_ngram(tokens, N):\n    \"\"\"\n    get [1, N]-grams\n    \"\"\"\n    ngrams = Counter(tokens)\n    n = 2\n    while n &lt;= N and n &lt;= len(tokens):\n        tmps = [\"\".join(tokens[i:i + n]) for i in range(0, len(tokens) - n)]\n        ngrams.update(tmps)\n        n = n + 1\n    return ngrams\n\n\ndef get_topk_features(batch_tokens, feature_top_k=20000, feature_min_freq=10):\n    term_freqs = Counter()\n    for item in batch_tokens:\n        term_freqs.update(item)\n    term_freqs = term_freqs.most_common(feature_top_k)\n    vocab = {x[0] for x in term_freqs if x[1] &gt; feature_min_freq}\n    print(\"Get %d ngrams with min_freq=%d\" % (len(vocab), feature_min_freq))\n    return vocab\n\n\ndef chi_square(a, b, c, d):\n    \"\"\"\n    chi_square = \\frac{n*(ad - bc)^2}{(a+b)(c+d)(a+c)(b+d)}\n        - |ad-bc|\u200b\u8d8a\u5c0f\u200b,\u200b\u7279\u5f81\u200b\u548c\u200b\u7c7b\u522b\u200b\u76f8\u5173\u6027\u200b\u8d8a\u5c0f\u200b\n        - |ad-bc|\u200b\u8d8a\u5927\u200b,\u200b\u7279\u5f81\u200b\u548c\u200b\u7c7b\u522b\u200b\u76f8\u5173\u6027\u200b\u8d8a\u5927\u200b\n    :param N11: a, \u200b\u8868\u793a\u200b\u540c\u65f6\u200b\u5177\u6709\u200b\u4e24\u79cd\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b\n    :param N10: b, \u200b\u8868\u793a\u200b\u5177\u6709\u200b\u7b2c\u4e00\u4e2a\u200b\u5c5e\u6027\u200b\u4f46\u200b\u4e0d\u200b\u5177\u6709\u200b\u7b2c\u4e8c\u4e2a\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b\n    :param N01: c, \u200b\u8868\u793a\u200b\u4e0d\u200b\u5177\u6709\u200b\u7b2c\u4e00\u4e2a\u200b\u5c5e\u6027\u200b\u4f46\u200b\u5177\u6709\u200b\u7b2c\u4e8c\u4e2a\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b\n    :param N00: d, \u200b\u8868\u793a\u200b\u540c\u65f6\u200b\u4e0d\u200b\u5177\u6709\u200b\u8fd9\u200b\u4e24\u79cd\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b\n    :return:\n    \"\"\"\n    fenzi = (a + b + c + d) * (a * d - b * c) * (a * d - b * c)\n    fenmu = (a + b) * (c + d) * (a + c) * (b + d)\n    if fenmu == 0:\n        return 0\n    return fenzi * 1.0 / fenmu\n\n\ndef multual_infomation(a, b, c, d):\n    \"\"\"\n    multual_infomation =\\sum_{x \\in X}\\sum_{y \\in Y} p(x,y)\\log\\frac{p(x,y)}{p(x)p(y)}\n    :param N_11: a, \u200b\u8868\u793a\u200b\u540c\u65f6\u200b\u5177\u6709\u200b\u4e24\u79cd\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b\n    :param N_10: b, \u200b\u8868\u793a\u200b\u5177\u6709\u200b\u7b2c\u4e00\u4e2a\u200b\u5c5e\u6027\u200b\u4f46\u200b\u4e0d\u200b\u5177\u6709\u200b\u7b2c\u4e8c\u4e2a\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b\n    :param N_01: c, \u200b\u8868\u793a\u200b\u4e0d\u200b\u5177\u6709\u200b\u7b2c\u4e00\u4e2a\u200b\u5c5e\u6027\u200b\u4f46\u200b\u5177\u6709\u200b\u7b2c\u4e8c\u4e2a\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b\n    :param N_00: d, \u200b\u8868\u793a\u200b\u540c\u65f6\u200b\u4e0d\u200b\u5177\u6709\u200b\u8fd9\u200b\u4e24\u79cd\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b\n    :return:\n    \"\"\"\n    n = (a + b + c + d) * 1.\n    I_UC = (a / n) * log2((a * n * 1.) / ((a + b) * (a + c))) + \\\n           (b / n) * log2((b * n * 1.) / ((a + b) * (b + d))) + \\\n           (c / n) * log2((c * n * 1.) / ((c + d) * (a + c))) + \\\n           (d / n) * log2((d * n * 1.) / ((c + d) * (b + d)))\n    return I_UC\n\n\ndef jaccard(a, b, c, d):\n    \"\"\"\n    jaccard = \\frac{|A\u2229B|}{|A| + |B| - |A\u2229B|}\n    :param N11: a, \u200b\u8868\u793a\u200b\u540c\u65f6\u200b\u5177\u6709\u200b\u4e24\u79cd\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b\n    :param N10: b, \u200b\u8868\u793a\u200b\u5177\u6709\u200b\u7b2c\u4e00\u4e2a\u200b\u5c5e\u6027\u200b\u4f46\u200b\u4e0d\u200b\u5177\u6709\u200b\u7b2c\u4e8c\u4e2a\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b\n    :param N01: c, \u200b\u8868\u793a\u200b\u4e0d\u200b\u5177\u6709\u200b\u7b2c\u4e00\u4e2a\u200b\u5c5e\u6027\u200b\u4f46\u200b\u5177\u6709\u200b\u7b2c\u4e8c\u4e2a\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b\n    :param N00: d, \u200b\u8868\u793a\u200b\u540c\u65f6\u200b\u4e0d\u200b\u5177\u6709\u200b\u8fd9\u200b\u4e24\u79cd\u200b\u5c5e\u6027\u200b\u7684\u200b\u4e2a\u4f53\u200b\u6570\u91cf\u200b\n    \"\"\"\n    return a*1./(b + c)\n\n\ndef term_frequency(t_freq, doc_freq):\n    return t_freq / (1. + doc_freq)\n\n\ndef select_features(batch_tokens, token2id, feature_type='chi'):\n    if feature_type not in {'chi', 'freq', 'mi'}:\n        raise ValueError('feature_type should in {\"chi\", \"freq\", \"mi\"}')\n\n    n0 = len(batch_tokens[0])\n    n1 = len(batch_tokens[1])\n    feature = []\n\n    if feature_type in ['chi', 'mi']:\n        N = [[0, 0] for _ in range(len(token2id))]\n\n        # count N_0x\n        for tokens in tqdm(batch_tokens[0]):\n            for token in tokens:\n                ret = token2id.get(token, None)\n                if ret:\n                    N[ret][0] += 1\n\n        # count N_1x\n        for tokens in tqdm(batch_tokens[1]):\n            for token in tokens:\n                ret = token2id.get(token, None)\n                if ret:\n                    N[ret][1] += 1\n\n        for token, idx in tqdm(token2id.items(), desc=f'calculate {feature_type}'):  # \u200b\u662f\u5426\u200b\u5305\u542b\u200b\u8bcd\u200bt / \u200b\u662f\u5426\u200b\u5c5e\u4e8e\u200b\u76ee\u6807\u200b\u7c7b\u522b\u200b.\n            N_11 = N[idx][1]\n            N_10 = N[idx][0]\n            N_01 = n1 - N_11\n            N_00 = n0 - N_10\n\n            if N_00 * N_01 * N_10 * N_11 == 0:\n                continue\n\n            # \u200b\u4e92\u4fe1\u606f\u200b\u8ba1\u7b97\u200b\n            if feature_type == \"mi\":\n                metric_score = multual_infomation(N_11, N_10, N_01, N_00)\n            # \u200b\u5361\u65b9\u200b\u8ba1\u7b97\u200b\n            else:\n                metric_score = chi_square(N_11, N_10, N_01, N_00)\n            feature.append((token, metric_score))\n\n    elif feature_type in ['freq']:\n        doc_cnt = len(batch_tokens[1])\n        xxx = [0] * len(token2id)\n        for tokens in tqdm(batch_tokens[1]):\n            for token in tokens:\n                ret = token2id.get(token, None)\n                if ret:\n                    xxx[ret] += 1\n\n        for token in tqdm(token2id, desc=f'calculate {feature_type}'):\n            # C\u200b\u7c7b\u200b\u6587\u6863\u200b\u96c6\u200b\u5305\u542b\u200b\u8bcd\u9879\u200bt\u200b\u7684\u200b\u6587\u6863\u200b\u6570\u200b\n            t_doc_cnt = xxx[token2id[token]]\n            metric_score = term_frequency(t_doc_cnt, doc_cnt)\n            feature.append((token, metric_score))\n        # feature.sort(key=lambda x: x[1], reverse=True)\n    return feature\n\n\nclass FeatureMap:\n    def __init__(self,\n                 feature_path,\n                 feature_names):\n        self.feature_path = feature_path\n        self.feature_names = feature_names\n        self.feature_word_score_index = self.read_features()\n\n    def read_features(self):\n        feature_word_score_index = []\n        for feature_name in self.feature_names:\n            word_score_index = dict()\n            with open(self.feature_path + feature_name, 'r', encoding='utf-8') as f:\n                for line in f:\n                    line = json.loads(line)\n                    word = line.get('w')\n                    score = line.get('score')\n                    index = line.get('id')\n                    word_score_index[word] = (score, index)\n            feature_word_score_index.append(word_score_index)\n            print(f'from {feature_name} reading {len(word_score_index)} features')\n        return feature_word_score_index\n\n    def build_sparse_vector(self, batch_tokens):\n        batch_sparse_vector = []\n        for tokens in batch_tokens:\n            sparse_vector = [0.] * sum(\n                [len(feature_word_score_index) for feature_word_score_index in self.feature_word_score_index])\n\n            prefix = 0\n            for i in range(len(tokens)):\n                for token in tokens[i]:\n                    ret = self.feature_word_score_index[i].get(token, None)\n                    if ret:\n                        sparse_vector[ret[1] + prefix] = ret[0]\n                prefix += len(self.feature_word_score_index[i])\n\n            batch_sparse_vector.append(sparse_vector)\n        return csr_matrix(batch_sparse_vector)\n\n\ndef read_batch_tokens(path, file_name, tokenize_type, N, top_k=20000, feature_min_freq=10):\n    batch_tokens = [[], []]\n    with open(path + file_name, 'r', encoding='utf-8') as f:\n        for i, line in enumerate(tqdm(f, desc=f'reading tokens file')):\n            # {\"label\": lbl, feature_type: tokens ...}\n            line = json.loads(line)\n            lbl = line['label']\n            tokens = line[tokenize_type]\n            batch_tokens[lbl].append(get_ngram(tokens, N))\n\n    # using positive samples to generate feature vocabulary\n    vocab = get_topk_features(batch_tokens[1], feature_top_k=top_k, feature_min_freq=feature_min_freq)\n    token2id = {x: i for i, x in enumerate(vocab)}\n    return batch_tokens, token2id\n\n\nif __name__ == \"__main__\":\n    feature_types = ['chi', 'freq', 'mi']\n    tokenize_types = ['char', 'sound']\n    N = 3\n    top_k = 20000\n    min_freq = 10\n    feature_path = './../data/prechecker/features/'\n    token_path = \"./../data/prechecker/dataset/\"\n    token_file_name = 'train.json'\n\n    for tokenize_type in tokenize_types:\n        batch_tokens, token2id = read_batch_tokens(token_path, token_file_name, tokenize_type, N,\n                                                   top_k=top_k, feature_min_freq=min_freq)\n\n        for feature_type in feature_types:\n            feature = select_features(batch_tokens, token2id, feature_type)\n            with open(feature_path + f'{N}-gram_{tokenize_type}_{feature_type}.txt', 'w', encoding='utf-8') as f:\n                for i, feat in enumerate(feature):\n                    f.write(json.dumps({'id': i, 'score': feat[1], 'w': feat[0]},\n                                       ensure_ascii=False) + '\\n')\n                    f.flush()\n</code></pre>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/lightgbm.html#prechecker_lightgbm","title":"prechecker_lightgbm","text":"prechecker_lightgbm.py<pre><code>import random\nfrom prechecker_features import FeatureMap\nimport json\nimport lightgbm\nimport numpy as np\nfrom tqdm import tqdm\n\n\ndef get_batch_samples(data, batch_size, shuffle=False, noleft=True):\n    n = len(data)\n    idxs = list(range(n))\n    if shuffle:\n        random.shuffle(idxs)\n\n    start = 0\n    for i in range(n // batch_size):\n        yield [data[idx] for idx in idxs[start: start + batch_size]]\n        start += batch_size\n\n    if noleft and start &lt; n:\n        yield [data[idx] for idx in idxs[start:]]\n\n\nif __name__ == \"__main__\":\n    feature_types = ['chi', 'freq', 'mi']\n    tokenize_types = ['char', 'sound']\n    N = 3\n    epochs = 5\n    batch_size = 10000\n    n_valid = 500\n    learning_rate = 0.1\n\n    param = {\n        'objective': 'binary',\n        'metric': 'binary',\n        'learning_rate': 0.1,\n        'boosting_type': 'gbdt',\n        'feature_fraction': 0.9,        # feature dropout\n        'bagging_fraction': 0.9,        # bagging dropout\n        'bagging_freq': 5\n    }\n\n    feature_path = \"./../data/prechecker/features/\"\n    token_path = \"./../data/prechecker/dataset/\"\n    model_path = \"./../data/prechecker/gbdts/\"\n\n    feature_map = FeatureMap(\n        feature_path,\n        [f'{N}-gram_{tokenize_type}_{feature_type}.txt'\n         for feature_type in feature_types\n         for tokenize_type in tokenize_types]\n    )\n\n    train_data_set = []\n    with open(token_path + 'train.json', 'r', encoding='utf-8') as f_tok:\n        for tok in tqdm(f_tok):\n            tok = json.loads(tok)\n            lbl = tok['label']\n            tokens = [tok[tokenize_type] for tokenize_type in tokenize_types]\n            train_data_set.append([lbl] + tokens)\n\n    valid_data_set = []\n    with open(token_path + 'valid.json', 'r', encoding='utf-8') as f_tok:\n        for tok in tqdm(f_tok):\n            tok = json.loads(tok)\n            lbl = tok['label']\n            tokens = [tok[tokenize_type] for tokenize_type in tokenize_types]\n            valid_data_set.append([lbl] + tokens)\n\n    model = None\n    for epoch in range(epochs):\n        print(f\"############### EPOCH-{epoch+1} ###############\")\n        n_step = 1\n        new_lr = learning_rate * (epochs - epoch) / epochs\n        print(\"learning = \" + str(new_lr))\n        param[\"learning_rate\"] = new_lr\n        for batch_samples in get_batch_samples(train_data_set, batch_size, True):\n            # \u200b\u7279\u5f81\u5411\u91cf\u200b\u4e0e\u200b\u6807\u7b7e\u200b\u5411\u91cf\u200b.\n            train_labels = [sample[0] for sample in batch_samples]\n            train_tokens = [sample[1:] for sample in batch_samples]\n            x_trains = feature_map.build_sparse_vector(train_tokens)\n            y_trains = train_labels\n            # \u200b\u6570\u636e\u200b\u96c6\u200b.\n\n            valid_samples = random.sample(valid_data_set, k=n_valid)\n            valid_tokens = [sample[1:] for sample in valid_samples]\n            x_valids = feature_map.build_sparse_vector(valid_tokens)\n            y_valids = [sample[0] for sample in valid_samples]\n\n            train_data = lightgbm.Dataset(x_trains, label=np.array(y_trains))\n            valid_data = lightgbm.Dataset(x_valids, label=np.array(y_valids), reference=train_data)\n            n_step += 1\n\n            model = lightgbm.train(\n                param,\n                train_data,\n                num_boost_round=5,\n                valid_sets=[valid_data],\n                init_model=model)\n            model.save_model(\n                model_path + f\"{N}-gram_{'-'.join(feature_types)}_model_{epoch+1}.txt\")\n</code></pre>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/xgboost.html","title":"Xgboost","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/xgboost.html#xgboost","title":"XGBoost","text":"<p>\u200b\u8bba\u6587\u200b\uff1aXGBoost: A Scalable Tree Boosting System XGBoost:eXtreme Gradient Boosting Tianqi Chen &amp; University of Washington, SIGKDD 2016</p>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/xgboost.html#_1","title":"\u57fa\u672c\u539f\u7406","text":"<p>\u200b\u672c\u8d28\u200b\u4e0a\u200b\u8fd8\u662f\u200bGBDT\uff0c\u200b\u5bf9\u4e8e\u200b\u5f53\u524d\u200b\u8fed\u4ee3\u200b\u8f6e\u6b21\u200b\\(t\\)\uff0c\\(f_t(x)=f_{t-1} + h_t(x)\\)\uff1a</p> <ul> <li> <p>\u200b\u76ee\u6807\u200bloss\u200b\u51fd\u6570\u200b\u5305\u62ec\u200b\u7ecf\u9a8c\u200b\u635f\u5931\u200b\u548c\u200b\u6b63\u5219\u200b\u9879\u200b</p> \\[ \\begin{aligned}     \\mathcal{L}&amp;=\\sum_{i=1}^n L\\big[f_t(x^i), y^i\\big] + \\sum_{j=1}^{t}\\Omega(h_j) \\\\     &amp;=\\sum_{i=1}^n L\\big[f_{t-1}(x^i) + h_t(x^i), y^i\\big] + \\sum_{j=1}^{t}\\Omega(h_j) \\\\     \u200b\u57fa\u4e8e\u200b&amp; \\text{Taylor}  \u200b\u516c\u5f0f\u200b\uff0c\u200b\u5c06\u200bf_{t-1}(x^i)\u200b\u89c6\u4f5c\u200bx_0\uff0ch_t(x^i) \u200b\u89c6\u4f5c\u200b \\Delta x\uff0c\u200b\u5f97\u200b \\\\     &amp;\\approx \\sum_{i=1}^n \\big(L[f_{t-1}(x^i), y^i] + \\frac{\\partial L[f_{t-1}(x^i), y^i]}{\\partial f_{t-1}(x^i)}h_t(x^i) + \\frac{1}{2}\\frac{\\partial^2 L[f_{t-1}(x^i), y^i]}{\\partial^2 f_{t-1}(x^i)}h_t^2(x^i) \\big) + \\sum_{j=1}^{t}\\Omega(h_j) \\\\      \u200b\u7531\u4e8e\u200b&amp;\u200b\u53ea\u200b\u5173\u6ce8\u200b\u8f6e\u6b21\u200bt\u200b\u7684\u200b\u5f31\u200b\u5206\u7c7b\u5668\u200bh_t(x)\uff0c\u200b\u56e0\u6b64\u200b\u6700\u7ec8\u200b\u635f\u5931\u200b\u53ef\u7b80\u5316\u200b\u4e3a\u200b \\\\     \\mathcal{L}&amp;=\\sum_{i=1}^n \\bigg(\\frac{\\partial L[f_{t-1}(x^i), y^i]}{\\partial f_{t-1}(x^i)}h_t(x^i) + \\frac{1}{2}\\frac{\\partial^2 L[f_{t-1}(x^i), y^i]}{\\partial^2 f_{t-1}(x^i)}h_t^2(x^i) \\bigg) + \\Omega(h_t) + c_t \\\\     &amp;= \\sum_{i=1}^n \\big(g_ih_t(x^i) +  \\frac{1}{2}\\hbar_ih_t^2(x^i) \\big) + \\Omega(h_t) + c_t  \\end{aligned} \\] <p>\\(g_i=\\frac{\\partial L[f_{t-1}(x^i), y^i]}{\\partial f_{t-1}(x^i)}\\) \u200b\u4e3a\u200b\\(t-1\\)\u200b\u8f6e\u6b21\u200b\u76ee\u6807\u200b\u6b8b\u5dee\u200b\u5bf9\u200b\u5206\u7c7b\u5668\u200b\u7684\u200b\u4e00\u9636\u200b\u5bfc\u6570\u200b \\(\\hbar_i=\\frac{\\partial^2 L[f_{t-1}(x^i), y^i]}{\\partial^2 f_{t-1}(x^i)}\\) \u200b\u4e3a\u200b\\(t-1\\)\u200b\u8f6e\u6b21\u200b\u76ee\u6807\u200b\u6b8b\u5dee\u200b\u5bf9\u200b\u5206\u7c7b\u5668\u200b\u7684\u200b\u4e8c\u9636\u200b\u5bfc\u6570\u200b   \\(c_t\\) \u200b\u4e3a\u200b\u524d\u200b\\(t-1\\)\u200b\u8f6e\u200b\u6240\u6709\u200b\u5f31\u200b\u5206\u7c7b\u5668\u200b\u7684\u200b\u6b8b\u5dee\u200b\u4e0e\u200b\u6b63\u5219\u200b\u9879\u200b\u7684\u200b\u603b\u548c\u200b</p> </li> <li> <p>\u200b\u5176\u4e2d\u200b\u6b63\u5219\u200b\u9879\u200b\u8ba1\u7b97\u200b\u4e3a\u200b</p> \\[ \\begin{aligned} \\Omega(h) =&amp; \\gamma M + \\frac{1}{2}\\lambda \\Vert w\\Vert^2_2 \\\\ =&amp; \\gamma M + \\frac{1}{2}\\lambda\\sum_{j=1}^{M} w_j^2 \\end{aligned} \\] <p>\\(M\\) \u200b\u4e3a\u200b\u51b3\u7b56\u6811\u200b \\(h\\) \u200b\u7684\u200b\u53f6\u200b\u8282\u70b9\u200b\u6570\u200b\uff0c\\(w \\in \\mathbb{R}^M\\) \u200b\u4e3a\u200b\u51b3\u7b56\u6811\u200b\u5404\u53f6\u8282\u200b\u8f93\u51fa\u200b\u7684\u200b\u56de\u5f52\u200b\u503c\u200b\u6784\u6210\u200b\u7684\u200b\u5411\u91cf\u200b \u200b\u6bcf\u4e2a\u200b\u8282\u70b9\u200b\u5bf9\u5e94\u200b\u4e8e\u200b\u4e00\u4e2a\u200b\u7c7b\u522b\u200b(\u200b\u6216\u200b\u7c7b\u522b\u200b\u96c6\u5408\u200b)\uff0c\u200b\u5bf9\u4e8e\u200b\u8f93\u5165\u200b\\(x^i\\)\uff0c\u200b\u5404\u200b\u8282\u70b9\u200b\u4f1a\u200b\u8f93\u51fa\u200b\u56de\u5f52\u200b\u503c\u200b\\(w^i_{j}\\) \\(\\gamma\\) \u200b\u548c\u200b \\(\\lambda\\) \u200b\u4e3a\u200b\u8d85\u200b\u53c2\u6570\u200b  </p> </li> <li> <p>\u200b\u8fdb\u4e00\u6b65\u200b\u7b80\u5316\u200b\u76ee\u6807\u200bloss\u200b\u51fd\u6570\u200b</p> \\[ \\begin{aligned}     \\mathcal{L}  &amp;= \\sum_{i=1}^n \\big(g_ih_t(x^i) +  \\frac{1}{2}\\hbar_ih_t^2(x^i) \\big) + \\gamma M + \\frac{1}{2}\\lambda\\sum_{j=1}^{M} w_j^2 + c_t \\\\     &amp;= \\sum_{j=1}^M\\Big[ (\\sum_{i \\in I_j} g_i)w_j + \\frac{1}{2}(\\sum_{i \\in I_j} \\hbar_i + \\lambda)w_j^2 \\Big] + \\gamma M + c_t  \\\\     \u200b\u6839\u636e\u200b&amp;\u200b\u4e8c\u5143\u200b\u4e00\u6b21\u65b9\u7a0b\u200b\u7279\u6027\u200b\uff08\\text{loss} \\ge 0\uff0c\u200b\u5f00\u53e3\u200b\u671d\u4e0a\u200b\uff09\uff0c\u200b\u53ef\u200b\u5f97\u200b\u6700\u5c0f\u200b\u635f\u5931\u200b\u4e3a\u200b \\\\     \\mathcal{L}_t^{opt} &amp;= -\\frac{1}{2}\\sum_{j=1}^M\\frac{(\\sum_{i\\in I_j} g_i)^2}{\\sum_{i\\in I_j }\\hbar_i + \\lambda} + \\gamma M \\end{aligned} \\] <p>\u200b\u5176\u4e2d\u200b\\(I_j=\\{x^i\\vert q(x^i)=j\\}\\) \u200b\u8868\u793a\u200b\u6700\u7ec8\u200b\u5206\u7c7b\u200b\u5728\u200b\u51b3\u7b56\u6811\u200b\u8282\u70b9\u200b\\(j\\)\u200b\u4e0a\u200b\u7684\u200b\u6837\u672c\u200b\u96c6\u200b \\(q\\) \u200b\u4e3a\u200b\u51b3\u7b56\u6811\u200b</p> </li> <li> <p>\u200b\u51b3\u7b56\u200b\u65f6\u53f6\u200b\u8282\u70b9\u200b\u5206\u88c2\u200b\u7684\u200b\u635f\u5931\u200b\u589e\u76ca\u200b(\u200b\u635f\u5931\u200b\u503c\u200b\u524d\u540e\u200b\u5dee\u5f02\u200b\u503c\u200b)  </p> \\[ \\begin{aligned}     \\text{Gain} =&amp; \\mathcal{L}_{previous} - \\mathcal{L}_{subsequent} \\\\     =&amp; \\frac{1}{2}\\bigg[\\frac{(\\sum_{i\\in I_L} g_i)^2}{\\sum_{i\\in I_L }\\hbar_i + \\lambda} + \\frac{(\\sum_{i\\in I_R} g_i)^2}{\\sum_{i\\in I_R }\\hbar_i + \\lambda} - \\frac{(\\sum_{i\\in I} g_i)^2}{\\sum_{i\\in I }\\hbar_i + \\lambda}\\bigg] - \\gamma \\end{aligned} \\] exact_greedy_split_finding<pre><code>def exact_greedy_split_finding(I, d):\n    \"\"\"\n    \u200b\u904d\u5386\u200b\u6240\u6709\u200b\u7279\u5f81\u200b\u627e\u51fa\u200b\u6700\u4f73\u200b\u5206\u88c2\u200b\u70b9\u200b(\u200b\u5206\u88c2\u200b\u7279\u5f81\u200b\uff0c\u200b\u7279\u5f81\u200b\u5206\u522b\u200b\u503c\u200b)\n    args:\n        I: instance set of current leaf node\n        d: instance feature dimension\n    return:\n        split with max score by G_L and G_R\n    \"\"\"\n    gain = 0\n    G, H = sum([g_i for i in I]), sum([hbar_i for i in I])\n    for k in range(1, d+1):                         # \u200b\u904d\u5386\u200b\u7279\u5f81\u200b\n        G_L = 0, H_L = 0\n        for i in sorted(I, key=lambda x: x[k]):     # \u200b\u6309\u200b\u5f53\u524d\u200b\u7279\u5f81\u200b\u5bf9\u200b\u6837\u672c\u200b\u96c6\u200b\u6392\u5e8f\u200b\n            G_L, H_L = G_L + g_i, H_L + hbar_i\n            G_R, H_R = G - G_L, H - H_L\n            gain = max(gain, G_L**2/(H_L + \u03bb) + G_R**2/(H_R + \u03bb) - G**2/(H + \u03bb))\n\n    return gain\n</code></pre> <p>\u200b\u679a\u4e3e\u200b\u601d\u8def\u200b\uff0c\u200b\u6548\u7387\u200b\u4e0d\u4f73\u200b</p> approximate_split_finding<pre><code>def approximate_split_finding(I, d):\n     \"\"\"\n    enumerates over all the possible splits on all the features to find the best split\n    args:\n        I: instance set of current leaf node\n        d: instance feature dimension\n        N: the number of approximate buckets of splitting the instance set on corresponding feature weight quantile\n    return:\n        split with max score by G_L and G_R\n    \"\"\"\n    for k in range(1, d+1):\n        S[k] = [s_k[i] for i in range(N)]            # \u200b\u83b7\u53d6\u200b\u6837\u672c\u200b\u96c6\u5728\u200b\u5f53\u524d\u200b\u7279\u5f81\u200bN\u200b\u7b49\u200b\u5206\u200b\u7684\u200b\u5206\u200b\u4f4d\u70b9\u200b\n    for k in range(1, d+1):\n        G_kv = sum([g_j for j in I if ])\n        H_kv = sum()\n\n    \u200b\u4ee5\u6876\u200b\u4e3a\u200b\u57fa\u672c\u200b\u5143\u7d20\u200b\u8fdb\u884c\u200bG_L\u200b\u548c\u200bG_R\u200b\u5212\u5206\u200b\u5e76\u200b\u8ba1\u7b97\u200bmax_score\n</code></pre> \\[     r_k(z) = \\frac{\\sum_{(x, k)\\in D_k, x\\lt z} \\hbar}{\\sum_{(x, k)\\in D_k} \\hbar} \\\\     \\vert r_k(s_{k, j}) - r_k(s_{k, j+1}) \\vert \\lt \\epsilon, s_{k1} = \\min_i x_{ik}, s_{kl} = \\max_{i} x_{i, k} \\] <p>\\(\\epsilon\\) \u200b\u4e3a\u5206\u200b\u4f4d\u7f6e\u200b\u8bef\u5dee\u200b\uff0c\u200b\u56e0\u6b64\u200b\u6bcf\u4e2a\u200bbucket\u200b\u4e2d\u7ea6\u200b\u6709\u200b \\(1/\\epsilon\\approx N\\) \u200b\u4e2a\u200b\u5019\u9009\u200b\u6837\u672c\u200b\uff0c\u200b\u57fa\u4e8e\u200b \\(\\hbar\\) \u200b\u8fdb\u884c\u200b N \u200b\u7b49\u200b\u5206\u200b</p> <p>\u200b\u56e0\u4e3a\u200bloss\u200b\u90fd\u200b\u7531\u200b \\(\\hbar\\) \u200b\u52a0\u6743\u200b\u8f93\u51fa\u200b\uff0c\u200b\u6240\u4ee5\u200b\u4f7f\u7528\u200b \\(1/\\hbar\\) \u200b\u8fdb\u884c\u200b\u5206\u200b\u4f4d\u6570\u200b\u5212\u5206\u200b\u57fa\u51c6\u200b  </p> \\[ \\begin{aligned}     \\mathcal{L} =&amp; \\sum_{i=1}^n \\big(g_ih_t(x^i) + \\frac{1}{2}\\hbar_i h_t^2(x^i)\\big) + \\Omega(h_t) + c_t \\\\     = &amp; \\frac{1}{2}\\hbar_i\\sum_{i=1}^n \\big(h_t(x^i) + g_i/\\hbar_i\\big)^2 + \\Omega(h_t) + c_t^{'} \\end{aligned} \\] <p>\u200b\u5b9e\u9645\u200b\u5e94\u7528\u200b\u4e2d\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u6837\u672c\u200bx\uff0c\u200b\u5177\u6709\u200b\u7a00\u758f\u200b\u7279\u5f81\u200b\u662f\u200b\u6781\u5176\u200b\u6b63\u5e38\u200b\u7684\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u91c7\u7528\u200b\u4ee5\u4e0b\u200b\u65b9\u6cd5\u200b\u5bf9\u200b\u7f3a\u503c\u200b\u6837\u672c\u200b\u8fdb\u884c\u200b\u5904\u7406\u200b\uff1a   1. \u200b\u53ea\u200b\u5bf9\u200b\u6709\u503c\u200b\u6837\u672c\u200b\u8fdb\u884c\u200b\u6392\u5e8f\u200b\uff0c\u200b\u968f\u540e\u200b\u5c06\u200b\u6240\u6709\u200b\u7f3a\u503c\u200b\u6837\u672c\u200b\u5206\u522b\u200b\u653e\u5165\u200bsorted \u200b\u6700\u200b\u5de6\u4fa7\u200b\u548c\u200b\u5de6\u53f3\u4fa7\u200b   2. \u200b\u904d\u5386\u200b\u4e24\u79cd\u200b\u5904\u7406\u200b\u65b9\u6848\u200b\u7684\u200b\u7ed3\u679c\u200b\uff0c\u200b\u9009\u62e9\u200b\u6700\u4f73\u200b(max_gain\u200b\u6700\u5927\u200b)\u200b\u7684\u200b\u65b9\u6848\u200b</p> sparsity-aware_split_finding<pre><code>\n</code></pre> <ul> <li>\u200b\u5217\u200b\u7279\u5f81\u200b\u5b50\u200b\u91c7\u6837\u200b\uff0c\u200b\u4e00\u822c\u200b\u53d6\u200b0.8</li> <li>Shrinkage\u200b\u901a\u8fc7\u200b\u51cf\u5c0f\u200b\u6bcf\u68f5\u200b\u6811\u200b\u7684\u200b\u8d21\u732e\u200b\uff08\u200b\u5373\u200b\u4e58\u4ee5\u200b\u5b66\u4e60\u200b\u7387\u200b\\(\\eta\\)\uff0c\u200b\u7f3a\u7701\u200b\u4e3a\u200b0.3\uff09\uff0c\u200b\u4f7f\u200b\u6a21\u578b\u200b\u66f4\u200b\u5e73\u6ed1\u200b\uff0c\u200b\u6709\u52a9\u4e8e\u200b\u9632\u6b62\u200b\u8fc7\u200b\u62df\u5408\u200b\u3002</li> <li>switch to out-of-core computation when it runs out of memory</li> <li>https://zhuanlan.zhihu.com/p/125617110  </li> <li>https://zhuanlan.zhihu.com/p/721576703  </li> <li>https://blog.csdn.net/anshuai_aw1/article/details/85093106  </li> <li>https://www.hrwhisper.me/machine-learning-xgboost/</li> <li>https://stats.stackexchange.com/questions/347078/xgboost-paper-time-complexity-analysis</li> </ul> </li> </ul>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/xgboost.html#pypi","title":"PyPI","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/xgboost.html#_2","title":"\u5e93\u200b\u5b89\u88c5","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Boosting/xgboost.html#params","title":"params","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Model_Merging/dare.html","title":"Dare","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Model_Merging/dare.html#dare","title":"DARE","text":"<p>\u200b\u8bba\u6587\u200b\uff1aLanguage Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch DARE: Drops delta parameters with a ratio p And REscales the remaining ones by 1/(1-p) Alibaba, 2023 Nov, ICLR 2024</p>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Model_Merging/dare.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Model_Merging/model_merging.html","title":"Model merging","text":"<ul> <li>Self Positioning</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Model_Merging/self-positioning.html","title":"Self positioning","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Model_Merging/self-positioning.html#self-positioning","title":"Self-Positioning","text":"<p>\u200b\u8bba\u6587\u200b\uff1aImproving General Text Embedding Model: Tackling Task Conflict and Data Imbalance through Model Merging Beihang University, 2024 Oct</p>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Model_Merging/self-positioning.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Model_Merging/self-positioning.html#model-merging-strategies","title":"Model Merging Strategies","text":"<p>\u200b\u7ed9\u5b9a\u200b\u6570\u636e\u200b\u96c6\u200b \\(\\{D_i\\}_{i=1}^N\\) \u200b\u548c\u200b\u76f8\u5e94\u200b\u7684\u200b\u57fa\u4e8e\u200b\u5404\u200b\u6570\u636e\u200b\u96c6\u200b\u8bad\u7ec3\u200b\u5f97\u5230\u200b\u7684\u200b\u6a21\u578b\u200b \\(\\{M_i\\}_{i=1}^{N}\\)\uff0c\u200b\u6a21\u578b\u200b\u7684\u200b\u53c2\u6570\u200b\u7528\u200b \\(\\{\\theta_i\\}_{i=1}^{N}\\) \u200b\u8868\u793a\u200b\uff0c\u200b\u5bf9\u5e94\u200b\u7684\u200b\u4efb\u52a1\u200b\u5411\u91cf\u200bTask Vector\u200b\u4e3a\u200b  \\(\\{V_i\\}_{i=1}^{N} = \\{\\theta_i - \\theta_0\\}_{i=1}^N\\)</p> <ol> <li> <p>Average Merging\uff1a\u200b\u52a0\u6743\u200b\u5408\u5e76\u200b\u5404\u200b\u6a21\u578b\u200b\u7684\u200bTask Vector</p> \\[ V_m = \\frac{\\sum_{i=1}^N a_i V_i}{\\sum_{i=1}^N a_i} \\] <ul> <li>\\(\\{a_i\\}_{i=1}^N \\in \\mathbb{R}\\) \u200b\u4e3a\u200b\u5404\u200b\u4efb\u52a1\u200b\u5411\u91cf\u200b\u6743\u91cd\u200b\u8d85\u53c2\u200b  </li> </ul> </li> <li> <p>SLERP Merging\uff08Spherical Linear intERPolation\uff09\uff1a\u200b\u4f9d\u6b21\u200b\u5408\u5e76\u200b\u4e24\u200b\u4efb\u52a1\u200b\u5411\u91cf\u200b\uff0c\u200b\u91cd\u590d\u200b\u5408\u5e76\u200b\u8fc7\u7a0b\u200b \\(N-1\\) \u200b\u6b21\u200b\u5f97\u5230\u200b \\(V_{m}\\)</p> \\[ V_{i+j} = \\frac{\\sin \\left(\\frac{a_j}{a_i + a_j}\\right)\\alpha_{(i,j)}V_i + \\sin \\left(\\frac{a_i}{a_i + a_j}\\right)\\alpha_{(i,j)}V_j}{\\sin \\alpha_{(i, j)}} \\] <ul> <li>\\(\\{a_{i}\\}_{i=1}^N\\) \u200b\u4e3a\u200b\u5404\u200b\u4efb\u52a1\u200b\u5411\u91cf\u200b\u89d2\u5ea6\u200b\u6743\u91cd\u200b\u8d85\u53c2\u200b</li> <li>\\(\\alpha_{(i, j)}\\) \u200b\u4e3a\u200b \u200b\u4efb\u52a1\u200b\u5411\u91cf\u200b \\(V_i\\) \u200b\u548c\u200b \\(V_j\\) \u200b\u7684\u200b\u5939\u89d2\u200b</li> </ul> </li> <li> <p>TIES Merging\uff08TrIm, Elect Sign &amp; Merging\uff09\uff1a\u200b\u89e3\u51b3\u200b\u6a21\u578b\u200b\u5408\u5e76\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u7684\u200b\u53c2\u6570\u200b\u51b2\u7a81\u200b\u5e76\u200b\u8fdb\u884c\u200b\u7f29\u653e\u200b\u5904\u7406\u200b\uff0c\u200b\u5177\u4f53\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u7b56\u7565\u200b\u663e\u8457\u200b\u63d0\u5347\u200b\u5408\u5e76\u200b\u6a21\u578b\u200b\u7684\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\uff1a</p> <ul> <li>\u200b\u4fee\u526a\u200bTrim\uff1a\u200b\u57fa\u4e8e\u200b\u5404\u200b\u4efb\u52a1\u200b\u5411\u91cf\u200b \\(V_i\\) \u200b\u7684\u200b\u7edd\u5bf9\u503c\u200b\u8fdb\u884c\u200b\u5206\u200b\u4f4d\u6570\u200b\u7edf\u8ba1\u200b\uff0c\u200b\u5148\u9a8c\u200b\u8ba4\u4e3a\u200b\u7edd\u5bf9\u503c\u200b\u8d8a\u5927\u200b\u53c2\u6570\u200b\u76f8\u5bf9\u200b\u66f4\u200b\u91cd\u8981\u200b\uff0c\u200b\u56e0\u6b64\u200b\u4fdd\u7559\u200b\u5404\u200b\u6a21\u578b\u200b\u6570\u503c\u200b\u524d\u200b \\(p\\%\\) \u200b\u6216\u200b\u9ad8\u4e8e\u200b\u67d0\u200b\u9608\u503c\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c\u200b\u5176\u4f59\u200b\u7f6e\u200b0\uff0c\u200b\u5f97\u5230\u200b \\(\\{V_i^{'}\\}_{i=1}^N\\)</li> <li>\u200b\u9009\u4e3e\u200bElect\uff1a\u200b\u57fa\u4e8e\u200b \\(\\{V_i^{'}\\}_{i=1}^N\\) \u200b\u7edf\u8ba1\u200b\u591a\u6570\u200b\u53c2\u6570\u200b\u7684\u200b\u6b63\u8d1f\u200b\u6027\u200b\uff0c\u200b\u968f\u540e\u200b\u4ec5\u200b\u4fdd\u7559\u200b\u4e0e\u200b\u7edf\u8ba1\u200b\u53c2\u6570\u200b\u6b63\u8d1f\u200b\u6027\u200b\u4e00\u81f4\u200b\u7684\u200b\u53c2\u6570\u200b\u8fdb\u884c\u200b\u5408\u5e76\u200b\uff0c\u200b\u5f97\u5230\u200b \\(\\hat{V}_m\\) </li> <li>\u200b\u7f29\u653e\u200bRescale\uff1a\u200b\u5bf9\u200b\u5408\u5e76\u200b\u540e\u200b\u7684\u200b\u4efb\u52a1\u200b\u5411\u91cf\u200b\u8fdb\u884c\u200b\u7f29\u653e\u200b \\(V_{m} = \\lambda \\cdot \\frac{\\hat{V}_m}{\\Vert \\hat{V}_m\\Vert}\\cdot \\Vert V\\text{avg} \\Vert\\)\uff0c\u200b\u5176\u4e2d\u200b\\(\\Vert V_\\text{avg} \\Vert = \\frac{1}{N}\\sum_{i=1}^N V_i^{'}\\)\uff0c\u200b\u5148\u200b\u8fdb\u884c\u200bNorm\uff0c\u200b\u518d\u200b\u8fdb\u884c\u200b\u7c7b\u4f3c\u200b\u4e8e\u200bdropout\u200b\u7684\u200b\u653e\u5927\u200b\u8fd8\u539f\u200b\u64cd\u4f5c\u200b</li> </ul> <ul> <li>\\(\\lambda \\in \\mathbb{R}\\) \u200b\u4e3a\u200b\u5408\u5e76\u200b\u4efb\u52a1\u200b\u5411\u91cf\u200b\u7f29\u653e\u200b\u8d85\u53c2\u200b</li> </ul> </li> <li> <p>Fisher Merging\uff1a\u200b\u57fa\u4e8e\u200b\u8f93\u5165\u200b\u6570\u636e\u200b\u7684\u200bInfoNCE loss\u200b\u8ba1\u7b97\u200b Fisher Information Matrix\uff08\u200b\u5373\u200binforNCE loss\u200b\u7684\u200b\u68af\u5ea6\u200b\u5e73\u65b9\u200b\u7684\u200b\u671f\u671b\u200b\uff0c\u200b\u5b9e\u9645\u200b\u7528\u200b\u8499\u7279\u5361\u6d1b\u200b\u65b9\u5f0f\u200b\u4f30\u8ba1\u200b\u5b9e\u73b0\u200b\uff09\u200b\u4f5c\u4e3a\u200b\u5408\u5e76\u200b\u7cfb\u6570\u200b\uff0c\u200b\u5e76\u200b\u5148\u9a8c\u200b\u8ba4\u4e3a\u200b\u77e9\u9635\u200b\u5143\u7d20\u200b\u503c\u8d8a\u200b\u5927\u8d8a\u200b\u91cd\u8981\u200b\uff0c\u200b\u6743\u91cd\u200b\u8d8a\u9ad8\u200b</p> \\[ \\begin{aligned}     \\hat{F}_{\\theta_i}=&amp; \\frac{1}{N_i} \\sum_{j=1}^{N_i} \\big( \\nabla_{\\theta_i} \\mathcal{L}^\\text{CL}(\\theta_i; I_j) \\big)^2 \\\\     V_m =&amp; \\frac{\\sum_{i=1}^N \\lambda_i \\hat{F}_{\\theta_i}*V_i}{\\sum_{i=1}^N \\lambda_i \\hat{F}_{\\theta_i}} \\end{aligned} \\] <ul> <li>\\(\\mathcal{L}^\\text{CL}\\)\u200b\u8868\u793a\u200b infoNCE loss\uff0c\\(I_j \\in D_i\\)\u200b\u8868\u793a\u200b\u8bad\u7ec3\u6837\u672c\u200b  </li> <li>\\(\\hat{F}_{\\theta_i}\\)\u200b\u7684\u200bshape\u200b\u4e0e\u200b\\(\\{V_i\\}_{i=1}^{N}\\)\u200b\u4e00\u81f4\u200b\uff0c\u200b\u4e3a\u200b\u5bf9\u6bd4\u200b\u5b66\u4e60\u200b\u7684\u200b\u68af\u5ea6\u200b\u503c\u200b\u5e73\u65b9\u200b\u77e9\u9635\u200b  </li> <li>\\(\\{\\lambda_i \\}_{i=1}^N \\in \\mathbb{R}\\) \u200b\u4efb\u52a1\u200b\u5411\u91cf\u200b\u6743\u91cd\u200b\u8d85\u53c2\u200b  </li> </ul> </li> <li> <p>RegMean Merging\uff08Regression-based Mean\uff09\uff1a\u200b\u662f\u200b\u4e00\u79cd\u200b\u5408\u5e76\u200b\u7ebf\u6027\u200b\u56de\u5f52\u200b\u6a21\u578b\u200b\u7684\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u4e13\u95e8\u200b\u89e3\u51b3\u200b\u795e\u7ecf\u7f51\u7edc\u200b\u6a21\u578b\u200b\u5408\u5e76\u200b\u4e2d\u200b\u7684\u200b\u53c2\u6570\u200b\u5339\u914d\u200b\u95ee\u9898\u200b\u3002\u200b\u5b83\u200b\u901a\u8fc7\u200b\u6700\u5c0f\u5316\u200b\u8f93\u51fa\u200b\u5dee\u5f02\u200b\uff08Square Error\uff09\u200b\u6765\u200b\u5b66\u4e60\u200b\u6700\u4f18\u200b\u7684\u200b\u5408\u5e76\u200b\u6743\u91cd\u200b\uff1a</p> \\[ \\min_{W_m} \\sum_{i=1}^N \\left\\Vert W_m^TX_i - W_i^TX_i\\right\\Vert^2 \\] <p>\u200b\u57fa\u4e8e\u200b\u7ebf\u6027\u200b\u56de\u5f52\u200b\u7684\u200b\u6700\u5c0f\u200b\u4e8c\u4e58\u89e3\u200b\u5c01\u95ed\u200b\u89e3\u200b\uff08Closed-Form Solution\uff09\u200b\u516c\u5f0f\u200b\u5f97\u200b\u6700\u7ec8\u200b\u5408\u5e76\u200b\u6743\u91cd\u200b\u77e9\u9635\u200b</p> \\[ \\begin{aligned}     W_m =&amp; \\left( \\sum_{i=1}^N X_i^TX_i \\right)^{-1} \\sum_{i=1}^N\\left( X_i^TX_iW_i\\right) \\end{aligned} \\] <ul> <li>\\(\\{W_i\\}_{i=1}^N\\) \u200b\u8868\u793a\u200b\u5404\u200b\u7ebf\u6027\u200b\u5c42\u200b\u6743\u91cd\u200b  </li> <li>\\(\\{X_i\\}_{i=1}^N\\) \u200b\u8868\u793a\u200b\u7528\u4e8e\u200b\u5404\u200b\u7ebf\u6027\u200b\u5c42\u200b\u8f93\u5165\u200b\u5411\u91cf\u200b\\(\\left&lt; X_1 \\in \\mathbb{R}^{N_1 \\times m}, y_1 \\right&gt;, \\dots, \\left&lt;X_N \\in \\mathbb{R}^{N_N \\times m}, y_N \\right&gt;\\) </li> <li>scaling factor/ration for non-diagonal items/elements</li> </ul> </li> </ol> <p>Info</p> <ul> <li><code>Fisher Merging</code>, <code>RegMean Merging</code> \u200b\u4ee5\u53ca\u200b\u672c\u6587\u200b\u7684\u200b <code>Self-Positioning</code> \u200b\u5408\u5e76\u200b\u7b56\u7565\u200b\u9700\u8981\u200b\u6570\u636e\u200b\u96c6\u200b\u8fdb\u884c\u200b\u77eb\u6b63\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Model_Merging/self-positioning.html#model-merging-pipelines","title":"Model Merging Pipelines","text":"<ol> <li>Separate Merging: \u200b\u4f7f\u7528\u200b\u5404\u200b\u6570\u636e\u200b\u96c6\u200b\u5206\u522b\u200b\u5bf9\u6a21\u578b\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u5f97\u5230\u200b \\(\\{M_{i}\\}_{i=1}^N\\), \u200b\u968f\u540e\u200b\u5408\u5e76\u200b\u6a21\u578b\u200b\u5f97\u5230\u200b \\(M_{m}^\\text{sep}\\)\u3002 <p>\u200b\u53ef\u7528\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u5c06\u200b\u73b0\u5b58\u200b\u7684\u200b\u57fa\u7ebf\u200b\u6216\u200bSOTA\u200b\u6a21\u578b\u200b\u5408\u5e76\u200b\u4f5c\u4e3a\u200b Embedding Model \u200b\u4f7f\u7528\u200b  </p> </li> <li>Iteratively (Sequential) Merging: \u200b\u57fa\u4e8e\u200b\u6570\u636e\u200b\u96c6\u200b \\((D_1, \\cdots, D_N)\\) \u200b\u5e8f\u5217\u200b\u8fed\u4ee3\u200b\uff0c\u200b\u4f9d\u6b21\u200b\u83b7\u5f97\u200b\u6a21\u578b\u200b \\((M_1, M_{(1, 2)}, \\dots, M_{(1, 2, \\dots, N)})\\)\uff0c\u200b\u968f\u540e\u200b\u5408\u5e76\u200b\u6a21\u578b\u200b\u5f97\u5230\u200b \\(M_{m}^\\text{iter}\\)\u3002   <p>\u200b\u53ef\u7528\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u589e\u5f3a\u200b\u73b0\u6709\u200bEmbedding Model\u200b\u5728\u200b\u7279\u5b9a\u200b\u4efb\u52a1\u200b\u4e0a\u200b\u7684\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u3002</p> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Model_Merging/self-positioning.html#joint-training-drawbacks","title":"Joint Training Drawbacks","text":"<ol> <li> <p>Multi-Task Confict\uff1a\u200b\u5982\u200bSTS\u200b\u4efb\u52a1\u200b\u76ee\u7684\u200b\u4e3a\u200b\u8bed\u4e49\u200b\u76f8\u4f3c\u200b\u9879\u200b\u5339\u914d\u200b\uff0c\u200b\u800c\u200bRetrival\u200b\u4efb\u52a1\u200b\u76ee\u7684\u200b\u4e3a\u200b\u5339\u914d\u200b\u8bdd\u9898\u200b\u76f8\u5173\u200b\u9879\u200b\uff0c\u200b\u4efb\u52a1\u200b\u76ee\u6807\u200b\u4e0d\u200b\u4e00\u81f4\u200b\uff0c\u200b\u591a\u4efb\u52a1\u200b\u8054\u5408\u200b\u8bad\u7ec3\u200b\u4f1a\u200b\u68af\u5ea6\u200b\u4f18\u5316\u200b\u65b9\u5411\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u5b58\u5728\u200b\u51b2\u7a81\u200b\uff0c\u200b\u5bfc\u81f4\u200b\u8d1f\u200b\u5411\u200b\u8fc1\u79fb\u200b\u6548\u679c\u200b\uff0c\u200b\u8868\u73b0\u200b\u4e3a\u200b\u591a\u4efb\u52a1\u200b\u8054\u5408\u200b\u8bad\u7ec3\u200b\u8868\u73b0\u200b\u8f83\u200b\u5355\u72ec\u200b\u4efb\u52a1\u200b\u5fae\u8c03\u200b\u6548\u679c\u200b\u5b58\u5728\u200b\u635f\u4f24\u200b\u3002     </p> <p></p> </li> <li> <p>Data Imbalance\uff1a\u200b\u4e0d\u540c\u200b\u6765\u6e90\u200b\u7684\u200b\u5404\u200b\u4efb\u52a1\u200b\u6570\u636e\u200b\u96c6\u200b\u6837\u672c\u200b\u6570\u91cf\u200b\u5dee\u5f02\u200b\u8fc7\u5927\u200b\uff08\u200b\u751a\u81f3\u200b\u6709\u200b\u6570\u91cf\u7ea7\u200b\u7684\u200b\u5dee\u5f02\u200b\uff09\uff0c\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u5bfc\u81f4\u200b\u5f52\u7eb3\u200b\u504f\u5dee\u200b\uff08\u200b\u5411\u200b\u591a\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u4efb\u52a1\u200b\uff09\uff0c\u200b\u4e25\u91cd\u200b\u5f71\u54cd\u200b\u6a21\u578b\u200b\u5728\u200b\u4e0d\u540c\u200b\u4efb\u52a1\u200b\u4e0a\u200b\u7684\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u3002     </p> <p></p> <p>Info</p> <ul> <li>\u200b\u8bad\u7ec3\u200b\u6570\u636e\u91cf\u200b\uff081. \u200b\u5355\u4e2a\u200b\u6570\u636e\u200b\u96c6\u200b\uff1b2. single-task\u200b\u6240\u6709\u200b\u6570\u636e\u200b\u96c6\u200b\uff1b3. multi-task\u200b\u6240\u6709\u200b\u6570\u636e\u200b\u96c6\u200b\uff09\u200b\u8d8a\u200b\u591a\u200b\uff0cTask Vector Norm \\(\\Vert V_i \\Vert\\) \u200b\u8d8a\u5927\u200b  </li> <li>\u200b\u8bad\u7ec3\u200b\u6570\u636e\u91cf\u200b\uff081. \u200b\u6570\u636e\u200b\u96c6\u200b\\(D_i\\)\uff1b2. \u200b\u6570\u636e\u200b\u96c6\u200b\\(D_j\\)\uff1b2. \u200b\u6570\u636e\u200b\u96c6\u200b\\(D_i + D_j\\)\uff09\u200b\u8d8a\u200b\u591a\u200b\uff0cTask Vector Direction \\(\\alpha_{(i+j, i)}/\\alpha_{(i+j, j)}\\) \u200b\u8d8a\u5c0f\u200b\uff0c\u200b\u8868\u73b0\u200b\u4e3a\u200b\u8054\u5408\u200b\u8bad\u7ec3\u4efb\u52a1\u200b\u5411\u91cf\u200b \\(V_{i+j}\\)\u200b\u5411\u200b\u6570\u636e\u91cf\u200b\u8d8a\u591a\u200b\u7684\u200b\u6570\u636e\u200b\u96c6\u200b\u503e\u5411\u200b\u8d8a\u200b\u660e\u663e\u200b</li> <li>\u200b\u53ef\u51b3\u200b\u7cfb\u6570\u200bcoefficient of determination \\(R^2 \\in [0, 1]\\) \u200b\u53cd\u6620\u200b\u4e86\u200b\u56de\u5f52\u200b\u6a21\u5f0f\u200b\u56e0\u53d8\u91cf\u200b\u53d8\u5316\u200b\u53ef\u9760\u200b\u7a0b\u5ea6\u200b\uff0c\u200b\u6570\u503c\u200b\u8d8a\u200b\u63a5\u8fd1\u200b1\u200b\u8868\u793a\u200b\u6a21\u578b\u200b\u89e3\u91ca\u200b\u80fd\u529b\u200b\u8d8a\u5f3a\u200b</li> </ul> </li> <li> <p>\u200b\u591a\u4efb\u52a1\u200b\u8054\u5408\u200b\u8bad\u7ec3\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</p> <p></p> <p></p> <ul> <li>\u200b\u591a\u4efb\u52a1\u200b\u8054\u5408\u200b\u8bad\u7ec3\u200b\u5bf9\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u6709\u200b\u4e00\u5b9a\u200b\u7684\u200b\u524a\u51cf\u200b\u73b0\u8c61\u200b</li> <li>\u200b\u6a21\u578b\u200b\u878d\u5408\u200b\u80fd\u591f\u200b\u63d0\u5347\u200b\u6a21\u578b\u200b\u6700\u7ec8\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\uff0c\u200b\u4e14\u200bSLERP\u200b\u80fd\u591f\u200b\u53d6\u5f97\u200b\u76f8\u5bf9\u200b\u6700\u4f73\u200b\u7684\u200b\u6548\u679c\u200b\u8868\u73b0\u200b</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Model_Merging/self-positioning.html#self-positioning_1","title":"Self-Positioning","text":"<p>\u200b\u4f7f\u7528\u200b<code>grid search</code>\u200b\u65b9\u5f0f\u200b\u786e\u5b9a\u200b\u5408\u5e76\u200b\u8d85\u53c2\u200b\u53ef\u200b\u4f7f\u200b\u6a21\u578b\u200b\u83b7\u5f97\u6700\u4f73\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\uff0c\u200b\u5355\u5f53\u200b\u6a21\u578b\u200b\u6570\u91cf\u200b \\(N\\) \u200b\u589e\u52a0\u200b\u65f6\u200b<code>grid search</code>\u200b\u7684\u200b\u65f6\u95f4\u200b\u590d\u6742\u5ea6\u200b\u4f1a\u200b\u6307\u6570\u200b\u7ea7\u200b\u589e\u957f\u200b\uff0c\u200b\u56e0\u6b64\u200b\u672c\u6587\u200b\u63d0\u51fa\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u8fd1\u4f3c\u200b\u6700\u4f18\u200b\u7684\u200b\u8d85\u53c2\u200b\u786e\u5b9a\u200b\u65b9\u6cd5\u200bSelf-Positioning\u200b\u83b7\u5f97\u200b\u5408\u5e76\u200b\u6a21\u578b\u200b \\(V_m\\)\u3002</p> <p>\u200b\u8be5\u200b\u65b9\u6cd5\u200b\uff08\u200b\u4ee5\u200bSLERP\u200b\u4e3a\u4f8b\u200b\uff09\u200b\u901a\u8fc7\u200b InfoNCE loss \u200b\u6765\u200b\u4f18\u5316\u200b\u66f4\u65b0\u200b\u76ee\u6807\u200b\u8d85\u53c2\u200b\uff0c\u200b\u4e3b\u8981\u200b\u6210\u5206\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li>Task Vector Direction Control\uff1a\\(\\{{a}_i\\}_{i=1}^{N}\\)</li> <li>Norm Control\uff1a\\(\\lambda\\)\uff0c\\(\\mu\\)\u3002\u200b\u540e\u8005\u200b\u4e3a\u200b\u9632\u6b62\u200b\u8fc7\u200b\u62df\u5408\u200b\u7684\u200b\u8d85\u53c2\u200b</li> </ol> \\[ \\begin{aligned}     \\left( \\{{a}_i\\}_{i=1}^{N}, {\\lambda} \\right) =&amp; \\arg \\min_{(\\{a_i\\}_{i=1}^{N}, \\lambda)} \\left( \\frac{1}{|D_t|} \\sum_{I \\in D_t} \\mathcal{L}^{\\text{CL}}(I; \\theta_0 + V_p) + \\mu \\lambda \\right) \\\\     V_p =&amp; \\lambda V_{(1, \\dots, N)} \\\\      V_{(1, \\dots, N)} =&amp; f^\\text{SLERP}(V_{(1, \\dots, N-1)}, V_N, \\frac{\\sum_{i=1}^{N-1}a_i}{N-1}, a_N) \\\\     f^\\text{SLERP}(V_i, V_j, a_i, a_j) =&amp; \\frac{\\sin \\left(\\frac{a_j}{a_i + a_j}\\right)\\alpha_{(i,j)}V_i + \\sin \\left(\\frac{a_i}{a_i + a_j}\\right)\\alpha_{(i,j)}V_j}{\\sin \\alpha_{(i, j)}} \\\\ \\end{aligned} \\] <ul> <li>\\(D_t\\) \u200b\u4e3a\u200b\u53c2\u6570\u200b\u641c\u7d22\u200b\u6570\u636e\u200b\u96c6\u200b\uff0c\u200b\u89c4\u6a21\u200b\u8fdc\u200b\u5c0f\u4e8e\u200b\u8bad\u7ec3\u200b\u96c6\u200b\uff0c\u200b\u53ef\u200b\u76f4\u63a5\u200b\u4ece\u200b\u8bad\u7ec3\u200b\u96c6\u4e2d\u200b\u91c7\u6837\u200b\u6216\u200b\u4ece\u200b\u5176\u5b83\u200b\u6570\u636e\u6e90\u200b\u83b7\u53d6\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Model_Merging/self-positioning.html#_2","title":"\u6027\u80fd\u200b\u6548\u679c\u200b\u8868\u73b0","text":"<p>Direction\u200b\u8f74\u4e3a\u200b\\(\\frac{a_j}{a_i + a_j}\\)</p> <ol> <li>Self-Positioning\u200b\u80fd\u591f\u200b\u81ea\u52a8\u66f4\u65b0\u200b\\(\\{{a}_i\\}_{i=1}^{N}\\) \u200b\u548c\u200b \\(\\lambda\\) \u200b\u786e\u5b9a\u200b\u8fd1\u4f3c\u200b\u6700\u4f18\u200b\u5408\u5e76\u200b\u6a21\u578b\u200b\u8d85\u53c2\u200b  </li> <li>Self-Positioning\u200b\u7684\u200b\u5408\u5e76\u200b\u6a21\u578b\u200b\u6548\u679c\u200b\u8f83\u200b\u5176\u4f59\u200b\u5408\u5e76\u200b\u7b56\u7565\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u66f4\u52a0\u200b</li> </ol> <p>\\(\\mu\\)\u200b\u7684\u200b\u53d8\u5316\u200b\u867d\u5bf9\u200bTask Vector Directoin\u200b\u5f71\u54cd\u200b\u8f83\u200b\u5c0f\u200b\uff0c\u200b\u4f46\u200b\u5bf9\u200bSelf-Positioning\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u5b58\u5728\u200b\u8f83\u5927\u200b\u5f71\u54cd\u200b\uff0c\u200b\u5efa\u8bae\u200b\u53d6\u503c\u200b \\(\\mu \\lt 0.05\\)</p> <p>Figure 8(a)\u200b\u6a2a\u8f74\u200b\u4e3a\u200b\u4ece\u200bSTS\u200b\u4efb\u52a1\u200b\u548c\u200bRetrival\u200b\u4efb\u52a1\u200b\u4e2d\u200b\u91c7\u6837\u200b\u7684\u200b\u6837\u672c\u200b\u6570\u91cf\u200b\u6bd4\u4f8b\u200b  </p> <ol> <li>Self-Positioning\u200b\u8f83\u200b\u4f20\u7edf\u200b\u91cd\u200b\u91c7\u6837\u200b\u65b9\u5f0f\u200b\u5904\u7406\u200b\u6837\u672c\u200b\u4e0d\u200b\u5e73\u8861\u200b\u95ee\u9898\u200b\u65f6\u200b\u5408\u5e76\u200b\u6a21\u578b\u200b\u6548\u679c\u200b\u8868\u73b0\u200b\u66f4\u597d\u200b  </li> <li>Self-Positioning\u200b\u8f83\u200b\u4f20\u7edf\u200b\u91cd\u200b\u91c7\u6837\u200b\u65b9\u5f0f\u200b\u5904\u7406\u200b\u6837\u672c\u200b\u4e0d\u200b\u5e73\u8861\u200b\u95ee\u9898\u200b\u65f6\u200b\u5408\u5e76\u200b\u6a21\u578b\u200b\u6548\u7387\u200b\u66f4\u9ad8\u200b  </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Ensemble/Ensemble/Stacking/stacking.html","title":"Stacking","text":"<p>Stacking \u200b\u7684\u200b\u6838\u5fc3\u200b\u5728\u4e8e\u200b\uff1a</p> <ul> <li>\u200b\u57fa\u200b\u5b66\u4e60\u200b\u5668\u200b\uff08Base Learners\uff09\uff1a\u200b\u591a\u4e2a\u200b\u4e0d\u540c\u200b\u7684\u200b\u673a\u5668\u200b\u5b66\u4e60\u200b\u6a21\u578b\u200b\uff08\u200b\u5982\u200b\u51b3\u7b56\u6811\u200b\u3001SVM\u3001\u200b\u795e\u7ecf\u7f51\u7edc\u200b\u7b49\u200b\uff09\u3002  </li> <li>\u200b\u5143\u200b\u5b66\u4e60\u200b\u5668\u200b\uff08Meta-Learner\uff09\uff1a\u200b\u5728\u200b\u57fa\u200b\u5b66\u4e60\u200b\u5668\u200b\u7684\u200b\u9884\u6d4b\u200b\u7ed3\u679c\u200b\u4e0a\u200b\u8bad\u7ec3\u200b\u7684\u200b\u4e00\u4e2a\u200b\u66f4\u200b\u9ad8\u5c42\u6b21\u200b\u7684\u200b\u6a21\u578b\u200b\uff0c\u200b\u7528\u4e8e\u200b\u6700\u7ec8\u200b\u51b3\u7b56\u200b\u3002</li> </ul> <p>\u200b\u6d41\u7a0b\u200b\u6982\u8ff0\u200b\uff1a</p> <ol> <li>\u200b\u8bad\u7ec3\u200b\u591a\u4e2a\u200b\u57fa\u200b\u5b66\u4e60\u200b\u5668\u200b\uff08Level-0 \u200b\u6a21\u578b\u200b\uff09\u3002  </li> <li>\u200b\u4f7f\u7528\u200b\u57fa\u200b\u5b66\u4e60\u200b\u5668\u200b\u5bf9\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u8fdb\u884c\u200b\u9884\u6d4b\u200b\uff0c\u200b\u751f\u6210\u200b\u65b0\u200b\u7684\u200b\u7279\u5f81\u200b\uff08Meta-Features\uff09\u3002  </li> <li>\u200b\u5c06\u200b\u8fd9\u4e9b\u200b\u9884\u6d4b\u200b\u7ed3\u679c\u200b\u4f5c\u4e3a\u200b\u8f93\u5165\u200b\uff0c\u200b\u8bad\u7ec3\u200b\u5143\u200b\u5b66\u4e60\u200b\u5668\u200b\uff08Level-1 \u200b\u6a21\u578b\u200b\uff09\u3002  </li> <li>\u200b\u6700\u7ec8\u200b\u9884\u6d4b\u200b\u7531\u5143\u200b\u5b66\u4e60\u200b\u5668\u200b\u7ed9\u51fa\u200b\u3002</li> </ol>"},{"location":"AI/Paper_Reading/Trick/Ensemble/MoE/gshard.html","title":"Gshard","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/MoE/gshard.html#gshard","title":"GShard","text":"<p>\u200b\u8bba\u6587\u200b\uff1aGShard: Scaling Giant Models with Conditional Computation and Automatic Sharding Github: mixture-of-experts Google 2020, ICLR 2021  </p>"},{"location":"AI/Paper_Reading/Trick/Ensemble/MoE/moe.html","title":"Moe","text":"<ul> <li>vanilla MoE </li> <li>GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding  <ul> <li>ffn experts</li> </ul> </li> <li>Switch Transformer</li> <li>[DeepSeekMoE]</li> </ul> <p>\u200b\u8d1f\u8f7d\u200b\u5747\u8861\u200b\u635f\u5931\u200b\u51fd\u6570\u200b</p>"},{"location":"AI/Paper_Reading/Trick/Ensemble/MoE/switch_transformer.html","title":"Switch transformer","text":"<ul> <li>https://huggingface.co/blog/zh/moe#%E9%83%A8%E7%BD%B2%E6%8A%80%E6%9C%AF</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Ensemble/MoE/switch_transformer.html#switch-transformer","title":"Switch Transformer","text":"<p>\u200b\u8bba\u6587\u200b\uff1aSwitch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity Google, JMLR 2022</p>"},{"location":"AI/Paper_Reading/Trick/Ensemble/MoE/switch_transformer.html#_1","title":"\u5de5\u4f5c\u200b\u8981\u70b9","text":"<ol> <li>selective precision training enables bf16 training</li> <li>initialization schema for larger number of experts training</li> <li>increased expert regularization improve</li> <li>overflow, referred to dropped tokens, skip and passed directly by residual connectation</li> <li>load blancing loss<ul> <li>\u200b\u7406\u60f3\u200b\u72b6\u6001\u200b\u4e0b\u200b\\(f_1\\)\u200b\u548c\u200b\\(P_i\\)\u200b\u90fd\u200b\u5e94\u8be5\u200b\u662f\u200b\\(\\frac{1}{N}\\)\uff0c\u200b\u5373\u200btokens\u200b\u5747\u5300\u5206\u5e03\u200b\u4e8e\u200b\u5404\u200bexperts\uff0c\\(\\sum_{i=1}^Nf_i\\cdot P_i=N*(\\frac{1}{N}\\cdot\\frac{1}{N})=\\frac{1}{N}\\)\uff0c\u200b\u56e0\u6b64\u200b\u9700\u8981\u200b\u989d\u5916\u200b\u4e58\u4ee5\u200b\\(N\\)\uff08\u200b\u8fdb\u884c\u200b\u5f52\u4e00\u5316\u200b\u6765\u200b\uff09\u200b\u6d88\u9664\u200b\u4e13\u5bb6\u200b\u6570\u76ee\u200b\u4e0d\u540c\u200b\u5e26\u6765\u200b\u7684\u200b\u5f71\u54cd\u200b  </li> </ul> </li> <li>\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u53ef\u4ee5\u200b\u52a0\u901f\u200b\u6a21\u578b\u200b\u4e14\u200b\u6548\u679c\u200b\u76f8\u5f53\u200b\uff1aswitch moe\u200b\u90e8\u5206\u200bfloat32\uff0c\u200b\u5176\u4f59\u90e8\u5206\u200bbfloat16<ul> <li>\u200b\u5355\u7eaf\u200b\u7528\u200bbfloat16\u200b\u6a21\u578b\u200b\u4f1a\u200b\u53d1\u6563\u200b</li> </ul> </li> <li>smaller parameter intialization for stability\uff1a\\(\\mu=0,\\sigma=\\sqrt{s/n}\\)\uff0c\\(n\\)\u200b\u4e3a\u200binput_dim, s\u200b\u4e3a\u200b\u6807\u91cf\u200b\u8d85\u53c2\u200b\uff0c\u200b\u6b64\u5904\u200b\u53d6\u200b0.1</li> <li>smaller dropout on no-expert layers(0.1) and larger dropout on expert layers(0.4) performs better</li> <li>distilling llm into small dense model, mixture of hard and soft label: 0.25 of teacher and 0.75 of ground truth label\uff0c\u200b\u4fdd\u7559\u200b30%\u200b\u7684\u200b\u63d0\u5347\u200b\u6548\u679c\u200b  </li> <li>experts ff, experts attention</li> <li>scaling law: Scaling laws for neural language models  </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Ensemble/MoE/vanilla_moe.html","title":"Vanilla moe","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/MoE/vanilla_moe.html#moe","title":"MoE","text":"<p>\u200b\u8bba\u6587\u200b\uff1aOutrageously Large Neural Networks: the Sparsely-gated Mixture-of-Experts Layer Github: mixture-of-experts Google Brain &amp; Jagiellonian University, ICLR 2017  </p>"},{"location":"AI/Paper_Reading/Trick/Ensemble/MoE/vanilla_moe.html#_1","title":"\u5de5\u4f5c\u200b\u8981\u70b9","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/MoE/vanilla_moe.html#_2","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Trick/Ensemble/MoE/vanilla_moe.html#moe_1","title":"MoE\u200b\u5de5\u4f5c\u200b\u539f\u7406","text":"<p>MoE\u200b\u901a\u8fc7\u200b\u95e8\u63a7\u200b\u7f51\u7edc\u200b\u52a0\u6743\u200b\\(K_r\\)\u200b\u4e2a\u200b\u4e13\u5bb6\u200b\u7f51\u7edc\u200b\u7684\u200b\u7ed3\u679c\u200b\u4f5c\u4e3a\u200b\u6700\u7ec8\u200b\u8f93\u51fa\u200b</p> <ol> <li> <p>\u200b\u6bcf\u6b21\u200b\u91c7\u6837\u200b\u566a\u58f0\u200b\u4ee5\u200b\u968f\u673a\u200b\u751f\u6210\u200b\u4e13\u5bb6\u200b\u7f51\u7edc\u200b\u95e8\u9650\u200b</p> \\[ \\begin{aligned}     H(x)&amp;=W_gx + noise*\\text{softplus}(W_{noise}x) \\\\     G(x)&amp;=\\text{softmax}\\big(\\text{KeepTopK}(H(x), K_r)\\big) \\\\ \\end{aligned} \\] <ul> <li>\\(W_g \\in \\mathbb{R}^{N_r\\times d}\\) \u200b\u4e0e\u200b \\(W_{noise} \\in \\mathbb{R}^{N_r\\times d}\\) \u200b\u5747\u200b\u4f7f\u7528\u200b\u5168\u96f6\u200b\u521d\u59cb\u5316\u200b\uff1b\u200b\u968f\u673a\u200b\u503c\u200b \\(noise \\in \\mathbb{R}^{N_r}\\) </li> <li>\\(\\text{KeepTopK}\\) \u200b\u51fd\u6570\u200b\u5bf9\u200btop-\\(K_r\\) \u200b\u7684\u200b\u6570\u503c\u200b\u8fdb\u884c\u200b\u4fdd\u7559\u200b\uff0c\u200b\u5176\u4f59\u200b\u503c\u7f6e\u200b\u4e3a\u200b-\\(\\infty\\)\uff08\u200b\u7ecf\u200bsoftmax\u200b\u540e\u200b\u6743\u91cd\u200b\u4e3a\u200b0\uff09</li> <li>\\(G(x)\\) \u200b\u5177\u6709\u200b\u7a00\u758f\u200b\u6027\u200b\uff08\\(K_r \\ll N_r\\)\uff09\u200b\u4e0e\u200b\u968f\u673a\u6027\u200b\uff08noise\u200b\u6bcf\u6b21\u200b\u90fd\u200b\u968f\u673a\u200b\u91c7\u6837\u200b\uff09</li> </ul> </li> <li> <p>\u200b\u52a0\u6743\u200b\\(K_r\\)\u200b\u4e2a\u200b\u4e13\u5bb6\u200b\u7f51\u7edc\u200b\u7684\u200b\u7ed3\u679c\u200b\u4f5c\u4e3a\u200b\u6700\u7ec8\u200b\u8f93\u51fa\u200b</p> \\[ y(x) = \\sum_{i=1}^{N_r} G(x)_i*E_i(x)  \\] <ul> <li>\u200b\u5f53\u200b\\(G(x)_i=0\\)\u200b\u65f6\u200b\uff0c\u200b\u53ef\u200b\u76f4\u63a5\u200b\u4e0d\u200b\u8ba1\u7b97\u200b\u5bf9\u5e94\u200b\u4e13\u5bb6\u200b\u7f51\u7edc\u200b\\(E_i(x)\\)\u200b\u4ee5\u200b\u8282\u7701\u200b\u8ba1\u7b97\u200b\u91cf\u200b</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Ensemble/MoE/vanilla_moe.html#moe-load-balance","title":"MoE Load Balance","text":"<ol> <li> <p>\\(L_{importance}\\) \u200b\u901a\u8fc7\u200b\u7f29\u5c0f\u200b\u4e13\u5bb6\u200b\u7f51\u7edc\u200b\u6743\u91cd\u200b\u503c\u200b\u5206\u6570\u200b\u7684\u200b\u79bb\u6563\u200b\u7a0b\u5ea6\u200b\u6765\u200b\u5747\u8861\u200b\u4e13\u5bb6\u200b\u7f51\u7edc\u200b\u7684\u200b\u4f7f\u7528\u7387\u200b\uff0c\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u53ea\u200b\u5747\u8861\u200b\u4e86\u200b\u4e13\u5bb6\u200b\u7f51\u7edc\u200b\u603b\u200b\u6743\u91cd\u200b\u5206\u6570\u200b\u548c\u200b\uff0c\u200b\u800c\u200b\u76f8\u540c\u200b\u5206\u6570\u200b\u548c\u200b\u53ef\u200b\u7531\u200b\u5c11\u91cf\u200b\u9ad8\u200b\u5206\u6570\u200btoken\u200b\u6216\u200b\u5927\u91cf\u200b\u4f4e\u200b\u5206\u6570\u200btoken\u200b\u7ec4\u5408\u200b\uff0c\u200b\u56e0\u6b64\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u51fa\u73b0\u200btoken number unblance\u200b\u73b0\u8c61\u200b\u3002</p> \\[ \\begin{aligned}   Importance(X) \\in \\mathbb{R}^{N_r} =&amp; \\sum_{x\\in X} G(x) \\\\   CV =&amp; \\frac{\\sigma}{\\mu} \\\\   L_{importance}(X) =&amp; w_{importance}\\cdot CV\\big(Importance(X)\\big)^2 \\end{aligned} \\] <ul> <li>\u200b\u53d8\u5f02\u7cfb\u6570\u200bCoefficient of Variation\uff0c\u200b\u7528\u4e8e\u200b\u8861\u91cf\u200b\u6570\u636e\u200b\u96c6\u200b\u7684\u200b\u76f8\u5bf9\u200b\u79bb\u6563\u200b\u7a0b\u5ea6\u200b\u3002  </li> </ul> </li> <li> <p>\\(L_{load}\\) \u200b\u901a\u8fc7\u200b\u7f29\u5c0f\u200btoken\u200b\u5728\u200b\u5404\u200b\u4e13\u5bb6\u200b\u7f51\u7edc\u200b\u4e0a\u200b\u5206\u5e03\u200b\u7684\u200b\u79bb\u6563\u200b\u7a0b\u5ea6\u200b \u200b\u6765\u200b\u5747\u8861\u200b\u88ab\u200b\u4e13\u5bb6\u200b\u7f51\u7edc\u200b\u88ab\u200b\u6fc0\u6d3b\u200b\u7684\u200b\u6982\u7387\u200b</p> \\[ \\begin{aligned}   kth\\_excluding(v, k, i) =&amp; \\text{k-th highest component of v after excluding }v_i\\\\   P(x, i) =&amp; Pr\\big(H(x)_i \\gt kth\\_excluding(H(x), K_r, i)\\big) \\\\   =&amp; \\Phi \\bigg(\\frac{(W_gx)_i - kth\\_excluding(H(x), K_r, i)}{\\text{softplus}((W_{noise}x)_i)}\\bigg) \\\\   Load(X)_i =&amp; \\sum_{x \\in X} P(x, i) \\\\   L_{load}(X) =&amp; w_{load}\\cdot CV\\big(Load(X)\\big)^2 \\end{aligned} \\] <ul> <li>\\(\\Phi\\) \u200b\u4e3a\u200b\u6807\u51c6\u200b\u6b63\u6001\u5206\u5e03\u200b\u7684\u200b\u7d2f\u79ef\u200b\u5206\u5e03\u200b\u51fd\u6570\u200bCDF</li> <li>Eq 3. \u200b\u901a\u8fc7\u200b\u79fb\u9879\u200b\u548c\u200b\u5bf9\u79f0\u6027\u200b\\(Pr(X \\gt -x) = Pr(X \\lt x)\\)\u200b\u6c42\u5f97\u200b\uff0c\u200b\u8868\u793a\u200btoken\u200b\u5728\u200b\u5f53\u524d\u200b\u4e13\u5bb6\u200b\u7f51\u7edc\u200b\u4e0a\u200b\u7684\u200b\u5206\u5e03\u200b\u6982\u7387\u200b</li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Ensemble/MoE/vanilla_moe.html#shrink-batch-problem","title":"Shrink Batch Problem","text":"<p>\\(\\frac{K_rb}{N_r}\\ll b\\) inefficient as the \\(N_r\\) increasing - Mixing Data Parallelism and Model Parallelism     - primary gating network employs Data P\uff0c\u200b\u6bcf\u4e2a\u200b\u8bbe\u5907\u200b\u4e0a\u200b\u90fd\u200b\u6709\u200b\u5b8c\u6574\u200b\u7684\u200b\u95e8\u63a7\u200b\u7f51\u7edc\u200b\u526f\u672c\u200b\uff0c\u200b\u5904\u7406\u200b\u4e0d\u540c\u200b\u6279\u6b21\u200b\u7684\u200b\u6570\u636e\u200b     - secondary MoEs imploy Model P\uff0c\u200b\u6bcf\u4e2a\u200b\u8bbe\u5907\u200b\u53ea\u200b\u8d1f\u8d23\u200b\u4e00\u4e2a\u200bmoe\u200b\u5c42\u200b     - hierachical MoE\uff1a\u200b\u53cc\u5c42\u200b\u95e8\u9650\u200b\uff0c\u200b\u5148\u200b\u786e\u5b9a\u200b\u7ec4\u200b\uff0c\u200b\u540e\u200b\u786e\u5b9a\u200b\u7ec4\u5185\u200b\u4e13\u5bb6\u200b\u7f51\u7edc\u200b - Taking Advantage of Convolutionality     - \u200b\u5c06\u200b\u591a\u4e2a\u200b\u65f6\u95f4\u200b\u6b65\u200b\u7684\u200b\\(h_t\\)\u200b\u7edf\u4e00\u200b\u8f93\u5165\u200b\u5230\u200b\u540c\u200b\u4e00\u6279\u200bexpert\uff08\u200b\u5404\u5c42\u200b\u5171\u4eab\u200bexperts\uff09\u200b\u8fdb\u884c\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u4ee5\u200b\u8fbe\u5230\u200b\u6269\u5927\u200bbatch - Increasing Batch Size for a Recurrent MoE     - Memory-efficient backpropagation through time - Network Bandwidth     - \u200b\u4e13\u5bb6\u200b\u7f51\u7edc\u200b\u4e2d\u200b\u7684\u200b\u8ba1\u7b97\u200b\u91cf\u200b\u4e0e\u200b\u8f93\u5165\u8f93\u51fa\u200bio\u200b\u4e4b\u6bd4\u8981\u200b\u5927\u4e8e\u200b\u673a\u5668\u8bbe\u5907\u200b\u7684\u200b\u8ba1\u7b97\u80fd\u529b\u200b\u4e0e\u200b\u7f51\u7edc\u5e26\u5bbd\u200b\u4e4b\u200b\u6bd4\u200b     - \\(C_{expert}\\)\u200b\u4e13\u5bb6\u200b\u7f51\u7edc\u200b\u7684\u200b\u8ba1\u7b97\u200b\u91cf\u200bFLOPS     - \\(D_{io}\\) \u200b\u8f93\u5165\u8f93\u51fa\u200b\u7684\u200b\u6570\u636e\u91cf\u200b\uff0c\u200b\u5373\u200b\\(d_{in}\\)\u200b\u548c\u200b\\(d_{out}\\)\u200b\u7ef4\u5ea6\u200b\u548c\u200b byte     - \\(C_{device}\\) \u200b\u8ba1\u7b97\u200b\u8bbe\u5907\u200b\u7684\u200b\u8ba1\u7b97\u80fd\u529b\u200b FLOPs/s     - \\(B_{network}\\) \u200b\u8ba1\u7b97\u200b\u8bbe\u5907\u200b\u7684\u200b\u7f51\u7edc\u5e26\u5bbd\u200b byte/s     - \u200b\u4fdd\u8bc1\u200b \\(\\frac{C{expert}}{D_{io}}\\gt \\frac{C_{device}}{B_{network}}\\) \u200b\u4ee5\u200b\u63d0\u9ad8\u200b\u8ba1\u7b97\u200b\u6548\u7387\u200b\uff08\u200b\u65e0\u6cd5\u200b\u5145\u5206\u5229\u7528\u200b\u8bbe\u5907\u200b\u8ba1\u7b97\u80fd\u529b\u200b\uff09     - \u200b\u53ef\u200b\u76f4\u63a5\u200b\u589e\u5927\u200b\\(hidden\\_dim\\)\u200b\u6216\u200b\u589e\u52a0\u200b\u9690\u5c42\u200b\u7684\u200b\u5927\u5c0f\u200b\u6216\u200b\u5c42\u6570\u200b</p> <p>\u200b\u5982\u679c\u200b\u6709\u200b b \u200b\u4e2a\u200b\u6837\u672c\u200b\uff0c\u200b\u6bcf\u4e2a\u200b\u6837\u672c\u200b\u9009\u62e9\u200b k \u200b\u4e2a\u200b\u4e13\u5bb6\u200b\uff0c\u200b\u4e00\u5171\u200b\u6709\u200b n \u200b\u4e2a\u200b\u4e13\u5bb6\u200b\uff0c\u200b\u90a3\u4e48\u200b\u5b9e\u9645\u4e0a\u200b\u5e73\u5747\u200b\u6bcf\u4e2a\u200b\u4e13\u5bb6\u200b\u6536\u5230\u200b\u7684\u200b\u6837\u672c\u200b\u6570\u91cf\u200b\u4e3a\u200b \\(\\frac{K_rb}{N_r}\\ll b\\)   \uff0c\u200b\u4e14\u200b\u968f\u7740\u200b n \u200b\u7684\u200b\u589e\u52a0\u200b\uff0c\u200b\u4f1a\u200b\u4f7f\u5f97\u200b\u5b9e\u9645\u4e0a\u200b\u6bcf\u4e2a\u200b\u4e13\u5bb6\u200b\u63a5\u6536\u200b\u5230\u200b\u7684\u200b\u6837\u672c\u91cf\u200b\u66f4\u200b\u4f4e\u200b\u4e86\u200b\uff0c\u200b\u4e3a\u4e86\u200b\u89e3\u51b3\u200b\u8fd9\u4e2a\u200b\u95ee\u9898\u200b\uff0c\u200b\u4e00\u822c\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u4f1a\u200b\u8ba9\u200b\u603b\u4f53\u200b\u7684\u200b b \u200b\u589e\u5927\u200b\uff0c\u200b\u4f46\u662f\u200b b \u200b\u589e\u5927\u200b\u4e4b\u540e\u200b\uff0c\u200b\u4f1a\u200b\u5bfc\u81f4\u200b\u5185\u5b58\u200b\u53d7\u9650\u200b\uff08\u200b\u5728\u200b\u524d\u200b\u5411\u200b\u548c\u200b\u53cd\u5411\u200b\u4e24\u4e2a\u200b\u4f20\u64ad\u200b\u9636\u6bb5\u200b\uff09\u200b\u56e0\u6b64\u200b\u505a\u200b\u4e86\u200b\u5f88\u591a\u200b\u5e76\u884c\u5904\u7406\u200b\uff0c\u200b\u6bd4\u5982\u200b\u6570\u636e\u200b\u5e76\u884c\u200b\u3001\u200b\u6a21\u578b\u200b\u5e76\u884c\u5904\u7406\u200b\u7b49\u200b</p> <ul> <li>https://zhuanlan.zhihu.com/p/669312652</li> <li>https://lilianweng.github.io/posts/2021-09-25-train-large/</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Ensemble/MoE/vanilla_moe.html#load-balance-loss","title":"Load Balance Loss","text":"<ol> <li>Expert-Level Balance Loss</li> <li>Device-Level Balance Loss</li> <li> <p>Communication Balance Loss</p> </li> <li> <p>batchwise mask</p> </li> <li>\\(M_{batch}(X, m)_{j, i}\\begin{cases}     1,\\text{ if } X_{j, i} \\text{ is the top } m \\text{ values for expert } i \\\\     0,\\text{ otherwise }   \\end{cases}\\)</li> <li>\\(L_{batchwise}\\)</li> </ol>"},{"location":"AI/Paper_Reading/Trick/Ensemble/MoE/vanilla_moe.html#_3","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/adalora.html","title":"Adalora","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/adalora.html#lora-ga","title":"LoRA-GA","text":"<p>\u200b\u8bba\u6587\u200b\uff1aAdaLoRA: adaptive budget allocation for parameter-effecient fine-tuning AdaLoRA: Adaptive Low Rank Adapation Github\uff1aAdaLoRA MicroSoft, 2023 Mar, ICLR 2023</p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/adalora.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li> <p>https://zhuanlan.zhihu.com/p/657130029</p> </li> <li> <p>train 1.5\u200b\u500d\u200bLoRA\uff0cinfer\u200b\u7b49\u540c\u200blora</p> </li> <li>\u200b\u52a8\u6001\u5206\u914d\u200brank\u200b\u7ed9\u200b\u6bcf\u5c42\u200b\u7684\u200b\u6bcf\u4e2a\u200b\u77e9\u9635\u200b</li> <li>\u200b\u8d8a\u540e\u200b\u5c42\u200b\u76f8\u5bf9\u6765\u8bf4\u200brank\u200b\u5206\u914d\u200b\u8d8a\u200b\u591a\u200b</li> <li>ablation\u200b\u6d88\u878d\u200b\u5b9e\u9a8c\u200b\u8868\u660e\u200b\u6b63\u5219\u200b\u9879\u200b\u548c\u200bSVD\u200b\u7684\u200b\u6548\u679c\u200b\u548c\u200b\u5fc5\u8981\u6027\u200b\uff0c\u200b\u7ea6\u675f\u200bP\u200b\u548c\u200bQ\u200b\u4e3a\u200b\u6b63\u4ea4\u200b\u77e9\u9635\u200b\u4e14\u200b\u4e92\u4e0d\u200b\u4f9d\u8d56\u200b</li> <li>\u200b\u4e0d\u540c\u200btask\u200b\u7684\u200b\u5206\u5e03\u200b\u4e0d\u540c\u200b</li> <li>only LoRA q and v, LoRA all weight matrix improved, table 14</li> <li>\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6027\u80fd\u200b\u5f00\u9500\u200b\uff0c11%-16% incur</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/dora.html","title":"Dora","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/dora.html#dora","title":"DoRA","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDoRA: weight-Decomposed low-Rank Adaptation NVIDIA &amp; HKUST, 2024</p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/lora-ga.html","title":"Lora ga","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/lora-ga.html#lora-ga","title":"LoRA-GA","text":"<p>\u200b\u8bba\u6587\u200b\uff1aLoRA-GA: Low-Rank Adaptation with Gradient Approximation Github\uff1aLoRA-GA Tsinghua, 2024 Jul, NeurIPS 2024</p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/lora-ga.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/lora.html","title":"Lora","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/lora.html#lora","title":"LoRA","text":"<p>\u200b\u8bba\u6587\u200b\uff1aLow-Rank Adaptation of large language models Github: LoRA-GA: Low-Rank Adaptation with Gradient Approximation MicroSoft, 2021 Jun, ICLR 2022</p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/lora.html#_1","title":"\u5de5\u4f5c\u200b\u8981\u70b9","text":"<ol> <li>lora\u200b\u5148\u9a8c\u200b\u5730\u200b\u5047\u8bbe\u200b\u53ef\u200b\u901a\u8fc7\u200blora\u200b\u601d\u60f3\u200b\u5c06\u200b\u5206\u89e3\u200b\u7684\u200b\u4f4e\u200b\u79e9\u200b\u77e9\u9635\u200b\u6765\u200b\u8fd1\u4f3c\u200b\u5f85\u200b\u8c03\u6574\u200b\u7684\u200b\u9ad8\u7ef4\u200b\u77e9\u9635\u200b</li> <li>\u200b\u51bb\u7ed3\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c\u200b\u5728\u200b\u901a\u8fc7\u200b\u989d\u5916\u200b\u63d2\u5165\u200btrainable rank decomposition matrices\u200b\u8fbe\u5230\u200b\u5fae\u8c03\u200b\u76ee\u7684\u200b</li> <li>on GPT-3 175B, trainable\u200b\u53c2\u6570\u200b\u91cf\u51cf\u5c11\u200b\u4e3a\u200b10000\u200b\u5206\u200b\u4e4b\u4e00\u200b\uff0cGPU\u200b\u4f7f\u7528\u200b\u51cf\u5c11\u200b\u4e3a\u200b3\u200b\u5206\u200b\u4e4b\u4e00\u200b</li> <li>\u200b\u6548\u679c\u200b\u548c\u200b\u76f4\u63a5\u200b\u8bad\u7ec3\u200b\u5dee\u4e0d\u591a\u200b\uff0c\u200b\u4e14\u200binfer\u200b\u6027\u80fd\u200b\u6d88\u8017\u200b\u533a\u522b\u200b\u4e0d\u200b\u5927\u200b</li> </ol>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/lora.html#_2","title":"\u7ec6\u8282\u200b\u5b9e\u73b0","text":"<p>\\(W=W_o + \\frac{\\alpha}{r} BA, where\\ W, W_o \\in \\mathbb{R}^{d, k}, A \\in \\mathbb{R}^{d, r}, B \\in \\mathbb{R}^{r, k}, r\\ll\\min(d, k)\\)</p> <ul> <li>\u200b\u8d85\u53c2\u200b \\(r\\)\uff0c\u200b\u4e00\u822c\u200b1, 2, 4, 8\uff1b\\(r\\ll\\min(d, k)\\)\uff0c\u200b\u800c\u4e14\u200b\u4e00\u5473\u200b\u5730\u200b\u589e\u5927\u200b\\(r\\)\u200b\u6548\u679c\u200b\u63d0\u5347\u200b\u6709\u9650\u200b\uff0c\u200b\u5982\u679c\u200b\u4e0b\u6e38\u200b\u4efb\u52a1\u200b\u6570\u636e\u200b\u96c6\u548c\u9884\u200b\u8bad\u7ec3\u200b\u8bed\u6599\u5e93\u200b\u5dee\u522b\u200b\u8f83\u5927\u200b\u53ef\u4ee5\u200b\u9002\u5f53\u200b\u589e\u5927\u200b\u3002</li> </ul> <ul> <li>\\(\\alpha\\)\u200b\u4e3a\u200b\u6807\u91cf\u200b\uff08\u200b\u4e00\u822c\u200b\\(\\alpha\\ge 2*r\\)\uff09\uff0c\u200b\u503c\u8d8a\u200b\u5927\u200bLoRA\u200b\u6a21\u5757\u200b\u5360\u200b\u6bd4\u91cd\u200b\u8d8a\u9ad8\u200b\uff0c\u200b\u53cd\u4e4b\u200b\u540c\u7406\u200b\u3002</li> <li>\\(A\\) is initialized by \\(\\mathcal{N}(0, \\sigma ^2)\\)</li> <li>\\(B\\) is initialized by 0</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/lora.html#lora_1","title":"LoRA\u200b\u65b9\u6848\u200b\u9009\u62e9","text":"<ul> <li>\u200b\u6d88\u878d\u200b\u5b9e\u9a8c\u200b\u6548\u679c\u200b\u8868\u660e\u200b\u5355\u5bf9\u200b\\(W_q\\)\u200b\u6216\u200b\\(W_k\\)\u200b\u5e94\u7528\u200bLoRA\u200b\u6548\u679c\u200b\u8f83\u5dee\u200b\uff0c\u200b\u8f83\u200b\u597d\u200b\u7684\u200blora\u200b\u65b9\u6848\u200b\u662f\u200b\u3010\\(W_q\\) + \\(W_v\\)\u3011</li> </ul> <p>LoRA\u200b\u5728\u200bAttention\u200b\u5404\u200b\u90e8\u5206\u200b\u6743\u91cd\u200b\u4e0a\u200b\u7684\u200b\u6d88\u878d\u200b\u5b9e\u9a8c\u200b\u6548\u679c\u200b</p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/lora.html#_3","title":"\u6027\u80fd\u200b\u5f71\u54cd","text":"<ul> <li>\u200b\u5f53\u200b<code>batch_size</code>\u200b\u8f83\u5927\u200b\u65f6\u200b\uff0c\u200b\u5f15\u5165\u200b\u7684\u200bLoRA\u200b\u6a21\u5757\u200b\u5bf9\u6a21\u578b\u200binfer\u200b\u6027\u80fd\u200b\u5f71\u54cd\u200b\u53ef\u4ee5\u200b\u5ffd\u7565\u4e0d\u8ba1\u200b\uff1b</li> <li>\u200b\u5f53\u200b<code>batch_size</code>\u200b\u8f83\u200b\u5c0f\u65f6\u200b\uff0c\u200b\u5f15\u5165\u200b\u7684\u200bLoRA\u200b\u6a21\u5757\u200b\u5bf9\u6a21\u578b\u200binfer\u200b\u6027\u80fd\u200b\u5b58\u5728\u200b\u5f71\u54cd\u200b\uff0c\u200b\u4e14\u200b\u6700\u9ad8\u200b\u8fbe\u200b30%\u3002</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/peft.html","title":"Peft","text":"<p>\u200b\u7531\u4e8e\u200b\u6a21\u578b\u200b\u89c4\u6a21\u200b\u8fc7\u5927\u200b\uff0c\u200b\u5e38\u89c4\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u7684\u200b\u7b97\u529b\u200b\u65e0\u6cd5\u200b\u652f\u6301\u200b\u5168\u91cf\u200b\u5fae\u8c03\u200b\uff0c\u200b\u56e0\u6b64\u200b\u9700\u8981\u200b\u5176\u5b83\u200b\u90e8\u5206\u200b\u5fae\u8c03\u200b\u65b9\u6cd5\u200b\uff08\u200b\u5373\u200b\u9ad8\u6548\u200b\u53c2\u6570\u200b\u5fae\u8c03\u200b\u6cd5\u200bPEFT\uff0cParameter-Effecient Fine-Tuning\uff09\u200b\u5b9e\u73b0\u200b\u6a21\u578b\u200b\u7684\u200btransfer learning\u3002</p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/peft.html#peft","title":"PEFT","text":"<p>LLM-SFT</p> <pre><code>from peft import LoraConfig, TaskType, get_peft_model, PeftModel\nfrom transformers import trainer\n\nconfig = LoraConfig(\n    task_type=TaskType.CAUSAL_LM, \n    target_modules=[\"c_attn\", \"c_proj\", \"w1\", \"w2\"],\n    inference_mode=False,   # \u200b\u662f\u5426\u200b\u4e3a\u200b\u8bad\u7ec3\u200b\u6a21\u5f0f\u200b\n    r=8,                    # Lora \u200b\u79e9\u200b\n    lora_alpha=32,          # Lora alaph\uff0c\u200b\u5177\u4f53\u200b\u4f5c\u7528\u200b\u53c2\u89c1\u200b Lora \u200b\u539f\u7406\u200b\n    lora_dropout=0.1        # Dropout \u200b\u6bd4\u4f8b\u200b\n)\nmodel = get_peft_model(model, config)\n# \u200b\u52a0\u8f7d\u200blora \u200b\u6743\u91cd\u200b\uff0c\u200b\u9700\u8981\u200b\u7f6e\u200blora_config.inference_mode=True\n# model = PeftModel.from_pretrained(pre_trained_model, model_id=lora_path, config=lora_config)\n\nprint(config, model.print_trainable_parameters(), sep='\\n')\n# \u200b\u6253\u5370\u200b\u6bcf\u4e2a\u200b\u53ef\u200b\u8bad\u7ec3\u200b\u53c2\u6570\u200b\u7684\u200b\u540d\u79f0\u200b\u548c\u200b\u5f62\u72b6\u200b\nfor name, param in model.named_parameters():\n    if param.requires_grad:\n        print(f\"Parameter name: {name}, Shape: {param.shape}\")\n\nargs = TrainingArguments(\n    output_dir=\"./output/Qwen\",         # lora_checkpoint \u200b\u5b58\u50a8\u200b\u8def\u5f84\u200b\n    save_steps=100,                     # lora_checkpoint \u200b\u5b58\u50a8\u200b\u95f4\u9694\u200b\u6b65\u6570\u200b\n    per_device_train_batch_size=8,      # batch_size\n    num_train_epochs=3,                 # epoch\n    gradient_accumulation_steps=2,      # \u200b\u68af\u5ea6\u200b\u7d2f\u8ba1\u200b\u6b65\u6570\u200b\n    logging_steps=10,                   # \u200b\u65e5\u5fd7\u200b\u6253\u5370\u200b\u95f4\u9694\u200b\u6b65\u6570\u200b\n    gradient_checkpointing=True,\n    learning_rate=1e-4,\n    save_on_each_node=True\n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenization,     # \u200b\u5177\u4f53\u200b\u7684\u200btokenization\u200b\u65b9\u6848\u200b\n                                    # tokenization = dataset.map(preprocess_fn,\n                                    #    batched=True,\n                                    #    batch_size=10)\n    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n)\n\ntrainer.train()\n\n# inference\nipt = tokenizer(prompt.format(input_text) + prompt_details, return_tensors=\"pt\").to(\"cuda\")\nprint(tokenizer.decode(model.generate(\n    **ipt,\n    do_sample=True,\n    top_k=1,\n    eos_token_id=tokenizer_eos_token_id),\n    skip_special_tokens=True)\n)\n</code></pre>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/peft.html#lora","title":"LoRA","text":"<ul> <li>Mixture of LoRA Experts (MoLE)</li> <li>Higher Layers Need More LoRA Experts</li> <li>LoRA insight experiments</li> <li>Practical Tips when using LoRA</li> <li>LoRA servey</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/peft.html#adalora","title":"AdaLoRA","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/peft.html#pissa","title":"PiSSA","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/peft.html#dora","title":"DoRA","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/peft.html#lora-ga","title":"LoRA-GA","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/peft.html#qlora","title":"QLoRA","text":"<ul> <li>https://towardsdatascience.com/an-overview-of-the-lora-family-515d81134725</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/pissa.html","title":"Pissa","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/pissa.html#pissa","title":"PiSSA","text":"<p>\u200b\u8bba\u6587\u200b\uff1aPiSSA: Principal Singular values and Singular vectors Adaptation of large language models Github\uff1aPiSSA Peking University, 2024 Apr</p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/pissa.html#_1","title":"\u5de5\u4f5c\u200b\u5185\u5bb9","text":"<ol> <li>\u200b\u4e0e\u200bLoRA\u200b\u76f8\u6bd4\u200b\uff0c\u200b\u5c06\u200b\\(BA\\)\u200b\u66ff\u6362\u200b\u4e3a\u200b\u539f\u6765\u200b\u9ad8\u9636\u200b\u77e9\u9635\u200b\\(W\\)\u200b\u7684\u200b\u4e3b\u200b\u6210\u5206\u200b\uff0c\u200b\u65b9\u6848\u200b\u6548\u679c\u200b\u6574\u4f53\u200b\u8d85\u8fc7\u200bLoRA</li> </ol>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/pissa.html#_2","title":"\u7ec6\u8282\u200b\u5b9e\u73b0","text":"<ul> <li>nuclear norm\uff0c\u200b\u6838\u200b\u8303\u5f0f\u200b\uff0c\u200b\u77e9\u9635\u200b\u7279\u5f81\u200b\u503c\u5f97\u200b\u8ff9\u200btr </li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/qlora.html","title":"Qlora","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/qlora.html#qlora","title":"QLoRA","text":"<p>\u200b\u8bba\u6587\u200b\uff1aQLORA: Efficient Finetuning of Quantized LLMs QLoRA: Quantized Low-Rank Adaptation Github\uff1aqlora University of Washington, 2023 May, NeurIPS 2023</p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/qlora.html#_1","title":"\u5de5\u4f5c\u200b\u8981\u70b9","text":"<p>QLoRA\u200b\u5305\u542b\u200b\u4e24\u200b\u90e8\u5206\u200b\uff0c\u200b\u9996\u5148\u200b\u5c06\u200bFrozen pretrained LLM\u200b\u4f7f\u7528\u200bNF4\u200b\u65b9\u5f0f\u200b\u91cf\u5316\u200b, \u200b\u968f\u540e\u200b\u57fa\u4e8e\u200bLoRA\u200b\u601d\u60f3\u200b\u8fdb\u884c\u200bPEFT\uff0c</p> \\[ \\begin{aligned} Y^{\\text{BF16}} = X^{\\text{BF16}}\\text{doubleDequant}(c_1^{\\text{FP32}}, &amp;c_2^{\\text{k-bit}}, W^{\\text{NF4}}) + X^{\\text{BF16}}A^{\\text{BF16}}B^{\\text{BF16}} \\\\ \\text{doubleDequant}(c_1^{\\text{FP32}}, c_2^{\\text{k-bit}}, W^{\\text{NF4}})&amp;=\\text{dequant}(\\text{dequant}(c_1^{\\text{FP32}}, c_2^{\\text{k-bit}}), W^{\\text{NF4}}) \\\\ &amp;= W^{\\text{BF16}} \\end{aligned} \\] <ul> <li> 4-bit NormalFloat(NF4) \u200b\u5728\u200b\u7b26\u5408\u200b\u6b63\u6001\u5206\u5e03\u200b\u6570\u636e\u200b\u4e0a\u200b\u91cf\u5316\u200b\u6548\u679c\u200b\u4f18\u4e8e\u200b4-bit Integers\u200b\u548c\u200b4-bit Floats</li> <li> double quantization\u200b\u53cc\u91cd\u200b\u91cf\u5316\u200b\uff0c\u200b\u8fdb\u4e00\u6b65\u200b\u90fd\u200b\u91cf\u5316\u200b\u7f29\u653e\u200b\u5e38\u6570\u200b\u8fdb\u884c\u200b\u7f29\u653e\u200b\u4ee5\u200b\u51cf\u5c11\u200b\u5b58\u50a8\u200b\u5f00\u9500\u200b</li> <li> paged optimizers\uff0cGPU\u200b\u663e\u5b58\u200b\u4e0d\u8db3\u200b\u65f6\u200b\uff0c\u200b\u81ea\u52a8\u200b\u5728\u200bGPU\u200b\u548c\u200bCPU RAM\u200b\u95f4\u200b\u8fdb\u884c\u200bpage2page\u200b\u7684\u200b\u4f20\u8f93\u200b\uff0c\u200b\u4ee5\u200b\u907f\u514d\u200bOOM\u200b\u7684\u200b\u73b0\u8c61\u200b\uff0c\u200b\u7c7b\u4f3c\u200bCPU\u200b\u5185\u5b58\u4e0d\u8db3\u200b\u65f6\u200b\uff0c\u200b\u81ea\u52a8\u200b\u5728\u200bRAM\u200b\u548c\u200bDisk\u200b\u95f4\u200b\u8fdb\u884c\u200bpage2page\u200b\u7684\u200b\u4f20\u8f93\u200b</li> <li> finetue 33B/65B(&gt;780GB) LLM of GPU memory to 24GB/48GB without sacrificing performance</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/qlora.html#_2","title":"\u7ec6\u8282\u200b\u5b9e\u73b0","text":"<ol> <li> <p>4-bit NormalFloat Quantile Quantization\uff0c\u200b\u6b64\u524d\u200b\u7684\u200b\u91cf\u5316\u200b\u64cd\u4f5c\u200b\u5148\u9a8c\u200b\u5730\u200b\u8ba4\u4e3a\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u5728\u200b\u503c\u57df\u200b\u533a\u95f4\u200b\u5747\u5300\u5206\u5e03\u200b\uff0c\u200b\u7136\u800c\u200b\u5b9e\u9645\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u66f4\u200b\u503e\u5411\u200b\u6b63\u6001\u5206\u5e03\u200b(\u200b\u5982\u200bbatch_norm\u3001layer_norm\u3001normal_initializer\u3001truncated_normal_initializer)\uff0c\u200b\u56e0\u6b64\u200b\u57fa\u4e8e\u200b\u6b63\u6001\u5206\u5e03\u200b\u5bc6\u5ea6\u200b\u60c5\u51b5\u200b\u91cf\u5316\u200b\u66f4\u4e3a\u200b\u5408\u7406\u200b\uff0cNF4 convert\u200b\u5305\u62ec\u200b\uff1a</p> <ol> <li> <p>\u200b\u83b7\u53d6\u200bcdf\u200b\u5206\u4f4d\u200b\u6570\u503c\u200b <code>normal_map</code> </p><pre><code>if is_asymmetric:         # \u200b\u5b9e\u9645\u200b\u4f7f\u7528\u200b16\u200b\u503c\u200b: \u200b\u5de6\u200b7\u200b\u7b49\u200b\u5206\u200b, \u200b\u53f3\u200b8\u200b\u7b49\u200b\u5206\u200b\n    normal_cdf_left = -norm.ppf(torch.linspace(offset, 0.5, 8)[:-1])\n    normal_cdf_right = norm.ppf(torch.linspace(offset, 0.5, 9))\n\nelif not is_asymmetric:   # \u200b\u5b9e\u9645\u200b\u4f7f\u7528\u200b15\u200b\u503c\u200b: \u200b\u5de6\u200b7\u200b\u7b49\u200b\u5206\u200b, \u200b\u53f3\u200b7\u200b\u7b49\u200b\u5206\u200b\n    normal_cdf_left = -norm.ppf(torch.linspace(offset, 0.5, 8))\n    normal_cdf_right = norm.ppf(torch.linspace(offset, 0.5, 8))\n\nnormal_cdf = normal_cdf_left + normal_cdf_right\n# \u200b\u5206\u4f4d\u200b\u503c\u200b\u5f52\u4e00\u5316\u200b\nnormal_map = normal_cdf/absmax(normal_cdf)\n# [-1.0, -0.6961928009986877, -0.5250730514526367, -0.39491748809814453, -0.28444138169288635, -0.18477343022823334, -0.09105003625154495, 0.0, 0.07958029955625534, 0.16093020141124725, 0.24611230194568634, 0.33791524171829224, 0.44070982933044434, 0.5626170039176941, 0.7229568362236023, 1.0]\n</code></pre><p></p> <p>\u200b\u7f3a\u7701\u200bcdf\u200b\u8fb9\u754c\u503c\u200b <code>offset=(1-1/(2*15)+1-1/(2*16))/2</code> <code>offset\u22481</code> \u200b\u7684\u200b\u540c\u65f6\u200b\u8981\u6c42\u200b<code>absmax(normal_cdf)</code>\u200b\u4e0d\u8fc7\u200b\u4e8e\u5927\u4ee5\u200b\u907f\u514d\u200b\u5206\u4f4d\u200b\u503c\u200b\u5f52\u4e00\u5316\u200b\u540e\u200b\u4e2d\u5fc3\u200b\u5927\u200b\u5bc6\u5ea6\u200b\u533a\u57df\u200b\u7c92\u5ea6\u200b\u6a21\u7cca\u200b(\u200b\u5f52\u5c5e\u200b\u5de6\u5206\u200b\u4f4d\u6bb5\u200b\u548c\u200b\u5f52\u5c5e\u200b\u53f3\u5206\u200b\u4f4d\u6bb5\u200b\u5dee\u5f02\u200b\u8fc7\u200b\u5c0f\u200b)</p> </li> <li> <p>\u200b\u5f52\u4e00\u5316\u200b <code>x = x/absmax(x)</code></p> </li> <li>\u200b\u83b7\u53d6\u200b\u6700\u8fd1\u200b\u5206\u4f4d\u200b\u503c\u200b\uff0c<code>x = [find_nearest(v, normal_cdf) for v in x]</code></li> <li>\u200b\u6620\u5c04\u200b\u4e3a\u5206\u200b\u4f4d\u503c\u200b\u4e0b\u6807\u200b\u5bf9\u5e94\u200b\u7684\u200b4-bit\u200b\u503c\u200b</li> </ol> </li> <li> <p>double quantization\uff0c\u200b\u5bf9\u200b\u91cf\u5316\u200b\u5e38\u6570\u200b\u8fdb\u4e00\u6b65\u200b\u7f29\u653e\u200b(\u200b\u4e8c\u9636\u200b\u91cf\u5316\u200b\u5e38\u6570\u200b\u5171\u4eab\u200b\u4e00\u9636\u200b\u91cf\u5316\u200b\u5e38\u6570\u200b)\u200b\u4ee5\u200b\u51cf\u5c11\u200b\u5b58\u50a8\u200b\u5f00\u9500\u200b\uff0c\u200b\u5047\u8bbe\u200b\u53cc\u91cd\u200b\u91cf\u5316\u200bblock size\u200b\u5206\u522b\u200b\u4e3a\u200b\\(B_1=64, B_2=256\\)</p> <ul> <li>\u200b\u65e0\u200b\u53cc\u91cd\u200b\u91cf\u5316\u200b\uff0c\u200b\u4e00\u9636\u200b\u91cf\u5316\u200b\u5e38\u6570\u200b\u7c7b\u578b\u200b\u4e3a\u200bfp32<ul> <li>\u200b\u5e73\u5747\u200b\u6bcf\u4e2a\u200b\u53c2\u6570\u200b\u989d\u5916\u200b\u5f00\u9500\u200b\u4e3a\u200bfp32/64=0.5bit\uff1b</li> <li>\u200b\u5b58\u50a8\u200b\u91cf\u5316\u200b\u5e38\u6570\u200b\u989d\u5916\u200b\u5f00\u9500\u200b\u6bd4\u4f8b\u200b\u4e3a\u200bfp32/(64*nf4)=12.5%</li> </ul> </li> <li>\u200b\u5e94\u7528\u200b\u53cc\u91cd\u200b\u91cf\u5316\u200b\uff0c\u200b\u4e00\u9636\u200b\u3001\u200b\u4e8c\u9636\u200b\u91cf\u5316\u200b\u5e38\u6570\u200b\u7c7b\u578b\u200b\u5206\u522b\u200b\u4e3a\u200bfp32\u200b\u548c\u200bfp8<ul> <li>\u200b\u5e73\u5747\u200b\u6bcf\u4e2a\u200b\u53c2\u6570\u200b\u989d\u5916\u200b\u5f00\u9500\u200b\u4e3a\u200b(256*fp8 + fp32)/(256*64)=0.127bit</li> <li>\u200b\u5b58\u50a8\u200b\u91cf\u5316\u200b\u5e38\u6570\u200b\u989d\u5916\u200b\u5f00\u9500\u200b\u6bd4\u4f8b\u200b\u4e3a\u200b(256*fp8 + fp32)/(256*64*nf4)=3.175%</li> </ul> </li> </ul> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/PEFT/qlora.html#_3","title":"\u5b9e\u9a8c\u200b\u6548\u679c","text":"<ol> <li>NF4 is better other 4-bit quantization      </li> <li>Guanaco is the best-performing model after GPT-4      </li> <li> <p>NF4 quantization enables inference speedup     </p> <pre><code>from scipy.stats import norm\n\n# norm.ppf: Percent point function (inverse of `cdf`)\n# norm.cdf: Cumulative distribution function\n</code></pre><p></p> </li> <li> <p>https://medium.com/@levxn/lora-and-qlora-effective-methods-to-fine-tune-your-llms-in-detail-6e56a2a13f3c</p> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/cot.html","title":"Cot","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/cot.html#cot","title":"CoT","text":"<p>\u200b\u8bba\u6587\u200b\uff1aChain-of-Thought Prompting Elicits Reasoning in Large Language Models Google Brain, 2022 Jan, NeurIPS 2022</p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/cot.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/p-tuning.html","title":"P tuning","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/p-tuning.html#p-tuning-1","title":"P-tuning-1","text":"<p>\u200b\u8bba\u6587\u200b\uff1aGPT Understands, Too  Tsinghua University &amp; Massachusetts Institute of Technology, 2021 Mar </p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/p-tuning.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>https://www.zhihu.com/tardis/bd/art/627642632?source_id=1001</li> <li>prefix tuning\u200b\u5728\u200b\u9996\u90e8\u200b\u6dfb\u52a0\u200b\u4e86\u200bcontinue prompt\uff08\u200b\u53ef\u200b\u7406\u89e3\u200b\u4e3a\u200bvirtual instruction\uff09\uff0c\u200b\u800c\u200bp-tuning\u200b\u989d\u5916\u200b\u5728\u200b\u4e2d\u95f4\u200b\u6dfb\u52a0\u200b\u4e86\u200bcontinue prompt</li> <li>P-Tuning that employs trainable continuous prompt embeddings in concatenation with discrete prompts\uff0c\u200b\u8fde\u7eed\u200b\u7684\u200bprompt\u200b\u662f\u200bP\uff0c\u200b\u79bb\u6563\u200b\u7684\u200bprompt\u200b\u662f\u200bx\u200b\u548c\u200by</li> <li>Results in Table 1 show that manual discrete prompts lead to unstable performance. For example, if we compare the last two prompts in the table, changing a single word in prompt causes a drastic decrease of 20 points in performance</li> <li>Let \\([P_i]\\) be the ith continuous prompt embedding. The prompt template for P-Tuning is as follows: \\(T = \\{[P_{0:i}], x, [P_{i+1: j}], y, [P_{j+1: k}]\\}\\)\uff0c\u200b\u9700\u200b\u8bad\u7ec3\u200bembeddings \\(\\{P_i\\}_{i=1}^k\\)</li> <li></li> <li>3 Experiments</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/p-tuning.html#p-tuning-2","title":"P-tuning-2","text":"<p>\u200b\u8bba\u6587\u200b\uff1aP-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks Tsinghua University &amp; BAAI &amp; Shanghai Qi Zhi Institute, 2021 Oct, ACL 2022</p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/p-tuning.html#_2","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>prompt tuning can be comparable to fine-tuning when the model scales to over 10 billion parameters. However, for medium-sized models (from 100M to 1B) that are widely used, prompt tuning performs much worse than fine-tuning.</li> <li>prompt tuning: Lack of universality across scales, Lack of universality across tasks</li> <li>P-Tuning v2 is an implementation of prefix tuning optimized and adapted for NLU</li> <li>Reparameterization. Appendix B</li> <li>Prompt Length. Appendix B, simple classification tasks prefer shorter prompts (less than 20); hard sequence labeling tasks prefer longer ones (around 100).</li> <li>Multi-task Learning</li> <li>Classification Head, use [CLS] for prediction!</li> <li>4 Experiments</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/prefix_tuning.html","title":"Prefix tuning","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/prefix_tuning.html#prefix-tuning","title":"Prefix Tuning","text":"<p>\u200b\u8bba\u6587\u200b\uff1aPrefix-Tuning: Optimizing Continuous Prompts for Generation Stanford University, 2021 Jan, ACL 2021</p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/prefix_tuning.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>\u200b\u4e00\u79cd\u200bprefix\u200b\u5bf9\u5e94\u200b\u4e00\u79cd\u200btask\uff0c\u200b\u5373\u200btask-specific prefix\uff08\u200b\u53ef\u4ee5\u200b\u4e3a\u540c\u200btask\u200b\u4e0d\u540c\u200btopic\uff09\uff0c\u200b\u63d2\u4ef6\u200b\u5f62\u5f0f\u200b</li> <li>for NLG tasks, keeps language model parameters frozen, but optimizes a small continuous task-specific vector (called prefix)</li> <li>prefix as if were previous virtual tokens, \u200b\u8fde\u7eed\u200b\u7684\u200b\u865a\u62df\u200btoken\u200b\u5411\u91cf\u200b\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u79bb\u6563\u200b\u7684\u200bprompt\u200b\u5411\u91cf\u200b</li> <li>learning only 0.1% of the parameters, prefix-tuning obtains comparable performance in the full data setting</li> <li>table-to-text, \u200b\u8f93\u5165\u200b\u8868\u683c\u200b\u4fe1\u606f\u200b\uff0c\u200b\u8f93\u51fa\u200b\u76f8\u5e94\u200b\u7684\u200b\u6587\u672c\u200b\u63cf\u8ff0\u200b</li> <li>\\(X_\\text{idx}\\) \u200b\u8868\u793a\u200b\u5c5e\u4e8e\u200b\\(X\\)\u200b\u90e8\u5206\u200b\u7684\u200b\u5e8f\u5217\u200b\u4e2d\u200b\u4e0b\u6807\u200b\u96c6\u5408\u200b</li> <li>\\(h_i\\) \u200b\u8868\u793a\u200b \\(n\\) \u200b\u5c42\u200b\u7684\u200bhidden state</li> <li>decoder, <code>z=[prefix; x; y]</code></li> <li>encoder-deocer, <code>z=[prefix_1; x], z1=[prefix_2; y]</code></li> <li>prefix embedding table: trainable matrix \\(P_\\theta \\in \\mathbb{R}^{\\vert P_\\text{idx} \\vert \\times d}\\)</li> <li> <p>prefix length\u200b\u654f\u611f\u200b </p><pre><code>import torch\nimport torch.nn as nn\n\nclass PrefixTuning(nn.Module):\n    def __init__(self, model, prefix_length=10, hidden_size=768):\n        super().__init__()\n        self.model = model  # \u200b\u51bb\u7ed3\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\n        self.prefix_length = prefix_length\n        self.prefix_embedding = nn.Parameter(\n            torch.randn(prefix_length, hidden_size)\n        )  # \u200b\u53ef\u200b\u8bad\u7ec3\u200b\u7684\u200b\u524d\u7f00\u200b\n\n    def forward(self, input_ids):\n        batch_size = input_ids.shape[0]\n        prefixes = self.prefix_embedding.unsqueeze(0).expand(batch_size, -1, -1)\n        extended_input = torch.cat([prefixes, input_ids], dim=1)\n        outputs = self.model(inputs_embeds=extended_input)\n        return outputs\n</code></pre><p></p> \\[ h_i = \\begin{cases} P_\\theta[i: ] &amp; \\text{if } i \\in P_\\text{idx} \\\\ \\text{LM}_\\phi(z_i, h_{\\lt i}) &amp; \\text{otherwise} \\end{cases} \\] </li> <li> <p>\u200b\u5b9e\u9a8c\u200b\u4e2d\u4e2d\u200b\u53d1\u73b0\u200b\u76f4\u63a5\u200b\u4f7f\u7528\u200b\\(P_\\theta[i:]\\)\u200b\u53ef\u80fd\u200b\u8bad\u7ec3\u200b\u4e0d\u200b\u7a33\u5b9a\u200b\u5e76\u200b\u5e26\u6765\u200b\u4e00\u5b9a\u200b\u7684\u200b\u6548\u679c\u200b\u51cf\u76ca\u200b\uff0c\u200b\u56e0\u6b64\u200b \\(P_\\theta[i:] = \\text{MLP}(P'_\\theta[i:]), P'_\\theta[i:] \\in \\mathbb{R}^{\\vert P_\\text{idx} \\vert \\times d_2}\\)\uff0c\u200b\u5728\u200b\u8bad\u7ec3\u200b\u5b8c\u6210\u200b\u540e\u200b\u53ef\u200b\u8fd0\u7b97\u200b\u4e00\u904d\u200b\u540e\u200b\u53ea\u200b\u4fdd\u5b58\u200b\\(P_\\theta\\)\u200b\u5e76\u200b\u820d\u5f03\u200b \\(P'_{\\theta}\\)</p> </li> </ul> <ul> <li>prompt tuning\u200b\u90e8\u5206\u200b\u7684\u200bprompt\u200b\u53ef\u80fd\u200b\u8fc7\u957f\u200b\uff0c\u200b\u5bb9\u6613\u200b\u8d85\u51fa\u200b<code>context_window</code></li> <li>6 Main Results</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/prefix_tuning.html#ablation","title":"Ablation","text":"<ul> <li>longer prefixes have a negligible impact on inference speed, because attention computation over the entire prefix is parallellized on GPUs.</li> <li>discrete prompting &lt; embedding-only ablation &lt; prefix-tuning</li> <li>embedding-only ablation, \u200b\u53ea\u200b\u5728\u200bembedding layer\u200b\u8f93\u5165\u200b\u65f6\u200b\u52a0\u4e0a\u200bprefix\uff1bfull\uff1a\u200b\u6240\u6709\u200b\u5c42\u4e0a\u200b\u90fd\u200b\u52a0\u200bprefix</li> <li>infix-tuning slightly underperforms prefix-tuning, because prefix-tuning can affect the activations of x and y whereas infix-tuning can only influence the activations of y</li> <li>how the prefix is initialized has a large impact in low-data settings, random: low performance + high var; read_word: improve generation</li> <li>In particular, initializing with task relevant words such as \u201csummarization\u201d and \u201ctable-to-text\u201d obtains slightly better performance than task irrelevant words such as \u201celephant\u201d and \u201cdivide\u201d, but using real words is still better than random</li> <li>Additional Results for the Initialization Experiment</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/prompt_thought.html","title":"Prompt thought","text":"<ul> <li>CoT</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/prompt_tuning.html","title":"Prompt tuning","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/prompt_tuning.html#prompt-tuning","title":"Prompt Tuning","text":"<p>\u200b\u8bba\u6587\u200b\uff1aThe Power of Scale for Parameter-Efficient Prompt Tuning Google Research, 2021 Apr, ACL 2021</p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/prompt_tuning.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>prompt ensembling</li> <li>freeze the entire pre-trained model and only allow an additional k tunable tokens per downstream task to be prepended to the input text (with no intermediate-layer prefixes or task-specific output layers)</li> <li>Prompt tuning removes the restriction that the prompt P be parameterized by \\(\\theta\\); instead the prompt has its own dedicated parameters, \\(\\theta_P\\) , that can be updated. \\(P_{\\theta, \\theta_P}(Y\\vert [P; X])\\)</li> <li>\u200b\u5bf9\u4e8e\u200bencoder-decoder\u200b\u7ed3\u6784\u200b\u4e2d\u200b\uff0c\u200b\u53ea\u200b\u5728\u200bencoder\u200b\u7aef\u200b\u6267\u884c\u200bprepend</li> <li>compared to random initialization, a word-like representation might serve as a good initialization spot, For classification tasks, a third option is to initialize the prompt with embeddings that enumerate the output classes, similar to the \u201cverbalizers\u201d of [Exploiting cloze-questions for few-shot text classification and natural language inference.]</li> <li>prompt length</li> <li></li> <li></li> <li>3 Results</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/image/adapter_tuning_1.html","title":"Adapter tuning 1","text":""},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/image/adapter_tuning_1.html#adapter-tuning","title":"Adapter Tuning","text":"<p>\u200b\u8bba\u6587\u200b\uff1aParameter-Efficient Transfer Learning for NLP Google Research &amp; Jagiellonian University, 2019 Feb, ICML 2019</p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Prompt_Engineering/image/adapter_tuning_1.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>Adapter modules yield a compact and extensible model; they add only a few trainable parameters per task</li> <li>Adapter-based tuning requires training two orders of magnitude fewer parameters to fine-tuning, while attaining similar performance</li> <li>Adapters are new modules added between layers of a pre-trained network</li> <li>\\(\\phi_{w, v}(x)\\)\uff0c\u200b\u5176\u4e2d\u200b\\(\\phi_{w, v_0}(x) \\approx \\phi_w(x), \\vert v \\vert \\ll \\vert w \\vert\\), only task-specific parameters \\(v\\) and LN layer trained. (training the layer normalization parameters alone is insufficient for good performance)</li> <li>Adapter modules have two main features: a small number of parameters, and a near-identity initialization, We also observe that if the initialization deviates too far from the identity function, the model may fail to train.</li> <li>Adapter internal skip-connection: with the skip-connection, if the parameters of the projection layers are initialized to near-zero, the module is initialized to an approximate identity function.</li> <li>insect to all layer</li> <li>\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u80fd\u591f\u200b\u5728\u200b\u53ea\u200b\u989d\u5916\u200b\u5bf9\u200b\u589e\u52a0\u200b\u7684\u200b 3.6% \u200b\u53c2\u6570\u200b\u89c4\u6a21\u200b\uff08\u200b\u76f8\u6bd4\u200b\u539f\u6765\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\u7684\u200b\u53c2\u200b\u6570\u91cf\u200b\uff09\u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u53d6\u5f97\u200b\u548c\u200bFull-Finetuning \u200b\u63a5\u8fd1\u200b\u7684\u200b\u6548\u679c\u200b\uff08GLUE\u200b\u6307\u6807\u200b\u5728\u200b0.4%\u200b\u4ee5\u5185\u200b\uff09</li> <li>3.1. Experimental Settings</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Scaling_Law/scaling_law.html","title":"Scaling law","text":"<ul> <li>forward\uff1a\u200b\u6b63\u5e38\u200b\u77e9\u9635\u200b\u8fd0\u7b97\u200bflops\u200b\u5305\u62ec\u200b\u4e58\u6cd5\u200b\u548c\u200b\u52a0\u6cd5\u200b\uff0c\u200b\u5982\u200b \\(W\\in \\mathbb{R}^{m\\times n}, X\\in \\mathbb{R}^{bs\\times m}\\)\uff0c\u200b\u56e0\u6b64\u200b\u8fd0\u7b97\u200b\\(AB\\)\u200b\u7684\u200b\u6d6e\u70b9\u6570\u200b\u8fd0\u7b97\u200b\u6570\u4e3a\u200b\\(2*bs*m*n\\)</li> <li> <p>backwrd\uff1a\u200b\u53cd\u5411\u200b\u4f20\u64ad\u200b\u8fc7\u7a0b\u200b\u4e00\u822c\u200b\u4e3a\u200b\u6b63\u5411\u200b\u4f20\u64ad\u200b\u8fc7\u7a0b\u200b\u7684\u200b2\u200b\u500d\u200b\uff0c\u200b\u5206\u522b\u200b\u5bf9\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b \\(W \\in \\mathbb{R}^{m\\times n}\\) \u200b\u548c\u200b\u8f93\u5165\u200b \\(X \\in \\mathbb{R}^{bs \\times m}\\) \u200b\u8fdb\u884c\u200b\u68af\u5ea6\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u5373\u200b \\(\\frac{\\partial L}{\\partial W} = X^T \\frac{\\partial L}{\\partial Y}\\) \u200b\u548c\u200b \\(\\frac{\\partial L}{\\partial X} =  \\frac{\\partial L}{\\partial Y} W^T\\)\uff0c\u200b\u6d6e\u70b9\u6570\u200b\u8ba1\u7b97\u200b\u91cf\u200b\u4e3a\u200b\\(2*2*bs*m*n=4*bs*m*n\\)\uff0c\u200b\u504f\u7f6e\u200b\u9879\u200b\u68af\u5ea6\u200b \\(\\frac{\\partial L}{\\partial b}=\\text{reduce_sum}(\\frac{\\partial L}{\\partial Y}, 0)\\) \u200b\u53ef\u200b\u5ffd\u7565\u4e0d\u8ba1\u200b  </p> <p>\u200b\u4e00\u822c\u200b\u4e0d\u200b\u9700\u8981\u200b\u8ba1\u7b97\u200b\u8f93\u5165\u200b\\(X\\) \u200b\u68af\u5ea6\u200b  </p> </li> <li> <p>forward + backward = \\(2*3*N\\)\uff0c\\(N\\)\u200b\u8868\u793a\u200b\u53c2\u200b\u6570\u91cf\u200b\uff0c2\u200b\u8868\u793a\u200bmultiply+add\u200b\u64cd\u4f5c\u200b</p> </li> <li>scaling law\u200b\u5728\u200b\u5904\u7406\u200bmoe model\u200b\u65f6\u200b\uff0c\u200b\u8003\u91cf\u200b\u7684\u200b\u65f6\u200b \\(N_\\text{active}\\) \u200b\u800c\u200b\u4e0d\u662f\u200b \\(N_\\text{total}\\) \uff08\u200b\u4f46\u200b\u53ef\u80fd\u200b\u5e26\u6765\u200b\u672a\u6fc0\u6d3b\u200b\u53c2\u200b\u6570\u91cf\u200b\u5f71\u54cd\u200b\u6548\u7387\u200b\u7684\u200b\u95ee\u9898\u200b\uff09</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Scaling_Law/scaling_law.html#1","title":"1","text":"<p>\u200b\u8bba\u6587\u200b\uff1aDeep Learning Scaling is Predictable, Empirically Baidu Research, 2017 Dec</p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Scaling_Law/scaling_law.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>this paper is the first to empirically characterize learning curve and model size scaling trends for a broad range of application domains and models.</li> <li>Our empirical results show power-law generalization error scaling across a breadth of factors, resulting in power-law exponents\u2014\u2014the \"steepness\" of the learning curve\u2014\u2014yet to be explained by theoretical work. Further, model improvements only shift the error but do not appear to affect the power-law exponent. We also show that model size scales sublinearly with data size.</li> <li>These scaling relationships have significant implications on deep learning research, practice, and systems. They can assist model debugging, setting accuracy targets, and decisions about data set growth. They can also guide computing system design and underscore the importance of continued computational scaling.</li> <li>accurately predicting generalization error scaling with training set size would provide a powerful tool for estimating the costs\u2014in data and compute requirements\u2014for advancing state-of-the-art (SOTA).</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Scaling_Law/scaling_law.html#generalization-error-scaling-with-data","title":"Generalization Error Scaling with Data","text":"<ul> <li>learning curves measure how much training data a model family requires to reach a particular accuracy.</li> <li>generalization error curve</li> <li>loss learning curve</li> <li> <p>Many studies theoretically predict that generalization error \"learning curves\" take a power-law form, \\(\\epsilon (m) \\propto \\alpha m^{\\beta_g}\\). </p> <ul> <li>\\(\\epsilon\\) \u200b\u4e3a\u200bgeneralization error  </li> <li>\\(m\\) number of training samples</li> <li>\\(\\alpha\\) is a scalar</li> <li>\\(\\beta_g\\) scaling exponent\uff0c\u200b\u4e00\u822c\u200b\u4e3a\u200b\u8d1f\u6570\u200b, g=generation error</li> </ul> </li> <li> <p>Our results show that power-law learning curves exist across all tested domains. Although different applications yield different power-law exponents and intercepts</p> </li> <li>Improved model architectures and optimizers can improve the power-law intercept, but not the exponent</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Scaling_Law/scaling_law.html#model-capacity-required-to-fit-data","title":"Model Capacity Required to Fit Data","text":"<ul> <li>model size scaling</li> <li> <p>number of model parameters to fit a data set should follow \\(s(m) \\propto  \\alpha m^{\\beta_p}\\)</p> <ul> <li>\\(s(m)\\) is the required model size to fit a training set of size m</li> <li>\\(\\alpha\\) is a scalar</li> <li>\\(\\beta_p \\in [0.5, 1]\\) p=parameter</li> </ul> </li> <li> <p>These studies show that while model capacity might explain a model\u2019s ability to memorize training examples, capacity may not adequately explain the model\u2019s ability to generalize to new examples.</p> </li> <li>Rather than reason through these complexities, it is currently easier for researchers and practitioners to over-parameterize models to fit training data</li> <li>train \"hyperparameter-reduced\" versions of these models on successively larger subsets (shards) of a training set to see how the accuracy of the model grows with training set size.</li> <li>\"large data set\" is a training set that could be reduced in size by 2-3 orders of magnitude and still be significant enough to perform valuable model architecture studies.</li> <li>Data sets: shard in steps of roughly 2x, e.g., 0.1% T, 0.2% T, 0.2% T, ...</li> <li>We use either the validation set available with training data, or if such a validation set is not available, we use a hold-out subset of T that does not overlap with any of the T shards.</li> <li>\\(\\forall_i V \\cap T_i = \\phi\\)</li> </ul> <p> - small data region - power-law region - irreducible error region</p> <p>3 types of scaling limits: </p> <ul> <li>training data is too small</li> <li>computation is too slow</li> <li>irreducible error</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Scaling_Law/scaling_law.html#2","title":"2","text":"<p>\u200b\u8bba\u6587\u200b\uff1aScaling Laws for Neural Language Models Johns Hopkins University &amp; OpenAI, 2020 Jan  </p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Scaling_Law/scaling_law.html#_2","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>observe precise power-law scalings for performance as a function of training time, context length, dataset size, model size, and compute budget</li> <li>display predicted compute when using a sufficiently small batch size</li> <li>model size &gt; batch size &gt; steps</li> <li>PF-day \\(=10^{15}*24*3600=8.64*10^{19}\\) FLOPs</li> <li>equation 1.7\u200b\u548c\u200b1.8\u200b\u5982\u4f55\u200b\u5f97\u6765\u200b</li> <li>\\(B_\\text{crit}\\) provides a roughly optimal compromise(trade-off) between time and compute efficiency.</li> <li>\\(C_\\text{min}\\) \u200b\u548c\u200b \\(S_\\text{min}\\) \u200b\u5206\u522b\u200b\u662f\u200b\u5728\u200b\u6781\u5c0f\u200bbatch_size\u200b\u4e0e\u200b\u6781\u5927\u200bbatch_size\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u7684\u200b\u53d6\u503c\u200b</li> <li>recurrent Transformers\uff0c\u200b\u7c7b\u4f3c\u200b\u4e8e\u200bALBERT</li> </ul>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Scaling_Law/scaling_law.html#3","title":"3","text":"<p>\u200b\u8bba\u6587\u200b\uff1aScaling Laws for Autoregressive Generative Modeling OpenAI, 2020 Oct</p>"},{"location":"AI/Paper_Reading/Trick/LLM_Extend/Scaling_Law/scaling_law.html#chinchilla","title":"Chinchilla","text":"<p>\u200b\u8bba\u6587\u200b\uff1aTraining Compute-Optimal Large Language Models DeepMind, 2022 Mar</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Compression/mrl.html","title":"Mrl","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Compression/mrl.html#mrl","title":"MRL","text":"<p>\u200b\u8bba\u6587\u200b\uff1aMatryoshka Representation Learning Github\uff1aMRL University of Washington &amp; Google Research &amp; Harvard University, 2022 May, NeurIPS 2022</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Compression/mrl.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>MRL: \u200b\u8be5\u79cd\u200b\u65b9\u6cd5\u200b\u662f\u200b\u5728\u200bbert\u200b\u540e\u9762\u200b\u63a5\u200b9\u200b\u4e2a\u200bmlp\u200b\u5c42\u200b\u3002mlp(768,8),(768,16),...(768,2048)\u3002\u200b\u7136\u540e\u200b\u628a\u200bbert\u200b\u7f16\u7801\u200b\u5f97\u5230\u200b\u7684\u200b768\u200b\u7ef4\u200b\u5411\u91cf\u200b\uff0c\u200b\u5728\u200b\u540c\u65f6\u200b\u901a\u8fc7\u200b\u8fd9\u200b9\u200b\u4e2a\u200bmlp\u200b\u5f97\u5230\u200b\u4e0d\u540c\u200b\u7ef4\u5ea6\u200b\u7684\u200b\u5411\u91cf\u200b\uff0c\u200b\u7136\u540e\u200b\u8ba1\u7b97\u200b9\u200b\u4e2a\u200bloss\uff0c\u200b\u7d2f\u52a0\u200b\u8d77\u6765\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b\u3002</li> <li>Efficient Matryoshka Representation Learning\uff08MRL-E\uff09\uff1a\u200b\u5206\u522b\u200b\u5c06\u200b\u524d\u200b 8\u300116\u3001...\u30012048\u200b\u7ef4\u200b\u5411\u91cf\u200b\u8ba1\u7b97\u200b9\u200b\u4e2a\u200bloss\uff0c\u200b\u7d2f\u52a0\u200b\u8d77\u6765\u200b\u8fdb\u884c\u200b\u8bad\u7ec3\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Compression/slimmable_network.html","title":"Slimmable network","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Compression/slimmable_network.html#slimmable-neural-networks","title":"Slimmable Neural Networks","text":"<p>\u200b\u8bba\u6587\u200b\uff1aSlimmable Neural Networks Github\uff1aslimmable_networks  University of Illinois at Urbana-Champaign &amp; Snap Inc. &amp; ByteDance Inc, 2018 Dec, ICLR 2019</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Compression/slimmable_network.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<ul> <li>\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u968f\u673a\u200b\u9009\u53d6\u200b n_head, d_model \u200b\u6216\u200b d_ffn</li> <li>Attention: <code>(bs, n_head, seq_len, head_dim)</code></li> <li>FFN: <code>(bs, seq_len, d_ff) \u2192 (bs, seq_len, d_model)</code></li> <li>LN: <code>(bs, seq_len, d_model) \u200b\u8fdb\u884c\u200bLN</code></li> <li>\u200b\u63a8\u7406\u200b\u9636\u6bb5\u200b\u8bbe\u7f6e\u200b n_head, d_model \u200b\u548c\u200b d_ffn</li> <li>\u200b\u4e0d\u50cf\u200bMRL\u200b\u4e00\u6837\u200b\u5bf9\u4e8e\u200b\u5355\u200bbatch\u200b\u6837\u672c\u200b\u8fdb\u884c\u200b\u7ebf\u6027\u200b\u76f8\u52a0\u200b\uff0c\u200b\u7531\u4e8e\u200bLN\uff08\u200b\u6216\u200bRMSNorm\uff09\u200b\u7279\u6027\u200b\uff0c\u200b\u53ea\u80fd\u200b\u5355\u6b21\u200b\u8ba1\u7b97\u200b\u9009\u5b9a\u200bwidth\u200b\u7684\u200bloss</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Distillation/distillation.html","title":"Distillation","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Distillation/distillation.html#_1","title":"\u84b8\u998f\u200b\u6280\u5de7","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Distillation/distillation.html#soft-label-hard-label","title":"Soft Label &amp; Hard Label","text":"<p>\u200b\u6559\u5e08\u200b\u6a21\u578b\u200b\u7684\u200b\u5206\u7c7b\u200b\u7ed3\u679c\u200b\u4e00\u822c\u200b\u4e3a\u200b\u8fde\u7eed\u200b\u6982\u7387\u200b\u8f6f\u200b\u6807\u7b7e\u200b\uff0c\u200b\u53ef\u200b\u53ea\u200b\u4f7f\u7528\u200b\u8f6f\u200b/\u200b\u786c\u200b\u6807\u7b7e\u200b\u84b8\u998f\u200b\u6216\u200b\u5229\u7528\u200b\u6df7\u5408\u200b\u6807\u7b7e\u200b\u8fdb\u884c\u200b\u84b8\u998f\u200b  </p> <ol> <li>Soft Label\uff1a\\(\\mathcal{L}_\\text{soft} = \\sum_{i}\\sum_{k} p_{i, k}^\\text{teacher}\\log q_{i, k}\\)</li> <li>Hard Label\uff1a\\(\\mathcal{L}_\\text{hard} = \\sum_{i} y_i^\\text{teacher}\\log q_{i}\\)</li> <li>Hybrid Label: \\(\\mathcal{L} = \\alpha\\mathcal{L}_\\text{soft} + (1-\\alpha) \\mathcal{L}_\\text{hard}\\)\uff0c\\(\\alpha\\) \u200b\u4e3a\u200b\u6743\u91cd\u200b\u8d85\u200b\u53c2\u6570\u200b</li> </ol> <ul> <li>\u200b\u84b8\u998f\u200b\u65f6\u200b\u53ef\u200b\u4f7f\u7528\u200b\u9884\u200b\u8bad\u7ec3\u200b word_embedding\u200b\u6216\u200bmodel \u200b\u8fdb\u884c\u200b\u5feb\u901f\u200b\u8fc1\u79fb\u200b\u5b66\u4e60\u200b</li> <li>\u200b\u6311\u9009\u200b\u84b8\u998f\u200b\u6837\u672c\u200b\u65f6\u200b\uff0c\u200b\u53ef\u200b\u9009\u62e9\u200b\u6559\u5e08\u200b\u6a21\u578b\u200b\u547d\u4e2d\u200b\u7684\u200b\u6b63\u200b\u6837\u672c\u200b\\(N_\\text{pos}\\)\uff0c\u200b\u5e76\u200b\u91c7\u6837\u200b\u6536\u96c6\u200b\u8d1f\u200b\u6837\u672c\u200b \\(pp*N_\\text{neg}\\)</li> <li>\u200b\u4e3a\u200b\u4f7f\u200b\u5b66\u751f\u200b\u6a21\u578b\u200b\u5145\u5206\u5229\u7528\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\uff0c\u200b\u53ef\u200b\u5c06\u200b\u6559\u5e08\u200b\u6a21\u578b\u200b\u7684\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u52a0\u5165\u200b\u4f5c\u4e3a\u200b\u84b8\u998f\u200b\u6570\u636e\u200b\u96c6\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Distillation/distillation.html#temperature","title":"Temperature","text":"<p>\u200b\u6e29\u5ea6\u200b\u7cfb\u6570\u200b\u7528\u4e8e\u200b\u63a7\u5236\u200b\u6559\u5e08\u200b\u6a21\u578b\u200b\u7684\u200b\u8f6f\u200b\u6807\u7b7e\u200b\u6982\u7387\u5206\u5e03\u200b \\(p_i = \\frac{e^{z_i/T}}{\\sum_j e^{z_j/T}}\\)\uff0c</p> <ul> <li>\\(T\\rightarrow 0\\)\uff0c\u200b\u9000\u5316\u200b\u4e3a\u200b\u786c\u200b\u6807\u7b7e\u200b\u84b8\u998f\u200b</li> <li>\\(T\\lt 1\\)\uff0c\u200b\u9510\u5316\u200b\u6982\u7387\u5206\u5e03\u200b\uff0c\u200b\u4f7f\u200b\u4e3b\u8981\u200b\u7c7b\u522b\u200b\u6982\u7387\u200b\u66f4\u200b\u663e\u8457\u200b\uff0c\u200b\u4e00\u822c\u200b\u4e0d\u200b\u9002\u7528\u200b\u800c\u662f\u200b\u76f4\u63a5\u200b\u5e94\u7528\u200b\u786c\u200b\u6807\u7b7e\u200b</li> <li>\\(T=1\\)\uff0c\u200b\u9000\u5316\u200b\u4e3a\u200b\u6807\u51c6\u200bsoftmax</li> <li>\\(T\\gt 1\\)\uff0c\u200b\u8f6f\u5316\u200b\u6982\u7387\u5206\u5e03\u200b\uff0c\u200b\u8ba9\u200b\u6b21\u8981\u200b\u7c7b\u522b\u200b\u6982\u7387\u200b\u66f4\u200b\u663e\u8457\u200b\uff0c\u200b\u4f7f\u7528\u200b\u8f83\u200b\u591a\u200b</li> <li>\\(T\\rightarrow \\infty\\)\uff0c\u200b\u6240\u6709\u200b\u7c7b\u522b\u200b\u6982\u7387\u200b\u8d8b\u8fd1\u200b\u5747\u5300\u5206\u5e03\u200b \\(1/K\\)</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/atom.html","title":"Atom","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/atom.html#atom","title":"Atom","text":"<p>\u200b\u8bba\u6587\u200b\uff1aAtom: Low-Bit Quantization for Efficient and Accurate LLM Serving Shanghai Jiao Tong University &amp; University of Washington &amp; Peking University &amp; OctoAI &amp; Carnegie Mellon University, 2023 Oct, MLSys 2024</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/atom.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/gptq.html","title":"Gptq","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/gptq.html#gptq","title":"GPTQ","text":"<p>\u200b\u8bba\u6587\u200b\uff1aGPTQ: Accurate Post-Training Quantization for Generative Pretrained Transformers Github\uff1agptq IST Austria &amp; ETH Zurich &amp; NeuralMagic, 2022 Oct, ICLR 2023</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/gradient_checkpointing.html","title":"Gradient checkpointing","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/kv_quant.html","title":"Kv quant","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/kv_quant.html#kvquant","title":"KVQuant","text":"<p>\u200b\u8bba\u6587\u200b\uff1aKVQuant: Towards 10 million context length LLM inference with KV cache quantization Github\uff1aKVQuant UC Berkeley &amp; Stanford University &amp; Independent Researcher &amp; UC San Diego, 2023 Sep, SIGOPS 2023</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/kv_quant.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<p>\u200b\u968f\u7740\u200bLLM\u200b\u7684\u200b\u53d1\u5c55\u200b\uff0cKV Cache\u200b\u5df2\u200b\u79f0\u4e3a\u200b\u4e3b\u6d41\u200b\u7684\u200b\u5b58\u50a8\u200b\u4f18\u5316\u200b\u65b9\u6848\u200b\u4e4b\u4e00\u200b\uff0c\u200b\u4f46\u200b\u968f\u7740\u200bcontext_window\u200b\u7684\u200b\u589e\u957f\u200b\uff0c\u200b\u957f\u200b\u5e8f\u5217\u200bKV Cache\u200b\u6210\u4e3a\u200b\u4e86\u200b\u5b58\u50a8\u7a7a\u95f4\u200b\u6d88\u8017\u200b\u7684\u200b\u91cd\u8981\u200b\u539f\u56e0\u200b\uff0cKVQuant\u200b\u901a\u8fc7\u200b\u91c7\u7528\u200b\u51e0\u79cd\u200b\u65b0\u9896\u200b\u7684\u200b\u65b9\u6cd5\u200b\u4fc3\u8fdb\u200b\u4e86\u200b\u4f4e\u200b\u7cbe\u5ea6\u200bKV Cache\u200b\u91cf\u5316\u200b\u3002</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/kv_quant.html#group-wise-pre-rope-key-quantization","title":"Group-wise Pre-RoPE Key Quantization","text":"<p>\u200b\u5728\u200bLLM\u200b\u4e2d\u200b\uff0cpre/post-RoPE Key\u200b\u4ee5\u53ca\u200bValue\u200b\u6709\u200b\u4e0d\u540c\u200b\u7684\u200b\u8868\u73b0\u5f62\u5f0f\u200b</p> <ul> <li>pre-RoPE Key\u200b\u5728\u200b\u67d0\u4e9b\u200b\u7279\u5f81\u200b\u7ef4\u5ea6\u200b\u4e2d\u200b\u8868\u73b0\u200b\u51fa\u200b\u660e\u663e\u200b\u7684\u200b\u91cf\u7ea7\u200b\u79bb\u7fa4\u200b\u503c\u200b</li> <li>post-RoPE Kye\u200b\u76f8\u5e94\u200b\u7684\u200b\u79bb\u7fa4\u200b\u7279\u5f81\u200b\u7ef4\u5ea6\u200b\u7684\u200b\u5e45\u5ea6\u200b\u91cf\u7ea7\u200b\u4e0d\u518d\u200b\u6709\u200b\u4e00\u81f4\u6027\u200b</li> <li>Value\u200b\u65e0\u200b\u660e\u663e\u200b\u7684\u200b\u56fa\u5b9a\u200b\u79bb\u7fa4\u200b\u503c\u200b\u8868\u73b0\u5f62\u5f0f\u200b</li> </ul> <p>\u200b\u57fa\u4e8e\u200b\u4e0a\u8ff0\u200b\u73b0\u8c61\u200b\u4ee5\u53ca\u200b\u6d88\u878d\u200b\u5bf9\u6bd4\u200b\u5b9e\u9a8c\u200b\uff0c\u200b\u91c7\u7528\u200b\u4e86\u200b\u4ee5\u4e0b\u200b\u91cf\u5316\u200b\u65b9\u6848\u200b</p> <ol> <li>Token-wise Value Quantization</li> <li> <p>Group-wise Pre-RoPE Key Quantization \u200b\u5148\u200b\u91cf\u5316\u200bpre-RoPE Key\uff0c\u200b\u53cd\u200b\u91cf\u5316\u200b\u540e\u200b\u518d\u200b\u5b9e\u65f6\u200b\u5d4c\u5165\u200b\u4f4d\u7f6e\u200b\u7f16\u7801\u200b\u4fe1\u606f\u200bRoPE</p> <p></p> <p></p> <p>Info</p> <ul> <li>Group-wise\uff1apre-RoPE Key Quantization \u200b\u8f83\u200b post-RoPE Key Quantization\u200b\u6548\u679c\u200b\u66f4\u4f73\u200b</li> <li>Token-wise\uff1apost-RoPE Key Quantization \u200b\u8f83\u200b pre-RoPE Key Quantization\u200b\u6548\u679c\u200b\u66f4\u4f73\u200b</li> </ul> <p></p> <p></p> <p></p> <p></p> <p><code>gs</code>: group-size</p> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/kv_quant.html#non-uniform-quantization","title":"Non-Uniform Quantization","text":"<p>nuqX (An X-Bit Sensitivity-Weighted Non-Uniform Datatype) \u200b\u4f4d\u200b\u5bbd\u200b\u4e3a\u200bX\u200b\u7684\u200b\u654f\u611f\u5ea6\u200b\u52a0\u6743\u200b\u975e\u200b\u5747\u5300\u200b\u91cf\u5316\u200b\u6570\u636e\u7c7b\u578b\u200b\uff0c\u200b\u8be5\u200b\u975e\u200b\u5747\u5300\u200b\u91cf\u5316\u200b\u4e3b\u8981\u200b\u5305\u62ec\u200b\u4ee5\u4e0b\u200b\u90e8\u5206\u200b</p> <ol> <li>\u200b\u654f\u611f\u5ea6\u200b\uff1a\u200b\u6709\u200b\u6807\u7b7e\u200b\u6570\u636e\u200b\u5bf9\u200b\u53cd\u5411\u200b\u68af\u5ea6\u200b\u7684\u200b\u5e73\u65b9\u200b Fisher Information Matrix  \\(\\mathcal{F}_{i,i}\\)\uff0c\u200b\u7528\u4e8e\u200b\u8ba1\u7b97\u200bloss\u200b\u65f6\u200b\u52a0\u6743\u200b</li> <li> <p>Quantization\uff1a\u200b\u5bf9\u200bactivation\u200b\u8fdb\u884c\u200b\u5f52\u4e00\u5316\u200b\u540e\u200b\u518d\u200b\u91cf\u5316\u200b</p> \\[ \\begin{aligned}     A_{i, norm} =&amp; \\frac{A_i - z_i}{s_i} \\\\     \\hat{A}_i =&amp; s_i \\hat{A}_{i, norm} + z_i \\\\      \\Delta A =&amp; s \\cdot (A_{norm} - \\hat{A}_{norm}) \\end{aligned} \\] <ul> <li>\\(z_i\\) \u200b\u4e3a\u200b\u5747\u503c\u200b\uff0c\u200b\u7c7b\u578b\u200b\u4e3a\u200bfp16</li> <li>\\(s_i\\) \u200b\u4e3a\u200b\u5bf9\u5e94\u200b\u7684\u200b\u7f29\u653e\u200b\u56e0\u5b50\u200b</li> </ul> </li> <li> <p>Calibration Loss\uff1a \u200b\u7528\u200b \\(N\\) \u200b\u6761\u200b\u6570\u636e\u200b\u7684\u200b\u6821\u6b63\u200b\u96c6\u200b\uff0c\u200b\u79bb\u7ebf\u200b k-means \u200b\u91cf\u5316\u200b\u6821\u6b63\u200bactivation quantization</p> \\[ \\begin{aligned}     Q(A) \\simeq&amp; \\mathop{\\text{arg min}}\\limits_{Q} \\sum_{i=1}^{N} \\mathcal{F}_{i,i} \\cdot \\left(A_i - Q\\left(A_i\\right)\\right)^2 \\end{aligned} \\] Calibration\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u63a8\u5bfc\u200b\u8fc7\u7a0b\u200b\uff1a\u200b\u57fa\u4e8e\u200b\u6709\u200b\u76d1\u7763\u200bMSE \\[ \\begin{aligned} \\mathbb{E}_{\\Delta A} \\left[ \\vert f(A) - f(A + \\Delta A) \\vert^2\\right] \\approx &amp; \\mathbb{E}_{\\Delta A} \\left[ \\left(J(A)\\Delta A)^2\\right) \\right] \\\\  =&amp; \\mathbb{E}_{\\Delta A}\\left[ \\left(\\sum_{i} J_i \\Delta A_i \\right)^2\\right] \\\\ =&amp; \\mathbb{E}_{\\Delta A} \\left[ \\sum_{i} J_i\\Delta A_i^2 \\right]\\\\ =&amp; \\sum_{i} J_i^2 \\mathbb{E}_{\\Delta A}[\\Delta A_i^2]\\\\ \\end{aligned} \\] <ul> <li>\\(\\approx\\) \u200b\u8fd1\u4f3c\u200b\u6b65\u9aa4\u200b\u8fdb\u884c\u200b\u4e86\u200b\u6cf0\u52d2\u200b\u5c55\u5f00\u200b</li> <li>\\(J(A) = \\frac{\\partial f}{\\partial A} (A), J_i = \\frac{\\partial f}{\\partial A} (A_i)\\)</li> </ul> </li> <li> <p>Calibration Runtime \u200b\u79bb\u7ebf\u200b\u91cf\u5316\u200b\u65f6\u95f4\u200b\u5f00\u9500\u200b     </p> <p></p> </li> <li> <p>\u200b\u5404\u200b\u90e8\u5206\u200b\u6548\u679c\u200b\u8d21\u732e\u200b \u200b\u6d88\u878d\u200b\u5bf9\u6bd4\u200b\u5b9e\u73b0\u200b\u5404\u200b\u90e8\u5206\u200b\u6548\u679c\u200b\u8d21\u732e\u200b     </p> <p></p> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/kv_quant.html#per-vector-dense-and-sparse-quantization","title":"Per-Vector Dense-and-Sparse Quantization","text":"<p>\u200b\u7531\u200bpre-RoPE Key\u200b\u548c\u200bValue\u200b\u7684\u200bnormalized\u200b\u6570\u503c\u200b\u5206\u5e03\u200bCDF\u200b\u53ef\u77e5\u200b\uff0c\u200b\u5927\u90e8\u5206\u200b\u7684\u200b\u6570\u636e\u5206\u5e03\u200b\u5728\u200b\u8f83\u7a84\u200b\u7684\u200b\u6570\u503c\u200b\u7a7a\u95f4\u200b\u5185\u200b\uff0c\u200b\u79bb\u7fa4\u200b\u503c\u200b\u5206\u5e03\u200b\u5728\u200b\u8f83\u5927\u200b\u7684\u200b\u6570\u503c\u200b\u7a7a\u95f4\u200b\u5185\u200b\u3002\u200b\u56e0\u6b64\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u7ea6\u675f\u200b\u5c11\u90e8\u5206\u200b\u7684\u200b\u79bb\u7fa4\u200b\u503c\u6765\u200b\u5c06\u200b\u6570\u503c\u200b\u7a7a\u95f4\u200b\u6709\u6548\u200b\u7f29\u5c0f\u200b\uff0c\u200b\u4ece\u800c\u200b\u63d0\u9ad8\u200b\u91cf\u5316\u200b\u7cbe\u5ea6\u200b\u3002\u200b\u800c\u200b\u4e0d\u540c\u200b\u7279\u5f81\u200b\u7ef4\u5ea6\u200b\u7684\u200b\u6570\u503c\u200b\u91cf\u7ea7\u200b\u4e0d\u540c\u200b\uff0c\u200b\u56e0\u6b64\u200b\u53ef\u200b\u5bf9\u200b Group-wise pre-RoPE Key Quantization \u200b\u4ee5\u53ca\u200b Token-wise Value Quantization \u200b\u5206\u522b\u200b\u8bbe\u7f6e\u200b\u79bb\u7fa4\u200b\u503c\u200b\u9608\u503c\u200b\uff1a</p> <ol> <li>Clamp + Normalize \u200b\u786e\u5b9a\u200b\u4e0a\u200b\u3001\u200b\u4e0b\u200b\u79bb\u7fa4\u200b\u503c\u200b\u9608\u503c\u200b\uff0c\u200b\u5c06\u200b\u533a\u95f4\u200b\u5185\u200b\u6570\u636e\u200b\u4fdd\u7559\u200b\u5e76\u200b\u5f52\u4e00\u5316\u200b\u81f3\u200b\u503c\u57df\u200b\u7a7a\u95f4\u200b\\([-1, 1]\\)\uff0c\u200b\u4fdd\u6301\u200b\u79bb\u7fa4\u200b\u503c\u200b\u6570\u636e\u200b\u7cbe\u5ea6\u200b\u4e0d\u200b\u91cf\u5316\u200b</li> <li>Calibration \u200b\u7167\u200b\u4e0a\u8ff0\u200b nuqX \u200b\u65b9\u6cd5\u200b\u5bf9\u200b\u533a\u95f4\u200b\u503c\u200b\u8fdb\u884c\u200b\u77eb\u6b63\u200b</li> </ol> <p>\u200b\u5728\u200b\u8fdb\u884c\u200bDense-and-Sparse Quantization\u200b\u64cd\u4f5c\u200b\u65f6\u200b\uff0c\u200b\u53d1\u73b0\u200b\u4ee5\u4e0b\u200b\u51e0\u79cd\u200b\u65b9\u5f0f\u200b\u80fd\u591f\u200b\u8fdb\u4e00\u6b65\u200b\u4f18\u5316\u200b\u91cf\u5316\u200b\u6548\u679c\u200b</p> <ul> <li> <p> \u200b\u5b9e\u9a8c\u200b\u8868\u660e\u200b\u7ec6\u7c92\u5ea6\u200b\u7684\u200bper-Vector\u200b\u65b9\u6848\u200b\u8f83\u200bper-Matrix\u200b\u65b9\u6848\u200b\u80fd\u591f\u200b\u53d6\u5f97\u200b\u66f4\u597d\u200b\u7684\u200b\u91cf\u5316\u200b\u6548\u679c\u200b     </p> <p></p> </li> <li> <p> \u200b\u5e76\u884c\u64cd\u4f5c\u200b<code>Value Projection + CPU Outlier Isolation &amp;&amp; Key Projection</code> \u200b\u91cf\u5316\u200b\u6548\u7387\u200b\u66f4\u9ad8\u200b\uff0c\u200b\u524d\u8005\u200b\u5b9e\u65f6\u200b\u8ba1\u7b97\u200b\u91cf\u5316\u200b\uff0c\u200b\u540e\u8005\u200b\u79bb\u7ebf\u200b\u6821\u6b63\u200b\u91cf\u5316\u200b     </p> <p></p> <p><code>nuq2-1%</code> \u200b\u8868\u793a\u200b\u7a00\u758f\u200b\u5ea6\u4e3a\u200b1%\uff0c\u200b\u5373\u200b\u5ffd\u7565\u200b\u793a\u200b1%\u200b\u7684\u200b\u79bb\u7fa4\u200b\u503c\u200b\u4e0d\u200b\u8fdb\u884c\u200b\u91cf\u5316\u200b</p> </li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/kv_quant.html#attention-sink-aware-quantization","title":"Attention Sink-Aware Quantization","text":"<p>\u200b\u5728\u200bLLM\u200b\u4e2d\u200b\uff0c\u200b\u6a21\u578b\u200b\u5bf9\u4e8e\u200b\u7b2c\u4e00\u4e2a\u200btoken\u200b\u7684\u200battention\u200b\u5206\u6570\u200b\u4f1a\u200b\u5f88\u200b\u9ad8\u200b\uff0c\u200b\u4e14\u200b\u4e0e\u200b\u7b2c\u4e00\u4e2a\u200btoken\u200b\u7684\u200b\u8bed\u4e49\u200b\u91cd\u8981\u200b\u5ea6\u200b\u76f8\u5173\u6027\u200b\u4e0d\u9ad8\u200b\uff0c\u200b\u4e3a\u200b\u5c3d\u91cf\u51cf\u5c11\u200b\u8be5\u4e2a\u200btoken\u200b\u7684\u200b\u91cf\u5316\u200b\u8bef\u5dee\u200b\uff0c\u200b\u4fdd\u6301\u200bKey\u200b\u4e2d\u200b\u7b2c\u4e00\u4e2a\u200btoken\u200b\u539f\u6709\u200b\u7cbe\u5ea6\u200b\u4e0d\u200b\u8fdb\u884c\u200b\u91cf\u5316\u200b\u3002\u200b\u5b9e\u9a8c\u200b\u8868\u660e\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u5bf9\u200b\u91cf\u5316\u200b\u6548\u679c\u200b\u6709\u200b\u4e00\u5b9a\u200b\u7684\u200b\u63d0\u5347\u200b</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/kv_quant.html#kernel-implementation","title":"Kernel Implementation","text":"<p>\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u65b9\u5f0f\u200b\u5b9e\u65f6\u200b\u9ad8\u6548\u200b\u5b9e\u73b0\u200bactivation quantization</p> <ul> <li> \u200b\u901a\u8fc7\u200b Compressed-Sparse Row (CSR) or Compressed-Sparse Column (CSC) \u200b\u6570\u636e\u683c\u5f0f\u200b\u5b58\u50a8\u200bValue/pre-RoPE Key\u200b\u79bb\u7fa4\u200b\u503c\u200b, see Appendix R Kernel Implementation Details</li> <li> \u200b\u4f7f\u7528\u200b\u7a00\u758f\u200b\u79bb\u7fa4\u200b\u503c\u200b\u6267\u884c\u200b\u7a00\u758f\u200b\u77e9\u9635\u200b\u5bc6\u96c6\u200b\u5411\u91cf\u200b\u4e58\u6cd5\u200b</li> <li> \u200b\u878d\u5408\u200b <code>pre-RoPE Key Quantization + apply RoPE on-the-fly</code> \u200b\u7b97\u5b50\u200b</li> </ul> <p><code>matvec</code>: matrix-vector</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/kv_quant.html#evaluation","title":"Evaluation","text":"<ul> <li> <p> \u200b\u79bb\u7fa4\u200b\u503c\u200b\u7a00\u758f\u200b\u5ea6\u200b\u5728\u200b\\([0.1\\%, 1\\%]\\) \u200b\u5185\u200b\uff0c\u200b\u7a00\u758f\u200b\u5ea6\u8d8a\u200b\u9ad8\u200b\uff0c\u200b\u91cf\u5316\u200b\u6548\u679c\u200b\u8d8a\u4f73\u200b     </p> <p></p> <p><code>baseline</code>: Token-wise post-RoPE Key Quantization</p> </li> <li> <p> KVQuant\u200b\u6821\u6b63\u200b\u7cbe\u5ea6\u200b\u5bf9\u200b\u6821\u6b63\u200b\u6570\u636e\u200b\u96c6\u200b\u4e0d\u200b\u654f\u611f\u200b</p> <p></p> <p></p> </li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html","title":"Quantization","text":"<p>\u200b\u91cf\u5316\u200b\u662f\u200b\u5c06\u200b\u5305\u542b\u200b\u66f4\u200b\u591a\u200b\u4fe1\u606f\u200b\u7684\u200b\u8868\u793a\u200b\u79bb\u6563\u200b\u5316\u4e3a\u200b\u5305\u542b\u200b\u8f83\u200b\u5c11\u200b\u4fe1\u606f\u200b\u8868\u793a\u200b\u7684\u200b\u8fc7\u7a0b\u200b\uff0c\u200b\u901a\u8fc7\u200b\u51cf\u5c11\u200b\u6a21\u578b\u200b\u53c2\u6570\u200b\u4e0e\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u7684\u200b\u8868\u793a\u200b\u7cbe\u5ea6\u200b\u4ee5\u200b\u8fbe\u5230\u200b\u964d\u4f4e\u200b\u6a21\u578b\u200b\u5b58\u50a8\u7a7a\u95f4\u200b\u548c\u200b\u8ba1\u7b97\u200b\u91cf\u200b\u7684\u200b\u76ee\u7684\u200b\u3002</p> <ol> <li>\u200b\u6a21\u578b\u200b\u5b58\u50a8\u7a7a\u95f4\u200b\u4f1a\u200b\u51cf\u5c11\u200b\uff0c\u200b\u7b97\u529b\u200b\u8981\u6c42\u200b\u964d\u4f4e\u200b\uff0c\uff0c\u200b\u4f46\u200b\u63a8\u7406\u200b\u901f\u5ea6\u200b\u4e0d\u200b\u4e00\u5b9a\u200b\u66f4\u200b\u5feb\u200b\uff1b</li> <li>\u200b\u6a21\u578b\u200b\u6548\u679c\u200b\u6548\u679c\u200b\u4f1a\u200b\u7565\u5fae\u200b\u4e0b\u964d\u200b\uff1b</li> </ol>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#_1","title":"\u91cf\u5316\u200b\u6982\u5ff5","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#_2","title":"\u6d6e\u70b9\u6570\u200b\u683c\u5f0f","text":"<ul> <li>S(ign): \u200b\u7b26\u53f7\u200b\u4f4d\u200b\u90e8\u5206\u200b; </li> <li>E(xponent): \u200b\u6307\u6570\u200b\u4f4d\u200b\u90e8\u5206\u200b\uff0c\u200b\u4f4d\u6570\u200b\u8d8a\u200b\u591a\u200b\u6570\u503c\u200b\u8303\u56f4\u200b\u8d8a\u5927\u200b</li> <li>M(antissa): \u200b\u4e5f\u200b\u7528\u200bFraction\u200b\u8868\u793a\u200b\uff0c\u200b\u5c0f\u6570\u200b/\u200b\u5c3e\u6570\u200b\u4f4d\u200b\u90e8\u5206\u200b\uff0c\u200b\u4f4d\u6570\u200b\u8d8a\u200b\u591a\u200b\u7cbe\u5ea6\u200b\u8d8a\u9ad8\u200b</li> <li> <p>\u200b\u6d6e\u70b9\u6570\u200b\u8f6c\u200b\u4e8c\u8fdb\u5236\u200b\u683c\u5f0f\u200b\u53ef\u89c6\u5316\u200b\u5de5\u5177\u200b IEEE 754 Conventer</p> \\[ fp=(-1)^s*2^{e-bias}*(1 + m) \\] <p>\\(bias = 2^{E-1} - 1\\)\uff0c\u200b\u56e0\u6b64\u200b\u6307\u6570\u200b\u90e8\u5206\u200b\u503c\u57df\u200b\u4e3a\u200b\\([-2^{E-1}+1, 2^{E-1}]\\) \\(m = \\sum_{n=1}^{M1} \\text{bit}_n*2^{-n}\\)</p> </li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#_3","title":"\u6d6e\u70b9\u6570\u200b\u5206\u7c7b","text":"Type S E M/F FP64 1 11 52 FP32 1 8 23 TF32 1 8 10 BF16 1 8 7 FP16 1 5 10 FP8 E4M3 1 4 3 FP8 E5M2 1 5 2 FP4 1 2 1 <ul> <li>Nvidia\u200b\u4e13\u200b\u4e3a\u200bAmpere\u200b\u67b6\u6784\u8bbe\u8ba1\u200b\u7684\u200b\u6570\u636e\u683c\u5f0f\u200bTF32(TensorFloat 32)\uff0c\u200b\u5b9e\u9645\u4e0a\u200b\u53ea\u200b\u4f7f\u7528\u200b\u4e86\u200b19\u200b\u4f4d\u200b</li> <li>Google Brain\u200b\u63d0\u51fa\u200bBF16(BrainFloat 16)</li> <li>\u200b\u534e\u76db\u987f\u5927\u5b66\u200b\u5728\u200bQLoRA\u200b\u4e2d\u200b\u63d0\u51fa\u200b\u7684\u200bNF4(NormalFloat 4)\uff0c\u200b\u672c\u8d28\u200b\u4e0a\u200b\u4e3a\u200b4-bit\u200b\u5b57\u8282\u200b\u7801\u200b\uff0c\u200b\u5bf9\u5e94\u200b0-15\u200b\u4e0b\u200b\u6807\u7684\u200b\u56fa\u5b9a\u200b\u6d6e\u70b9\u6570\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#uniform-quantization","title":"Uniform Quantization","text":"<p>\u200b\u53ef\u200b\u901a\u8fc7\u200b\u7f13\u5b58\u200b\u5386\u53f2\u200bactivation\uff08\u200b\u5982\u200bKV cache\uff09\u200b\u548c\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b\u4f18\u5316\u200b\u6a21\u578b\u200b\u5728\u200bLLM\u200b\u63a8\u7406\u200b\u6027\u80fd\u200b\uff0c\u200b\u5373\u5c06\u200b  \\(Y = XW\\) \u200b\u901a\u8fc7\u200b\u91cf\u5316\u200b\u6570\u636e\u200b $\\tilde{Y} = \\tilde{X}\\tilde{W} = \\hat{X} \\cdot s_X\\hat{W} \\cdot s_W $ \u200b\u8fd1\u4f3c\u200b</p> <ol> <li> <p>\u200b\u786e\u5b9a\u200b\u91cf\u5316\u200b\u6570\u503c\u200b\u8303\u56f4\u200bRange (Clipping)\uff0c\u200b\u5305\u62ec\u200b\u8303\u56f4\u200b\u786e\u5b9a\u200b\u548c\u200b\u8303\u56f4\u200b\u88c1\u526a\u200b\uff0c\u200b\u79bb\u7fa4\u200b\u503c\u200b\u53ef\u4e0d\u200b\u8fdb\u884c\u200b\u91cf\u5316\u200b\u5904\u7406\u200b\u4e5f\u200b\u53ef\u200bclamp\u200b\u4e3a\u200b\u8fb9\u754c\u503c\u200b</p> <ul> <li>\u200b\u5206\u200b\u4f4d\u6570\u200b\u7edf\u8ba1\u6cd5\u200b\uff0c\\(\\text{quantile}\\left(\\vert x \\vert, \\text{cdf_percent}\\right)\\)</li> <li> <p>\u200b\u52a8\u91cf\u200b\u7d2f\u8ba1\u6cd5\u200b\uff0c\u200b\u57fa\u4e8e\u200b\u52a8\u91cf\u200b\u65b9\u6cd5\u200b(running mean)\u200b\u8ba1\u7b97\u200bactivation range\uff0c\u200b\u5982\u200b</p> \\[ \\begin{aligned}     x_\\text{max} =&amp; \\alpha x_\\text{max} + (1-\\alpha) \\max\\left(x_\\text{current-iteration} \\right) \\\\     x_\\text{min} =&amp; \\alpha x_\\text{min} + (1-\\alpha) \\min\\left(x_\\text{current-iteration} \\right) \\\\ \\end{aligned} \\] </li> </ul> </li> <li> <p>\u200b\u91cf\u5316\u200bQuantize\uff0c\u200b\u5c06\u200b\u9ad8\u7cbe\u5ea6\u200b\u6570\u503c\u200b\u8868\u793a\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u4f4e\u200b\u7cbe\u5ea6\u200b\u6570\u503c\u200b\u8868\u793a\u200b\uff0c\u200b\u5982\u200b<code>FP32 \u2192 FP16</code>\uff1b</p> </li> <li>\u200b\u53cd\u200b\u91cf\u5316\u200bDequantize\uff0c\u200b\u5c06\u200b\u91cf\u5316\u200b\u540e\u200b\u7684\u200b\u4f4e\u200b\u7cbe\u5ea6\u200b\u6570\u503c\u200b\u8868\u793a\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u9ad8\u7cbe\u5ea6\u200b\u6570\u503c\u200b\u8868\u793a\u200b\uff0c\u200b\u5982\u200b<code>FP16 \u2192 FP32</code></li> </ol> \\[ \\begin{aligned} s  =&amp; \\frac{\\max \\left(\\vert x \\vert \\right)}{ 2^{b-1} - 1} \\\\ \\hat{x}  =&amp; \\text{round}\\left(\\text{clamp}\\left(\\frac{x} {s}, -2^{b-1}, 2^{b-1}-1 \\right)\\right) \\\\ \\tilde{x} =&amp; \\hat{x}\\cdot s \\end{aligned} \\] <p>WxAy \u200b\u8868\u793a\u200b\u4f7f\u7528\u200bINT-x\u200b\u91cf\u5316\u200b\u6743\u91cd\u200b\u53c2\u6570\u200bweight\uff0cINT-y\u200b\u91cf\u5316\u200b\u6fc0\u6d3b\u200b\u503c\u200bactivation</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#non-uniform-quantization","title":"Non-Uniform Quantization","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#_4","title":"\u4e8c\u503c\u5316\u200b/\u200b\u4e09\u503c\u5316","text":"<p>\u200b\u5143\u7d20\u200b\u53ea\u200b\u5305\u542b\u200b+1, -1\uff08\u200b\u548c\u200b0\uff09\uff0c\u200b\u867d\u7136\u200b\u91cf\u5316\u200b\u540e\u200b\u6743\u91cd\u200b\u503c\u200b\u53d8\u5f97\u200b\u6781\u7aef\u200b\uff0c\u200b\u4f46\u200b\u6743\u91cd\u200b\u7b26\u53f7\u200b Sign \u200b\u5f80\u5f80\u200b\u6bd4\u200b\u66f4\u200b\u7cbe\u786e\u200b\u7684\u200b\u5e45\u503c\u200b Magnitude \u200b\u627f\u8f7d\u200b\u66f4\u200b\u591a\u200b\u7684\u200b\u4fe1\u606f\u200b\uff0c\u200b\u4e14\u200b\u795e\u7ecf\u7f51\u7edc\u200b\u5728\u200b\u4e00\u5b9a\u200b\u7a0b\u5ea6\u200b\u4e0a\u200b\u5bf9\u200b\u6743\u91cd\u200b\u566a\u58f0\u200b\u5177\u6709\u200b\u9c81\u68d2\u6027\u200b\uff0c\u200b\u4e8c\u503c\u5316\u200b/\u200b\u4e09\u503c\u5316\u200b\u53ef\u4ee5\u200b\u89c6\u4f5c\u200b\u4e00\u79cd\u200b\u6781\u7aef\u200b\u7684\u200b\u566a\u58f0\u200b\u3002</p> \\[ \\hat{W}_{i, j} = \\begin{cases}  1 &amp; \\text{if }W_{i, j} \\gt 0 \\\\  0 &amp; \\text{if }W_{i, j}  = 0 \\\\  -1  &amp; \\text{if }W_{i, j}  \\lt 0 \\end{cases} \\]"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#logarithmic-quantization","title":"Logarithmic Quantization","text":"<p>\u200b\u5f53\u200b\u5e95\u6570\u200b\u4e3a\u200b2\u200b\u65f6\u200b\uff0c\u200b\u91cf\u5316\u200b\u540e\u200b\u7684\u200b\u6570\u503c\u200b\u90fd\u200b\u662f\u200b2\u200b\u7684\u200b\u5e42\u6b21\u200b\u3002\u200b\u8fd9\u200b\u4f7f\u5f97\u200b\u590d\u6742\u200b\u7684\u200b\u4e58\u6cd5\u200b\u8fd0\u7b97\u200b\u53ef\u4ee5\u200b\u88ab\u200b\u7b80\u5316\u200b\u4e3a\u200b\u7b80\u5355\u200b\u7684\u200b\u4f4d\u79fb\u200b\uff08Bit-shift\uff09\u200b\u64cd\u4f5c\u200b\u3002\u200b\u5373\u200b\u4f20\u7edf\u200b\u4e58\u6cd5\u200b\\(y = wx\\) \u200b\u9700\u8981\u200b\u4e58\u6cd5\u5668\u200b\u7535\u8def\u200b\uff0c\u200b\u529f\u8017\u200b\u9ad8\u200b\uff0c\u200b\u9762\u79ef\u200b\u5927\u200b\uff1b\u200b\u800c\u200b\u5bf9\u4e8e\u200b\u5bf9\u200b\u6570\u91cf\u5316\u200b\u540e\u200b\u201c\u200b\u4e58\u6cd5\u200b\u201d\uff0c\u200b\u5982\u679c\u200b \\(w = 2^n\\)\uff0c\u200b\u5219\u200b <code>y = x &lt;&lt; n</code> \u200b\u53ea\u200b\u9700\u8981\u200b\u79fb\u4f4d\u200b\u5668\u200b\u7535\u8def\u200b\uff0c\u200b\u6781\u5176\u200b\u9ad8\u6548\u200b\u3002\u200b\u5e38\u89c1\u200b\u7684\u200b\u91cf\u5316\u200b\u65b9\u6848\u200b\uff1a</p> <ol> <li> <p>\u200b\u5747\u5300\u200b\u5bf9\u200b\u6570\u91cf\u5316\u200b\uff08Uniform Logarithmic Quantization\uff09\uff0c\u200b\u76f4\u63a5\u200b\u5c06\u200b\u6570\u503c\u200b\u57df\u200b\u6620\u5c04\u200b\u5230\u200b\u5bf9\u6570\u200b\u503c\u57df\u200b\u4e0a\u200b</p> <ul> <li>\u200b\u786e\u5b9a\u200b\u91cf\u5316\u200b\u8303\u56f4\u200b \\([a, b]\\) \u200b\u548c\u200b\u91cf\u5316\u200b\u7ea7\u522b\u200b\u6570\u200b \\(K=2^b\\)</li> <li>\u200b\u5728\u200b\u5bf9\u6570\u200b\u7a7a\u95f4\u200b\u4e0a\u200b\u5747\u5300\u200b\u5730\u200b\u521b\u5efa\u200b \\(K\\) \u200b\u4e2a\u200b\u91cf\u5316\u200b\u70b9\u200b</li> <li>\u200b\u5c06\u200b\u5b9e\u6570\u200b\u6620\u5c04\u200b\u5230\u200b\u6700\u8fd1\u200b\u7684\u200b\u91cf\u5316\u200b\u70b9\u4e0a\u200b</li> </ul> \\[ \\begin{aligned}     \\hat{x} =&amp; \\text{sign}(x)\\cdot 2^{L(x)} \\\\     L(x) =&amp; \\text{round}\\left(\\log_2 \\vert x \\vert\\right) \\end{aligned} \\] <ul> <li>\u200b\u53ea\u200b\u4fdd\u7559\u200b\u6307\u6570\u200b\u4f4d\u200bE\u200b\u548c\u200b\u7b26\u53f7\u200b\u4f4d\u200bS\uff0c\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u4e5f\u200b\u79f0\u4e3a\u200bPower-of-Two Quantization</li> <li>\\(2^n\\) \u200b\u6c38\u8fdc\u200b\u65e0\u6cd5\u200b\u4e3a\u200b0\uff0c\u200b\u56e0\u6b64\u200b\u9700\u200b\u5355\u72ec\u200b\u5206\u914d\u200b\u4e00\u4e2a\u200b\u7279\u5b9a\u200b\u7684\u200b\u7801\u5b57\u200bcodeword\u200b\u8868\u793a\u200b\u96f6\u200b\uff0c\u200b\u52a0\u4e0a\u200b \\(\\text{sign}(x)\\) \uff0c\u200b\u5171\u6709\u200b\\(2^{b+1} - 1\\) \u200b\u79cd\u200b\u53d6\u503c\u200b</li> </ul> </li> <li> <p>\u200b\u57fa\u4e8e\u200b\u6bb5\u200b\u7684\u200b\u5bf9\u200b\u6570\u91cf\u5316\u200b\uff08Segment-Based Logarithmic Quantization\uff09\uff0c\u200b\u4e5f\u200b\u88ab\u200b\u79f0\u4e3a\u200b\u6307\u6570\u200b\u8868\u793a\u6cd5\u200b\u91cf\u5316\u200b\uff0c\u200b\u5bf9\u200b\u6d6e\u70b9\u6570\u200b\u6307\u6570\u200b\u4f4d\u200bE\u200b\u548c\u200b\u5c3e\u6570\u200b\u4f4d\u200bM\u200b\u4e24\u200b\u90e8\u5206\u200b\u5206\u522b\u200b\u8fdb\u884c\u200b\u91cf\u5316\u200b</p> \\[ \\begin{aligned}     \\hat{x} = \\text{sign}(x)\\cdot \\left(1 + \\frac{m}{2^M}\\right) \\cdot 2^e \\end{aligned} \\] <p>\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u4e3a\u200b <code>float2float</code> \u200b\u7c7b\u578b\u200b</p> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#k-means-quantization","title":"K-means Quantization","text":"<p>K-means \u200b\u91cf\u5316\u200b\u5c06\u200b\u6743\u91cd\u200b\u503c\u200b\u770b\u4f5c\u200b\u6570\u636e\u200b\u70b9\u200b\uff0c\u200b\u4f7f\u7528\u200b K-means \u200b\u805a\u7c7b\u200b\u7b97\u6cd5\u200b\u627e\u5230\u200b\u6700\u80fd\u200b\u4ee3\u8868\u200b\u8fd9\u4e9b\u200b\u6570\u636e\u5206\u5e03\u200b\u7684\u200b \\(K\\) \u200b\u4e2a\u200b\u4e2d\u5fc3\u70b9\u200b\uff08\u200b\u805a\u7c7b\u200b\u4e2d\u5fc3\u200b\uff09\uff0c\u200b\u7136\u540e\u200b\u5c06\u200b\u6bcf\u4e2a\u200b\u6743\u91cd\u200b\u503c\u200b\u91cf\u5316\u200b\u4e3a\u200b\u79bb\u200b\u5b83\u200b\u6700\u8fd1\u200b\u7684\u200b\u90a3\u4e2a\u200b\u4e2d\u5fc3\u70b9\u200b\u7684\u200b\u503c\u200b\uff08\u200b\u503c\u57df\u200b\u4e3a\u200b \\(K\\) \u200b\u4e2a\u70b9\u200b\uff09\u3002\u200b\u91cf\u5316\u200b\u6b65\u9aa4\u200b\uff1a</p> <ul> <li>\u200b\u5e94\u7528\u200bK-means\u200b\u805a\u7c7b\u200b<ol> <li>\u200b\u521d\u59cb\u5316\u200b\uff1a\u200b\u9009\u53d6\u200b \\(K\\) \u200b\u4e2a\u200b\u8d28\u5fc3\u200b\uff0c\u200b\u5982\u200b\u968f\u673a\u200b\u6216\u200b\u57fa\u4e8e\u200b\u76f4\u65b9\u56fe\u200b\u521d\u59cb\u5316\u200b</li> <li>E step\uff1a\u200b\u8ba1\u7b97\u200b\u79bb\u6743\u503c\u200b \\(W_{i,j}\\) \u200b\u7684\u200b\u6700\u8fd1\u200b\u8d28\u5fc3\u200b</li> <li>M step\uff1a\u200b\u57fa\u4e8e\u200b\u805a\u7c7b\u200b\u6743\u503c\u200b\u66f4\u65b0\u200b\\(K\\) \u200b\u4e2a\u200b\u8d28\u5fc3\u200b\u4f4d\u7f6e\u200b</li> <li>\u200b\u91cd\u590d\u200b\u6b65\u9aa4\u200b b-c\uff0c\u200b\u76f4\u5230\u200b\u6536\u655b\u200b</li> </ol> </li> <li>\u200b\u6784\u5efa\u200b\u91cf\u5316\u200b\u6620\u5c04\u200b\u8868\u200b \u200b\u57fa\u4e8e\u200b\\(K\\)\u200b\u4e2a\u200b\u8d28\u5fc3\u200b\u6784\u5efa\u200b\u7d22\u5f15\u200b\u8868\u200b \\(\\{idx: val\\}\\)</li> <li>\u200b\u6267\u884c\u200b\u91cf\u5316\u200b \u200b\u5b9e\u9645\u4e0a\u200b\u9700\u200b\u53ea\u8981\u200b\u4fdd\u5b58\u200b\u91cf\u5316\u200b\u503c\u200b\uff08\u200b\u6240\u5c5e\u200b\u8d28\u5fc3\u200b\uff09\u200b\u5bf9\u5e94\u200b\u7684\u200b\u7d22\u5f15\u200b\uff0c\u200b\u6240\u200b\u9700\u200b\u7d22\u5f15\u200b\u4f4d\u6570\u200b\u4e3a\u200b \\(\\lceil \\log_2 K \\rceil\\)</li> </ul> <p>\u200b\u5e38\u7528\u200b\u4e8e\u200b\u9759\u6001\u200b\u7279\u6027\u200b\u7684\u200bWeight Quantization\u200b\u6743\u91cd\u200b\u91cf\u5316\u200b</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#quantile-quantization","title":"Quantile Quantization","text":"<p>\u200b\u795e\u7ecf\u7f51\u7edc\u200b\u7684\u200b\u6743\u91cd\u200b\u548c\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u901a\u5e38\u200b\u4e0d\u200b\u670d\u4ece\u200b\u5747\u5300\u5206\u5e03\u200b\uff0c\u200b\u800c\u662f\u200b\u5448\u73b0\u51fa\u200b\u7c7b\u4f3c\u200b\u9ad8\u65af\u5206\u5e03\u200b\u6216\u200b\u91cd\u5c3e\u200b\u5206\u5e03\u200b\u7684\u200b\u7279\u70b9\u200b\u3002\u200b\u7ebf\u6027\u200b\u91cf\u5316\u200b\uff08\u200b\u5747\u5300\u200b\u91cf\u5316\u200b\uff09\u200b\u7684\u200b\u4e3b\u8981\u200b\u7f3a\u70b9\u200b\u662f\u200b\u5b83\u200b\u5bf9\u200b\u6240\u6709\u200b\u533a\u95f4\u200b\u7684\u200b\u5904\u7406\u200b\u662f\u200b\u5e73\u7b49\u200b\u7684\u200b\uff0c\u200b\u5ffd\u7565\u200b\u4e86\u200b\u6570\u636e\u200b\u7684\u200b\u5b9e\u9645\u200b\u6982\u7387\u5bc6\u5ea6\u200b\u3002\u200b\u5206\u4f4d\u200b\u6570\u91cf\u5316\u200b\u7684\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\u8ba9\u200b\u6bcf\u4e2a\u200b\u91cf\u5316\u200b\u533a\u95f4\u200b\u5305\u542b\u200b\u5927\u81f4\u76f8\u540c\u200b\u6570\u91cf\u200b\u7684\u200b\u6570\u636e\u200b\u70b9\u200b\uff0c\u200b\u5b83\u200b\u901a\u8fc7\u200b\u786e\u4fdd\u200b\u6bcf\u4e2a\u200b\u91cf\u5316\u200b\u7bb1\u200b\uff08bin\uff09\u200b\u7684\u200b\u6982\u7387\u200b\u8d28\u91cf\u200b\u76f8\u7b49\u200b\u6765\u200b\u5b9e\u73b0\u200b\u8fd9\u4e00\u200b\u76ee\u6807\u200b\u3002\u200b\u91cf\u5316\u200b\u6b65\u9aa4\u200b</p> <ol> <li>\u200b\u6784\u5efa\u200b\u7ecf\u9a8c\u200b\u7d2f\u8ba1\u200b\u5206\u5e03\u200b\u51fd\u6570\u200bECDF</li> <li>\u200b\u786e\u5b9a\u200b\u91cf\u5316\u200b\u8fb9\u754c\u200b \u200b\u57fa\u4e8e\u200bECDF\u200b\u4ee5\u53ca\u200b\u786e\u5b9a\u200b\u7684\u200b\\(K\\)\u200b\u4e2a\u200b\u91cf\u5316\u200b\u533a\u95f4\u200b\u6570\u200b\uff0c\u200b\u786e\u5b9a\u200b\u91cf\u5316\u200b\u8fb9\u754c\u200b</li> <li>\u200b\u5206\u914d\u200b\u91cf\u5316\u200b\u503c\u200b \u200b\u4e3a\u200b\u6bcf\u4e2a\u200bbin\u200b\u5206\u914d\u200b\u4ee3\u8868\u200b\u503c\u200b\uff0c\u200b\u6839\u636e\u200b\u6570\u503c\u200b\u5173\u7cfb\u200b\u786e\u5b9a\u200b\u6240\u5c5e\u200bbin\uff0c\u200b\u5e76\u200b\u5206\u914d\u200b\u76f8\u5e94\u200b\u7684\u200b\u91cf\u5316\u200b\u503c\u200b</li> <li>\u200b\u6267\u884c\u200b\u91cf\u5316\u200b \u200b\u627e\u5230\u200b\u91cf\u5316\u200b\u503c\u200b\u6240\u5c5e\u200b\u533a\u95f4\u200b\u5e76\u200b\u5b58\u50a8\u200b\u76f8\u5e94\u200b\u7684\u200b\u7d22\u5f15\u200b\u503c\u200b\uff0c\u200b\u6240\u200b\u9700\u200b\u7d22\u5f15\u200b\u4f4d\u6570\u200b\u4e3a\u200b \\(\\lceil \\log_2 K \\rceil\\)</li> </ol> <p>\u200b\u5178\u578b\u200b\u5de5\u4f5c\u200b  </p> <ul> <li> <p>NF4 quantization \u200b\u6d6e\u70b9\u200b\u578b\u200b\u5206\u4f4d\u200b\u91cf\u5316\u200b</p> \\[ \\begin{aligned}     s =&amp; \\max(\\vert x \\vert) \\\\     \\hat{x} =&amp; \\text{find_nearest_bin_value}\\left(\\frac{x}{c}\\right) \\\\     \\tilde{x} = &amp; \\hat{x} \\cdot s \\end{aligned} \\] </li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#sparse-non-uniform-quantization","title":"Sparse Non-uniform Quantization","text":"<p>\u200b\u7a00\u758f\u200b\u975e\u200b\u5747\u5300\u200b\u91cf\u5316\u200b\u7ed3\u5408\u200b\u4e86\u200b\u4e24\u79cd\u200b\u4e0d\u540c\u200b\u7684\u200b\u6a21\u578b\u200b\u538b\u7f29\u200b\u601d\u60f3\u200b\uff0c\u200b\u7a00\u758f\u200b\u5316\u200b\uff08Sparsity\uff09 \u200b\u548c\u200b\u975e\u200b\u5747\u5300\u200b\u91cf\u5316\u200b\uff08Non-uniform Quantization\uff09\uff0c\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\u4e0d\u200b\u5e73\u7b49\u200b\u5730\u200b\u5bf9\u5f85\u200b\u6743\u91cd\u200b\uff08\u200b\u6216\u200b\u6fc0\u6d3b\u200b\u503c\u200b\uff09\u3002</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#_5","title":"\u91cf\u5316\u200b\u79cd\u7c7b","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#amp","title":"AMP","text":"<p>Automatic Mixed Precision\u200b\u81ea\u52a8\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\uff0c\u200b\u5bf9\u4e8e\u200b\u6a21\u578b\u200b\u603b\u53c2\u200b\u6570\u91cf\u200b\\(\\Psi\\)\uff0c\u200b\u4ee5\u200bAdam\u200b\u4f18\u5316\u200b\u5668\u4e0b\u200bFP32/FP16\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u8bad\u7ec3\u200b\u4e3a\u4f8b\u200b,\u200b\u603b\u200b\u7a7a\u95f4\u200b\u6d88\u8017\u91cf\u200b\u4e3a\u200b \\(2\\Psi + 2\\Psi + 3*4\\Psi\\)</p> <ol> <li>FP16 Weight, FP16 Activation and FP16 Gradient</li> <li>cast FP16 Gradient to FP32</li> <li>\u200b\u8ba1\u7b97\u200bFP32 Momentum \u200b\u548c\u200b FP32 Variance</li> <li> <p>\u200b\u8ba1\u7b97\u200bFP32 Gradient Update \\(\\eta \\frac{\\hat{m}}{\\sqrt{\\hat{v}} + \\epsilon}\\) </p> <p>\u200b\u57fa\u4e8e\u200b\u7cbe\u5ea6\u200b\u8003\u91cf\u200b\u4f7f\u7528\u200bFP32\u200b\u8fdb\u884c\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u9632\u6b62\u200b\u5206\u5b50\u200b\u8fc7\u200b\u5c0f\u200b/\u200b\u5206\u6bcd\u200b\u8fc7\u200b\u5c0f\u200b\u5bfc\u81f4\u200b\u68af\u5ea6\u200b\u6d88\u5931\u200b/\u200b\u68af\u5ea6\u200b\u7206\u70b8\u200b</p> </li> <li> <p>cast FP32 Gradient Update to FP16</p> </li> <li>FP16\u200b\u7cbe\u5ea6\u200b\u4e0b\u200b\u6743\u91cd\u200b\u66f4\u65b0\u200b <code>Weight = Weight - Gradient Update</code></li> </ol>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#mpq","title":"MPQ","text":"<p>Mixed-Precision Quantization\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u91cf\u5316\u200b</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#ptq","title":"PTQ","text":"<p>Post Training Quantization\uff0c\u200b\u5bf9\u200b\u8bad\u7ec3\u200b\u540e\u200b\u7684\u200b\u6a21\u578b\u200b\u8fdb\u884c\u200b\u91cf\u5316\u200b\u5904\u7406\u200b\uff0c\u200b\u5f53\u91cf\u200b\u5316\u4e3a\u200bFP16\u200b\u65f6\u200b\uff0c\u200b\u65e0\u9700\u200b\u6821\u51c6\u200b\uff1b\u200b\u5f53\u91cf\u200b\u5316\u4e3a\u200bINT8\u200b\u65f6\u200b\uff0c\u200b\u4e00\u822c\u200b\u9700\u8981\u200b\u4f7f\u7528\u200b\u5c11\u91cf\u200b\u4ee3\u8868\u6027\u200b\u6821\u51c6\u200b\u6570\u636e\u200b\u96c6\u200b\uff0c\u200b\u4e0d\u200b\u91cd\u65b0\u200b\u8bad\u7ec3\u200b\u800c\u662f\u200b\u901a\u8fc7\u200b\u7edf\u8ba1\u5206\u6790\u200b\u786e\u5b9a\u200b\u6700\u4f18\u200b\u91cf\u5316\u200b\u53c2\u6570\u200b\uff0c</p> <ul> <li>\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b\u76f4\u63a5\u200b\u91cf\u5316\u200b\uff0c\u200b\u65e0\u9700\u200b\u6821\u51c6\u200b\u96c6\u200b\uff0c\u200b\u901a\u5e38\u200b\u5bf9\u79f0\u200b\u91cf\u5316\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u200b\u975e\u5bf9\u79f0\u200b\u91cf\u5316\u200b  </li> <li>\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u9700\u8981\u200b\u901a\u8fc7\u200b\u6821\u51c6\u200b\u96c6\u200b\u8fdb\u884c\u200b\u52a8\u6001\u200b\u8c03\u6574\u200b\u6821\u6b63\u200b\uff0c\u200b\u53ef\u200b\u5bf9\u79f0\u200b\u4e5f\u200b\u53ef\u200b\u975e\u5bf9\u79f0\u200b  </li> <li>\u200b\u6df7\u5408\u200b\u7cbe\u5ea6\u200b\u91cf\u5316\u200b\uff0c\u200b\u67d0\u4e9b\u200b\u5c42\u200b\u9ad8\u7cbe\u5ea6\u200b\uff0c\u200b\u67d0\u4e9b\u200b\u5c42\u4f4e\u200b\u7cbe\u5ea6\u200b</li> </ul> <p>\u200b\u4e00\u822c\u200b\u6821\u51c6\u200b\u64cd\u4f5c\u200b\u9ed8\u8ba4\u200b\u5728\u200b\u5c42\u200b\u878d\u5408\u200b\u4e4b\u524d\u200b\uff0c\u200b\u7528\u4e8e\u200b\u6821\u6b63\u200b\u6fc0\u6d3b\u200b\u503c\u200b\uff0c\u200b\u6821\u51c6\u200b\u6b65\u9aa4\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li>\u200b\u51c6\u5907\u200b\u6821\u51c6\u200b\u6570\u636e\u200b\u96c6\u200b\uff0c\u200b\u6570\u636e\u200b\u89c4\u6a21\u200b\u4e00\u822c\u200b\u4e3a\u200b500~1000  </li> <li>P\u200b\u6a21\u578b\u200b\u63a8\u7406\u200b\uff0c\u200b\u8bb0\u5f55\u200b\u524d\u5411\u200b\u4f20\u64ad\u200b\u5404\u5c42\u200b\u6fc0\u6d3b\u200b\u503c\u200bactivations  </li> <li>\u200b\u6784\u5efa\u200b\u76f4\u65b9\u56fe\u200b\u5206\u522b\u200b\u7edf\u8ba1\u200b\u5404\u5c42\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u5728\u200b\u4e0d\u540c\u200b\u6570\u503c\u200b\u533a\u95f4\u200b\u7684\u200b\u51fa\u73b0\u200b\u9891\u7387\u200b<ul> <li>\u200b\u7edf\u8ba1\u200b\u6700\u5c0f\u503c\u200b\u548c\u200b\u6700\u5927\u503c\u200b\uff0c\u200b\u786e\u5b9a\u200b\u6570\u503c\u200b\u8303\u56f4\u200b  </li> <li>\u200b\u5c06\u200b\u8303\u56f4\u200b\u5212\u5206\u200b\u4e3a\u200b\u82e5\u5e72\u4e2a\u200b\u6876\u200bbin\uff08\u200b\u5982\u200b2048\uff09\uff0c\u200b\u7edf\u8ba1\u200b\u5404\u200b\u533a\u95f4\u200b\u5185\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u7684\u200b\u51fa\u73b0\u200b\u9891\u7387\u200b  </li> </ul> </li> <li>\u200b\u4f7f\u7528\u200b\u6821\u51c6\u200b\u7b97\u6cd5\u200b\u5206\u6790\u200b\u76f4\u65b9\u56fe\u200b  <ul> <li>\u200b\u901a\u8fc7\u200bKL\u200b\u6563\u5ea6\u200b\u6bd4\u8f83\u200b\u539f\u59cb\u200b\u5206\u5e03\u200b\u548c\u200b\u91cf\u5316\u200b\u540e\u200b\u5206\u5e03\u200b\uff0c\u200b\u5bfb\u627e\u200b\u6700\u5c0f\u200b\u4fe1\u606f\u200b\u635f\u5931\u200b\u7684\u200b\u622a\u65ad\u200b\u9608\u503c\u200b (\u200b\u4fdd\u7559\u200b\u7684\u200b\u6700\u5927\u200bFP32\u200b\u503c\u200b\uff0c\u200b\u5373\u200b<code>x=min(x, threshold), fp32_dist = hist[:threshold] / np.sum(hist[:threshold])</code>) </li> <li>\u200b\u6839\u636e\u200b\u9608\u503c\u200b\u8ba1\u7b97\u200b\u6bcf\u4e2a\u200b\u91cf\u5316\u200b\u540e\u200bbin\u200b\u7684\u200b\u5bbd\u5ea6\u200b <code>scale = threshold / INT8_max</code>\uff0c\u200b\u5373\u200b<code>quant_bins = np.liespace(0, threshold, INT8_max)</code> </li> <li>\u200b\u7edf\u8ba1\u200bFP32\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u5728\u200b\u4e0a\u8ff0\u200b\u91cf\u5316\u200b\u6876\u200b\u7684\u200b\u51fa\u73b0\u200b\u9891\u6570\u200b\uff0c\u200b\u5e76\u200b\u5f52\u4e00\u5316\u200b\u9891\u7387\u200b<code>quant_dist /= np.sum(quant_dist)</code> </li> <li>\u200b\u4e3a\u200b\u907f\u514d\u200blog 0\uff0c<code>fp32_dist = np.clip(fp32_dist, 1e-10, 1), quant_dist=np.clip(quant_dist, 1e-10, 1)</code></li> <li>\u200b\u8ba1\u7b97\u200bKL distance</li> <li>\u200b\u9009\u5b9a\u200brange_width\uff08\u200b\u5bf9\u200b\u5de6\u53f3\u200b\u8fb9\u754c\u200b\u8fdb\u884c\u200b\u622a\u65ad\u200b\u9009\u62e9\u200b\uff09\uff0c\u200b\u7136\u540e\u200b\u8fdb\u884c\u200b <code>bin_width = range_width / INT8_max</code> \u200b\u5206\u6876\u200b  </li> <li>\u200b\u8ba1\u7b97\u200b\u5f52\u4e00\u5316\u200b\u8303\u56f4\u200b\u8fdb\u884c\u200b\u5206\u6876\u200b <code>(x - min(x)) / bin_width</code></li> <li>KL\u200b\u77eb\u6b63\u200b\u7b97\u6cd5\u200b\uff1a\u200b\u8ba1\u7b97\u200b\u5e76\u200b\u9009\u62e9\u200b\u6700\u5c0f\u200b\u91cf\u5316\u200b\u524d\u540e\u200bKL\u200b\u6563\u5ea6\u200b\u5bf9\u5e94\u200b\u7684\u200b\u622a\u65ad\u200b\u8303\u56f4\u200b\uff0c\u200b\u9002\u7528\u200b\u4e8e\u200b\u957f\u5c3e\u200b\u5206\u5e03\u200b\u3001\u200b\u53cc\u5cf0\u5206\u5e03\u200b\u7b49\u200b  </li> <li>MinMax\uff1a\u200b\u76f4\u63a5\u200b\u53d6\u200bmin/max\u200b\u503c\u4ee5\u200b\u5168\u91cf\u200b\u4fdd\u5b58\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u52a8\u6001\u200b\u8303\u56f4\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5bf9\u200b\u79bb\u7fa4\u200b\u673a\u503c\u200b\u70b9\u200b\u5341\u5206\u200b\u654f\u611f\u200b\uff0c\u200b\u9002\u7528\u200b\u4e8e\u200b\u5747\u5300\u5206\u5e03\u200b\u60c5\u51b5\u200b  </li> <li>MinMax\u200b\u6539\u8fdb\u200b\uff0c\u200b\u4f7f\u7528\u200b\u5206\u200b\u4f4d\u6570\u200b\u622a\u65ad\u200b\u7f13\u89e3\u200b\u79bb\u7fa4\u200b\u70b9\u200b\u5f71\u54cd\u200b\uff0c\u200b\u5982\u200b\\([P_{0.1\\%}, P_{99.9\\%}]\\)</li> <li>\u200b\u8303\u56f4\u200b\u65e0\u9700\u200b\u5bf9\u79f0\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u53ef\u200b\u901a\u8fc7\u200b\u51cf\u53bb\u200b <code>min_value</code> \u200b\u8fdb\u884c\u200b\u5e73\u79fb\u200b\u5904\u7406\u200b</li> </ul> </li> </ol> <pre><code>import numpy as np\nfrom scipy.stats import entropy\n\ndef compute_scale(activations, num_bins=2048):\n    hist, bin_edges = np.histogram(activations, bins=num_bins)\n    bin_width = bin_edges[1] - bin_edges[0]\n\n    # \u200b\u4f7f\u7528\u200bKL\u200b\u6563\u5ea6\u200b\u9009\u62e9\u200b\u6700\u4f18\u200b\u622a\u65ad\u200b\u9608\u503c\u200b\n    def kl_divergence(threshold):\n        # \u200b\u5c06\u200bFP32\u200b\u5206\u5e03\u200b\u622a\u65ad\u200b\u5230\u200b[0, threshold]\u200b\u5e76\u200b\u5f52\u4e00\u5316\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u6b64\u5904\u200b\u65f6\u200bReLU\u200b\u6fc0\u6d3b\u200b\u51fd\u6570\u200b\u793a\u4f8b\u200b\n        fp32_dist = hist[:threshold] / np.sum(hist[:threshold])\n\n        # \u200b\u751f\u6210\u200b\u91cf\u5316\u200b\u540e\u200b\u7684\u200b\u5206\u5e03\u200b\uff08INT8\u200b\u6a21\u62df\u200b\uff09\n        quant_bins = np.linspace(0, threshold, 256)\n        quant_dist = np.zeros(256)\n        for i in range(256):\n            start = quant_bins[i]\n            end = quant_bins[i+1] if i &lt; 255 else threshold\n            quant_dist[i] = np.sum(hist[(bin_edges &gt;= start) &amp; (bin_edges &lt; end)])\n        quant_dist /= np.sum(quant_dist)\n\n        # \u200b\u907f\u514d\u200blog(0)\n        fp32_dist = np.clip(fp32_dist, 1e-10, 1)\n        quant_dist = np.clip(quant_dist, 1e-10, 1)\n\n        return entropy(fp32_dist, quant_dist)\n\n    # \u200b\u641c\u7d22\u200b\u6700\u4f73\u200b\u9608\u503c\u200b\n    best_threshold = np.argmin([kl_divergence(t) for t in range(100, num_bins)])\n    scale = bin_edges[best_threshold] / 127.0  # INT8\u200b\u5bf9\u79f0\u200b\u91cf\u5316\u200b\n\n    return scale\n</code></pre> <p>\u200b\u4e0d\u540c\u200bbatch\u200b\u987a\u5e8f\u200b\u4f1a\u200b\u4ea7\u751f\u200b\u4e0d\u540c\u200b\u7684\u200b\u6821\u51c6\u200b\u5c3a\u5ea6\u200b\uff0c\u200b\u56e0\u6b64\u200b\u5efa\u8bae\u200b\u4f7f\u7528\u200blarge batch     - https://docs.nvidia.com/deeplearning/tensorrt/archives/tensorrt-843/pdf/TensorRT-Developer-Guide.pdf     - \u200b\u5e38\u89c1\u200b\u6821\u51c6\u200b\u7b97\u6cd5\u200b\u5982\u4e0b\u200b</p> <ol> <li> <p>Entropy Calibration\uff0c\u200b\u9009\u62e9\u200b\u5bf9\u5e94\u200b\u91cf\u5316\u200b\u524d\u540e\u200b\u5206\u5e03\u200b\u6700\u5c0f\u200bKL\u200b\u6563\u5ea6\u200b\u7684\u200b\u9608\u503c\u200b\u6765\u200b\u786e\u5b9a\u200b\u6700\u4f18\u200b\u7684\u200b\u91cf\u5316\u200b\u53c2\u6570\u200b</p> \\[ D_{KL}(P\\Vert Q) = \\sum_{i} P(i)\\log \\frac{P(i)}{Q(i)} \\] <p>\\(P\\) \u200b\u4e3a\u200b\u539f\u59cb\u200b\u6a21\u578b\u200b\uff0c\\(Q\\) \u200b\u4e3a\u200b\u91cf\u5316\u200b\u540e\u200b\u6a21\u578b\u200b</p> </li> <li> <p>MinMax Calibration\uff0c\u200b\u66f4\u200b\u9002\u5408\u200bNLP\u200b\u4efb\u52a1\u200b</p> </li> <li>Legacy Calibration\uff0c\u200b\u6700\u5c0f\u5316\u200b\u91cf\u5316\u200b\u524d\u540e\u200b\u7684\u200b\u5747\u200b\u65b9\u5dee\u200b</li> </ol> <p>converter.representative_dataset</p> <pre><code>converter.optimizations = [tf.lite.Optimize.DEFAULT]\n# \u200b\u52a8\u6001\u200b\u8303\u56f4\u200b\u91cf\u5316\u200b\uff0c\u200b\u7f3a\u7701\u200b\u72b6\u6001\u200b\n\n# \u200b\u534a\u200b\u7cbe\u5ea6\u200b\u91cf\u5316\u200b Float16 Quantization: \u200b\u4ec5\u200b\u91cf\u5316\u200b\u6743\u91cd\u200b\nconverter.target_spec.supported_types = [tf.float16]\n\n# \u200b\u5168\u200b\u6574\u578b\u200b\u91cf\u5316\u200b Full Integer Quantization: \u200b\u6743\u91cd\u200b\u548c\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u90fd\u200b\u8fdb\u884c\u200b\u91cf\u5316\u200b\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\nconverter.inference_input_type = tf.uint8   # or tf.int8\nconverter.inference_output_type = tf.uint8  # or tf.int8\n\n# int8\u200b\u6743\u91cd\u200bfloat16\u200b\u6fc0\u6d3b\u200b\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8]\n</code></pre>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#qat","title":"QAT","text":"<p>Quantization Aware Training</p> <ol> <li>data free\uff0c\u200b\u4e0d\u200b\u9002\u7528\u200b\u6821\u51c6\u200b\u96c6\u200b\uff0c\u200b\u76f4\u63a5\u200b\u91cf\u5316\u200b\u5e76\u200b\u8f93\u51fa\u200b\uff0c\u200b\u4f46\u200b\u4e00\u822c\u200b\u4f1a\u200b\u5e26\u6765\u200b\u8f83\u5927\u200b\u7cbe\u5ea6\u200b\u635f\u5931\u200b</li> <li>calibration\uff0c\u200b\u57fa\u4e8e\u200b\u6821\u51c6\u200b\u96c6\u200b\uff0c\u200b\u901a\u8fc7\u200b\u8f93\u5165\u200b\u5c11\u91cf\u200b\u7684\u200b\u771f\u5b9e\u200b\u6570\u636e\u200b\u8fdb\u884c\u200b\u7edf\u8ba1\u5206\u6790\u200b\u6765\u200b\u77eb\u6b63\u200b\u91cf\u5316\u200b\u6570\u636e\u200b</li> <li> <p>finetune\uff0c\u200b\u57fa\u4e8e\u200b\u8bad\u7ec3\u200b\u5fae\u8c03\u200b\u7684\u200b\u65b9\u6848\u200b\uff0c\u200b\u5c06\u200b\u91cf\u5316\u200b\u80e1\u832c\u200b\u5728\u200b\u8bad\u7ec3\u200b\u65f6\u200b\u81ea\u52a8\u200b\u8c03\u6574\u200b\u6743\u91cd\u200b\uff0c\u200b\u53ef\u200b\u5e26\u6765\u200b\u66f4\u597d\u200b\u7684\u200b\u7cbe\u5ea6\u200b\u63d0\u5347\u200b\uff0c\u200b\u4f46\u200b\u9700\u8981\u200b\u989d\u5916\u200b\u4fee\u6539\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u4ee3\u7801\u200b\uff0c\u200b\u5f00\u53d1\u5468\u671f\u200b\u8f83\u957f\u200b</p> </li> <li> <p>TensorFlow Lite Optimizing Converter(Toco) \u200b\u8f6c\u6362\u5668\u200b</p> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#qkd","title":"QKD","text":"<p>Quantization-aware Knowledge Distillation\uff0c\u200b\u5c06\u200b\u539f\u59cb\u200b\u6a21\u578b\u200b\u4f5c\u4e3a\u200bteacher model\u3001\u200b\u91cf\u5316\u200b\u540e\u200b\u7684\u200b\u6a21\u578b\u200b\u4f5c\u4e3a\u200bstudent model\u200b\u8fdb\u884c\u200b\u84b8\u998f\u200b</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#_6","title":"\u91cf\u5316\u200b\u7c92\u5ea6","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#layer-wise-quantization","title":"Layer-wise Quantization","text":"<p>Layer-wise Quantization \u200b\u662f\u200b\u4e00\u79cd\u200b\u57fa\u7840\u200b\u7684\u200b\u6a21\u578b\u200b\u91cf\u5316\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u5b83\u200b\u5c06\u200b\u795e\u7ecf\u7f51\u7edc\u200b\u4e2d\u200b\u6bcf\u200b\u4e00\u5c42\u200b\u7684\u200b\u6743\u91cd\u200b\u6216\u200b\u6fc0\u6d3b\u200b\u503c\u200b\u4f5c\u4e3a\u200b\u4e00\u4e2a\u200b\u6574\u4f53\u200b\u8fdb\u884c\u200b\u91cf\u5316\u200b\uff08\u200b\u4f7f\u7528\u200b\u7edf\u4e00\u200b\u7684\u200b\u91cf\u5316\u200b\u53c2\u6570\u200b\u7f29\u653e\u200b\u56e0\u5b50\u200b\u548c\u200b\u96f6\u70b9\u200b\uff09</p> <ul> <li>\u200b\u7c92\u5ea6\u200b\u8f83\u4e3a\u200b\u7c97\u7cd9\u200b\uff0c\u200b\u7cbe\u5ea6\u200b\u635f\u5931\u200b\u8f83\u5927\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#block-wise-quantization","title":"Block-wise Quantization","text":"<p>Block-wise k-bit Quantization\u200b\u5c06\u200b\u6570\u636e\u200b\u5212\u5206\u200b\u6210\u200b blocks\uff08\u200b\u5982\u200b\\(8\\times 8\\)\uff09\uff0c\u200b\u5bf9\u4e8e\u200b\u6bcf\u4e2a\u200bblock\u200b\u72ec\u7acb\u200b\u5e94\u7528\u200bINT-k\u200b\u91cf\u5316\u200b\u65b9\u6848\u200b</p> <ul> <li> \u200b\u5206\u5757\u200b\u72ec\u7acb\u200b\u5904\u7406\u200b\u80fd\u200b\u6709\u6548\u200b\u51cf\u7f13\u200b\u7531\u200b\u6781\u7aef\u200b\u6781\u503c\u200b \\(\\max(\\vert x \\vert)\\) \u200b\u5bfc\u81f4\u200b\u91cf\u5316\u200b\u7f29\u653e\u200b\u56e0\u5b50\u200b \\(s_{x, k}\\) \u200b\u8fc7\u5927\u200b\uff0c\u200b\u8868\u73b0\u200b\u91cf\u5316\u200b\u7ed3\u679c\u200b\u8fc7\u4e8e\u200b\u96c6\u4e2d\u200b\u6a21\u7cca\u200b\uff0c\u200b\u635f\u5bb3\u200b\u6574\u4f53\u200b\u91cf\u5316\u200b\u6548\u679c\u200b</li> <li>\u200b\u8f6c\u4e3a\u200bTensor Core\u200b\u8bbe\u8ba1\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#group-wise-quantization","title":"Group-wise Quantization","text":"<p>Group-wise Quantization\u200b\u5c06\u200b\u6570\u636e\u200b\u6309\u200b\u901a\u9053\u200b\u65b9\u5411\u200b\u5212\u5206\u200b\u6210\u200b groups\uff08\\(W\\in \\mathbb{R}^{d_{in}\\times d_{out}}\\) \u200b\u6309\u884c\u200b\u7ef4\u5ea6\u200b\u6216\u5217\u200b\u7ef4\u5ea6\u200b\u5212\u5206\u200b\uff0c\u200b\u4e00\u822c\u200b\u57fa\u4e8e\u200bGEMM \\(Y=XW\\)\u200b\u7279\u6027\u200b\u91c7\u7528\u200bColumn-wise\u200b\u62c6\u5206\u200b\uff09\uff0c\u200b\u5bf9\u4e8e\u200b\u6bcf\u4e2a\u200bgroup\u200b\u72ec\u7acb\u200b\u5e94\u7528\u200bINT-k\u200b\u91cf\u5316\u200b\u65b9\u6848\u200b</p> <ul> <li>\u200b\u66f4\u200b\u9002\u7528\u200b\u4e8e\u200bAttention\u200b\u4e2d\u200b\u7684\u200b\u6ce8\u610f\u529b\u200b\u6743\u91cd\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u4e0e\u200bGEMM\u200b\u517c\u5bb9\u200b</li> <li>\u200b\u901a\u7528\u200b\u4e8e\u200bCPU/GPU\u200b\u786c\u4ef6\u200b\u67b6\u6784\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/quantization.html#token-wise-quantization","title":"Token-wise Quantization","text":"<p>Token-wise Quantization \u200b\u662f\u200b\u4e00\u79cd\u200b\u9762\u5411\u200b\u52a8\u6001\u200b\u5e8f\u5217\u200b\u6570\u636e\u200b\uff08\u200b\u5982\u200bTransformer\u200b\u7684\u200b\u8f93\u5165\u200b\u548c\u200b\u6fc0\u6d3b\u200b\u503c\u200b\uff09\u200b\u7684\u200b\u7ec6\u7c92\u5ea6\u200b\u91cf\u5316\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u5176\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\u4e3a\u200b\u8f93\u5165\u200b\u5e8f\u5217\u200b\u4e2d\u200b\u7684\u200b\u6bcf\u4e2a\u200b Token \u200b\u72ec\u7acb\u200b\u8ba1\u7b97\u200b\u91cf\u5316\u200b\u53c2\u6570\u200b\uff0c\u200b\u4ece\u800c\u200b\u663e\u8457\u200b\u63d0\u5347\u200b\u4f4e\u200b\u6bd4\u7279\u200b\u91cf\u5316\u200b\u4e0b\u200b\u7684\u200b\u6a21\u578b\u200b\u7cbe\u5ea6\u200b\u3002</p> <ul> <li>\u200b\u5728\u200b\u63a8\u7406\u200b\u9636\u6bb5\u200b\u4f1a\u200b\u56e0\u4e3a\u200b\u5b9e\u65f6\u200b\u8ba1\u7b97\u200b \\(s_t\\) \u200b\u800c\u200b\u5f15\u5165\u200b\u989d\u5916\u200b\u5f00\u9500\u200b\uff0c\u200b\u4f46\u200b\u4e00\u822c\u200b\uff1c5%</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/smooth_quant.html","title":"Smooth quant","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/smooth_quant.html#smoothquant","title":"SmoothQuant","text":"<p>\u200b\u8bba\u6587\u200b\uff1aSmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models Github\uff1asmoothquant Massachusetts Institute of Technology &amp; Nvidia, 2022 Nov, ICML 2023</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/smooth_quant.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":"<p>\u200b\u7531\u4e8e\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b weight \u200b\u7684\u200b\u79bb\u7fa4\u200b\u503c\u8f83\u200b\u6fc0\u6d3b\u200b\u503c\u200b activation \u200b\u4e2d\u200b\u79bb\u7fa4\u200b\u503c\u200b\u66f4\u5c11\u200b\uff0c\u200b\u66f4\u200b\u5bb9\u6613\u200b\u91cf\u5316\u200b\uff0c\u200b\u56e0\u6b64\u200b\u53ef\u200b\u901a\u8fc7\u200b\u6570\u5b66\u200b\u5f0f\u200b\u7b49\u4ef7\u200b\u53d8\u6362\u200b\u5c06\u200b activation\u200b\u91cf\u5316\u200b\u56f0\u96be\u200b\u5ea6\u200b\u8fc1\u79fb\u200b\u5230\u200b weight\u200b\u6765\u200b\u9ad8\u6548\u200b\u5b9e\u73b0\u200b\u91cf\u5316\u200b</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/smooth_quant.html#smoothquant_1","title":"SmoothQuant","text":"<p>\u200b\u56e0\u4e3a\u200bactivation\u200b\u4e0d\u540c\u200b\u7279\u5f81\u200b\u7ef4\u5ea6\u200b\u7684\u200b\u6570\u503c\u200b\u91cf\u7ea7\u200b\u5b58\u5728\u200b\u660e\u663e\u200b\u5dee\u5f02\u200b\uff0c\u200b\u4f46\u200b\u4e0d\u540c\u200btoken\u200b\u540c\u4e00\u200b\u7279\u5f81\u200b\u7ef4\u5ea6\u200b\u7684\u200b\u6570\u503c\u200b\u91cf\u7ea7\u200b\u65b9\u5dee\u200b\u4e0d\u200b\u5927\u200b\uff0c\u200b\u800c\u200bweight\u200b\u7684\u200b\u6570\u503c\u200b\u91cf\u7ea7\u200b\u4e0e\u200b\u65b9\u5dee\u200b\u5747\u200b\u8f83\u4e3a\u200b\u5e73\u7f13\u200b\u5747\u5300\u200b\uff0c\u200b\u56e0\u6b64\u200b\u53ef\u200b\u5c06\u200b\u91cf\u5316\u200b\u96be\u5ea6\u200b\u4ece\u200bactivation\u200b\u8f6c\u79fb\u200b\u5230\u200bweight\u200b\u4e0a\u200b\uff0c\u200b\u5373\u200b</p> \\[ Y = (X \\text{diag}(s)^{-1})(\\text{diag}(s)W) = \\hat{X}\\hat{W} \\] <p>\u200b\u5176\u4e2d\u200b \u200b\u91cf\u5316\u200b\u96be\u5ea6\u200b\u8fc1\u79fb\u200b\u7a0b\u5ea6\u200b \\(\\text{diag}(s) \\in \\mathbb{R}^{d_{in}\\times d_{in}}\\)</p> <ul> <li>\\(s_j  = \\max(\\vert X_j \\vert )\\) cloumn-wise\u200b\u53d6\u200b\\(\\text{absmax}(X)\\)\uff0c\u200b\u5c06\u200b\u6240\u6709\u200b\u7684\u200bactivation\u200b\u91cf\u5316\u200b\u96be\u5ea6\u200b\u8fc1\u79fb\u200b\u81f3\u200bweight</li> <li>\\(s_j  = \\max\\left(1/{\\vert W_j \\vert} \\right)\\) row-wise\u200b\u53d6\u200b\\(\\text{absmax}(W)\\)\uff0c\u200b\u5c06\u200b\u6240\u6709\u200b\u7684\u200bweight\u200b\u91cf\u5316\u200b\u96be\u5ea6\u200b\u8fc1\u79fb\u200b\u81f3\u200bactivation</li> <li>\\(s_j = \\max(\\vert X_j \\vert)^\\alpha / \\max(\\vert W_j \\vert)^{1-\\alpha}\\)\uff0c\u200b\u8d85\u53c2\u200b\\(\\alpha\\) \u200b\u534f\u8c03\u200bactivation\u200b\u91cf\u5316\u200b\u96be\u5ea6\u200b\u8fc1\u79fb\u200b\u81f3\u200bactivation\u200b\u7684\u200b\u7a0b\u5ea6\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/smooth_quant.html#smoothquant-to-trm-block","title":"SmoothQuant to TRM Block","text":"<ul> <li>Attention\u200b\u5c42\u200b\u7684\u200b\u8f93\u5165\u200b\u4ee5\u53ca\u200b\u9ad8\u7b97\u529b\u200b\u8981\u6c42\u200b BMM(Batch Matrix Multiplication) \u200b\u6743\u91cd\u200b\u53c2\u6570\u200b\u4f7f\u7528\u200bINT8\u200b\u91cf\u5316\u200b</li> <li>ReLU, LN\u200b\u4ee5\u53ca\u200bSoftmax\u200b\u7b49\u200b\u8f7b\u91cf\u7ea7\u200belement-wise\u200b\u64cd\u4f5c\u200b\u4f7f\u7528\u200bFP16\u200b\u5b58\u50a8\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/zero_quant.html","title":"Zero quant","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/zero_quant.html#zeroquant","title":"ZeroQuant","text":"<p>\u200b\u8bba\u6587\u200b\uff1aZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers Microsoft, 2022 Jun, NeurIPS 2022</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/zero_quant.html#_1","title":"\u4e3b\u8981\u200b\u5185\u5bb9","text":""},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/zero_quant.html#motivation","title":"Motivation","text":"<ul> <li> Dynamic Activation Range \u200b\u6fc0\u6d3b\u200b\u503c\u200b\u8303\u56f4\u200b\u5177\u6709\u200b\u8f83\u5927\u200b\u7684\u200b\u65b9\u5dee\u200b\uff0c\u200b\u76f4\u63a5\u200b\u5bf9\u200b\u6240\u6709\u200btoken\u200b\u4f7f\u7528\u200b\u76f8\u540c\u200b\u7684\u200bINT8\u200b\u91cf\u5316\u200b\u65b9\u6848\u200b\u4f1a\u200b\u5bfc\u81f4\u200b\u660e\u663e\u200b\u7684\u200b\u6548\u679c\u200b\u4e0b\u964d\u200b\u3002      </li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/zero_quant.html#zeroquant_1","title":"ZeroQuant","text":"<p>ZeroQuant\u200b\u5728\u200bweight \u200b\u548c\u200b activation \u200b\u4e0a\u200b\u5e94\u7528\u200b\u4e86\u200b\u7ec6\u7c92\u5ea6\u200b\u786c\u4ef6\u200b\u53cb\u597d\u200b\u7684\u200bPTQ\u200b\u91cf\u5316\u200b\u65b9\u6848\u200b\uff0c</p> <ul> <li>Group-wise Weight Quantization, \u200b\u5c06\u200b\u77e9\u9635\u200b\u62c6\u200b\u5206\u6210\u200b\u591a\u7ec4\u200b\u5206\u522b\u200b\u8fdb\u884c\u200b\u72ec\u7acb\u200b\u91cf\u5316\u200b\uff08\u200b\u4e00\u822c\u200b\u57fa\u4e8e\u200bGEMM \\(Y=XW\\)\u200b\u7279\u6027\u200b\u91c7\u7528\u200bColumn-wise\u200b\u62c6\u5206\u200b\uff09</li> <li>Token-wise Activation Quantization\uff0c\u200b\u5bf9\u4e8e\u200b\u6bcf\u4e2a\u200btoken \u200b\u7684\u200b\u5411\u91cf\u200b\u8868\u793a\u200b \\(h_t \\in \\mathbb{R}^d\\)\uff0c\u200b\u5206\u522b\u200b\u8ba1\u7b97\u200b\u7f29\u653e\u200b\u56e0\u5b50\u200b \\(s_t = \\frac{\\text{absmax}(h_t)}{2^{b-1} - 1}\\) \u200b\u7528\u4e8e\u200b\u91cf\u5316\u200b</li> </ul> <p>TQ\u200b\u52a8\u6001\u200b\u8ba1\u7b97\u200b\u8303\u56f4\u200b\uff0c\u200b\u65e0\u9700\u200b\u9759\u6001\u200b\u6821\u6b63\u200bactivation range</p>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/zero_quant.html#lkd","title":"LKD","text":"<p>\u200b\u8fdb\u4e00\u6b65\u200b\u8bbe\u8ba1\u200b\u4e86\u200b\u5bf9\u200b\u91cf\u5316\u200b\u540e\u200b\u7684\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\u53c2\u6570\u200b weight \u200b\u8fdb\u884c\u200b\u84b8\u998f\u200b\u7684\u200b\u65b9\u6cd5\u200bLKD (Layer-by-layer Knowledge Distillation)\uff1a\u200b\u4f7f\u7528\u200b\u539f\u59cb\u200b\u6a21\u578b\u200b\u4f5c\u4e3a\u200bteacher model\uff0c\u200b\u76ee\u6807\u200b\u91cf\u5316\u200b\u84b8\u998f\u200b\u6a21\u578b\u200b\u4f5c\u4e3a\u200bstudent model\uff0c\u200b\u8fed\u4ee3\u200b\u5730\u200b\u9010\u5c42\u200b\u84b8\u998f\u200b\u3002\u200b\u5bf9\u4e8e\u200b\u539f\u59cb\u200b\u6a21\u578b\u200b\u5c42\u200b \\(L_k\\) \uff0c\u200b\u76ee\u6807\u200b\u91cf\u5316\u200b\u84b8\u998f\u200b\u6a21\u578b\u200b\u5c42\u200b \\(\\hat{L}_{k}\\)</p> <ol> <li>\u200b\u83b7\u53d6\u200bteacher model\u200b\u7684\u200b\u8f93\u51fa\u200b \\(L_k(h^{k-1})\\) \u200b\u4f5c\u4e3a\u200bground-truth</li> <li> <p>\u200b\u901a\u8fc7\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u7ea6\u675f\u200bstudent model\u200b\u8f93\u51fa\u200b \\(\\hat{L}_k(h^{k-1})\\)\u200b\u5411\u200bteacher model\u200b\u9760\u9f50\u200b\uff0c\u200b\u5373\u200b</p> \\[ \\mathcal{L}_{\\text{LKD}, k}=\\mathcal{L}\\left(L_k(h^{k-1}), \\hat{L}_k(h^{k-1})\\right) \\] </li> </ol> <p>Info</p> <ul> <li>\u200b\u5bf9\u4e8e\u200b\u5c42\u200b\\(k\\)\uff0cteacher model\u200b\u4e0e\u200bstudent model\u200b\u5171\u4eab\u200b\u524d\u200b\\(k-1\\)\u200b\u5c42\u200b\uff0c\u200b\u5373\u200b\\(L_k\\) \u200b\u4e0e\u200b \\(\\hat{L}_k\\) \u200b\u8f93\u5165\u200b\u76f8\u540c\u200b\uff0c\u200b\u65e0\u9700\u200b\u7aef\u5230\u200b\u7aef\u200b\uff0c\u200b\u4efb\u4f55\u65f6\u523b\u200b\u53ea\u6709\u200b\u4e00\u5c42\u200b\u9700\u8981\u200b\u88ab\u200b\u84b8\u998f\u200b\uff0c\u200b\u5927\u5927\u51cf\u5c11\u200b\u5b58\u50a8\u200b\u5f00\u9500\u200b  </li> <li>\\(\\mathcal{L}\\) \u200b\u53ef\u200b\u4e3a\u200bMSE\u200b\u4e5f\u200b\u53ef\u4e3a\u200bKL divergence</li> <li>LKD\u200b\u65e0\u9700\u200b\u4f7f\u7528\u200b\u539f\u59cb\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u84b8\u998f\u200b\u5373\u53ef\u200b\u8fbe\u5230\u200b\u4e0e\u200b\u539f\u59cb\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u76f8\u5f53\u200b\u6548\u679c\u200b</li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/zero_quant.html#system-kernel-optimization","title":"System Kernel Optimization","text":"<p>\u200b\u5728\u200b\u63a8\u7406\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\uff0c\u200b\u6279\u5904\u7406\u200b\u5927\u5c0f\u200b\u901a\u5e38\u200b\u76f8\u5bf9\u200b\u8f83\u200b\u5c0f\u200b\uff0c\u200b\u56e0\u6b64\u200b\u6a21\u578b\u200b\u7684\u200b\u63a8\u7406\u200b\u5ef6\u8fdf\u200b\u4e3b\u8981\u200b\u53d6\u51b3\u4e8e\u200b\u4ece\u4e3b\u200b\u5185\u5b58\u200b\u52a0\u8f7d\u200b\u6570\u636e\u200b\u7684\u200b\u65f6\u95f4\u200b\u3002\u200b\u901a\u8fc7\u200b\u5c06\u200b\u6743\u91cd\u200b\u548c\u200b\u6fc0\u6d3b\u200b\u91cf\u5316\u200b\u4e3a\u200b\u8f83\u200b\u4f4e\u200b\u7cbe\u5ea6\u200b\uff0c\u200b\u6211\u4eec\u200b\u51cf\u5c11\u200b\u4e86\u200b\u52a0\u8f7d\u200b\u8fd9\u4e9b\u200b\u6570\u636e\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u6570\u636e\u91cf\u200b\uff0c\u200b\u4ece\u800c\u200b\u53ef\u4ee5\u200b\u66f4\u200b\u6709\u6548\u200b\u5730\u200b\u5229\u7528\u200b\u5185\u5b58\u200b\u5e26\u5bbd\u200b\u5e76\u200b\u63d0\u9ad8\u200b\u52a0\u8f7d\u200b\u541e\u5410\u91cf\u200b\u3002\u200b\u7136\u800c\u200b\uff0c\u200b\u76f4\u63a5\u200b\u4f7f\u7528\u200b\u73b0\u6709\u200b\u7684\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6846\u67b6\u200b\uff08\u200b\u5982\u200b PyTorch\uff09\u200b\u8fdb\u884c\u200bToken-wise Quantization \u200b\u91cf\u5316\u200b\u4e0e\u200b\u53cd\u200b\u91cf\u5316\u200b\u64cd\u4f5c\u200b\u4ea7\u751f\u200b\u7684\u200b\u989d\u5916\u200b\u6570\u636e\u200b\u79fb\u52a8\u200b\u5f00\u9500\u200b\u975e\u5e38\u200b\u6602\u8d35\u200b\uff0c\u200b\u751a\u81f3\u200b\u8d85\u8fc7\u200b\u4e86\u200b\u4f4e\u200b\u7cbe\u5ea6\u200b\u5e26\u6765\u200b\u7684\u200b\u6027\u80fd\u200b\u63d0\u5347\u200b\u3002\u200b\u56e0\u6b64\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u65b9\u6cd5\u200b\u51cf\u5c11\u200b\u6027\u80fd\u200b\u635f\u5931\u200b</p> <ol> <li>CUTLASS INT8 GeMM CUTLASS(CUDA Templates for Linear Algebra Subroutines) INT8 GeMM\u200b\u5e93\u200b</li> <li> <p>Fusing Token-wise Activation Quantization \u200b\u901a\u8fc7\u200b\u878d\u5408\u200b\u7b97\u5b50\u200b\u4ee5\u8f83\u200b\u5c11\u91cf\u200b\u5316\u200b\u4e0e\u200b\u53cd\u200b\u91cf\u5316\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u7684\u200b\u6570\u636e\u200b\u79fb\u52a8\u200b</p> <ul> <li>Operation Fusion for Token-wise Activation Quantization \u200b\u5c06\u200b <code>add-bias, GELU, LN</code> \u200b\u7b49\u200belement-wise\u200b\u64cd\u4f5c\u200b\u4e0e\u200b\u91cf\u5316\u200b\u6b65\u9aa4\u200b\u878d\u5408\u200b</li> <li>Dequantization Associated with GeMM Schedule \\(\\tilde{Y} = (\\hat{X}*s_X) (\\hat{W}*s_W) =\\)$ \\hat{X}\\hat{W} * s_Xs_W$\uff0c\u200b\u4e2d\u95f4\u200b\u503c\u200b \\(Y_\\text{int32} = \\hat{X}\\hat{W}\\) \u200b\u4f7f\u7528\u200b\u66f4\u200b\u5bbd\u200b\u7684\u200b\u4f4d\u200b\u5bbd\u200b\u5b58\u50a8\u200b\u9632\u6b62\u200b\u6ea2\u51fa\u200b</li> </ul> <p></p>  3. Cuda Graph Enhanced Small Model Inference As the execution time for specific kernels reduce by optimizing the throughput using the INT8 inference pipeline, the overhead of launching the GPU kernels and the CPU-to-GPU communication become a major bottleneck mostly on small-scale models. To address this issue, we add the CUDA-Graph support to our inference pipeline that reduces the CPU overhead, by storing the trace of the kernels launched during the inference forward computation, and creating the computation-graph to be reused in the next call to the inference pipeline. Thus, after storing the graph for the first time, we can replay the graph for the following requests, which substantially improves the performance especially on small models, such as BERTbase. For a fair comparison, we also enable Cuda Graph for FP16 baseline. - thread-blocks, WARPs, and WMMA (Tensor cores)  <p></p> </li> <li> <p>Self-Attention\u200b\u6a21\u5757\u200b\u6570\u503c\u200b\u654f\u611f\u5ea6\u200b\u8f83\u200b\u9ad8\u200b\uff0c\u200b\u53ef\u200b\u4fdd\u5b88\u200b\u9009\u62e9\u200b\u91cf\u5316\u200b\u6bd4\u4f8b\u200b\uff08\\(W_{q/k/v}\\) \u200b\u7684\u200b\u8f93\u5165\u200b\u4f7f\u7528\u200bFP16\uff09     </p> <p></p> </li> </ol>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/zero_quant.html#evaluation","title":"Evaluation","text":"<ul> <li>ZeroQuant\u200b\u4e0e\u200bLKD\u200b\u80fd\u591f\u200b\u5e26\u6765\u200b\u660e\u663e\u200b\u7684\u200b\u6548\u679c\u200b\u63d0\u5347\u200b</li> <li> \u200b\u8f83\u200bPTQ\u200b\u4e0e\u200bQAT\u200b\u80fd\u200b\u5e26\u6765\u200b\u660e\u663e\u200b\u7684\u200b\u6548\u679c\u200b\u63d0\u5347\u200b\uff0c\u200b\u80fd\u591f\u200b\u66f4\u200b\u9ad8\u6548\u200b\u5730\u200b\u5b8c\u6210\u200b\u91cf\u5316\u200b\u5de5\u4f5c\u200b</li> <li> \u200b\u5728\u200b\u8d85\u4f4e\u200b\u7cbe\u5ea6\u200b\u91cf\u5316\u200b\u6761\u4ef6\u200b\u4e0b\u200b\u4f9d\u7136\u200b\u80fd\u591f\u200b\u53d6\u5f97\u200b\u8f83\u200b\u597d\u200b\u7684\u200b\u6548\u679c\u200b\u8868\u73b0\u200b  </li> </ul>"},{"location":"AI/Paper_Reading/Trick/Light_Weighting/Quantization/zero_quant.html#ablation","title":"Ablation","text":"<ul> <li> GQ, TQ\u200b\u4ee5\u53ca\u200bLKD\u200b\u5747\u200b\u5bf9\u200bPTQ\u200b\u6709\u200b\u589e\u76ca\u200b\u8868\u73b0\u200b      </li> </ul>"},{"location":"AI/Paper_Reading/Trick/Multimodality/modality_fusion.html","title":"Modality fusion","text":""},{"location":"AI/Paper_Reading/Trick/Multimodality/modality_fusion.html#modality-fusion","title":"Modality Fusion","text":""},{"location":"AI/Paper_Reading/Trick/Multimodality/modality_fusion.html#train","title":"train","text":"<ol> <li>\u200b\u591a\u6d41\u200b\u8f93\u5165\u200b<code>input_modality_i</code></li> <li>\u200b\u591a\u6d41\u200b\u8f93\u51fa\u200b<code>output_modality_i</code></li> <li>\u200b\u878d\u5408\u200b\u591a\u200b\u6a21\u6001\u200b<code>fusion=concat(modality_1, ..., modality_n)</code></li> <li>\\(\\mathcal{L} = \\sum \\mathcal{L}(output_{modality_i}) + \\mathcal{L}(fusion)\\)</li> </ol>"},{"location":"AI/Paper_Reading/Trick/Multimodality/modality_fusion.html#infer","title":"infer","text":"<ol> <li>\u200b\u591a\u6d41\u200b\u8f93\u5165\u200b<code>input_modality_i</code></li> <li>\u200b\u591a\u6d41\u200b\u8f93\u51fa\u200b<code>output_modality_i</code></li> <li>\u200b\u878d\u5408\u200b\u591a\u200b\u6a21\u6001\u200b<code>fusion=concat(modality_1, ..., modality_n)</code></li> <li><code>max(output_modality_i_prob, ..., fusion_prob)</code></li> </ol>"},{"location":"AI/Paper_Reading/Trick/Multimodality/modality_fusion.html#attentions","title":"Attentions","text":""},{"location":"AI/Paper_Reading/Trick/Multimodality/modality_fusion.html#embeddingstate-concat","title":"embedding/state concat","text":"<ol> <li> <p>embedding concat</p> <p>\u200b\u4e3a\u4e86\u200b\u66f4\u597d\u200b\u5730\u4f7f\u200b\u5404\u200b\u6a21\u6001\u200b\u5145\u5206\u200b\u878d\u5408\u200b\u4ea4\u7ec7\u200b\uff0c\u200b\u9009\u62e9\u200b\u5728\u200bembedding\u200b\u5c42\u200b\u8fdb\u884c\u200bconcat\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u6b64\u65f6\u200b\uff1a</p> <ul> <li>\u200b\u4ec5\u200b\u4fdd\u7559\u200b\u878d\u5408\u200b\u66f4\u4e3a\u200b\u5f7b\u5e95\u200b\u7684\u200bfusion\u200b\u4f5c\u4e3a\u200b\u4f18\u5316\u200b\u76ee\u6807\u200b\uff0c\u200b\u5373\u200b\\(\\mathcal{L}(fusion)\\)</li> </ul> </li> <li> <p>hidden_state concat</p> <p>\u200b\u4e00\u822c\u200b\u4e3a\u4e86\u200b\u5145\u5206\u200b\u5b66\u4e60\u200b\u597d\u200b\u5404\u200b\u6a21\u6001\u200b\u7684\u200bembedding\uff0c\u200b\u4f1a\u200b\u9009\u62e9\u200b\u5728\u200b\u6700\u540e\u200b\u7684\u200b\u6295\u5f71\u200b\u5c42\u200b\u8fdb\u884c\u200bconcat\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u6b64\u65f6\u200b\uff1a</p> <ul> <li>\u200b\u65e2\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200bfusion\u200b\u4f5c\u4e3a\u200b\u4f18\u5316\u200b\u76ee\u6807\u200b\uff0c\u200b\u5373\u200b\\(\\mathcal{L}(fusion)\\)</li> <li>\u200b\u53c8\u200b\u80fd\u200b\u4fdd\u7559\u200b\u5404\u200b\u6a21\u6001\u200b\u4f5c\u4e3a\u200b\u4f18\u5316\u200b\u76ee\u6807\u200b\uff0c\u200b\u5373\u200b\\(\\sum \\mathcal{L}(output_{modality_i})\\)</li> </ul> </li> </ol> <p>Info</p> <ol> <li>\u200b\u6700\u597d\u200b\u8fdb\u884c\u200b<code>concat</code>\u200b\u64cd\u4f5c\u200b\u800c\u200b\u4e0d\u662f\u200b\u7b80\u5355\u200b\u7684\u200b\u7ebf\u6027\u200b\u76f8\u52a0\u200b\uff0c\u200b\u540e\u8005\u200b\u4f1a\u200b\u968f\u7740\u200b\u975e\u7ebf\u6027\u200b\u64cd\u4f5c\u200b\u7684\u200b\u589e\u52a0\u200b\u800c\u200b\u6a21\u7cca\u200b\u5404\u200b\u6a21\u6001\u200b\u7684\u200b\u7279\u5f81\u200b\u533a\u522b\u200b\u5bfc\u81f4\u200b\u53d1\u6563\u200b\u3002</li> <li>\u200b\u5bf9\u4e8e\u200b\u76f4\u63a5\u200b\u8bad\u7ec3\u200b\u5c0f\u200b\u6a21\u578b\u200b\uff0c\u200b\u8bad\u7ec3\u200b\u6570\u636e\u200b\u8f83\u200b\u5c11\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u4e0d\u5b9c\u200b\u589e\u52a0\u200b\u8fc7\u591a\u200btrick\uff08\u200b\u5982\u200b\u591a\u5c42\u200bcnn+dropout\uff09\uff0c\u200b\u5bb9\u6613\u200b\u5bfc\u81f4\u200b\u53d1\u6563\u200b\u3002</li> </ol>"},{"location":"AI/Paper_Reading/Trick/Multimodality/shape_modality.html","title":"Shape modality","text":""},{"location":"AI/Paper_Reading/Trick/Multimodality/shape_modality.html#shape-modality","title":"Shape Modality","text":"<ul> <li>\u200b\u7b14\u753b\u200b\u62c6\u89e3\u200b</li> <li>\u200b\u4e0a\u4e0b\u200b\u7ed3\u6784\u200b\uff0c\u200b\u5de6\u53f3\u200b\u7ed3\u6784\u200b</li> </ul> <ol> <li>\u200b\u5b57\u5f62\u200bshape\u200b\u9700\u200b\u4e0e\u200btoken\u200b\u4e00\u4e00\u5bf9\u5e94\u200b\uff0cshape\u200b\u7f3a\u5931\u200b\u53ef\u200b\u76f4\u63a5\u200b\u7528\u200b\u7f3a\u7701\u200b\u72b6\u6001\u200b\uff08\u200b\u5982\u200bUNK\uff09\u200b\u66ff\u4ee3\u200b\uff08shape\u200b\u53ef\u200b\u72ec\u7acb\u200b\u4e3a\u200b\u4e00\u5f20\u200bembedding\u200b\u8868\u200b\uff09</li> </ol>"},{"location":"AI/Paper_Reading/Trick/Multimodality/sound_modality.html","title":"Sound modality","text":""},{"location":"AI/Paper_Reading/Trick/Multimodality/sound_modality.html#sound-modality","title":"Sound Modality","text":"<ol> <li>\u200b\u76f4\u63a5\u200b\u6574\u4f53\u200b\u5bf9\u5e94\u200b\u4e00\u4e2a\u200bembedding\uff0c[seq_len, dim]</li> <li>sound\u200b\u5e8f\u5217\u200b\uff0c[seq_len, K, dim]\uff0c\u200b\u4e00\u822c\u200bK\u22648</li> <li>\u200b\u7b2c\u200b2\u200b\u7ef4\u200b\u5206\u522b\u200b\u4e3a\u200b\u58f0\u6bcd\u200b\u3001\u200b\u97f5\u6bcd\u200b\u3001\u200b\u4ecb\u6bcd\u200b,\u200b\u5373\u200b [seq_len, 3, dim]\uff0c\u200b\u4e00\u822c\u200b\u901a\u8fc7\u200bCNN\u200b\u5b66\u4e60\u200b\u5f97\u5230\u200b\u4e00\u4e2a\u200b\u53e5\u200bsound\u200b\u5411\u91cf\u200b\u8868\u793a\u200b<code>flatter_embedding.shape=(seq_len, dim)</code>\uff0c<ul> <li>\u200b\u5f53\u200b\u6837\u672c\u6570\u200b\u591f\u200b\u591a\u200b\u65f6\u200b\uff0c\u200b\u53ef\u200b\u76f4\u63a5\u200b\u57fa\u4e8e\u200b\u8db3\u91cf\u200b\u6570\u636e\u200b\u5b66\u5230\u200b\u6cdb\u5316\u200b\u529f\u80fd\u200b\uff0c\u200b\u6b64\u65f6\u200b\u6548\u679c\u200b\u7b49\u540c\u4e8e\u200b\u65b9\u6cd5\u200b1\uff08sound\u200b\u6574\u4f53\u200b\u5bf9\u5e94\u200b\u4e00\u4e2a\u200bembedding\uff09</li> <li>\u200b\u5f53\u200b\u6837\u672c\u6570\u200b\u4e0d\u662f\u200b\u5f88\u591a\u200b\u65f6\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u8003\u8651\u200b\u4f7f\u7528\u200b\u8be5\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u901a\u8fc7\u200b\u62c6\u89e3\u200b\u5143\u7d20\u200b\u5b66\u5230\u200b\u6cdb\u5316\u200b\u6548\u679c\u200b\uff08\u200b\u4e24\u4e2a\u200b\u5b57\u200bpinyin\u200b\u5728\u200b\u67d0\u4e2a\u200b\u7f16\u8f91\u200b\u8ddd\u79bb\u200b\u5185\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\u8f83\u200b\u9ad8\u200b\uff09</li> </ul> </li> </ol> <ol> <li>\u200b\u4e0a\u8ff0\u200b\u65b9\u6cd5\u200b\u5747\u200b\u53ef\u200b\u6307\u5b9a\u200b\u662f\u5426\u200b\u5e26\u200b\u58f0\u8c03\u200b</li> <li>\u200b\u63d0\u524d\u200b\u83b7\u53d6\u200bpinyin\u200b\u6620\u5c04\u200b\u8868\u200b\uff0c\u200b\u591a\u97f3\u5b57\u200b\u53d6\u200b\u6700\u200b\u5e38\u7528\u200b\u7684\u200b\u90a3\u4e2a\u200b\u4ee5\u200b\u52a0\u5feb\u901f\u5ea6\u200b</li> <li>\u200b\u5b57\u97f3\u200bsound\u200b\u9700\u200b\u4e0e\u200btoken\u200b\u4e00\u4e00\u5bf9\u5e94\u200b\uff0csound\u200b\u7f3a\u5931\u200b\u53ef\u200b\u76f4\u63a5\u200b\u7528\u200btoken\u200b\u66ff\u4ee3\u200b\uff0c\u200b\u6bcf\u4e2a\u200btable\u200b\u4e92\u76f8\u200b\u72ec\u7acb\u200b\u4e14\u200b\u6700\u597d\u200b\u91c7\u7528\u200b\u76f8\u540c\u200bdim\uff0c\u200b\u5426\u5219\u200b\u6781\u5bb9\u6613\u200b\u53d1\u6563\u200b</li> <li>\u200b\u6700\u597d\u200b\u53ea\u200b\u5bf9\u200b\u6c49\u5b57\u200b\u3001\u200b\u6570\u5b57\u200b\u548c\u200b\u5b57\u6bcd\u200b\u8fdb\u884c\u200bpinyin\u200b\u5316\u200b\uff08\u200b\u5b57\u6bcd\u200b\u548c\u200b\u5355\u4e2a\u200b\u5b57\u6bcd\u200bpinyin\u200b\u9700\u8981\u200b\u8fdb\u884c\u200b\u533a\u5206\u200b\uff09</li> </ol>"},{"location":"AI/Paper_Reading/Trick/Multimodality/token_modality.html","title":"Token modality","text":""},{"location":"AI/Train_Overview/index.html","title":"\u8bad\u7ec3\u200b\u603b\u89c8","text":""},{"location":"AI/Train_Overview/index.html#pre-process","title":"Pre-process","text":"<p>\u200b\u7ecf\u5178\u200b\u7b97\u6cd5\u200b\u7ec6\u8282\u200b\u5904\u7406\u200b\uff1a</p> <ol> <li>\u200b\u6570\u5b57\u200b\u5f62\u5f0f\u200b\u5f52\u4e00\u5316\u200b\uff0c\u200b\u5982\u200b <code>\u2460 -&gt; \uff11</code></li> <li>\u200b\u7a7a\u767d\u200b\u5b57\u7b26\u200b\u5f52\u4e00\u5316\u200b\uff0c\u200b\u5982\u200b <code>[SPACE]</code> \u200b\u6216\u200b <code>\" \"</code><ul> <li>\u200b\u524d\u8005\u200b\u5728\u200b\u7a7a\u767d\u200b\u5b57\u7b26\u200b\u8868\u200b\u8bed\u4e49\u200b\u65f6\u200b\u4f7f\u7528\u200b\uff0c\u200b\u540e\u8005\u200b\u5728\u200b\u7a7a\u767d\u200b\u5b57\u7b26\u200b\u65e0\u200b\u8bed\u4e49\u200b\u65f6\u200b\u4f7f\u7528\u200b</li> </ul> </li> <li>emoji\u200b\u5904\u7406\u200b\uff0c\u200b\u5982\u200b\u6b63\u5411\u200b <code>\ud83d\ude42 -&gt; [\u200b\u5fae\u7b11\u200b]</code> \u200b\u6216\u200b\u9006\u5411\u200b <code>[\u200b\u5fae\u7b11\u200b] -&gt; \ud83d\ude42</code><ul> <li>\u200b\u524d\u8005\u200b\u76f4\u63a5\u200b\u89e3\u6790\u200bemoji\uff0c\u200b\u540e\u8005\u200b\u57fa\u4e8e\u200b<code>emoji_embedding</code></li> </ul> </li> <li>\u200b\u5b57\u7b26\u200b\u4e0a\u4e0b\u200b\u6807\u200b\u53bb\u9664\u200b\uff1a\u200b\u5982\u200b BasicTokenizer._run_strip_accents</li> </ol>"},{"location":"AI/Train_Overview/index.html#data-augmentation","title":"Data Augmentation","text":""},{"location":"AI/Train_Overview/index.html#tokenization","title":"Tokenization","text":"<ul> <li>char-tokenization: \u200b\u53ef\u8f83\u200b\u597d\u200b\u5730\u200b\u9002\u5e94\u200b\u53d8\u79cd\u200b\u8868\u8ff0\u200b\u65b9\u5f0f\u200b</li> </ul> <ol> <li>sound_modality\uff1a\u200b\u4e3a\u200b\u9632\u6b62\u200b\u53d1\u6563\u200b\uff0c\u200b\u65e0\u6cd5\u200b\u83b7\u53d6\u200b\u62fc\u97f3\u200b\u7684\u200btoken\u200b\u5e94\u200b\u4fdd\u7559\u200b\u539f\u503c\u200b</li> <li> \u200b\u7531\u4e8e\u200b <code>pad_to_max_length</code> \u200b\u662f\u200b\u7ed9\u200b\u6240\u6709\u200b\u77ed\u200b\u7684\u200b\u90e8\u5206\u200b\u7528\u200b0\u200b\u586b\u5145\u200b\uff08\u200b\u56e0\u6b64\u200b\u8bcd\u8868\u200b0-th\u200b\u8bcd\u200b\u4e00\u822c\u200b\u4e3a\u200b[PAD]\uff09\uff0c\u200b\u4e3a\u200b\u9632\u6b62\u200b\u4e0d\u540c\u200b\u6a21\u6001\u200b\u7684\u200b[PAD]\u200b\u5b57\u7b26\u200b\u8bed\u4e49\u200b\u6df7\u6dc6\u200b\uff0c\u200b\u5404\u200b\u6a21\u6001\u200b\u7684\u200b\u8bcd\u8868\u200b\u548c\u200bembedding_table\u200b\u5e94\u200b\u4e92\u76f8\u200b\u72ec\u7acb\u200b</li> <li>\u200b\u5904\u7406\u200b\u4efb\u610f\u200b\u957f\u5ea6\u200b\u6837\u672c\u200b\uff1a\u200b\u4e0d\u200b\u5728\u200b\u5206\u8bcd\u200b\u9636\u6bb5\u200b(\u200b\u524d\u200b\u5411\u200b\u6216\u200b\u540e\u200b\u5411\u200b)\u200b\u622a\u65ad\u200b\u8fc7\u957f\u200b\u5b57\u7b26\u4e32\u200b\uff0c\u200b\u800c\u662f\u200b\u6574\u4f53\u200btokenization\u200b\u5e76\u200b\u8f93\u5165\u200b\uff0c\u200b\u53ea\u200b\u901a\u8fc7\u200b\u8fc7\u6ee4\u200b\u903b\u8f91\u200b\u63a7\u5236\u200b\u8f93\u5165\u200b\u6837\u672c\u200b\u957f\u5ea6\u200b</li> <li>shape_modality</li> </ol>"},{"location":"AI/Train_Overview/index.html#embedding","title":"Embedding","text":""},{"location":"AI/Train_Overview/index.html#ensemble-moe","title":"Ensemble &amp; MoE","text":""},{"location":"AI/Train_Overview/index.html#distillation","title":"Distillation","text":""},{"location":"MISC/Car/index.html","title":"\u8f66","text":""},{"location":"MISC/Car/index.html#_1","title":"\u57fa\u672c\u6982\u5ff5","text":""},{"location":"MISC/Car/index.html#_2","title":"\u8f66\u8f86\u200b\u63a7\u5236","text":"<ol> <li><code>AH (Auto Hold)</code>\uff0c\u200b\u81ea\u52a8\u200b\u9a7b\u8f66\u200b\uff0c\u200b\u6c7d\u8f66\u200b\u505c\u200b\u7a33\u540e\u200b\u6c7d\u8f66\u200b\u81ea\u52a8\u200b\u5239\u8f66\u200b\uff0c\u200b\u4e14\u200b\u62ac\u8d77\u200b\u5239\u8f66\u200b\u540e\u200b\u4ecd\u200b\u80fd\u200b\u7ef4\u6301\u200b\u9a7b\u8f66\u200b\u72b6\u6001\u200b</li> <li><code>SST (Stop &amp; Start)</code>\uff0c\u200b\u81ea\u52a8\u200b\u542f\u505c\u200b\uff0c\u200b\u5728\u200b\u8f66\u8f86\u200b\u884c\u9a76\u200b\u8fc7\u7a0b\u200b\u4e2d\u200b\u4e34\u65f6\u200b\u505c\u8f66\u200b(\u200b\u4f8b\u5982\u200b\u7b49\u200b\u7ea2\u706f\u200b)\u200b\u7684\u200b\u65f6\u5019\u200b\uff0c\u200b\u81ea\u52a8\u200b\u7184\u706b\u200b\uff1b\u200b\u5f53\u200b\u9700\u8981\u200b\u7ee7\u7eed\u524d\u8fdb\u200b\u7684\u200b\u65f6\u5019\u200b\uff0c\u200b\u7cfb\u7edf\u200b\u81ea\u52a8\u200b\u91cd\u542f\u200b\u53d1\u52a8\u673a\u200b <p>\u200b\u81ea\u52a8\u200b\u9a7b\u8f66\u200b\u901a\u8fc7\u200b\u5239\u8f66\u200b\u505c\u6b62\u200b\uff0c\u200b\u81ea\u52a8\u200b\u542f\u505c\u200b\u901a\u8fc7\u200b\u7184\u706b\u200b\u505c\u6b62\u200b</p> </li> <li><code>CCS (Cruise Control System)</code>\uff0c\u200b\u5b9a\u901f\u5de1\u822a\u200b\uff0c\u200b\u6c7d\u8f66\u200b\u8bbe\u7f6e\u200b\u56fa\u5b9a\u200b\u65f6\u901f\u200b\u884c\u9a76\u200b <p>\u200b\u8e29\u200b\u5239\u8f66\u200b\u4f1a\u200b\u53d6\u6d88\u200b\u5b9a\u901f\u200b\u5faa\u73af\u200b\uff1b\u200b\u8e29\u6cb9\u95e8\u200b\u4f1a\u200b\u52a0\u901f\u200b\uff0c\u200b\u677e\u5f00\u200b\u540e\u200b(\u200b\u4e0d\u4f1a\u200b\u53d6\u6d88\u200b)\u200b\u4f1a\u200b\u56de\u5230\u200b\u5b9a\u901f\u5de1\u822a\u200b\u8bbe\u5b9a\u200b\u65f6\u901f\u200b</p> </li> <li><code>ACC(Adaptive Cruise Control)</code>\uff0c\u200b\u81ea\u200b\u9002\u5e94\u200b\u5b9a\u901f\u5de1\u822a\u200b\u63a7\u5236\u200b\uff0c\u200b\u5982\u679c\u200b\u8f66\u8f86\u200b\u524d\u65b9\u200b\u7545\u901a\u200b\uff0c\u200b\u81ea\u200b\u9002\u5e94\u200b\u5de1\u822a\u200b\uff08ACC\uff09\u200b\u5c06\u200b\u4fdd\u6301\u200b\u8bbe\u5b9a\u200b\u7684\u200b\u6700\u5927\u200b\u5de1\u822a\u901f\u5ea6\u200b\u5411\u524d\u884c\u9a76\u200b\u3002\u200b\u5982\u679c\u200b\u68c0\u6d4b\u200b\u5230\u200b\u524d\u65b9\u200b\u6709\u200b\u8f66\u8f86\u200b\uff0c\u200b\u81ea\u200b\u9002\u5e94\u200b\u5de1\u822a\u200b\uff08ACC\uff09 \u200b\u5c06\u200b\u6839\u636e\u200b\u9700\u8981\u200b\u964d\u4f4e\u200b\u8f66\u901f\u200b\uff0c\u200b\u4e0e\u200b\u524d\u8f66\u200b\u4fdd\u6301\u200b\u57fa\u4e8e\u200b\u9009\u5b9a\u200b\u65f6\u95f4\u200b\u7684\u200b\u8ddd\u79bb\u200b\uff0c\u200b\u76f4\u5230\u200b\u8fbe\u5230\u200b\u5408\u9002\u200b\u7684\u200b\u5de1\u822a\u901f\u5ea6\u200b\u3002 <p>\u200b\u4e0e\u200b\u5b9a\u901f\u5de1\u822a\u200b\u76f8\u6bd4\u200b\u662f\u200b\u80fd\u591f\u200b\u81ea\u52a8\u63a7\u5236\u200b\u65f6\u901f\u200b\u4e0e\u200b\u884c\u9a76\u200b\u73af\u5883\u200b\u4fdd\u6301\u200b\u5b89\u5168\u200b\u8f66\u8ddd\u200b</p> </li> <li><code>AEB (Autonomous Emergency Braking)</code>\uff0c\u200b\u81ea\u52a8\u200b\u7d27\u6025\u200b\u5239\u8f66\u200b\u7cfb\u7edf\u200b</li> </ol>"},{"location":"MISC/Car/index.html#_3","title":"\u5b9e\u7528\u529f\u80fd","text":"<ol> <li><code>\u200b\u8f66\u7a97\u200b\u5347\u964d\u200b</code>\uff0c\u200b\u9065\u63a7\u200b\u81ea\u52a8\u200b\u964d\u7a97\u200b\uff0c\u200b\u9501\u8f66\u200b\u6216\u200b\u9065\u63a7\u200b\u81ea\u52a8\u200b\u5347\u7a97\u200b <p>\u200b\u6ca1\u6709\u200b\u7535\u52a8\u8f66\u7a97\u200b\u9632\u5939\u200b\u4e0d\u4f1a\u200b\u914d\u5907\u200b\u9501\u8f66\u200b\u81ea\u52a8\u200b\u5347\u7a97\u200b\u529f\u80fd\u200b\uff0c\u200b\u53ef\u200b\u901a\u8fc7\u200b\u5b89\u88c5\u200bOBD\u200b\u81ea\u52a8\u200b\u5347\u200b\u7a97\u5668\u200b\u5b9e\u73b0\u200b</p> </li> <li><code>\u200b\u7535\u52a8\u200b\u5c3e\u95e8\u200b</code>\uff0c\u200b\u901a\u8fc7\u200b\u89e6\u51fb\u200b\u540e\u5907\u7bb1\u200b\u95e8\u200b\u7684\u200b\u7535\u52a8\u200b\u6309\u94ae\u200b\uff0c\u200b\u81ea\u884c\u200b\u5173\u95ed\u200b/\u200b\u5f00\u542f\u200b\u540e\u5907\u7bb1\u200b\u95e8\u200b\uff0c\u200b\u8fc7\u7a0b\u200b\u65e0\u9700\u200b\u4eba\u529b\u200b\u4ecb\u5165\u200b\u3002\u200b\u82e5\u200b\u65e0\u200b\u7535\u52a8\u200b\u5c3e\u95e8\u200b\uff0c\u200b\u4e14\u200b\u540e\u5907\u7bb1\u200b\u53ea\u200b\u6253\u5f00\u200b\u4e0d\u200b\u81ea\u52a8\u200b\u5f39\u8d77\u200b\uff0c\u200b\u53ef\u200b\u901a\u8fc7\u200b\u4ee5\u4e0b\u200b\u65b9\u5f0f\u200b\u8fdb\u884c\u200b\u5b9e\u73b0\u200b\u81ea\u52a8\u200b\u5f00\u5c3e\u200b\u7bb1\u95e8\u200b\uff1a<ul> <li>\u200b\u52a0\u88c5\u200b\u6db2\u538b\u200b\u6746\u200b</li> <li>\u200b\u52a0\u88c5\u200b\u5f39\u7c27\u200b</li> <li>\u200b\u540e\u5907\u7bb1\u200b\u5de6\u53f3\u200b\u5185\u4fa7\u200b\u80f6\u6761\u200b\u5185\u6709\u200b\u5f39\u7c27\u200b\uff0c\u200b\u901a\u8fc7\u200b\u8c03\u8282\u200b\u5f39\u7c27\u200b\u6302\u5b54\u200b\u4f4d\u7f6e\u200b\uff0c\u200b\u6539\u53d8\u200b\u540e\u5907\u7bb1\u200b\u5f39\u7c27\u200b\u62c9\u529b\u200b\u5b9e\u73b0\u200b\u81ea\u52a8\u200b\u5f39\u8d77\u200b</li> </ul> </li> <li><code>\u200b\u540e\u89c6\u955c\u200b\u4e0b\u7ffb\u200b</code></li> <li><code>\u200b\u8f66\u200b\u5185\u200b\u540e\u89c6\u955c\u200b\u9632\u7729\u76ee\u200b</code></li> </ol>"},{"location":"MISC/Car/index.html#_4","title":"\u8bb0\u5fc6\u200b\u529f\u80fd","text":"<ol> <li><code>\u200b\u5ea7\u6905\u200b\u8bb0\u5fc6\u200b</code></li> <li><code>\u200b\u8f66\u200b\u5916\u200b\u540e\u89c6\u955c\u200b\u8bb0\u5fc6\u200b</code></li> </ol>"},{"location":"MISC/Car/index.html#_5","title":"\u65b0\u80fd\u6e90","text":"<ol> <li><code>\u200b\u4e09\u7535\u200b</code>\uff1a\u200b\u7535\u673a\u200b\u3001\u200b\u7535\u63a7\u200b\u4ee5\u53ca\u200b\u7535\u6c60\u200b</li> <li>\u200b\u9664\u7eaf\u200b\u7535\u8f66\u200b\u5916\u200b\uff0c\u200b\u8fd8\u200b\u5177\u6709\u200b\u4ee5\u4e0b\u200b\u6df7\u52a8\u200b\u65b9\u5f0f\u200b<ul> <li><code>\u200b\u6cb9\u7535\u200b\u6df7\u52a8\u200b(HEV, Hybrid Electric Vehicle)</code>\uff0c\u200b\u53d1\u52a8\u673a\u200b + \u200b\u7535\u673a\u200b\uff0c\u200b\u540e\u8005\u200b\u901a\u8fc7\u200b\u71c3\u6cb9\u200b\u53d1\u7535\u200b\u8fdb\u884c\u200b\u9a71\u52a8\u200b\uff0c\u200b\u4e0d\u80fd\u200b\u5145\u7535\u200b\uff0c\u200b\u4e0d\u80fd\u200b\u4e0a\u200b\u84dd\u724c\u200b</li> <li><code>\u200b\u63d2\u7535\u200b\u6df7\u52a8\u200b(PHEV, Plug-in Hybrid Electric Vehicle)</code>\uff0c\u200b\u53d1\u52a8\u673a\u200b + \u200b\u7535\u673a\u200b\uff0c\u200b\u540e\u8005\u200b\u53ef\u5145\u7535\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u200b\u5728\u200b\u4e8f\u7535\u200b\u72b6\u6001\u200b\u4e0b\u200b\u53ef\u200b\u901a\u8fc7\u200b\u70e7\u6cb9\u200b\u53d1\u7535\u200b\u9a71\u52a8\u200b</li> <li><code>\u200b\u589e\u200b\u7a0b\u5f0f\u200b\u6df7\u52a8\u200b(RREV, Range Extended Electric Vehicle)</code>\uff0c\u200b\u53d1\u52a8\u673a\u200b + \u200b\u7535\u673a\u200b\uff0c\u200b\u540e\u8005\u200b\u53ef\u5145\u7535\u200b\uff0c\u200b\u53d1\u52a8\u673a\u200b\u4e0d\u200b\u9a71\u52a8\u200b\u8f66\u8f86\u200b\u53ea\u200b\u7528\u4e8e\u200b\u71c3\u70e7\u200b\u53d1\u7535\u200b\u3002\u200b\u548c\u200b\u6cb9\u7535\u200b\u6df7\u52a8\u200b\u7684\u200b\u533a\u522b\u200b\u5728\u4e8e\u200b\u80fd\u591f\u200b\u5145\u7535\u200b\u4e14\u200b\u53d1\u52a8\u673a\u200b\u4e0d\u80fd\u200b\u5355\u72ec\u200b\u9a71\u52a8\u200b\u6c7d\u8f66\u200b</li> </ul> </li> </ol>"},{"location":"MISC/Car/index.html#_6","title":"\u6cb9\u8f66","text":"<ol> <li><code>\u200b\u4e09\u200b\u5927\u4ef6\u200b</code>\uff1a\u200b\u53d1\u52a8\u673a\u200b\u3001\u3001\u200b\u53d8\u901f\u7bb1\u200b\u4ee5\u53ca\u200b\u5730\u76d8\u200b</li> </ol>"},{"location":"MISC/Chess_Cards/Cards.html","title":"\u724c","text":""},{"location":"MISC/Chess_Cards/Cards.html#_1","title":"\u8fc7\u70b8","text":"<ol> <li>\u200b\u5956\u200b\u4e2a\u6570\u200b = \u200b\u666e\u901a\u200b\u5956\u200b + \u200b\u738b\u5956\u200b + \u200b\u7eaf\u8272\u200b\u738b\u5956\u200b<ul> <li>\u200b\u666e\u901a\u200b\u5956\u200b\uff1a\\(\\Sigma_i (x_i - 6),\\enspace\\small{\\#}x_i \\ge 7\\)</li> <li>\u200b\u738b\u5956\u200b\uff1a\\((x_b + x_s - 3),\\enspace\\small{\\#}x_b + \\#x_s \\ge 3\\)</li> <li>\u200b\u7eaf\u8272\u200b\u738b\u5956\u200b\uff1a\\(\\Sigma_i (2\\times x_i-5),\\enspace\\small{\\#}x_i \\ge 3\\)</li> </ul> </li> <li>\u200b\u8fdb\u5956\u6570\u200b\uff1a\\((1 + \\text{int}(\u200b\u5956\u200b_i \u2265 \\text{N})) * \u200b\u5956\u200b_i \\times \\text{K} - \\Sigma_i{\u200b\u5956\u200b_i}\\)</li> <li>\u200b\u5206\u200b</li> </ol>"},{"location":"MISC/Chess_Cards/Cards.html#_2","title":"\u5fb7\u5dde\u200b\u6251\u514b","text":""},{"location":"MISC/Chess_Cards/Chess.html","title":"\u68cb","text":""},{"location":"MISC/Chess_Cards/Mahjong.html","title":"\u9ebb\u5c06","text":""},{"location":"MISC/Chess_Cards/PaiGow.html","title":"\u724c\u4e5d","text":""},{"location":"MISC/Clothes/index.html","title":"\u8863\u670d","text":""},{"location":"MISC/Clothes/index.html#_1","title":"\u670d\u88c5\u9762\u6599","text":""},{"location":"MISC/Clothes/index.html#_2","title":"\u5929\u7136\u7ea4\u7ef4","text":"<p>\u200b\u5438\u6e7f\u200b\u900f\u6c14\u200b\u3001\u200b\u6ca1\u6709\u200b\u9759\u7535\u200b\u3001\u200b\u6709\u200b\u81ea\u7136\u200b\u5149\u6cfd\u200b\u4e14\u200b\u6bd4\u8f83\u200b\u67d4\u7136\u200b\uff0c\u200b\u4f46\u200b\u5177\u6709\u200b\u6613\u76b1\u200b\u3001\u200b\u6613\u200b\u7f29\u6c34\u200b\u4ee5\u53ca\u200b\u8272\u200b\u7262\u5ea6\u200b\u4f4e\u7b49\u200b\u7f3a\u70b9\u200b</p> <ul> <li>\u200b\u68c9\u200b</li> <li>\u200b\u9ebb\u200b</li> <li>\u200b\u7f8a\u6bdb\u200b\uff1a\u200b\u526a\u200b\u7ef5\u7f8a\u6bdb\u200b</li> <li>\u200b\u7f8a\u7ed2\u200b\uff1a\u200b\u68b3\u5c71\u200b\u7f8a\u6bdb\u200b\uff0c\u200b\u5f88\u200b\u7a00\u6709\u200b</li> <li>\u200b\u8695\u4e1d\u200b</li> </ul>"},{"location":"MISC/Clothes/index.html#_3","title":"\u518d\u751f\u200b\u7ea4\u7ef4\u7d20\u200b\u7ea4\u7ef4","text":"<p>\u200b\u4ece\u200b\u5929\u7136\u7ea4\u7ef4\u200b\u4e2d\u200b\u5316\u5b66\u200b\u5206\u7406\u200b\u51fa\u200b\u690d\u7269\u200b\u7ea4\u7ef4\u7d20\u200b\uff0c\u200b\u7136\u540e\u200b\u518d\u200b\u5408\u6210\u200b\u7684\u200b\u7ea4\u7ef4\u200b\uff0c\u200b\u4e3b\u8981\u200b\u539f\u6599\u200b\u662f\u200b\u68c9\u82b1\u200b\u548c\u200b\u6728\u6d46\u200b\u3002\u200b\u4e0d\u6613\u200b\u8d77\u200b\u9759\u7535\u200b\u3001\u200b\u5438\u6e7f\u200b\u900f\u6c14\u200b\u3001\u200b\u4eb2\u80a4\u200b\u67d4\u8f6f\u200b\u3001\u200b\u73af\u4fdd\u200b\u53ef\u964d\u89e3\u200b\u3001\u200b\u6bd4\u200b\u5929\u7136\u7ea4\u7ef4\u200b\u8272\u200b\u7262\u5ea6\u200b\u9ad8\u200b\uff0c\u200b\u4f46\u200b\u4f46\u200b\u9047\u6c34\u4f1a\u200b\u53d8\u786c\u200b\uff0c\u200b\u5f3a\u529b\u200b\u62c9\u626f\u200b\u6613\u200b\u7834\u635f\u200b</p>"},{"location":"MISC/Clothes/index.html#_4","title":"\u5316\u5b66\u200b\u5408\u6210\u7ea4\u7ef4","text":"<p>\u200b\u4e3b\u8981\u200b\u539f\u6599\u200b\u662f\u200b\u77f3\u6cb9\u200b\uff0c\u200b\u5171\u540c\u200b\u7f3a\u70b9\u200b\u662f\u200b\u6613\u200b\u4ea7\u751f\u200b\u9759\u7535\u200b\uff0c\u200b\u900f\u6c14\u6027\u200b\u548c\u200b\u5438\u6e7f\u6027\u200b\u8f83\u5dee\u200b</p> <ul> <li>\u200b\u6da4\u7eb6\u200b\uff0c \u200b\u805a\u916f\u7ea4\u7ef4\u200b\u7684\u200b\u4e00\u79cd\u200b\u5178\u578b\u200b\u4ee3\u8868\u200b\uff0c\u200b\u6297\u76b1\u200b</li> <li>\u200b\u6c28\u7eb6\u200b\uff0c\u200b\u5f39\u6027\u200b\uff0c\u200b\u5047\u200b\u7684\u200b\u8d8a\u200b\u591a\u200b\u5f39\u529b\u200b\u8d8a\u200b\u6301\u4e45\u200b\uff08\u200b\u4e0d\u80fd\u200b\u7528\u200b84\u200b\u6f02\u767d\u200b\uff0c\u200b\u5426\u5219\u200b\u5f39\u529b\u200b\u7acb\u9a6c\u200b\u4e0b\u964d\u200b\u53d8\u200b\u677e\u57ae\u200b\uff09</li> <li>\u200b\u9526\u7eb6\u200b\uff0c\u200b\u4e5f\u200b\u53eb\u200b\u5c3c\u9f99\u200b\uff08Nylon\uff09\uff0c\u200b\u4ef7\u683c\u200b\u4e3a\u200b\u6da4\u7eb6\u200b\u7684\u200b3x\u200b\u500d\u200b\uff0c\u200b\u8010\u78e8\u200b\uff0c\u200b\u4e14\u200b\u6e7f\u6c34\u200b\u66f4\u52a0\u200b\u575a\u97e7\u200b\uff0c\u200b\u5e38\u7528\u200b\u4e8e\u200b\u505a\u200b\u51b2\u950b\u8863\u200b\u3001\u200b\u7fbd\u7ed2\u670d\u200b\u548c\u200b\u9632\u6652\u200b\u670d\u200b</li> <li>\u200b\u8148\u7eb6\u200b\uff0c\u200b\u53f7\u79f0\u200b\u4eba\u9020\u200b\u7f8a\u6bdb\u200b\uff0c\u200b\u4fdd\u6696\u6027\u200b\u597d\u200b\uff0c\u200b\u57fa\u672c\u200b\u51fa\u73b0\u200b\u5728\u200b\u51ac\u8863\u200b\u3001\u200b\u6bdb\u8863\u200b\u6216\u200b\u5185\u8863\u200b\u4e0a\u200b</li> </ul>"},{"location":"MISC/Shoe/index.html","title":"\u978b\u5b50","text":""},{"location":"MISC/Shoe/index.html#_1","title":"\u4f11\u95f2\u978b","text":""},{"location":"MISC/Shoe/index.html#_2","title":"\u6930\u5b50\u200b\u978b","text":""},{"location":"MISC/Shoe/index.html#_3","title":"\u8001\u7239\u200b\u978b","text":""},{"location":"MISC/Shoe/index.html#_4","title":"\u8fd0\u52a8\u978b","text":""},{"location":"MISC/Shoe/index.html#_5","title":"\u7bee\u7403\u978b","text":""},{"location":"MISC/Shoe/index.html#_6","title":"\u8dd1\u6b65\u200b\u978b","text":""},{"location":"MISC/Shoe/index.html#_7","title":"\u76ae\u978b","text":""},{"location":"MISC/Wine/index.html","title":"\u9152","text":""},{"location":"MISC/Wine/index.html#_1","title":"\u57fa\u672c\u6982\u5ff5","text":"<ul> <li><code>Vol.</code>\uff1avolumn\u200b\u7684\u200b\u7b80\u79f0\u200b\uff0c\u200b\u5373\u200b\u9152\u7cbe\u200b\u6d53\u5ea6\u200b(\u200b\u4f53\u79ef\u200b\u767e\u5206\u6bd4\u200b)\uff0c\u200b\u5e38\u7528\u200b\u4f5c\u200b\u8868\u793a\u200b\u767d\u9152\u200b\u4e2d\u200b\u9152\u7cbe\u200b\u6d53\u5ea6\u200b\uff0c\u200b\u5e38\u89c1\u200b\u5564\u9152\u200b\u9152\u7cbe\u200b\u6d53\u5ea6\u200b\u4e00\u822c\u200b\u4e3a\u200b2.5%vol~7.5%vol <p>\u200b\u6807\u51c6\u200b\u6765\u8bb2\u200b\uff0c\u200b\u5728\u200b20\u2103\u200b\u6761\u4ef6\u200b\u4e0b\u200b\uff0c\u200b\u6bcf\u767e\u200b\u6beb\u5347\u200b\u9152\u6db2\u200b\u4e2d\u200b\u6240\u200b\u542b\u200b\u591a\u5c11\u200b\u6beb\u5347\u200b\u9152\u7cbe\u200b(\u200b\u4e59\u9187\u200b)</p> </li> <li><code>proof</code>\uff1a\u200b\u9152\u7cbe\u200b\u7eaf\u5ea6\u200b\uff0c\u200b\u7f8e\u5236\u200b\u9152\u5ea6\u200b\u7684\u200b\u8868\u793a\u200b\uff0c\u200b\u4e00\u4e2a\u200b\u9152\u7cbe\u200b\u7eaf\u5ea6\u200b\u76f8\u5f53\u4e8e\u200b0.5%\u200b\u4e2a\u200b\u9152\u7cbe\u200b\u6d53\u5ea6\u200b\uff0c\u200b\u5982\u200b 80 proof = 40% Vol</li> <li><code>\u00b0P</code>\uff1a\u200b\u9ea6\u82bd\u200b\u6c41\u200b\u6d53\u5ea6\u200b\uff0c\u200b\u4e00\u822c\u200b\u7528\u4e8e\u200b\u8868\u793a\u200b\u5564\u9152\u200b\u9ea6\u82bd\u200b\u6c41\u200b\u6d53\u5ea6\u200b<ul> <li>6\u00b0P \u2014 8\u00b0P\uff0c\u200b\u9152\u7cbe\u200b\u6d53\u5ea6\u200b~2% Vol.\uff0c\u200b\u4f4e\u7aef\u200b\u5564\u9152\u200b</li> <li>8\u00b0P \u2014 12\u00b0P\uff0c\u200b\u9152\u7cbe\u200b\u6d53\u5ea6\u200b~3.5% Vol.\uff0c\u200b\u4e2d\u200b\u9ad8\u7aef\u200b\u5564\u9152\u200b</li> <li>12\u00b0P \u2014 20\u00b0P\uff0c\u200b\u9152\u7cbe\u200b\u6d53\u5ea6\u200b~5% Vol.\uff0c\u200b\u9ad8\u7ea7\u200b\u5564\u9152\u200b</li> </ul> </li> </ul>"},{"location":"MISC/Wine/index.html#_2","title":"\u5564\u9152","text":""},{"location":"MISC/Wine/index.html#_3","title":"\u539f\u6599","text":"<p>\u200b\u597d\u200b\u7684\u200b\u5564\u9152\u200b\u4e00\u822c\u200b\u53ea\u542b\u200b<code>\u200b\u6c34\u200b</code>\u3001<code>(\u200b\u5927\u9ea6\u200b/\u200b\u5c0f\u9ea6\u200b)\u200b\u9ea6\u82bd\u200b</code>\u3001<code>\u200b\u5564\u9152\u82b1\u200b</code>(\u200b\u63d0\u4f9b\u200b\u82e6\u5473\u200b\u548c\u200b\u9999\u5473\u200b\uff0c\u200b\u5e76\u200b\u6291\u5236\u200b\u5564\u9152\u200b\u4e2d\u200b\u7684\u200b\u7ec6\u83cc\u200b\u751f\u957f\u200b) \u200b\u548c\u200b <code>\u200b\u9175\u6bcd\u200b</code>\uff0c\u200b\u8fd0\u7528\u200b\u4ee5\u4e0b\u200b\u6750\u6599\u200b\u917f\u9020\u200b\u7684\u200b\u4e00\u5b9a\u200b\u7a0b\u5ea6\u200b\u4e0a\u200b\u4e0d\u7b97\u200b\u201c\u200b\u597d\u200b\u5564\u9152\u200b\u201d\uff1a</p> <ul> <li>\u200b\u7389\u7c73\u200b\u3001\u200b\u5927\u7c73\u200b\u3001\u200b\u6dc0\u7c89\u200b\uff1a\u200b\u5ec9\u4ef7\u200b\u7684\u200b\u539f\u6750\u6599\u200b\uff0c\u200b\u53d1\u9175\u200b\u65f6\u95f4\u200b\u8f83\u200b\u77ed\u200b\uff0c\u200b\u7f3a\u5c11\u200b\u9152\u200b\u9999\u5473\u200b</li> <li>\u200b\u7cd6\u6d46\u200b\u3001\u200b\u9999\u7cbe\u200b\uff1a\u200b\u6dfb\u52a0\u5242\u200b\uff0c\u200b\u8c03\u5473\u54c1\u200b</li> <li>\u200b\u9152\u82b1\u200b\u6d78\u818f\u200b\u3001\u200b\u5564\u9152\u82b1\u200b\u5236\u54c1\u200b\uff1a\u200b\u4e3a\u200b\u5229\u4e8e\u200b\u8fd0\u8f93\u200b\u548c\u200b\u5b58\u50a8\u200b\u800c\u200b\u52a0\u5de5\u200b\u7684\u200b\u5564\u9152\u82b1\u200b\u63d0\u53d6\u7269\u200b\uff0c\u200b\u4f46\u200b\u7531\u4e8e\u200b\u4e0d\u662f\u200b\u751f\u200b\u9c9c\u54c1\u200b\u4f1a\u200b\u4e00\u5b9a\u200b\u7a0b\u5ea6\u200b\u4e0a\u200b\u51cf\u5c11\u200b\u5564\u9152\u200b\u7684\u200b\u9999\u5473\u200b\uff0c\u200b\u540c\u65f6\u200b\u8fd8\u6709\u200b\u53ef\u80fd\u200b\u7531\u4e8e\u200b\u67d0\u4e9b\u200b\u52a0\u5de5\u200b\u73af\u5883\u200b\u4e0d\u5f53\u200b\u800c\u200b\u53c2\u6742\u200b\u90e8\u5206\u200b\u6709\u5bb3\u200b\u6210\u5206\u200b</li> </ul>"},{"location":"MISC/Wine/index.html#_4","title":"\u53e3\u5473","text":"<ol> <li>\u200b\u9ec4\u5564\u200b\uff1a\u200b\u9ec4\u8272\u200b\uff0c\u200b\u989c\u8272\u200b\u900f\u660e\u200b</li> <li>\u200b\u767d\u200b\u5564\u200b\uff1a\u200b\u6de1\u9ec4\u8272\u200b\uff0c\u200b\u989c\u8272\u200b\u4e0d\u200b\u900f\u660e\u200b</li> <li>\u200b\u9ed1\u5564\u200b\uff1a\u200b\u9ed1\u8272\u200b</li> </ol>"},{"location":"MISC/Wine/index.html#_5","title":"\u54c1\u724c","text":"<ol> <li>\u200b\u767e\u5a01\u200b</li> <li>\u200b\u9752\u5c9b\u200b</li> <li>\u200b\u96ea\u82b1\u200b</li> <li>(\u200b\u5fb7\u56fd\u200b\u6155\u5c3c\u9ed1\u200b)\u200b\u67cf\u9f99\u200b<ul> <li><code>\u200b\u4fdd\u200b\u62c9\u7eb3\u200b(Paulaner)</code></li> </ul> </li> <li>\u200b\u559c\u529b\u200b</li> <li>\u200b\u96ea\u6d25\u200b</li> </ol>"},{"location":"MISC/Wine/index.html#_6","title":"\u767d\u9152","text":""},{"location":"MISC/Wine/index.html#_7","title":"\u57fa\u672c\u6982\u5ff5","text":"<ol> <li>\u200b\u66f2\u200b\uff1a\u200b\u4e5f\u200b\u79f0\u4f5c\u200b\u201c\u200b\u7cd6\u5316\u200b\u53d1\u9175\u5242\u200b\u201d\uff0c\u200b\u5728\u200b\u767d\u9152\u200b\u917f\u9020\u200b\u8fc7\u7a0b\u200b\u4e2d\u4e3a\u200b\u5fae\u751f\u7269\u200b\u63d0\u4f9b\u200b\u751f\u957f\u200b\u73af\u5883\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u5fae\u751f\u7269\u200b\u80fd\u591f\u200b\u901a\u8fc7\u200b\u5206\u6ccc\u200b\u5404\u79cd\u200b\u9176\u200b\uff08\u200b\u5982\u200b\u6dc0\u7c89\u9176\u200b\u3001\u200b\u7cd6\u5316\u9176\u200b\u548c\u200b\u86cb\u767d\u9176\u200b\uff09\u200b\u6765\u200b\u4fc3\u8fdb\u200b\u7cae\u98df\u200b\u4e2d\u200b\u7684\u200b\u6dc0\u7c89\u200b\u3001\u200b\u86cb\u767d\u8d28\u200b\u7b49\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u7cd6\u5206\u200b\uff0c\u200b\u8fdb\u800c\u200b\u8f6c\u5316\u6210\u200b\u4e59\u9187\u200b\u3002</li> </ol>"},{"location":"MISC/Wine/index.html#_8","title":"\u9999\u578b","text":"<p>https://zhuanlan.zhihu.com/p/106971902?utm_source=wechat_session</p> <ol> <li>\u200b\u9171\u9999\u200b</li> <li>\u200b\u6d53\u9999\u200b</li> <li>\u200b\u6e05\u9999\u200b</li> <li>\u200b\u7c73\u200b\u9999\u200b</li> </ol> <ol> <li>\u200b\u517c\u9999\u200b</li> <li>\u200b\u51e4\u9999\u200b</li> </ol>"},{"location":"MISC/Wine/index.html#_9","title":"\u7ea2\u9152","text":""},{"location":"MISC/Wine/index.html#_10","title":"\u57fa\u672c\u77e5\u8bc6","text":"<ul> <li>\u200b\u539f\u74f6\u200b\u8fdb\u53e3\u200b\uff1a\u200b\u4e5f\u200b\u53eb\u200b\u539f\u88c5\u200b\u8fdb\u53e3\u200b\uff0c\u200b\u5373\u200b\u4ece\u200b\u56fd\u5916\u200b\u76f4\u63a5\u200b\u8fdb\u53e3\u200b\u6210\u54c1\u200b\u5305\u88c5\u200b\u9152\u200b\u552e\u5356\u200b\uff0c\u200b\u63a8\u8350\u200b\u3002 <p>\u200b\u51e0\u4e4e\u200b\u65e0\u200b\u4e8c\u9053\u200b\u989d\u5916\u200b\u6dfb\u52a0\u200b</p> </li> <li>\u200b\u539f\u9152\u200b\u8fdb\u53e3\u200b\uff1a\u200b\u4e5f\u200b\u53eb\u200b\u539f\u6c41\u200b\u8fdb\u53e3\u200b\u3001\u200b\u539f\u6db2\u200b\u8fdb\u53e3\u200b\uff0c\u200b\u5373\u200b\u4ece\u200b\u56fd\u5916\u200b\u8fdb\u53e3\u200b\u917f\u9020\u200b\u540e\u200b\u7684\u200b\u9152\u200b\uff08\u200b\u4e00\u822c\u200b\u901a\u8fc7\u200b\u5927\u200b\u5bb9\u5668\u200b\u6216\u200b\u9152\u6876\u200b\u76db\u88c5\u200b\uff09\uff0c\u200b\u5728\u200b\u56fd\u80fd\u200b\u7f50\u88c5\u200b\u540e\u200b\u518d\u200b\u552e\u5356\u200b\uff0c\u200b\u4e0d\u200b\u63a8\u8350\u200b\u3002 <p>\u200b\u5927\u200b\u6982\u7387\u200b\u56fd\u5185\u200b\u5382\u5bb6\u200b\u4e3a\u4e86\u200b\u98ce\u5473\u200b\u3001\u200b\u4fdd\u8d28\u671f\u200b\u800c\u200b\u6dfb\u52a0\u200b\u9152\u7cbe\u200b\u6216\u200b\u5176\u4ed6\u200b\u6dfb\u52a0\u5242\u200b</p> </li> <li>DRY RED WINE\uff1a\u200b\u4e2d\u5f0f\u200b\u82f1\u8bed\u200b\uff0c\u200b\u8bd1\u200b\u4e3a\u200b\u5e72\u7ea2\u200b\uff0c\u200b\u5927\u200b\u6982\u7387\u200b\u5bf9\u5e94\u200b\u539f\u9152\u200b\u8fdb\u53e3\u200b\uff0c\u200b\u4e0d\u200b\u63a8\u8350\u200b\u3002</li> <li>VCE\uff1a\u200b\u5168\u200b\u79f0\u4e3a\u200bVin de la Communaute Europeene\uff0c\u200b\u8bd1\u200b\u4e3a\u200b\u6b27\u76df\u200b\u9910\u9152\u200b\uff0c\u200b\u4e00\u822c\u200b\u4e3a\u200b\u5f02\u5730\u200b\u7f50\u88c5\u200b\u3001\u200b\u65e0\u200b\u660e\u786e\u200b\u5730\u7406\u200b\u6807\u5fd7\u200b\u7684\u200b\u9910\u9152\u200b\uff0c\u200b\u7ea7\u522b\u200b\u8f83\u200b\u4f4e\u200b\uff0c\u200b\u4e0d\u200b\u63a8\u8350\u200b\u3002</li> </ul>"},{"location":"MISC/Wine/index.html#_11","title":"\u8461\u8404\u9152\u200b\u5206\u7c7b","text":"<p>\u200b\u989c\u8272\u200b</p> <ol> <li>\u200b\u7ea2\u200b\uff1axxx      <p>\u200b\u968f\u7740\u200b\u5e74\u4efd\u200b\u589e\u52a0\u200b\uff0c\u200b\u7ea2\u8461\u8404\u9152\u200b\u989c\u8272\u200b\u53d8\u5316\u200b\u4e3a\u200b\uff1a\u200b\u7d2b\u8272\u200b \u2192 \u200b\u5b9d\u77f3\u200b\u7ea2\u200b \u2192 \u200b\u77f3\u69b4\u200b\u7ea2\u200b</p> </li> <li>\u200b\u767d\u200b\uff1axxx      <p>\u200b\u968f\u7740\u200b\u5e74\u4efd\u200b\u589e\u52a0\u200b\uff0c\u200b\u767d\u8461\u8404\u9152\u200b\u989c\u8272\u200b\u53d8\u5316\u200b\u4e3a\u200b\uff1a\u200b\u67e0\u6aac\u9ec4\u200b \u2192 \u200b\u91d1\u9ec4\u8272\u200b \u2192 \u200b\u7425\u73c0\u8272\u200b</p> </li> <li>\u200b\u6843\u7ea2\u200b</li> <li>\u200b\u6a59\u200b</li> </ol> <p>\u200b\u542b\u7cd6\u91cf\u200b</p> <ol> <li>\u200b\u6781\u5e72\u200b</li> <li>\u200b\u5e72\u200b</li> <li>\u200b\u534a\u5e72\u200b</li> <li>\u200b\u534a\u751c\u200b</li> <li>\u200b\u751c\u200b</li> </ol> <p>\u200b\u72b6\u6001\u200b</p> <ol> <li>\u200b\u9759\u6001\u200b</li> <li>\u200b\u8d77\u6ce1\u200b</li> <li>\u200b\u52a0\u5f3a\u200b</li> <li>\u200b\u84b8\u998f\u200b\u9152\u200b</li> </ol>"},{"location":"MISC/Wine/index.html#_12","title":"\u8461\u8404\u9152\u200b\u4e94\u5927\u200b\u8981\u7d20","text":"<ol> <li>\u200b\u751c\u5ea6\u200b\uff1a\u200b\u8461\u8404\u9152\u200b\u4e2d\u200b\u7684\u200b\u6b8b\u7cd6\u200b</li> <li>\u200b\u5355\u5b81\u200b\uff1a\u200b\u7ea2\u8461\u8404\u9152\u200b\u7684\u200b\u9aa8\u67b6\u200b\uff0c\u200b\u53e3\u8154\u200b\u4e2d\u200b\u5e26\u6765\u200b\u7684\u200b\u5e72\u6da9\u200b\u3001\u200b\u6536\u655b\u200b\u5ea6\u200b</li> <li>\u200b\u9178\u5ea6\u200b\uff1a\u200b\u767d\u8461\u8404\u9152\u200b\u7684\u200b\u9aa8\u67b6\u200b\uff0c\u200b\u8d77\u5230\u200b\u5e73\u8861\u200b\u4f5c\u7528\u200b</li> <li>\u200b\u9152\u4f53\u200b\uff1a\u200b\u9152\u200b\u5728\u200b\u53e3\u8154\u200b\u4e2d\u200b\u7684\u200b\u539a\u91cd\u200b/\u200b\u8f7b\u8584\u200b\u7684\u200b\u611f\u89c9\u200b</li> <li>\u200b\u9152\u7cbe\u5ea6\u200b</li> </ol>"},{"location":"MISC/Wine/index.html#_13","title":"\u8461\u8404\u200b\u54c1\u79cd","text":"<ol> <li>\u200b\u7ea2\u8461\u8404\u200b<ul> <li>Cabernet Sauvignon \u200b\u8d64\u971e\u200b\u73e0\u200b</li> <li>Cabernet Franc \u200b\u54c1\u4e3d\u73e0\u200b</li> <li>Cabernet Gernischt \u200b\u86c7\u9f99\u73e0\u200b</li> <li>Merlot \u200b\u6885\u6d1b\u200b/\u200b\u7f8e\u4e50\u200b</li> <li>Pinot Noir \u200b\u9ed1\u6bd4\u8bfa\u200b/\u200b\u9ed1\u76ae\u200b\u8bfa\u200b</li> <li>Syrah \u200b\u897f\u62c9\u200b</li> <li>Grenache \u200b\u6b4c\u6d77\u5a1c\u200b</li> </ul> </li> <li>\u200b\u767d\u200b\u8461\u8404\u200b<ul> <li>\u200b\u971e\u591a\u4e3d\u200b</li> <li>\u200b\u957f\u200b\u76f8\u601d\u200b</li> <li>\u200b\u96f7\u200b\u53f8\u4ee4\u200b</li> <li>\u200b\u743c\u7476\u200b\u6d46\u200b</li> </ul> </li> </ol>"},{"location":"MISC/Wine/index.html#_14","title":"\u5564\u9152\u200b\u585e","text":"<ol> <li>\u200b\u5408\u6210\u200b\u585e\u200b</li> <li>\u200b\u539f\u200b\u6728\u585e\u200b</li> <li>\u200b\u87ba\u65cb\u200b\u76d6\u200b</li> <li>\u200b\u8d34\u7247\u200b\u585e\u200b</li> <li>\u200b\u9ad8\u5206\u5b50\u200b\u585e\u200b</li> <li>DINM\u200b\u585e\u200b</li> </ol>"},{"location":"MISC/Wine/index.html#_15","title":"\u5564\u9152\u200b\u54c1\u724c","text":"<pre><code>for i in range(10):\n    print(f\"hello word_{i}\")\n</code></pre>"},{"location":"Math/annotation.html","title":"\u4e13\u4e1a\u540d\u8bcd","text":""},{"location":"Math/annotation.html#c","title":"C","text":"<ul> <li>CDF\uff1aCumulative Distribution Function\uff0c\u200b\u7d2f\u8ba1\u200b\u5206\u5e03\u200b\u51fd\u6570\u200b\uff0c\u200b\u7528\u200b\\(\\Phi(z)\\)\u200b\u8868\u793a\u200b\uff0c\u200b\u7b49\u4ef7\u200b\u4e8e\u200b\\(\\text{Pr}(X\\le z)\\)\uff0c\u200b\u5176\u4e2d\u200b\\(\\text{Pr}\\)\u200b\u8868\u793a\u200b\u6982\u7387\u200bprobability</li> </ul>"},{"location":"Math/annotation.html#g","title":"G","text":"<ul> <li>GEMM\uff1aGEneral Matrix Multiplication\uff0c\u200b\u901a\u7528\u200b\u77e9\u9635\u200b\u4e58\u6cd5\u200b</li> </ul>"},{"location":"Math/annotation.html#l","title":"L","text":"<ul> <li>LDA\uff1aLatent Dirichlet Allocation\uff0c\u200b\u6f5c\u5728\u200b\u72c4\u5229\u514b\u200b\u96f7\u200b\u5206\u5e03\u200b</li> </ul>"},{"location":"Math/annotation.html#m","title":"M","text":"<ul> <li>MCMC\uff1aMarkov Chain Monte Carlo\uff0c\u200b\u57fa\u4e8e\u200b\u9a6c\u5c14\u79d1\u592b\u200b\u94fe\u200b\u8499\u7279\u5361\u7f57\u200b</li> </ul>"},{"location":"Math/annotation.html#n","title":"N","text":"<ul> <li>NMF\uff1aNonnegative Matrix Factorization\uff0c\u200b\u975e\u8d1f\u200b\u77e9\u9635\u200b\u5206\u89e3\u200b</li> </ul>"},{"location":"Math/annotation.html#p","title":"P","text":"<ul> <li>PCA\uff1aPrincipal Component Analysis\uff0c\u200b\u4e3b\u200b\u6210\u5206\u200b\u5206\u6790\u200b</li> <li>PDF\uff1aProbability Density Function\uff0c\u200b\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u200b\uff0c\u200b\u8fde\u7eed\u578b\u200b\u968f\u673a\u53d8\u91cf\u200b\u7684\u200b\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u200b</li> <li>PMF\uff1a\u200cProbability Mass Function\uff0c\u200b\u6982\u7387\u200b\u8d28\u91cf\u200b\u51fd\u6570\u200b\uff0c\u200b\u79bb\u6563\u200b\u968f\u673a\u53d8\u91cf\u200b\u5728\u200b\u5404\u200b\u7279\u5b9a\u200b\u53d6\u503c\u200b\u4e0a\u200b\u7684\u200b\u6982\u7387\u5206\u5e03\u200b\u3002</li> </ul>"},{"location":"Math/annotation.html#s","title":"S","text":"<ul> <li>SVD\uff1aSingular Value Decomposition\uff0c\u200b\u5947\u5f02\u200b\u503c\u200b\u5206\u89e3\u200b</li> </ul>"},{"location":"Math/annotation.html#t","title":"T","text":"<ul> <li>t-SNE\uff1at-distributed Stochastic Neighbor Embedding</li> </ul>"},{"location":"Math/Calculus/index.html","title":"\u5fae\u79ef\u5206","text":""},{"location":"Math/Calculus/index.html#_1","title":"\u6cf0\u52d2\u200b\u5c55\u5f00","text":"<p>https://zhuanlan.zhihu.com/p/138153530</p> \\[ \\begin{aligned}     f(x)=f(x_0)+\\frac{f^{'}(x_0)}{1!}(x-x_0)^1+&amp;\\frac{f^{''}(x_0)}{2!}(x-x_0)^2 + \\dots + \\frac{f^{(n)}(x_0)}{n!}(x-x_0)^n + R_n \\\\     &amp; R_n(x) = o[(x-x_0)^n] \\end{aligned} \\] <ul> <li> <p>power iteration method</p> </li> <li> <p>\u200b\u590d\u6570\u200b\u7684\u200b\u4e09\u89d2\u51fd\u6570\u200b\u8868\u793a\u200b\uff1a</p> <ul> <li>\\(e^{i\\theta}=\\cos \\theta + i\\sin \\theta\\)</li> </ul> </li> </ul>"},{"location":"Math/Calculus/Differential/differential.html","title":"Differential","text":""},{"location":"Math/Distribution/index.html","title":"Index","text":""},{"location":"Math/Distribution/index.html#_1","title":"\u5206\u5e03","text":""},{"location":"Math/Distribution/index.html#normal-distribution","title":"Normal Distribution","text":"<p>\\(X \\sim\\mathcal{N}(\\mu, \\sigma^2)\\)\uff0c\u200b\u5bc6\u5ea6\u200b\u51fd\u6570\u200b\\(f(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\) - \u200b\u72ec\u7acb\u200b\u5206\u5e03\u200b\u6b63\u6001\u5206\u5e03\u200b\u7ec4\u5408\u200b \\(Z = aX  + bY\\)\uff1a\\(E(Z)=a\\mu_X + b\\mu_Y\\) \u200b\u548c\u200b \\(Var(Z) = a^2\\sigma^2_X + b^2\\sigma_Y^2\\) - \u200b\u72ec\u7acb\u200b\u5206\u5e03\u200b\u6b63\u6001\u5206\u5e03\u200b\u7ec4\u5408\u200b \\(Z = XY\\)\uff1a\\(E(Z)=\\frac{\\mu_X\\sigma_Y^2 + \\mu_Y\\sigma_X^2}{\\sigma_X^2 + \\sigma_Y^2} + b\\mu_Y\\) \u200b\u548c\u200b \\(Var(Z) = \\frac{\\sigma_X^2  \\sigma_Y^2}{\\sigma_X^2 + \\sigma_Y^2}\\) - \u200b\u7d2f\u8ba1\u200b\u5206\u5e03\u200b\u51fd\u6570\u200bCDF \\(\\Phi(x)=\\text{Pr}(X\\le x)=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^{x}e^{-\\frac{x^2}{2}}dx\\)</p>"},{"location":"Math/Distribution/index.html#poisson-distribution","title":"Poisson Distribution","text":"<p>\u200b\u6cca\u677e\u200b\u5206\u5e03\u200b\uff0c\u200b\u662f\u200b\u4e00\u79cd\u200b\u79bb\u6563\u200b\u6982\u7387\u5206\u5e03\u200b\uff0c\u200b\u7528\u4e8e\u200b\u63cf\u8ff0\u200b\u5728\u200b\u4e00\u5b9a\u200b\u65f6\u95f4\u200b\u6216\u200b\u7a7a\u95f4\u200b\u5185\u200b\u4e8b\u4ef6\u200b\u53d1\u751f\u200b\u7684\u200b\u6b21\u6570\u200b\u3002\u200b\u5b83\u200b\u7279\u522b\u200b\u9002\u7528\u200b\u4e8e\u200b\u5f53\u200b\u8fd9\u4e9b\u200b\u4e8b\u4ef6\u200b\u662f\u200b\u72ec\u7acb\u200b\u53d1\u751f\u200b\u4e14\u200b\u4ee5\u200b\u6052\u5b9a\u200b\u7684\u200b\u5e73\u5747\u200b\u901f\u7387\u200b\u51fa\u73b0\u200b\u65f6\u200b\u7684\u200b\u60c5\u666f\u200b\u3002</p>"},{"location":"Math/Distribution/index.html#zipfian-distribution","title":"Zipfian Distribution","text":"<p>\u200b\u4e00\u4e2a\u200b\u79bb\u6563\u200b\u5e42\u5f8b\u200b\u6982\u7387\u5206\u5e03\u200b\uff0c\u200b\u4e5f\u200b\u5c31\u662f\u200b\u5e38\u5e38\u200b\u63d0\u5230\u200b\u7684\u200b\u957f\u5c3e\u200b\u5206\u5e03\u200b\uff0c\u200b\u5373\u200b\u67d0\u4e2a\u200b\u5bf9\u8c61\u200b\u7684\u200b\u51fa\u73b0\u200b\u9891\u7387\u200b\u4e0e\u5176\u200b\u6392\u540d\u200b\u6210\u53cd\u6bd4\u200b\uff08\u200b\u5c11\u6570\u200b\u5bf9\u8c61\u200b\u5360\u636e\u200b\u4e86\u200b\u5927\u90e8\u5206\u200b\u9891\u7387\u200b\uff0c\u200b\u5927\u591a\u6570\u200b\u5bf9\u8c61\u200b\u7684\u200b\u9891\u7387\u200b\u5f88\u200b\u4f4e\u200b\uff09\uff0c\u200b\u901a\u5e38\u200b\u7528\u4e8e\u200b\u63cf\u8ff0\u200b\u81ea\u7136\u8bed\u8a00\u200b\u3001\u200b\u57ce\u5e02\u200b\u4eba\u53e3\u200b\u3001\u200b\u7f51\u7ad9\u200b\u8bbf\u95ee\u91cf\u200b\u7b49\u200b\u9886\u57df\u200b\u7684\u200b\u73b0\u8c61\u200b\u3002</p> \\[ f(k) = \\frac{C}{k^s} \\] <p>\\(k\\) \u200b\u4e3a\u200b\u5bf9\u8c61\u200b\u7684\u200b\u6392\u540d\u200b\uff0c\\(C\\) \u200b\u4e3a\u200b\u5f52\u4e00\u5316\u200b\u5e38\u6570\u200b\uff0c\\(s\\) \u200b\u4e3a\u200b\u5206\u5e03\u200b\u7684\u200b\u5e42\u5f8b\u200b\u8d85\u53c2\u200b\uff0c\u200b\u901a\u5e38\u200b\u63a5\u8fd1\u200b\u4e8e\u200b1</p>"},{"location":"Math/Distribution/index.html#_2","title":"\u91c7\u6837\u200b\u65b9\u5f0f","text":""},{"location":"Math/Distribution/index.html#importance-sampling","title":"Importance Sampling","text":"<ul> <li> <p>\u200b\u76ee\u6807\u200b\uff1a\u200b\u4f30\u8ba1\u200b\u76ee\u6807\u200b\u5206\u5e03\u200b\\(P(x)\\)\u200b\u4e0b\u200b\u7684\u200b\u671f\u671b\u503c\u200b</p> \\[ \\mathbb{E}_{P}[f(x)] = \\int f(x)P(x) dx \\] </li> <li> <p>\u200b\u6311\u6218\u200b\uff1a\u200b\u5982\u679c\u200b\\(P(x)\\)\u200b\u96be\u4ee5\u200b\u76f4\u63a5\u200b\u91c7\u6837\u200b\u6216\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u91cd\u8981\u6027\u200b\u91c7\u6837\u200b  </p> </li> <li> <p>\u200b\u65b9\u6cd5\u200b\u5982\u4e0b\u200b\uff1a  </p> <ol> <li>\u200b\u9009\u62e9\u200b\u4e00\u4e2a\u200b\u6613\u4e8e\u200b\u91c7\u6837\u200b\u7684\u200b\u63d0\u8bae\u200b\u5206\u5e03\u200b\\(Q(x)\\)</li> <li>\u200b\u4ece\u200b\\(Q(x)\\)\u200b\u4e2d\u200b\u91c7\u6837\u200b\\(x_1, x_2, \\dots, x_N\\)</li> <li>\u200b\u8ba1\u7b97\u200b\u91cd\u8981\u6027\u200b\u6743\u91cd\u200b\\(w(x_i) = \\frac{P(x_i)}{Q_{x_i}}\\)</li> <li> <p>\u200b\u4f30\u8ba1\u200b\u671f\u671b\u503c\u200b</p> \\[ \\mathbb{E}_{P}[f(x)]\\approx\\mathbb{E}_{Q}[f(x)\\frac{P(x)}{Q(x)}] = \\frac{1}{N} \\sum_{i=1}^{N}f(x_i)w(x_i) \\] </li> </ol> </li> <li> <p>\u200b\u7075\u6d3b\u6027\u200b\uff1a\u200b\u53ef\u4ee5\u200b\u9009\u62e9\u200b\u4efb\u610f\u200b\u6613\u4e8e\u200b\u91c7\u6837\u200b\u7684\u200b\u63d0\u8bae\u200b\u5206\u5e03\u200b\\(Q(x)\\)</p> </li> <li>\u200b\u9ad8\u6548\u6027\u200b\uff1a\u200b\u901a\u8fc7\u200b\u9009\u62e9\u200b\u5408\u9002\u200b\u7684\u200bQ(x)\uff0c\u200b\u53ef\u4ee5\u200b\u51cf\u5c11\u200b\u4f30\u8ba1\u200b\u7684\u200b\u65b9\u5dee\u200b</li> </ul>"},{"location":"Math/Distribution/index.html#inverse-sampling","title":"Inverse Sampling","text":"<ul> <li>\u200b\u9006\u200b\u91c7\u6837\u200binverse sampling\u200b\u662f\u200b\u4e00\u79cd\u200b\u53ef\u4ee5\u200b\u4ece\u200b\u6982\u7387\u5206\u5e03\u200b\u4e2d\u200b\u751f\u6210\u200b\u968f\u673a\u6837\u672c\u200b\u7684\u200b\u8ba1\u6570\u200b\u3002\u200b\u7279\u522b\u200b\u9002\u7528\u200b\u4e8e\u200b\u79bb\u6563\u200b\u5206\u5e03\u200b\u6216\u200b\u67d0\u4e9b\u200b\u7279\u5b9a\u200b\u7684\u200b\u8fde\u7eed\u200b\u5206\u5e03\u200b\uff0c\u200b\u5176\u4e2d\u200b\u7d2f\u8ba1\u200b\u5206\u5e03\u200b\u51fd\u6570\u200bCDF\u200b\u662f\u200b\u5df2\u77e5\u200b\u7684\u200b\uff0c\u200b\u5e76\u4e14\u200b\u53ef\u4ee5\u200b\u65b9\u4fbf\u200b\u6c42\u9006\u200b\uff0c\u200b\u9006\u200b\u91c7\u6837\u200b\u7684\u200b\u57fa\u672c\u601d\u8def\u200b\u662f\u200b\u5229\u7528\u200b\u5206\u5e03\u200b\u7684\u200b\u7d2f\u8ba1\u200b\u5206\u5e03\u200b\u51fd\u6570\u200bCDF\u200b\u6765\u200b\u751f\u6210\u200b\u968f\u673a\u6570\u200b\uff0c\u200b\u6b65\u9aa4\u200b\u4e3a\u200b<ol> <li>\u200b\u786e\u5b9a\u200b\u7d2f\u8ba1\u200b\u5206\u5e03\u200b\u51fd\u6570\u200b\\(F(x)\\) </li> <li>\u200b\u4ece\u200b\u5747\u5300\u200b\u968f\u673a\u200b\u5206\u5e03\u200b<code>uniform(0, 1)</code>\u200b\u4e2d\u200b\u751f\u6210\u200b\u968f\u673a\u6570\u200b\\(u\\)</li> <li>\u200b\u4f7f\u7528\u200b\u9006\u200bCDF\u200b\u51fd\u6570\u200b\\(F^{-1}(x)\\)\u200b\u6ee1\u8db3\u200b\\(x=F^{-1}(u)\\)\u3010\u200b\u6b64\u5904\u200b\u53ef\u4ee5\u200b\u7406\u89e3\u200bx\u200b\u4e3a\u200b\\(F(x_i)\\ge u\\)\u200b\u7684\u200b\u6700\u5c0f\u200b\\(x_i\\)\u200b\u503c\u200b\u3011\uff0c\u200b\u6b64\u65f6\u200bx\u200b\u5373\u200b\u4e3a\u200b\u751f\u6210\u200b\u7684\u200b\u968f\u673a\u6570\u200b\u6837\u672c\u200b</li> </ol> </li> </ul>"},{"location":"Math/Distribution/index.html#rejection-sampling","title":"Rejection Sampling","text":"<ul> <li>\u200b\u62d2\u7edd\u200b\u91c7\u6837\u200b\uff0c\u200b\u4e5f\u200b\u53eb\u200b\u63a5\u53d7\u200b-\u200b\u62d2\u7edd\u200b\u91c7\u6837\u200bAcceptance-Rejection Sampling\u200b\u662f\u200b\u4e00\u79cd\u200b\u7528\u4e8e\u200b\u4ece\u200b\u590d\u6742\u200b\u5206\u5e03\u200b\u4e2d\u200b\u751f\u6210\u200b\u6837\u672c\u200b\u7684\u200b\u6280\u672f\u200b\u3002\u200b\u5f53\u200b\u76ee\u6807\u200b\u5206\u5e03\u200b\\(P(x)\\)\u200b\u7684\u200b\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u200bPDF\u200b\u96be\u4ee5\u200b\u76f4\u63a5\u200b\u91c7\u6837\u200b\u65f6\u200b\uff0c\u200b\u4f46\u200b\u53ef\u4ee5\u200b\u8ba1\u7b97\u200b\u5176\u503c\u200b\u6216\u200b\u6bd4\u4f8b\u200b\uff0c\u200b\u90a3\u4e48\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u62d2\u7edd\u200b\u91c7\u6837\u200b\u65b9\u6cd5\u200b\u6765\u200b\u95f4\u63a5\u200b\u5730\u200b\u751f\u6210\u200b\u6837\u672c\u200b\u3002\u200b\u6b65\u9aa4\u200b\u4e3a\u200b\uff1a<ol> <li>\u200b\u9009\u62e9\u200b\u4e00\u4e2a\u200b\u5bb9\u6613\u200b\u91c7\u6837\u200b\u7684\u200bproposal distribution\u200b\u63d0\u8bae\u200b\u5206\u5e03\u200b\\(Q(x)\\)\uff0c\u200b\u8981\u6c42\u200b\u63d0\u8bae\u200b\u5206\u5e03\u200b\\(Q(x)\\)\u200b\u9700\u8981\u200b\u8986\u76d6\u200b\u76ee\u6807\u200b\u5206\u5e03\u200b\\(P(x)\\)\u200b\u7684\u200b\u5b9a\u4e49\u57df\u200bX  </li> <li>\u200b\u627e\u5230\u200b\u4e00\u4e2a\u200b\u5e38\u6570\u200bc\uff0c\u200b\u4f7f\u5f97\u200b\u5bf9\u4e8e\u200b\u6240\u6709\u200bx\uff0c\\(cQ(x)\\ge P(x)\\)\uff0c\u200b\u4fdd\u8bc1\u200b\u5206\u5e03\u200b\\(P(x)\\)\u200b\u7684\u200b\u503c\u57df\u200b\u603b\u662f\u200b\u5728\u200b\\(cQ(x)\\)\u200b\u4e4b\u4e0b\u200b  </li> <li>\u200b\u91c7\u6837\u200b\u548c\u200b\u63a5\u53d7\u200b/\u200b\u62d2\u7edd\u200b<ul> <li>\u200b\u4f9d\u7167\u200b\u63d0\u8bae\u200b\u5206\u5e03\u200bQ\u200b\u4e2d\u200b\u91c7\u6837\u200b\u5f97\u5230\u200bx_0  </li> <li>\u200b\u4ece\u200b\u5747\u5300\u5206\u5e03\u200b<code>uniform(0, 1)</code> \u200b\u4e2d\u200b\u91c7\u6837\u200b\u5f97\u5230\u200b \\(u\\)</li> <li>\u200b\u5982\u679c\u200b\\(u\\lt\\frac{P(x_0)}{cQ(x_0)}\\)\uff0c\u200b\u5219\u200b\u63a5\u53d7\u200bx_0\u200b\u4f5c\u4e3a\u200bP\u200b\u751f\u6210\u200b\u7684\u200b\u6837\u672c\u200b\uff1b\u200b\u5426\u5219\u200b\u62d2\u7edd\u200bx_0\uff0c\u200b\u91cd\u590d\u200b\u4e0a\u8ff0\u200b\u8fc7\u7a0b\u200b\u76f4\u5230\u200b\u83b7\u5f97\u200b\u8db3\u591f\u200b\u591a\u200b\u7684\u200b\u6837\u672c\u200b   <p>\u200b\u5e38\u6570\u200bc\u200b\u9700\u8981\u200b\u624b\u52a8\u200b\u9009\u62e9\u200b\u5e76\u200b\u6ee1\u8db3\u6761\u4ef6\u200b2</p> </li> </ul> </li> </ol> </li> </ul> <p>https://www.zhihu.com/question/38056285/answer/1803920100</p> <ul> <li>\u200b\u9a6c\u5c14\u79d1\u592b\u200b\u94fe\u200b\u7684\u200b\u5f53\u524d\u200b\u72b6\u6001\u200b\u53ea\u200b\u4f9d\u8d56\u4e8e\u200b\u524d\u200b\u4e00\u200b\u72b6\u6001\u200b\uff0c\u200b\u5373\u200b\\(P(x_t\\vert x_1, x_2, \\dots, x_{t-1}) = P(x_t\\vert x_{t-1})\\)<ul> <li>\\(\\pi\\) \u200b\u4e3a\u200b\u9a6c\u5c14\u79d1\u592b\u200b\u94fe\u200b\u7684\u200b\u5e73\u7a33\u200b\u5206\u5e03\u200b\uff0c\u200b\u6ee1\u8db3\u200b\\(\\pi P = \\pi\\)</li> </ul> </li> <li>\u200b\u57fa\u4e8e\u200b\u9a6c\u6c0f\u94fe\u200b\u7684\u200b\u8499\u7279\u5361\u7f57\u200b\u65b9\u6cd5\u200b\u91c7\u6837\u200bMCMC (Markov Chain &amp; Monte Carlo)<ul> <li>Detailed Balance\u200b\u7ec6\u81f4\u200b\u5e73\u8861\u200b\\(\\pi(i)P(i, j)=\\pi(j)P(j, i)  \\rightarrow \\pi(i)Q(i,j)\\alpha(i, j)=\\pi(j)Q(j,i)\\alpha(i, j)\\)</li> <li>\\(P(i, j)=Q(i, j)\\alpha(i, j) \\rightarrow \\alpha(i, j)=\\min\\{\\frac{\\pi(j)Q(j,i)}{\\pi(i)Q(i,j)}, 1\\}\\)</li> <li>\u200b\u5176\u4e2d\u200bQ\u200b\u4e3a\u200b\u72b6\u6001\u200b\u8f6c\u79fb\u200b\u77e9\u9635\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u662f\u200b\u72b6\u6001\u200b\u8f6c\u79fb\u200b\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u200b\uff0c\\(P(A\\rightarrow B) = P(B\\vert A)\\)</li> <li>\u200b\u7ecf\u8fc7\u200b1~t\u200b\u65f6\u95f4\u200bburn-in\u200b\u71c3\u70e7\u200b\u671f\u200b\u7684\u200b\u72b6\u6001\u200b\u53d8\u6362\u200b\u540e\u200b\uff0c\u200b\u5728\u200b[t+1, \u221e]\u200b\u540e\u200b\u8fdb\u5165\u200b\u7ec6\u81f4\u200b\u5e73\u8861\u200b\u671f\u200b\uff0c\u200b\u8fdb\u5165\u200b\u7ec6\u81f4\u200b\u5e73\u8861\u200b\u671f\u540e\u200b\u5f00\u59cb\u200b\u8fdb\u884c\u200b\u6700\u7ec8\u200b\u91c7\u6837\u200b</li> <li>\u200b\u91c7\u6837\u200b\u70b9\u95f4\u200b\u4e0d\u200b\u4e92\u76f8\u200b\u72ec\u7acb\u200b\uff0cmixing time t\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u5f88\u957f\u200b</li> </ul> </li> <li>MH\u200b\u91c7\u6837\u200b Metropolis Hastings<ul> <li>norm.pdf\uff0c\u200b\u8f93\u5165\u200bx\uff0c\u200b\u4f9d\u7167\u200b\u7ed9\u5b9a\u200b\u7684\u200bnorm\u200b\u8d85\u53c2\u200b\u03bc\u200b\u548c\u200b\u03c3\u200b\u751f\u6210\u200b\u5bf9\u5e94\u200b\u7684\u200by\u200b\u503c\u200b</li> <li>norm.rvs\uff0c\u200b\u4f9d\u7167\u200b\u7ed9\u5b9a\u200bnorm\u200b\u8d85\u53c2\u200b\u03bc\u200b\u548c\u200b\u03c3\u200b\u968f\u673a\u200b\u91c7\u6837\u200bsize\u200b\u4e2a\u200bx\u200b\u503c\u200b</li> </ul> </li> <li>Gibbs sampling\u200b\u5409\u5e03\u65af\u200b\u91c7\u6837\u200b<ul> <li>\u200b\u8054\u5408\u200b\u6982\u7387\u5206\u5e03\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u6761\u4ef6\u200b\u6982\u7387\u200b\uff08\u200b\u9ad8\u7ef4\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u4f4e\u7ef4\u200b\uff09\uff0c\u200b\u4e0d\u200b\u4e00\u5b9a\u200b\u8981\u200b\u8f6e\u6362\u200b\u5750\u6807\u8f74\u200b\uff0c\u200b\u53ea\u200b\u9700\u8981\u200b\u7b26\u5408\u6761\u4ef6\u200b\u6982\u7387\u5206\u5e03\u200b\u8fdb\u884c\u200b\u91c7\u6837\u200b\u5373\u53ef\u200b\uff0c\u200b\u4e0d\u200b\u62d2\u7edd\u200b\uff0c\u200b\u6240\u6709\u200b\u91c7\u6837\u200b\u5747\u200b\u63a5\u53d7\u200b</li> <li>\u200b\u662f\u200b\u03b1=1\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u7684\u200bMH\u200b\u91c7\u6837\u200b\uff0c\u200b\u4e3a\u200bMH\u200b\u91c7\u6837\u200b\u7684\u200b\u7279\u6b8a\u200b\u5f62\u5f0f\u200b\u3002\u200b\u9002\u7528\u200b\u4e8e\u200b\u968f\u673a\u53d8\u91cf\u200bX\u200b\u7ef4\u5ea6\u200b\u975e\u5e38\u200b\u9ad8\u200b\u7684\u200b\u60c5\u51b5\u200b\uff0c\u200b\u4ece\u200bt\u200b\u5230\u200bt+1\u200b\u65f6\u523b\u200b\uff0c\u200b\u53ea\u200b\u6539\u53d8\u200b\u4e00\u4e2a\u200b\u7ef4\u5ea6\u200b\u7684\u200b\u503c\u200b\u3002\u200b\u72b6\u6001\u200b\u8f6c\u79fb\u200b\u77e9\u9635\u200b\u53d6\u5f97\u200b\u5c31\u662f\u200b\u76ee\u6807\u200b\u6982\u7387\u200bp(X)\u3002</li> </ul> </li> </ul> <p>https://www.cnblogs.com/pinard/p/6645766.html https://pan.baidu.com/s/1EJonwMsvVWvgo1utzWydHQ#list/path=%2Fsharelink90532273-812830912909501%2FLDA%E4%BB%A3%E7%A0%81&amp;parentPath=%2Fsharelink90532273-812830912909501 \u200b\u9006\u200b\u91c7\u6837\u200b\u3001\u200b\u62d2\u7edd\u200b\u91c7\u6837\u200b\u3001MH\u200b\u91c7\u6837\u200b\u3001MCMC\u200b\u91c7\u6837\u200b https://zhuanlan.zhihu.com/p/94313808 https://zhuanlan.zhihu.com/p/95467302 https://www.zhihu.com/topic/20683707/top-answers https://www.cnblogs.com/feynmania/p/13420194.html https://www.zhihu.com/question/38056285/answer/1803920100 https://zhuanlan.zhihu.com/p/669645171 https://www.jianshu.com/p/5c510694c07e https://blog.csdn.net/Galbraith_/article/details/104577253 https://blog.csdn.net/weixin_46265255/article/details/120250624 https://blog.51cto.com/u_16213652/12201210  </p> <pre><code># \u200b\u521d\u59cb\u5316\u200b\nfor each document d in corpus:\n    for each word w in document d:\n        assign a random topic z to word w\n\n# \u200b\u5b9a\u4e49\u200b\u8fed\u4ee3\u200b\u6b21\u6570\u200b\nnum_iterations = predefined_number\n\n# \u200b\u5f00\u59cb\u200b\u5409\u5e03\u65af\u200b\u91c7\u6837\u200b\u8fed\u4ee3\u200b\u8fc7\u7a0b\u200b\nfor iteration from 1 to num_iterations:\n    for each document d in corpus:\n        for each word w in document d:\n            # \u200b\u79fb\u9664\u200b\u5f53\u524d\u200b\u5355\u8bcd\u200b\u7684\u200b\u4e3b\u9898\u200b\u5206\u914d\u200b\n            remove_topic_assignment_from_word(w)\n\n            # \u200b\u8ba1\u7b97\u200b\u65b0\u200b\u4e3b\u9898\u200b\u7684\u200b\u6982\u7387\u5206\u5e03\u200b\n            for each topic z in topics:\n                # \u200b\u66f4\u65b0\u200b doc_topic[d][k]^t\uff0c\u200b\u7531\u200b\u8ba1\u7b97\u200b\u5f0f\u200b\u53ef\u77e5\u200b\u6bcf\u884c\u200b\u5fc5\u548c\u4e3a\u200b1\uff0cP(x_i^t|x excluds x_i)\n                # \u200b\u66f4\u65b0\u200b topic_word[k][n]^t\uff0c\u200b\u7531\u200b\u8ba1\u7b97\u200b\u5f0f\u200b\u53ef\u77e5\u200b\u6bcf\u884c\u200b\u5fc5\u548c\u4e3a\u200b1\n                doc_topic_prob[z] = (count_of_words_in_doc_d_with_topic_z + alpha) / \n                                    (total_words_in_doc_d + num_topics * alpha)\n                topic_word_prob[z] = (count_of_word_w_in_topic_z + beta) / \n                                     (total_words_in_topic_z + vocab_size * beta)\n\n                # \u200b\u5408\u5e76\u200b\u6587\u6863\u200b-\u200b\u4e3b\u9898\u200b\u548c\u200b\u4e3b\u9898\u200b-\u200b\u5355\u8bcd\u200b\u6982\u7387\u200b\n                prob_distribution[z] = doc_topic_prob[z] * topic_word_prob[z]\n\n            # \u200b\u6839\u636e\u200b\u8ba1\u7b97\u200b\u51fa\u200b\u7684\u200b\u6982\u7387\u200b\u91cd\u65b0\u200b\u4e3a\u200b\u5355\u8bcd\u200b\u5206\u914d\u200b\u4e3b\u9898\u200b\n            new_topic = sample_from(prob_distribution)\n            assign_topic_to_word(w, new_topic)\n\n# \u200b\u53c2\u6570\u4f30\u8ba1\u200b\uff08\u200b\u5728\u200b\u6700\u540e\u200b\u4e00\u6b21\u200b\u8fed\u4ee3\u200b\u540e\u200b\uff09\nfor each document d in corpus:\n    for each topic z in topics:\n        doc_topic_distribution[d][z] = (count_of_words_in_doc_d_with_topic_z + alpha) / \n                                       (total_words_in_doc_d + num_topics * alpha)\n\nfor each topic z in topics:\n    for each word w in vocabulary:\n        topic_word_distribution[z][w] = (count_of_word_w_in_topic_z + beta) /\n                                        (total_words_in_topic_z + vocab_size * beta)\n\n# \u200b\u8f93\u51fa\u200b\u6700\u7ec8\u200b\u7684\u200b\u4e3b\u9898\u200b-\u200b\u6587\u6863\u200b\u548c\u200b\u4e3b\u9898\u200b-\u200b\u5355\u8bcd\u200b\u5206\u5e03\u200b\noutput doc_topic_distribution, topic_word_distribution\n</code></pre> <pre><code># coding: utf-8\n\n# # sklearn-LDA\n\n# \u200b\u4ee3\u7801\u200b\u793a\u4f8b\u200b\uff1ahttps://mp.weixin.qq.com/s/hMcJtB3Lss1NBalXRTGZlQ \uff08\u200b\u7389\u6811\u829d\u5170\u200b\uff09 &lt;br&gt;\n# \u200b\u53ef\u89c6\u5316\u200b\uff1ahttps://blog.csdn.net/qq_39496504/article/details/107125284  &lt;br&gt;\n# sklearn lda\u200b\u53c2\u6570\u200b\u89e3\u8bfb\u200b:https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html\n# &lt;br&gt;\u200b\u4e2d\u6587\u7248\u200b\u53c2\u6570\u200b\u89e3\u8bfb\u200b\uff1ahttps://blog.csdn.net/TiffanyRabbit/article/details/76445909\n# &lt;br&gt;LDA\u200b\u539f\u7406\u200b-\u200b\u89c6\u9891\u200b\u7248\u200b\uff1ahttps://www.bilibili.com/video/BV1t54y127U8\n# &lt;br&gt;LDA\u200b\u539f\u7406\u200b-\u200b\u6587\u5b57\u7248\u200b\uff1ahttps://www.jianshu.com/p/5c510694c07e\n# &lt;br&gt;score\u200b\u7684\u200b\u8ba1\u7b97\u65b9\u6cd5\u200b\uff1ahttps://github.com/scikit-learn/scikit-learn/blob/844b4be24d20fc42cc13b957374c718956a0db39/sklearn/decomposition/_lda.py#L729\n# &lt;br&gt;\u200b\u4e3b\u9898\u200b\u56f0\u60d1\u200b\u5ea6\u200b1\uff1ahttps://blog.csdn.net/weixin_43343486/article/details/109255165\n# &lt;br&gt;\u200b\u4e3b\u9898\u200b\u56f0\u60d1\u200b\u5ea6\u200b2\uff1ahttps://blog.csdn.net/weixin_39676021/article/details/112187210\n\n# ## 1.\u200b\u9884\u5904\u7406\u200b\n\n# In[3]:\n\n\nimport os\nimport pandas as pd\nimport re\nimport jieba\nimport jieba.posseg as psg\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\nimport numpy as np\nimport pyLDAvis.sklearn\nimport matplotlib.pyplot as plt\n\n\noutput_path = './save'\nfile_path = './data'\ndata = pd.read_excel(\"./data/data.xlsx\")  # content type\ndic_file = \"./data/dict.txt\"\nstop_file = \"./data/stopwords.txt\"\n\n\n# \u200b\u5c06\u200b\u4e2d\u6587\u200b\u8fdb\u884c\u200b\u53bb\u200bstop_word\u200b\u7684\u200b\u5206\u8bcd\u200b\uff0c\u200b\u8fd4\u56de\u200b \" \".join(seg_words)\ndef chinese_word_cut(mytext):\n    jieba.load_userdict(dic_file)\n    jieba.initialize()\n    try:\n        stopword_list = open(stop_file, encoding='utf-8')\n    except:\n        stopword_list = []\n        print(\"error in stop_file\")\n    stop_list = []\n    flag_list = ['n', 'nz', 'vn']\n    for line in stopword_list:\n        line = re.sub(u'\\n|\\\\r', '', line)\n        stop_list.append(line)\n\n    word_list = []\n    # jieba\u200b\u5206\u8bcd\u200b\n    seg_list = psg.cut(mytext)\n    for seg_word in seg_list:\n        word = re.sub(u'[^\\u4e00-\\u9fa5]', '', seg_word.word)\n        # word = seg_word.word  #\u200b\u5982\u679c\u200b\u60f3\u8981\u200b\u5206\u6790\u200b\u82f1\u8bed\u200b\u6587\u672c\u200b\uff0c\u200b\u6ce8\u91ca\u200b\u8fd9\u200b\u884c\u200b\u4ee3\u7801\u200b\uff0c\u200b\u542f\u52a8\u200b\u4e0b\u884c\u200b\u4ee3\u7801\u200b\n        find = 0\n        for stop_word in stop_list:\n            if stop_word == word or len(word) &lt; 2:  # this word is stopword\n                find = 1\n                break\n        if find == 0 and seg_word.flag in flag_list:\n            word_list.append(word)\n    return (\" \").join(word_list)\n\n\n# \u200b\u5bf9\u200b\u6587\u6863\u200b\u8fdb\u884c\u200b\u5206\u8bcd\u200b\ndata[\"content_cutted\"] = data.content.apply(chinese_word_cut)\nprint(type(data), data.shape)\n\n\n# \u200b\u964d\u5e8f\u200b\u8f93\u51fa\u200btopic-doc DA \u200b\u4e2d\u200b top-n\u200b\u6982\u7387\u200b\u7684\u200bfeature_words\ndef print_top_words(model, feature_names, n_top_words):\n    tword = []\n    for topic_idx, topic in enumerate(model.components_):\n        print(\"Topic #%d:\" % topic_idx)\n        topic_w = \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n        tword.append(topic_w)\n        print(topic_w)\n    return tword\n\n\n# \u200b\u6839\u636e\u200b\u8bcd\u9891\u200b\u9009\u53d6\u200btop-n features\uff08seg_word\uff09\u200b\u5f97\u5230\u200bdoc-words\u200b\u8868\u200b \u2192 [doc_num, n_features]\nn_features = 1000  # \u200b\u63d0\u53d6\u200b1000\u200b\u4e2a\u200b\u7279\u5f81\u200b\u8bcd\u8bed\u200b\ntf_vectorizer = CountVectorizer(strip_accents='unicode',\n                                max_features=n_features,\n                                stop_words='english',\n                                max_df=0.5,     # max_document_frequence: \u200b\u8bcd\u200b\u51fa\u73b0\u200b\u7684\u200b\u6587\u6863\u200b\u9891\u7387\u200b\u6700\u5927\u200b\u9608\u503c\u200b\n                                min_df=10)      # min_document_frequence\uff0c\u200b\u8bcd\u200b\u51fa\u73b0\u200b\u7684\u200b\u6587\u6863\u200b\u9891\u6570\u200b\u6700\u5c0f\u200b\u9608\u503c\u200b\ntf = tf_vectorizer.fit_transform(data.content_cutted)\nprint(type(tf), tf.shape)\n\n\n# \u200b\u57fa\u4e8e\u200b\u8bcd\u9891\u200b\u7279\u5f81\u200b\u77e9\u9635\u200b\u83b7\u53d6\u200bdoc-topic DA \u200b\u548c\u200b topic-word DA \u2192 [doc_num, topic_num], [topic_num, n_features]\nn_topics = 8\nlda = LatentDirichletAllocation(n_components=n_topics,      # topic_num\n                                max_iter=50,\n                                learning_method='batch',\n                                learning_offset=50,\n                                # doc_topic_prior=0.1,      # doc-topic\u200b\u5148\u9a8c\u200b\u5206\u5e03\u200b\u03b8\uff0c\u200b\u7f3a\u7701\u200b\u4e3a\u200b1/n_components\n                                # topic_word_prior=0.01,    # topic-word\u200b\u5148\u9a8c\u200b\u5206\u5e03\u200b\u03b2\uff0c\u200b\u7f3a\u7701\u200b\u4e3a\u200b1/n_components\n                                random_state=0)\n\nlda.fit(tf)\nprint(lda.components_.shape)    # topic-word DA\ntopics = lda.transform(tf)      # topic-word DA\nprint(lda.doc_topic_prior_, lda.doc_topic_prior)\nprint(lda.topic_word_prior_, lda.topic_word_prior)\n\nn_top_words = 25\ntf_feature_names = tf_vectorizer.get_feature_names()\n                                # \u200b\u83b7\u53d6\u200bdoc-words\u200b\u8868\u4e2d\u200b\u5404\u200bfeature\u200b\u5bf9\u5e94\u200b\u7684\u200bname\ntopic_word = print_top_words(lda, tf_feature_names, n_top_words)\n\ntopic = []\nfor t in topics:\n    topic.append(\"Topic #\" + str(list(t).index(np.max(t))))\ndata['\u200b\u6982\u7387\u200b\u6700\u5927\u200b\u7684\u200b\u4e3b\u9898\u200b\u5e8f\u53f7\u200b'] = topic\ndata['\u200b\u6bcf\u4e2a\u200b\u4e3b\u9898\u200b\u5bf9\u5e94\u200b\u6982\u7387\u200b'] = list(topics)\ndata.to_excel(\"./save/data_topic.xlsx\", index=False)\n\n\npic = pyLDAvis.sklearn.prepare(lda, tf, tf_vectorizer)\n# pyLDAvis.display(pic)\npyLDAvis.save_html(pic, './save/lda_pass' + str(n_topics) + '.html')\n# pyLDAvis.display(pic)\n# \u200b\u53bb\u200b\u5de5\u4f5c\u200b\u8def\u5f84\u200b\u4e0b\u200b\u627e\u200b\u4fdd\u5b58\u200b\u597d\u200b\u7684\u200bhtml\u200b\u6587\u4ef6\u200b\n# \u200b\u548c\u200b\u89c6\u9891\u200b\u91cc\u200b\u8bb2\u200b\u7684\u200b\u4e0d\u200b\u4e00\u6837\u200b\uff0c\u200b\u76ee\u524d\u200b\u8fd9\u4e2a\u200b\u4ee3\u7801\u200b\u4e0d\u200b\u9700\u8981\u200b\u624b\u52a8\u200b\u4e2d\u65ad\u200b\u8fd0\u884c\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5feb\u901f\u200b\u51fa\u200b\u7ed3\u679c\u200b\n\n\n# ### 2.4\u200b\u56f0\u60d1\u200b\u5ea6\u200b\n\n# LDA model hyper-parameter K evaluation test\nplexs = []\nscores = []\nn_max_topics = 16\nfor i in range(1, n_max_topics):\n    lda = LatentDirichletAllocation(n_components=i,\n                                    max_iter=50,\n                                    learning_method='batch',\n                                    learning_offset=50, random_state=0)\n    lda.fit(tf)\n    plexs.append(lda.perplexity(tf))\n    scores.append(lda.score(tf))\n\n\nn_t = 15  # \u200b\u533a\u95f4\u200b\u6700\u200b\u53f3\u4fa7\u200b\u7684\u200b\u503c\u200b\u3002\u200b\u6ce8\u610f\u200b\uff1a\u200b\u4e0d\u80fd\u200b\u5927\u4e8e\u200bn_max_topics\nx = list(range(1, n_t + 1))\n# plt.plot(x, plexs)\nplt.plot(x, scores)\nplt.xlabel(\"number of topics\")\n# plt.ylabel(\"perplexity\")\nplt.ylabel(\"score\")\nplt.show()\n</code></pre>"},{"location":"Math/Distribution/sampling.html","title":"Sampling","text":""},{"location":"Math/Linear_Algebra/index.html","title":"\u7ebf\u6027\u4ee3\u6570","text":"<ul> <li>\u200b\u77e9\u9635\u200b</li> <li>\u200b\u77e9\u9635\u200b\u8fd1\u4f3c\u7b97\u6cd5\u200b</li> </ul>"},{"location":"Math/Linear_Algebra/Approximation/approximation.html","title":"Approximation","text":""},{"location":"Math/Linear_Algebra/Approximation/approximation.html#matrix-factorization","title":"Matrix Factorization","text":""},{"location":"Math/Linear_Algebra/Approximation/approximation.html#svd","title":"SVD","text":"<ol> <li> <p>\u200b\u5947\u5f02\u200b\u503c\u200b\u5206\u89e3\u200bSingular Value Decomposition\uff0c\\(A=USV^T\\in\\mathbb{R}^{m*n}\\)\uff0c\u200b\u5176\u4e2d\u200b  </p> <ul> <li>\\(U\\in\\mathbb{R}^{m*m}\\)\u200b\u4e3a\u200b\u65b9\u9635\u200b\\(AA^T\\)\u200b\u7684\u200b\u7279\u5f81\u200b\u77e9\u9635\u200b\uff0c\u200b\u4e5f\u200b\u53eb\u200b\u5de6\u200b\u5947\u5f02\u200b\u5411\u91cf\u200b\u77e9\u9635\u200b\uff1b</li> <li>\\(S\\in\\mathbb{R}^{m*n}\\)\u200b\u4e3a\u200b\u65b9\u9635\u200b\\(AA^T\\)\u200b\u6216\u200b\\(A^TA\\)\u200b\u7684\u200b\u5947\u5f02\u200b\u503c\u200b\u5e73\u65b9\u6839\u200b\u7684\u200b\u964d\u5e8f\u200b\u975e\u8d1f\u200b\u77e9\u9635\u200b\u3002</li> <li>\\(V\\in\\mathbb{R}^{n*n}\\)\u200b\u4e3a\u200b\u65b9\u9635\u200b\\(A^TA\\)\u200b\u7684\u200b\u7279\u5f81\u200b\u77e9\u9635\u200b\uff0c\u200b\u4e5f\u200b\u53eb\u200b\u53f3\u200b\u5947\u5f02\u200b\u5411\u91cf\u200b\u77e9\u9635\u200b\uff1b</li> </ul> </li> <li> <p>Truncated Singular Value Decomposition\uff0c\u200b\u622a\u65ad\u200bSVD  </p> <ul> <li>\\(A_{m*n}\\approx U_{m*k}S_{k*k}V_{n*k}^T\\)\u200b\u5373\u200b\u4e3a\u200b\u538b\u7f29\u200b\u540e\u200b\u7684\u200b\u6570\u636e\u200b\uff0c\u200b\u6b64\u65f6\u200b\u5b58\u50a8\u200b\u503c\u200b\u538b\u7f29\u200b\u4e3a\u200b\\(k*(m+1+n)\\)\u200b\u4e2a\u200b</li> </ul> <pre><code>import numpy\nfrom numpy import linalg as LA  # Linear Algebra\nU, Sigma, VT = LA.svd(mat)      # shape=\u3010(m, m)\u3011 \u3010(min(m, n),)\u3011 \u3010(n, n)\u3011\n                                # Sigma\u200b\u4e2d\u200b\u5947\u5f02\u200b\u503c\u200b\u964d\u5e8f\u200b\u6392\u5217\u200b\n\ndef svd_dimension_reduce(U, s, VT, k):\n    Sigma = np.zeros((mat.shape[0], mat.shape[1]))\n    Sigma[:min(mat.shape[0], mat.shape[1]), :min(mat.shape[0], mat.shape[1])] = np.diag(s)\n    mat_rank_k = U[:, :k] @ Sigma[:k, :k] @ VT[:k, :]\n    return mat_rank_k\n</code></pre> </li> </ol> <p>SVD\u200b\u6c42\u200b\u7279\u5f81\u5411\u91cf\u200b\u548c\u200b\u7279\u5f81\u503c\u200b\u65f6\u200b\u9700\u8981\u200b\u8ba1\u7b97\u200b\u534f\u65b9\u5dee\u200b\u77e9\u9635\u200b\uff0c\u200b\u8ba1\u7b97\u200b\u91cf\u200b\u8f83\u5927\u200b</p>"},{"location":"Math/Linear_Algebra/Approximation/approximation.html#nmf","title":"NMF","text":"<p>\u200b\u975e\u8d1f\u200b\u77e9\u9635\u200b\u5206\u89e3\u200bNon-negative Matrix Factorization\uff0c\u200b\u7ed9\u5b9a\u200b\u4e00\u4e2a\u200b\u975e\u8d1f\u200b\u77e9\u9635\u200b\\(V\\in\\mathbb{R}^{m*n}\\)\uff0c\u200b\u80fd\u591f\u200b\u627e\u5230\u200b\u975e\u8d1f\u200b\u77e9\u9635\u200b \\(W\\in\\mathbb{R}^{m*k}\\) \u200b\u548c\u200b \\(H\\in\\mathbb{R}^{k*n}\\)\uff0c\u200b\u6ee1\u8db3\u200b\\(V\\approx WH\\)\u3002</p> <ul> <li>\\(W\\in\\mathbb{R}^{m*k}\\) features matrix\u200b\u7279\u5f81\u200b\u77e9\u9635\u200b\uff0c\u200b\u8868\u793a\u200b\u4ece\u200b\u539f\u59cb\u200b\u77e9\u9635\u200b\u4e2d\u200b\u62bd\u53d6\u200b\u51fa\u6765\u200b\u7684\u200b\u7279\u5f81\u200b\u3002\u200b\u8be5\u200b\u90e8\u5206\u200b\u53ef\u200b\u4f5c\u4e3a\u200bLSA\u200b\u4e3b\u9898\u200b\u6a21\u578b\u200b\u7ed3\u679c\u200b</li> <li>\\(H\\in\\mathbb{R}^{k*n}\\) cofficients matrix\u200b\u7cfb\u6570\u200b\u77e9\u9635\u200b\uff0c\u200b\u8868\u793a\u200b\u62bd\u53d6\u200b\u51fa\u200b\u7684\u200b\u7279\u5f81\u200b\u4e0e\u200b\u539f\u6709\u200b\u7a00\u758f\u200b\u7279\u5f81\u200b\u7684\u200b\u5173\u7cfb\u200b\u3002</li> </ul> <p>NMF\u200b\u77e9\u9635\u200b\u5206\u89e3\u200b\u4e24\u79cd\u200b\u89c4\u200b\u4f18\u5316\u200b\u76ee\u6807\u200b\u53ca\u200b\u57fa\u4e8e\u200b\u68af\u5ea6\u200b\u4e0b\u964d\u200b\u7684\u200b\u65e0\u200b\u76d1\u7763\u200b\u8fed\u4ee3\u200b\u66f4\u65b0\u200b\u5219\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li>Frobenius\u200b\u8303\u6570\u200b(\u200b\u77e9\u9635\u200bL2\u200b\u8303\u6570\u200b): \\(\\text{arg }\\mathop{\\text{min}}\\limits_{W, H}\\ \\frac{1}{2}\\Vert V-WH \\Vert_F^2 = \\frac{1}{2}\\sum_{i, j}(V_{ij} - (WH)_{ij})^2\\) </li> <li> <p>KL\u200b\u6563\u5ea6\u200b: \\(\\text{arg }\\mathop{\\text{min}}\\limits_{W, H}\\ D_{KL}(V\\Vert WH) = \\sum_{i, j} \\big[V_{ij}\\log \\frac{V_{ij}}{(WH)_{ij}} - V_{ij} + (WH)_{ij} \\big]\\)</p> <p>\\(V, W, H\\) \u200b\u5747\u200b\u4e3a\u200b\u975e\u8d1f\u200b\u77e9\u9635\u200b\uff0c\u200b\u6240\u4ee5\u200b\u53ef\u4ee5\u200b\u8fdb\u884c\u200bKL\u200b\u6563\u5ea6\u200b\u8ba1\u7b97\u200b \\(-V_{ij} + (WH)_{ij}\\) \u200b\u786e\u4fdd\u200b\u67d0\u4e00\u200b\u5143\u7d20\u200b\u503c\u4e3a\u200b0\u200b\u65f6\u200b\u4f9d\u7136\u200b\u53ef\u4ee5\u200b\u8ba1\u7b97\u200b\\(V_{ij}\\)\u200b\u548c\u200b\\((WH)_{ij}\\)\u200b\u7684\u200b\u5dee\u5f02\u200b</p> nmf<pre><code>W, H = np.abs(np.random.rand(m, k)), np.abs(np.random.rand(k, n))\nfor i in range(max_iter):\n    # Frobenius\u200b\u8303\u6570\u200b\u66f4\u65b0\u200b\u89c4\u5219\u200b\n    W = W * ((V @ H.T) / (W @ H @ H.T + 1e-9))\n    H = H * ((W.T @ V) / (W.T @ W @ H + 1e-9))\n    error = np.linalg.norm(V - W@H)\n    # KL\u200b\u6563\u5ea6\u200b\u66f4\u65b0\u200b\u89c4\u5219\u200b\uff0c\u200b\u66f4\u65b0\u200b\u6781\u6162\u200b\n    V_over_WH = V / (W@H + 1e-9)\n    W *= V_over_WH @ H.T / H.sum(axix=1)\n    V_over_WH = V / (W@H + 1e-9)\n    H *= (W.T @ V_over_WH) / W.sum(axis=0).T\n    error = sum(V*np.log(V) - V*np.log(W@H)) -V + W@H \n\n    if error &lt; tol:\n        break\nreturn W, H\n</code></pre> <p>NMF\u200b\u5206\u89e3\u200b\u77e9\u9635\u200b\u66f4\u65b0\u200b\u51fa\u81ea\u200b\u8bba\u6587\u200b: Algorithms for Non-negative Matrix Factorization \u200b\u8fed\u4ee3\u200b\u65f6\u200b\u53ef\u200b\u52a0\u5165\u200bL1\u200b\u8303\u5f0f\u200b\u548c\u200bL2\u200b\u8303\u5f0f\u200b\u8fdb\u884c\u200b\u6b63\u5219\u200b\u89c4\u7ea6\u200b\uff0c\u200b\u8be6\u89c1\u200b <code>sklearn.decomposition.NMF</code></p> </li> </ol>"},{"location":"Math/Linear_Algebra/Approximation/approximation.html#lsa","title":"LSA","text":"<p>\u200b\u6f5c\u5728\u200b\u8bed\u4e49\u200b\u5206\u6790\u200bLatent Semantic Analysis\uff0c\u200b\u4e5f\u200b\u88ab\u200b\u79f0\u4e3a\u200b\u6f5c\u5728\u200b\u8bed\u4e49\u200b\u7d22\u5f15\u200b\uff08Latent Semantic Indexing\uff0cLSI\uff09\uff0c\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\u5229\u7528\u200b\u77e9\u9635\u200b\u5206\u89e3\u200b\u6280\u672f\u200b\u6765\u200b\u51cf\u5c11\u200b\u7ef4\u5ea6\u200b\u5e76\u200b\u53d1\u73b0\u200b\u6587\u6863\u200b\u4e0e\u200b\u5355\u8bcd\u200b\u4e4b\u95f4\u200b\u7684\u200b\u6f5c\u5728\u200b\u5173\u7cfb\u200b\uff0c\u200b\u4ece\u800c\u200b\u514b\u670d\u200b\u4e86\u200b\u4f20\u7edf\u200b\u57fa\u4e8e\u200b\u5173\u952e\u8bcd\u200b\u7684\u200b\u65b9\u6cd5\u200b\u6240\u200b\u9762\u4e34\u200b\u7684\u200b\u540c\u4e49\u8bcd\u200b\u548c\u200b\u591a\u4e49\u8bcd\u200b\u95ee\u9898\u200b</p> <ol> <li> <p>\u200b\u4f7f\u7528\u200bTruncated SVD\u200b\u5206\u89e3\u200b</p> <ul> <li>\\(U\\Sigma^{1/2}\\) \u200b\u8868\u793a\u200b\u6587\u6863\u200b\u5728\u200bk\u200b\u7ef4\u200b\u6f5c\u5728\u200b\u8bed\u4e49\u200b\u7a7a\u95f4\u200b\u7684\u200b\u5206\u5e03\u200b</li> <li>\\(\\Sigma^{1/2}V\\) \u200b\u8868\u793a\u200bk\u200b\u7ef4\u200b\u6f5c\u5728\u200b\u8bed\u4e49\u200b\u5728\u200b\u8bcd\u9879\u200b\u7a7a\u95f4\u200b\u7684\u200b\u5206\u5e03\u200b</li> </ul> </li> <li> <p>\u200b\u4f7f\u7528\u200bNMF\u200b\u5206\u89e3\u200b</p> <ul> <li>\\(W\\in\\mathbb{R}^{m*k}\\) features matrix\u200b\u7279\u5f81\u200b\u77e9\u9635\u200b\uff0c\u200b\u8868\u793a\u200b\u4ece\u200b\u539f\u59cb\u200b\u77e9\u9635\u200b\u4e2d\u200b\u62bd\u53d6\u200b\u51fa\u6765\u200b\u7684\u200b\u7279\u5f81\u200b\u3002</li> <li>\\(H\\in\\mathbb{R}^{k*n}\\) cofficients matrix\u200b\u7cfb\u6570\u200b\u77e9\u9635\u200b\uff0c\u200b\u8868\u793a\u200b\u62bd\u53d6\u200b\u51fa\u200b\u7684\u200b\u7279\u5f81\u200b\u4e0e\u200b\u539f\u6709\u200b\u7a00\u758f\u200b\u7279\u5f81\u200b\u7684\u200b\u5173\u7cfb\u200b\u3002</li> </ul> </li> </ol>"},{"location":"Math/Linear_Algebra/Approximation/approximation.html#plsa","title":"pLSA","text":""},{"location":"Math/Linear_Algebra/Approximation/approximation.html#lda","title":"LDA","text":"<p>Latent Dirichlet Allocation\u200b\u6f5c\u5728\u200b\u72c4\u5229\u514b\u200b\u96f7\u200b\u5206\u5e03\u200b\uff0c\u200b\u4e00\u79cd\u200b\u4e3b\u4f53\u200b\u6316\u6398\u200b\u6a21\u578b\u200b</p> <ul> <li>https://www.bilibili.com/video/BV123411G7Z9/?spm_id_from=333.337.search-card.all.click&amp;vd_source=782e4c31fc5e63b7cb705fa371eeeb78</li> <li>from document collection to get topics</li> <li> <p>LDA algorithm\u200b\u4e3a\u200b\u51e0\u4f55\u200b\u5206\u5e03\u200b, \u200b\u63a5\u53d7\u200b\u7387\u200b\u03b1\u200b\u53d6\u503c\u200b{\u03b1=1, \u200b\u4f4d\u7f6e\u200b\u5747\u5300\u5206\u5e03\u200b; \u03b1&gt;1, \u200b\u66f4\u200b\u503e\u5411\u200b\u805a\u96c6\u200b\u5728\u200b\u4e2d\u5fc3\u200b; \u03b1&lt;1, \u200b\u66f4\u200b\u503e\u5411\u200b\u805a\u96c6\u200b\u5728\u200b\u89d2\u843d\u200b}  </p> <ul> <li>\u200b\u8fea\u5229\u514b\u96f7\u200b\u5206\u5e03\u200b\u03b1\u200b\u548c\u200b\u03b2\uff0c\u200b\u591a\u9879\u5f0f\u200b\u5206\u5e03\u200b\u8868\u793a\u200b\u5206\u522b\u200b\u4e3a\u200b\u03b8\u200b\u548c\u200b\u03c6\uff0c\u200b\u7531\u200b\u03b8\u200b\u751f\u6210\u200b\u7684\u200btopics\u200b\u96c6\u5408\u200b\u4e3a\u200bZ\uff0c\u200b\u7531\u200b\u03c6\u200b\u751f\u6210\u200b\u7684\u200b\u5355\u8bcd\u200b\u96c6\u5408\u200b\u4e3a\u200bW</li> <li>\\(P(W, Z, \\theta, \\phi; \\alpha, \\beta)=\\prod_{j=1}^MP(\\theta_j; \\alpha)\\prod_{i=1}^K(\\phi_i; \\beta)\\prod_{t=1}^{N_D}P(Z_{j,t}\\vert \\theta_j)P(W_{j,t}|\\phi_{Z_{j,t}})\\)</li> <li>\\(\\prod_{j=1}^MP(\\theta_j; \\alpha)\\): documents-topics DA</li> <li>\\(\\prod_{t=1}^{N_D}P(Z_{j,t}\\vert \\theta_j)\\) distribution-topic \u200b\u591a\u9879\u5f0f\u200b\u5206\u5e03\u200b\uff0c\\(N_D\\) \u200b\u7531\u6cca\u677e\u200b\u5206\u5e03\u200b\u91c7\u6837\u200b\u5f97\u5230\u200b</li> <li>\\(\\prod_{i=1}^K(\\phi_i; \\beta)\\) \u200b\u4ece\u200b\u03b2\u200b\u79cd\u200b\u5f97\u5230\u200b\u4e00\u5806\u200btopics-words DA</li> <li>\\(P(W_{j,t}|\\phi_{Z_{j,t}})\\) \u200b\u7ed9\u5b9a\u200btopic\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u91c7\u6837\u200bword\uff0c\u200b\u591a\u9879\u5f0f\u200b\u5206\u5e03\u200b</li> <li>topic_number, hyperparameter</li> <li>part 2 05:04, topic-words into document-topics</li> <li>from doc-topic 1xK distribution M1 generates sampling topic_k</li> <li>based on topic_k, from topic-word 1xN distribution M2 generates sampling word_n</li> <li>repeat 1,2 until generate N_d words</li> </ul> </li> <li> <p>gibbs sampling\u200b\u5409\u5e03\u65af\u200b\u91c7\u6837\u200b\uff0c\u200b\u901a\u8fc7\u200b\u67d0\u4e9b\u200b\u5bf9\u8c61\u200b\u7684\u200b\u76f8\u5bf9\u200b\u4f4d\u7f6e\u200b\u6765\u200b\u5bf9\u200bdocument-topic\u200b\u548c\u200btopic-word\u200b\u6574\u5408\u200b\u7740\u8272\u200b</p> <ul> <li>\u200b\u6bcf\u4e2a\u200bdoc\u200b\u7684\u200btopic\u200b\u5c3d\u53ef\u80fd\u200b\u5355\u8272\u200b\uff0c\u200b\u6bcf\u4e2a\u200bword\u200b\u7684\u200btopic\u200b\u5c3d\u53ef\u80fd\u200b\u5355\u8272\u200b\uff0c\u200b\u56e0\u6b64\u200b\u4e0d\u4f1a\u200b\u5b58\u5728\u200b\u67d0\u4e2a\u200b\u6587\u6863\u200b\u8868\u73b0\u200b\u4e3a\u200b\u591a\u4e2a\u200b(\u200b\u5341\u4e2a\u200b\u53ca\u200b\u4ee5\u4e0a\u200b)\u200b\u4e3b\u9898\u200b\u7684\u200b\u73b0\u8c61\u200b</li> <li>\u200b\u56e0\u6b64\u200b\u4f1a\u200b\u9010\u6b65\u200b\u5c06\u200btopic-word\u200b\u5c3d\u53ef\u80fd\u200b\u53d8\u4e3a\u200b\u5355\u8272\u200b\uff0c\u200b\u6700\u7ec8\u200b\u8868\u73b0\u200bdocument-topic\u200b\u4e3a\u200b\u5355\u8272\u200b\uff0c\u200b\u5b9e\u9645\u4e0a\u200b\u662f\u200b\u6700\u5927\u200b\u6216\u200b\u4e0a\u8ff0\u200b\u6982\u7387\u200b\\(P(W, Z, \\theta, \\phi; \\alpha, \\beta)\\)\u200b\u7684\u200b\u4e00\u4e2a\u200b\u8fc7\u7a0b\u200b</li> <li>\u200b\u5229\u7528\u200b\u6761\u4ef6\u200b\u5206\u5e03\u200b\u6765\u200b\u7b80\u5316\u200b\u591a\u7ef4\u200b\u95ee\u9898\u200b</li> <li>LDA \u200b\u5e76\u200b\u4e0d\u662f\u200b\u57fa\u4e8e\u200b\u201c\u200b\u5b8c\u5168\u200b\u63a5\u53d7\u200b\u201d\u200b\u7684\u200b\u539f\u5219\u200b\u5de5\u4f5c\u200b\u7684\u200b\uff0c\u200b\u800c\u662f\u200b\u4f9d\u8d56\u4e8e\u200b\u5148\u8fdb\u200b\u7684\u200b\u7edf\u8ba1\u200b\u63a8\u65ad\u200b\u6280\u672f\u200b\u6765\u200b\u5904\u7406\u200b\u5176\u200b\u5185\u90e8\u200b\u7684\u200b\u6982\u7387\u200b\u7ed3\u6784\u200b\u3002</li> <li>https://www.jianshu.com/p/5c510694c07e  </li> <li>from doc-words to get doc-topic and topic-words </li> </ul> </li> </ul> <p>LDA\u200b\u51fa\u81ea\u200bDavid M.Blei\u3001\u200b\u5434\u6069\u8fbe\u200b\u548c\u200bMichael I.Jordan 2003\u200b\u5e74\u200b\u8bba\u6587\u200b: Latent Dirichlet Allocation</p>"},{"location":"Math/Linear_Algebra/Approximation/approximation.html#dimensionality-reduction","title":"Dimensionality Reduction","text":""},{"location":"Math/Linear_Algebra/Approximation/approximation.html#pca","title":"PCA","text":"<p>\u200b\u4e3b\u200b\u6210\u5206\u200b\u5206\u6790\u200bPrincipal Component Analysis\uff0c\u200b\u5373\u200b\u4e00\u7ec4\u200b\u6570\u636e\u200b\uff08m\u200b\u6761\u200b\u6570\u636e\u200b\uff09\u200b\u4e0d\u540c\u200b\u7ef4\u5ea6\u200b\uff08n\u200b\u4e2a\u200b\u7ef4\u5ea6\u200b\uff09\u200b\u4e4b\u95f4\u200b\u53ef\u80fd\u200b\u5b58\u5728\u200b\u7ebf\u6027\u76f8\u5173\u200b\u5173\u7cfb\u200b\uff0cPCA\u200b\u80fd\u591f\u200b\u5bf9\u200b\u8fd9\u7ec4\u200b\u6570\u636e\u200b\uff08\u200b\u901a\u8fc7\u200b\u5254\u9664\u200b\u534f\u65b9\u5dee\u200b\u77e9\u9635\u200b\u5bf9\u5e94\u200b\u7684\u200b\u5c0f\u200b\u7279\u5f81\u503c\u200b\u7ef4\u5ea6\u200b\uff09\u200b\u6b63\u4ea4\u53d8\u6362\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u5404\u4e2a\u200b\u7ef4\u5ea6\u200b\u4e4b\u95f4\u200b\uff08\u200b\u7ef4\u5ea6\u200b\u7f29\u51cf\u200b\u4e3a\u200bk\uff09\u200b\u7ebf\u6027\u200b\u65e0\u5173\u200b\u7684\u200b\u6570\u636e\u200b\uff0c\u200b\u8fbe\u5230\u200b\u6570\u636e\u200b\u964d\u7ef4\u53bb\u200b\u566a\u200b\u7684\u200b\u76ee\u7684\u200b\u3002</p> <ol> <li>\u200b\u96f6\u200b\u5747\u503c\u200b\u5316\u200b\u5904\u7406\u200b\uff0c\u200b\u7279\u5f81\u200b\u5143\u7d20\u200b\u51cf\u53bb\u200b\u76f8\u5e94\u200b\u7279\u5f81\u200b\u7684\u200b\u5747\u503c\u200b\\(X_i=X_i-E[X_i] \\in \\mathbb{R}^{m*n}\\)</li> <li>\u200b\u8ba1\u7b97\u200b\u534f\u65b9\u5dee\u200b\u77e9\u9635\u200b\\(C=X^TX\\in\\mathbb{R}^{n*n}\\)\u200b\u7684\u200b\u7279\u5f81\u503c\u200b\u548c\u200b\u7279\u5f81\u5411\u91cf\u200b</li> <li> <p>\u200b\u6309\u200b\u7279\u5f81\u503c\u200b\u7684\u200b\u5927\u5c0f\u200b\u964d\u5e8f\u200b\u6392\u5217\u200b\uff0c\u200b\u9009\u62e9\u200b\u5bf9\u5e94\u200b\u7684\u200btop-k\u200b\u4e2a\u200b\u7279\u5f81\u5411\u91cf\u200b\u4f5c\u4e3a\u200b\u4e3b\u200b\u6210\u5206\u200b\u5f97\u5230\u200b\u77e9\u9635\u200b\\(P\\in\\mathbb{R}^{n*k}\\)</p> <p>k\u200b\u9664\u4e86\u200b\u53ef\u4ee5\u200b\u6307\u5b9a\u200b\u4e3a\u200b\u5177\u4f53\u200b\u7684\u200b\u6574\u6570\u200b\u503c\u5916\u200b\uff0c\u200b\u8fd8\u200b\u53ef\u4ee5\u200b\u6307\u5b9a\u200b\u4e3a\u200b\u767e\u5206\u6570\u200b\uff0c\u200b\u5bf9\u5e94\u200b\u6ee1\u8db3\u200b\u2265k\u200b\u7684\u200b\u7279\u5f81\u503c\u200b\u6bd4\u91cd\u200b\u7684\u200b\u6700\u5c0f\u200bk</p> </li> <li> <p>\u200b\u6295\u5f71\u200b\u7ed3\u679c\u200b\\(Y=XP \\in \\mathbb{R}^{m*k}\\)\u200b\u5373\u4e3a\u200b\u964d\u7ef4\u5230\u200bk\u200b\u7ef4\u540e\u200b\u7684\u200b\u6570\u636e\u200b</p> <pre><code>from sklearn.decomposition import PCA\n\npca = PCA(n_components=0.8)\npca.fit(X)                  # \u200b\u8ba1\u7b97\u200bPCA\u200b\u6295\u5f71\u200b\u77e9\u9635\u200b\uff0cX\u200b\u4e3a\u200b [m, n] \u200b\u6570\u7ec4\u200b\nY = ret = pca.transform(X)  # \u200b\u83b7\u53d6\u200bPCA\u200b\u6295\u5f71\u200b\u7ed3\u679c\u200b\uff0cY\u200b\u4e3a\u200b [m, k] \u200b\u6570\u7ec4\u200b\n</code></pre> </li> </ol> <p>\u200b\u964d\u7ef4\u200b\uff1a\u200b\u901a\u8fc7\u200b\u4fdd\u7559\u200b\u4e3b\u8981\u200b\u6210\u5206\u200b\u7684\u200b\u6295\u5f71\u200b\u7ed3\u679c\u200b\uff0c\u200b\u4e14\u200b\u7279\u5f81\u200b\u6570\u200b\u51cf\u5c11\u200b</p>"},{"location":"Math/Linear_Algebra/Approximation/approximation.html#t-sne","title":"t-SNE","text":"<p>t-distributed Stochastic Neighbor Embedding t\u200b\u5206\u5e03\u200b-\u200b\u968f\u673a\u200b\u90bb\u8fd1\u200b\u5d4c\u5165\u200b</p> <p>\u200b\u964d\u7ef4\u200b\uff1a\u3002\u200b\u9700\u8981\u200b\u8fed\u4ee3\u200b\u8ba1\u7b97\u200b\uff0c\u200b\u8ba1\u7b97\u200b\u65f6\u95f4\u200b\u957f\u200b\u3002</p>"},{"location":"Math/Linear_Algebra/Matrix/matrix.html","title":"Matrix","text":""},{"location":"Math/Linear_Algebra/Matrix/matrix.html#jacobian-matrix","title":"Jacobian Matrix","text":"<p>https://zhuanlan.zhihu.com/p/138334587 https://zhuanlan.zhihu.com/p/90496291/</p> <p>\u200b\u96c5\u200b\u53ef\u6bd4\u200b\u77e9\u9635\u200b\uff0c\\(f:\\mathbb{R}^n \\rightarrow \\mathbb{R}^m\uff0cJ_f(x)\\in \\mathbb{R}^{m*n}\uff0cJ_{ij}=\\frac{\\partial f_i}{\\partial x_j}\\)</p> \\[ J =\\big[\\frac{\\partial f}{\\partial x_1} \\dots \\frac{\\partial f}{\\partial x_n}\\big] = \\begin{bmatrix}     \\frac{\\partial f_1}{\\partial x_1} &amp; \\dots &amp; \\frac{\\partial f_1}{\\partial x_n} \\\\     \\vdots  &amp; \\ddots &amp; \\vdots  \\\\     \\frac{\\partial f_m}{\\partial x_1} &amp; \\dots &amp; \\frac{\\partial f_m}{\\partial x_n} \\end{bmatrix} \\]"},{"location":"Math/Linear_Algebra/Matrix/matrix.html#hessian-matrix","title":"Hessian matrix","text":"<p>\u200b\u9ed1\u585e\u200b\u77e9\u9635\u200b\uff0c\u200b\u53c8\u79f0\u200b\u4f5c\u6d77\u68ee\u200b\u77e9\u9635\u200b\u3001\u200b\u6d77\u585e\u200b\u77e9\u9635\u200b\u6216\u6d77\u745f\u200b\u77e9\u9635\u200b\uff0c\\(H_{ij}=I_{ij}=\\frac{\\partial^2 f}{\\partial x_i \\partial x_j}\\)</p> \\[ H = \\begin{bmatrix}     \\frac{\\partial^2 f}{\\partial x_1^2} &amp; \\frac{\\partial^2 f}{\\partial x_1\\partial x_2} &amp;\\dots &amp; \\frac{\\partial^2 f}{\\partial x_1\\partial x_n} \\\\     \\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} &amp; \\frac{\\partial^2 f}{\\partial x_2^2} &amp;\\dots &amp; \\frac{\\partial^2 f}{\\partial x_2\\partial x_n} \\\\     \\vdots  &amp; \\vdots  &amp; \\ddots &amp; \\vdots  \\\\     \\frac{\\partial^2 f}{\\partial x_n \\partial x_1} &amp; \\frac{\\partial^2 f}{\\partial x_n \\partial x_2} &amp;\\dots &amp; \\frac{\\partial^2 f}{\\partial x_n^2} \\\\ \\end{bmatrix} \\]"},{"location":"Programing/Algorithm/index.html","title":"Algorithm","text":"<ul> <li>\u200b\u56fe\u200b</li> <li>\u200b\u5b57\u7b26\u4e32\u200b</li> </ul>"},{"location":"Programing/Algorithm/Data_Compression/sparse_matrix.html","title":"Sparse matrix","text":"<ul> <li>https://blog.51cto.com/u_16213652/12201210</li> </ul>"},{"location":"Programing/Algorithm/Data_Compression/sparse_matrix.html#sparse-matrix","title":"Sparse Matrix","text":"<pre><code>import scipy.sparse as sp\n\ncsr/c_matrix = sp.csr/c_matrix(matrix.numpy())\ncoo_matrix = sp.coo_matrix(matrix.numpy())\n\ncsr/c_matrix.indptr   # a1\ncsr/c_matrix.indices  # a2\ncsr/c_matrix.data     # a3\n\ncoo_matrix.row        # a1 \ncoo_matrix.col        # a2 \ncoo_matrix.data       # a3\n</code></pre>"},{"location":"Programing/Algorithm/Data_Compression/sparse_matrix.html#coo","title":"COO","text":"<p>Coordinate List format \u200b\u4f7f\u7528\u200b\u4e00\u4e2a\u200b\u5217\u8868\u200b\uff0c\u200b\u628a\u200b\u6bcf\u4e2a\u200b\u975e\u96f6\u200b\u5143\u7d20\u200b\u7684\u200b\u884c\u200b\u7d22\u5f15\u200b\u3001\u200b\u5217\u200b\u7d22\u5f15\u200b\u548c\u200b\u503c\u200b\u90fd\u200b\u679a\u4e3e\u200b\u8bb0\u5f55\u200b\u3002</p> <pre><code># Matrix.shape = (m, n)\n1   0   2\n0   0   3\n4   5   6\n\n# COO Matrix\na1 = Array(0, 0, 1, 2, 2, 2)\na2 = Array(0, 2, 2, 0, 1, 2)\na3 = Array(1, 2, 3, 4, 5, 6)\n</code></pre> <ol> <li>Array 1 \u200b\u5b58\u50a8\u200b\u975e\u96f6\u200b\u5143\u7d20\u200b\u884c\u200b\u5750\u6807\u200b\u4fe1\u606f\u200b<ul> <li><code>len(a1) = #non-zero</code></li> </ul> </li> <li>Array 2 \u200b\u5b58\u50a8\u200b\u975e\u96f6\u200b\u5143\u7d20\u200b\u7eb5\u5750\u6807\u200b\u4fe1\u606f\u200b<ul> <li><code>len(a2) = #non-zero</code></li> </ul> </li> <li>Array 3 \u200b\u6309\u884c\u200b\u4f18\u5148\u200b\u5b58\u50a8\u200b\u7684\u200b\u975e\u200b\u96f6\u200b\u5143\u7d20\u200b\u6570\u503c\u200b<ul> <li><code>len(a3) = #non-zero</code></li> </ul> </li> </ol>"},{"location":"Programing/Algorithm/Data_Compression/sparse_matrix.html#csc","title":"CSC","text":"<p>Compressed Sparse Column format \u200b\u901a\u8fc7\u200b\u6309\u5217\u200b\u4f18\u5148\u200b\u65b9\u5f0f\u200b\u5b58\u50a8\u200b\u975e\u96f6\u200b\u5143\u7d20\u200b\u503c\u200b\u53ca\u5176\u200b\u4f4d\u7f6e\u200b\u4fe1\u606f\u200b\u6765\u200b\u89e3\u51b3\u200b\u7a00\u758f\u200b\u77e9\u9635\u200b\u7a7a\u95f4\u200b\u6d6a\u8d39\u200b\u95ee\u9898\u200b\uff0c\u200b\u901a\u5e38\u200b\u80fd\u200b\u5c06\u200b\u5b58\u50a8\u200b\u4f7f\u7528\u91cf\u200b\u964d\u4f4e\u200b\u591a\u4e2a\u200b\u6570\u91cf\u7ea7\u200b\u3002CSC\u200b\u7279\u522b\u200b\u9002\u5408\u200b\u7528\u4e8e\u200b\u5217\u200b\u64cd\u4f5c\u200b\uff08\u200b\u5982\u200b\u5feb\u901f\u8bbf\u95ee\u200b\u4e00\u5217\u200b\uff09\u200b\u548c\u200b\u57fa\u4e8e\u200b\u77e9\u9635\u200b\u7684\u200b\u6570\u5b66\u200b\u8fd0\u7b97\u200b\uff08\u200b\u5982\u200b\u5faa\u73af\u200b\u904d\u5386\u200b\u975e\u96f6\u200b\u5143\u7d20\u200b\u5b9e\u73b0\u200b\u77e9\u9635\u200b-\u200b\u5411\u91cf\u200b\u4e58\u6cd5\u200b\uff09\u3002</p> <pre><code># Matrix.shape = (m, n)\n1   0   2\n0   0   3\n4   5   6\n\n# CSC Matrix\na1 = Array(0, 2, 3, 6)\na2 = Array(0, 2, 2, 0, 1, 2)\na3 = Array(1, 4, 5, 2, 3, 6)\n</code></pre> <ol> <li>Array 1 \u200b\u5b58\u50a8\u200b\u5217\u975e\u200b\u96f6\u200b\u5143\u7d20\u200b\u4e2a\u6570\u200b\u4fe1\u606f\u200b<ul> <li><code>len(a1) = n+1</code>\uff0c\u200b\u4e14\u200b<code>a1[0] = 0</code>\uff0c<code>a1[i]</code> \u200b\u8868\u793a\u200b\u524d\u200b<code>i</code>\u200b\u5217\u200b <code>a1[:,:i]</code> \u200b\u4e2d\u975e\u200b\u96f6\u200b\u5143\u7d20\u200b\u4e2a\u6570\u200b\u603b\u6570\u200b</li> </ul> </li> <li>Array 2 \u200b\u5b58\u50a8\u200b\u975e\u96f6\u200b\u5143\u7d20\u200b\u884c\u200b\u5750\u6807\u200b\u4fe1\u606f\u200b<ul> <li><code>len(a2) = a1[-1]</code>\uff0c<code>a2[i]</code> \u200b\u8868\u793a\u200b\u7b2c\u200b<code>i</code>\u200b\u4e2a\u200b\u975e\u200b\u96f6\u200b\u5143\u7d20\u200b\u7684\u200b\u884c\u200b\u5750\u6807\u200b\uff0c\u200b\u53ef\u200b\u901a\u8fc7\u200b <code>i</code> \u200b\u4e0e\u200b <code>a1</code> \u200b\u7edf\u8ba1\u200b\u503c\u200b\u7684\u200b\u5927\u5c0f\u200b\u5173\u7cfb\u200b\u786e\u5b9a\u200b\u5217\u200b\u5750\u6807\u200b</li> </ul> </li> <li>Array 3 \u200b\u6309\u5217\u200b\u4f18\u5148\u200b\u5b58\u50a8\u200b\u7684\u200b\u975e\u200b\u96f6\u200b\u5143\u7d20\u200b\u6570\u503c\u200b<ul> <li><code>len(a3) = a1[-1]</code></li> </ul> </li> </ol>"},{"location":"Programing/Algorithm/Data_Compression/sparse_matrix.html#csr","title":"CSR","text":"<p>Compressed Sparse Row format \u200b\u901a\u8fc7\u200b\u6309\u884c\u200b\u4f18\u5148\u200b\u65b9\u5f0f\u200b\u5b58\u50a8\u200b\u975e\u96f6\u200b\u5143\u7d20\u200b\u503c\u200b\u53ca\u5176\u200b\u4f4d\u7f6e\u200b\u4fe1\u606f\u200b\u6765\u200b\u89e3\u51b3\u200b\u7a00\u758f\u200b\u77e9\u9635\u200b\u7a7a\u95f4\u200b\u6d6a\u8d39\u200b\u95ee\u9898\u200b\uff0c\u200b\u901a\u5e38\u200b\u80fd\u200b\u5c06\u200b\u5b58\u50a8\u200b\u4f7f\u7528\u91cf\u200b\u964d\u4f4e\u200b\u591a\u4e2a\u200b\u6570\u91cf\u7ea7\u200b\u3002CSR\u200b\u7279\u522b\u200b\u9002\u5408\u200b\u7528\u4e8e\u200b\u884c\u200b\u64cd\u4f5c\u200b\uff08\u200b\u5982\u200b\u5feb\u901f\u8bbf\u95ee\u200b\u4e00\u884c\u200b\uff09\u200b\u548c\u200b\u57fa\u4e8e\u200b\u77e9\u9635\u200b\u7684\u200b\u6570\u5b66\u200b\u8fd0\u7b97\u200b\uff08\u200b\u5982\u200b\u5faa\u73af\u200b\u904d\u5386\u200b\u975e\u96f6\u200b\u5143\u7d20\u200b\u5b9e\u73b0\u200b\u77e9\u9635\u200b-\u200b\u5411\u91cf\u200b\u4e58\u6cd5\u200b\uff09\u3002</p> <pre><code># Matrix.shape = (m, n)\n1   0   2\n0   0   3\n4   5   6\n\n# CSR Matrix\na1 = Array(0, 2, 3, 6)\na2 = Array(0, 2, 2, 0, 1, 2)\na3 = Array(1, 2, 3, 4, 5, 6)\n</code></pre> <ol> <li>Array 1 \u200b\u5b58\u50a8\u200b\u884c\u975e\u200b\u96f6\u200b\u5143\u7d20\u200b\u4e2a\u6570\u200b\u4fe1\u606f\u200b<ul> <li><code>len(a1) = m+1</code>\uff0c\u200b\u4e14\u200b<code>a1[0] = 0</code>\uff0c<code>a1[i]</code> \u200b\u8868\u793a\u200b\u524d\u200b<code>i</code>\u200b\u884c\u200b <code>a1[:,:i]</code> \u200b\u4e2d\u975e\u200b\u96f6\u200b\u5143\u7d20\u200b\u4e2a\u6570\u200b\u603b\u6570\u200b</li> </ul> </li> <li>Array 2 \u200b\u5b58\u50a8\u200b\u975e\u96f6\u200b\u5143\u7d20\u200b\u5217\u200b\u5750\u6807\u200b\u4fe1\u606f\u200b<ul> <li><code>len(a2) = a1[-1]</code>\uff0c<code>a2[i]</code> \u200b\u8868\u793a\u200b\u7b2c\u200b<code>i</code>\u200b\u4e2a\u200b\u975e\u200b\u96f6\u200b\u5143\u7d20\u200b\u7684\u200b\u5217\u200b\u5750\u6807\u200b\uff0c\u200b\u53ef\u200b\u901a\u8fc7\u200b <code>i</code> \u200b\u4e0e\u200b <code>a1</code> \u200b\u7edf\u8ba1\u200b\u503c\u200b\u7684\u200b\u5927\u5c0f\u200b\u5173\u7cfb\u200b\u786e\u5b9a\u200b\u884c\u200b\u5750\u6807\u200b</li> </ul> </li> <li>Array 3 \u200b\u6309\u884c\u200b\u4f18\u5148\u200b\u5b58\u50a8\u200b\u7684\u200b\u975e\u200b\u96f6\u200b\u5143\u7d20\u200b\u6570\u503c\u200b<ul> <li><code>len(a3) = a1[-1]</code></li> </ul> </li> </ol>"},{"location":"Programing/Algorithm/Data_Compression/sparse_matrix.html#lil","title":"LIL","text":""},{"location":"Programing/Algorithm/Data_Compression/sparse_matrix.html#dok","title":"DOK","text":""},{"location":"Programing/Algorithm/Data_Compression/sparse_matrix.html#dia","title":"DIA","text":""},{"location":"Programing/Algorithm/Data_Compression/sparse_matrix.html#bsr","title":"BSR","text":"<p>Block Sparse Row</p>"},{"location":"Programing/Algorithm/Graph/graph.html","title":"Graph","text":""},{"location":"Programing/Algorithm/Graph/graph.html#_1","title":"\u56fe","text":""},{"location":"Programing/Algorithm/Graph/graph.html#_2","title":"\u6700\u77ed\u200b\u8def\u5f84\u200b\u7b97\u6cd5","text":""},{"location":"Programing/Algorithm/Graph/graph.html#dijkstra","title":"Dijkstra","text":"<p>\u200b\u7531\u200b\u8377\u5170\u200b\u8ba1\u7b97\u673a\u200b\u79d1\u5b66\u5bb6\u200bDijkstra\u200b\u63d0\u51fa\u200b\u7684\u200b\u5355\u6e90\u200b\u6700\u200b\u77ed\u200b\u8def\u5f84\u200b\u7b97\u6cd5\u200b\uff0c\u200b\u89e3\u51b3\u200b\u7684\u200b\u662f\u200b\u6709\u6743\u200b\u56fe\u4e2d\u200b\u6700\u200b\u77ed\u200b\u8def\u5f84\u200b\u95ee\u9898\u200b\u3002Dijkstra\u200b\u7b97\u6cd5\u200b\u4e3b\u4ece\u200b\u8d77\u59cb\u200b\u70b9\u200b\u5f00\u59cb\u200b\uff0c\u200b\u91c7\u7528\u200b\u8d2a\u5fc3\u200b\u7b97\u6cd5\u200b\u7684\u200b\u7b56\u7565\u200b\uff0c\u200b\u6d41\u7a0b\u200b\u5982\u4e0b\u200b</p> <ol> <li>\\(start\\_node \\rightarrow S\\), \\(V\\text{-}S \\rightarrow T\\), <code>distance=[inf]*N, distance[start_node]=0</code></li> <li>\u200b\u904d\u5386\u200b \\(T\\) \u200b\u4e2d\u200b\u7684\u200b\u9876\u70b9\u200b\uff0c\u200b\u9009\u62e9\u200b\u8ddd\u200b <code>start_node</code> \u200b\u6700\u8fd1\u200b\u7684\u200b\u65b0\u200b\u9876\u70b9\u200b \\(v\\)</li> <li>\\(S\\text{+}v \\rightarrow S\\), \\(T\\text{-}v \\rightarrow T\\)</li> <li>\u200b\u66f4\u65b0\u200b\u65b0\u589e\u200b\u8282\u70b9\u200b\\(v\\)\u200b\u540e\u200b\u7684\u200b <code>distance</code> \u200b\u6570\u7ec4\u200b\uff08\u200b\u4fdd\u7559\u200b\u6700\u77ed\u200b\u8def\u5f84\u200b\uff09\uff0c\u200b\u91cd\u590d\u200bstep 2\u200b\u76f4\u5230\u200b <code>T==\u2205</code></li> </ol> Python <pre><code>def dijkstra(graph, start_node):\n    N = len(graph)                      # |V|\n    used_node = [False] * N             # S = [i for i, v in enumerate(used_node) if v]\n                                        # T = [i for i, v in enumerate(used_node) if not v]\n    distance = [math.inf] * N           # start_node\u200b\u81f3\u200b\u5404\u200b\u8282\u70b9\u200b\u7684\u200b\u6700\u200b\u77ed\u200b\u8def\u5f84\u200b\u8ddd\u79bb\u200b\u6570\u7ec4\u200b\n    distance[start_node] = 0            # start_node\u200b\u81f3\u200b\u81ea\u8eab\u200b\u7684\u200b\u6700\u200b\u77ed\u200b\u8def\u5f84\u200b\u4e3a\u200b0\n    pre_node = list(range(N))           # \u200b\u5404\u200b\u8282\u70b9\u200b\u81f3\u200bstart_node\u200b\u7684\u200b\u8def\u5f84\u200b\u7684\u200b\u4e0a\u200b\u4e00\u200b\u8282\u70b9\u200b\uff0c\u200b\u521d\u59cb\u5316\u200b\u4e3a\u200b\u81ea\u8eab\u200b\n\n    while used_node.count(False):\n        min_value = math.inf\n        min_value_index = -1\n\n        # \u200b\u904d\u5386\u200b\u627e\u5230\u200bstart_node\u200b\u81f3\u200bT\u200b\u4e2d\u8ddd\u79bb\u200b\u6700\u8fd1\u200b\u7684\u200b\u8282\u70b9\u200bv\n        for index in range(N):\n            if not used_node[index] and distance[index] &lt; min_value:\n                min_value = distance[index]\n                min_value_index = index\n\n        # S + v -&gt; S\n        used_node[min_value_index] = True\n\n        # distance[v] \u200b\u8868\u793a\u200b `start_node -&gt; v` \u200b\u7684\u200b\u6700\u200b\u77ed\u8ddd\u79bb\u200b\n        # distance[index] = min(distance[index], distance[min_value_index] + graph[min_value_index][index])\n        for index in range(N):\n            if distance[min_value_index] + graph[min_value_index][index] &lt; distance[index]:\n                distance[index] = distance[min_value_index] + graph[min_value_index][index]\n                pre_node[index] = min_value_index\n\n    # concat route and distance\n    routes = []\n    for i in range(N):\n        ret = [i]\n        pre_n = pre_node[i]\n        while pre_n != start_node:\n            ret.append(pre_n)\n            pre_n = pre_node[pre_n]\n        ret.append(start_node)\n        routes.append({'distance': distance[i], 'route': ret[::-1]})\n\n    return routes\n</code></pre> <ul> <li>\u200b\u662f\u200b\u4e00\u4e2a\u200bdp\u200b\u7684\u200b\u8d2a\u5fc3\u200b\u7b97\u6cd5\u200b</li> <li>\u200b\u8981\u6c42\u200b\u6240\u6709\u200b\u8fb9\u200b\u7684\u200b\u6743\u91cd\u200b\u975e\u8d1f\u200b</li> <li>\u200b\u8fd4\u56de\u200b\u6307\u5b9a\u200b\u5355\u6e90\u200b(start_node)\u200b\u81f3\u200b\u5176\u5b83\u200b\u9876\u70b9\u200b\u7684\u200b\u6700\u200b\u77ed\u200b\u8def\u5f84\u200b(\u200b\u548c\u200b\u8def\u5f84\u200b)\uff0c\u200b\u4f46\u200b\u4e0d\u200b\u4fdd\u8bc1\u200b\u662f\u200b\u6700\u5c0f\u200b\u751f\u6210\u200b\u6811\u200b</li> </ul>"},{"location":"Programing/Algorithm/Graph/graph.html#floyd","title":"Floyd","text":"<p>\u200b\u7531\u200b1978\u200b\u5e74\u200b\u56fe\u7075\u5956\u200b\u83b7\u5f97\u8005\u200b\u3001\u200b\u65af\u5766\u798f\u5927\u5b66\u200b\u8ba1\u7b97\u673a\u79d1\u5b66\u200b\u7cfb\u200b\u6559\u6388\u200bRobert Floyd\u200b\u63d0\u51fa\u200b\u7684\u200b\u591a\u6e90\u200b\u6700\u200b\u77ed\u200b\u8def\u5f84\u200b\u7b97\u6cd5\u200b\uff0c\u200b\u7a20\u5bc6\u200b\u56fe\u200b\u6548\u679c\u200b\u6700\u4f73\u200b\uff0c\u200b\u6d41\u7a0b\u200b\u5982\u4e0b\u200b\uff1a</p> <ol> <li>\u200b\u63d2\u5165\u200b\u9876\u70b9\u200b \\(v_i\\)</li> <li>\u200b\u66f4\u65b0\u200b\u63d2\u5165\u200b\u8be5\u200b\u9876\u70b9\u200b\u540e\u200b\u6240\u6709\u200b <code>start_node</code> \u200b\u5230\u200b <code>end_node</code> \u200b\u7684\u200b\u6700\u200b\u77ed\u8ddd\u79bb\u200b</li> <li>\u200b\u91cd\u590d\u200bstep 1 \u200b\u76f4\u5230\u200b\u63d2\u5165\u200b\u4e86\u200b\u6240\u6709\u200b\u9876\u70b9\u200b</li> </ol> python <pre><code>def floyd(graph):\n    # graph[i][j] \u200b\u8868\u793a\u200bstart_node `i` \u200b\u81f3\u200b end_node `j` \u200b\u7684\u200b\u6700\u200b\u77ed\u8ddd\u79bb\u200b\n    # min(Dis(i,j), Dis(i,k) + Dis(k,j))\n    N = len(graph)\n    for k in range(N):\n        for i in range(N):\n            for j in range(N):\n                if graph[i][j] &gt; graph[i][k] + graph[k][j]:\n                    graph[i][j] = graph[i][k] + graph[k][j]\n    return graph\n</code></pre> <ul> <li>\u200b\u662f\u200b\u4e00\u4e2a\u200bdp\u200b\u7b97\u6cd5\u200b\uff0c\u200b\u672c\u8d28\u200b\u4e0a\u200b\u662f\u4ece\u200b\u4e00\u4e2a\u4e2a\u200b\u6700\u77ed\u5b50\u200b\u7247\u6bb5\u200b\u56fe\u5230\u200b\u5168\u200b\u8fde\u901a\u200b\u56fe\u200b\u7684\u200b\u8fc7\u7a0b\u200b</li> <li>\u200b\u8fb9\u200b\u7684\u200b\u6743\u91cd\u200b\u53ef\u200b\u4e3a\u200b\u8d1f\u6570\u200b\uff0c\u200b\u4f46\u200b\u5982\u679c\u200b\u5b58\u5728\u200b\u8d1f\u200b\u6743\u91cd\u200b\u7684\u200b\u73af\u200b\uff0c\u200b\u7b97\u6cd5\u200b\u53ef\u80fd\u200b\u65e0\u6cd5\u200b\u6b63\u786e\u200b\u5de5\u4f5c\u200b</li> <li>\u200b\u8fd4\u56de\u200b\u6240\u6709\u200b\u5355\u6e90\u200b(start_node)\u200b\u81f3\u200b\u5176\u5b83\u200b\u9876\u70b9\u200b\u7684\u200b\u6700\u200b\u77ed\u8ddd\u79bb\u200b\uff0c\u200b\u4f46\u200b\u4e0d\u200b\u4fdd\u8bc1\u200b\u662f\u200b\u6700\u5c0f\u200b\u751f\u6210\u200b\u6811\u200b</li> </ul>"},{"location":"Programing/Algorithm/Graph/graph.html#prim","title":"Prim","text":"<ol> <li>\\(start\\_node \\rightarrow S\\), \\(V\\text{-}S \\rightarrow T\\), \u200b\u7a7a\u56fe\u200b \\(G\\)</li> <li>\u200b\u904d\u5386\u200b \\(T\\) \u200b\u4e2d\u200b\u7684\u200b\u9876\u70b9\u200b\uff0c\u200b\u9009\u62e9\u200b\u8ddd\u200b \\(S\\) \u200b\u6700\u8fd1\u200b\u7684\u200b\u8fb9\u200b\\(e\\) \u200b\u4ee5\u53ca\u200b\u65b0\u200b\u9876\u70b9\u200b \\(v\\)</li> <li>\\(S\\text{+}v \\rightarrow S\\), \\(T\\text{-}v \\rightarrow T\\), \\(G\\text{+}e\\rightarrow G\\)</li> <li>\u200b\u91cd\u590d\u200bstep 2\u200b\u76f4\u5230\u200b <code>T==\u2205</code></li> </ol> <ul> <li>\u200b\u4e0e\u200b<code>dijkstra</code>\u200b\u533a\u522b\u200b\u5728\u4e8e\u200b\u540e\u8005\u200b\u662f\u200bdp\u200b\u7b97\u6cd5\u200b\uff0c\u200b\u4f20\u9012\u200b\u56e0\u5b50\u200b\u662f\u200b\u5230\u200b<code>start_node</code>\u200b\u7684\u200b\u6700\u200b\u77ed\u8ddd\u79bb\u200b\uff0c\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u662f\u200b\u65b0\u8fb9\u200b<code>e</code>\u200b\u5230\u5b50\u200b\u56fe\u200b\u7684\u200b\u6700\u200b\u77ed\u8ddd\u79bb\u200b</li> </ul>"},{"location":"Programing/Algorithm/Graph/graph.html#kruskal","title":"Kruskal","text":"<ol> <li>\u200b\u8fb9\u200b\u4fe1\u606f\u200b \\(E\\)\uff0c\u200b\u7a7a\u56fe\u200b \\(G\\)\uff0c\u200b\u521d\u59cb\u5316\u200b\u5404\u200b\u9876\u70b9\u200b\u5e76\u200b\u67e5\u96c6\u200b<code>union_set</code>\u200b\u4e3a\u200b\u81ea\u8eab\u200b</li> <li>\u200b\u9009\u53d6\u200b\u6743\u91cd\u200b\u6700\u5c0f\u200b\u7684\u200b\u8fb9\u200b \\(e \\in E\\)\uff0c\u200b\u8981\u6c42\u200b\\(e\\)\u200b\u4e24\u7aef\u200b\u9876\u70b9\u200b\u4e0d\u80fd\u200b\u540c\u65f6\u200b\u5904\u200b\u4e00\u5e76\u200b\u67e5\u96c6\u200b\uff08\u200b\u5b50\u56fe\u200b\uff09\u200b\u4e2d\u200b</li> <li>\u200b\u5c06\u200b \\(e\\) \u200b\u52a0\u5165\u200b \\(G\\)\u3001\u200b\u57fa\u4e8e\u200b\u4e24\u7aef\u200b\u9876\u70b9\u200b\u66f4\u65b0\u200b\u5e76\u200b\u67e5\u96c6\u200b<code>union_set</code>\uff0c\u200b\u91cd\u590d\u200b step 2 \u200b\u76f4\u5230\u200b\u6240\u6709\u200b\u9876\u70b9\u200b\u8fde\u901a\u200b</li> </ol>"},{"location":"Programing/Algorithm/String/string.html","title":"String","text":""},{"location":"Programing/Algorithm/String/string.html#kmp","title":"KMP","text":"<p>D.E.Knuth\uff0cJ.H.Morris\u200b\u548c\u200bV.R.Pratt\u200b\u63d0\u51fa\u200b\u7684\u200b\u9ad8\u6548\u200b\u5b57\u7b26\u4e32\u200b\u5339\u914d\u200b\u7b97\u6cd5\u200b\uff0c\u200b\u8be5\u200b\u7b97\u6cd5\u200b\u7684\u200b\u6838\u5fc3\u200b\u662f\u200b\u5229\u7528\u200b\u5339\u914d\u200b\u5931\u8d25\u200b\u540e\u200b\u7684\u200b\u4fe1\u606f\u200b\uff0c\u200b\u5c3d\u91cf\u51cf\u5c11\u200b\u6a21\u5f0f\u200b\u4e32\u200b\uff08\u200b\u5b50\u4e32\u200b\uff09\u200b\u4e0e\u200b\u4e3b\u4e32\u200b\u7684\u200b\u5339\u914d\u200b\u6b21\u6570\u200b</p> <ul> <li>\u200b\u4e3a\u200b\u6a21\u5f0f\u200b\u4e32\u200b\u6784\u5efa\u200b<code>next</code>\u200b\u6570\u7ec4\u200b\uff0c<code>next[i]</code>\u200b\u8868\u793a\u200b\u5f53\u200b\u6a21\u5f0f\u200b\u4e32\u200b\u7684\u200b\u7b2c\u200bi\u200b\u4e2a\u200b\u5143\u7d20\u200b\u4e0e\u200b\u76ee\u6807\u200b\u4e32\u200b\u5339\u914d\u200b\u5931\u8d25\u200b\u65f6\u200b\uff0c\u200b\u5feb\u901f\u200b\u4f7f\u7528\u200b\u6a21\u5f0f\u200b\u4e32\u200b\u7684\u200b\u7b2c\u200b<code>next[i]</code>\u200b\u4e2a\u200b\u5143\u7d20\u200b\u4e0e\u200b\u76ee\u6807\u200b\u4e32\u200b\u5143\u7d20\u200b\u8fdb\u884c\u200b\u5339\u914d\u200b</li> <li>\u200b\u5339\u914d\u200b\u5931\u8d25\u200b\u65f6\u200b\uff0c\u200b\u6a21\u5f0f\u200b\u4e32\u200b\u53f3\u79fb\u200b\u8ddd\u79bb\u200b=\u200b\u5931\u914d\u200b\u5b57\u7b26\u200b\u6240\u5728\u4f4d\u7f6e\u200b-\u200b\u5931\u914d\u200b\u5b57\u7b26\u200b\u5bf9\u5e94\u200b\u7684\u200bnext\u200b\u503c\u200b <p>\u200b\u590d\u6742\u5ea6\u200b\u4e3a\u200b\\(O(m+n)\\)</p> </li> </ul> <pre><code>def get_next(pattern_text):\n    n = len(pattern_text)\n    k, j = -1, 0                # k: next\u200b\u6570\u7ec4\u200b\u503c\u200b\n                                # j: pattern_text index\n    next = [-1] * n\n    while j &lt; n-1:\n        # \u200b\u8d77\u59cb\u200b\u65f6\u523b\u200b\u6216\u200b\u4e0b\u200b\u4e00\u200b\u5143\u7d20\u200b\u5339\u914d\u200b\u6210\u529f\u200b\n        if k == -1 or pattern_text[j] == pattern_text[k]:\n            k += 1\n            j += 1\n            next[j] = k\n        else:\n            k = next[k]\n    return next\n\ndef kmp_str(text, pattern_text):\n    i, j = 0, 0\n    next = get_next(pattern_text)\n    max_common_len = 0\n    match_index = -1\n    while i &lt; len(text) and j &lt; len(pattern_text):\n        if j == -1 or text[i] == pattern_text[j]:\n            i += 1\n            j += 1\n        else:\n            j = next[j]\n        max_common_len = max(max_common_len, j)\n        if match_index == -1 and j == len(pattern_text):\n            match_index = i - j\n    return match_index, max_common_len\n</code></pre>"},{"location":"Programing/Container/Docker/index.html","title":"Docker","text":""},{"location":"Programing/Container/Docker/index.html#_1","title":"\u4fe1\u606f\u200b\u67e5\u770b","text":"<ol> <li><code>docker --version</code></li> <li><code>docker ps</code>\uff0c\u200b\u67e5\u770b\u200b\u8fd0\u884c\u200b\u7684\u200b docker \u200b\u5bb9\u5668\u200b\u4fe1\u606f\u200b<ul> <li><code>-a</code>\uff0c\u200b\u663e\u793a\u200b\uff08\u200b\u5305\u62ec\u200b\u672a\u200b\u8fd0\u884c\u200b\u7684\u200b\uff09\u200b\u6240\u6709\u200b docker \u200b\u5bb9\u5668\u200b\u4fe1\u606f\u200b </li> </ul> </li> <li><code>docker image</code>\uff0c\u200b\u5217\u51fa\u200b\u6240\u6709\u200b\u955c\u50cf\u200b</li> </ol>"},{"location":"Programing/Container/Docker/index.html#_2","title":"\u542f\u505c\u200b\u3001\u200b\u589e\u5220\u200b\u5bb9\u5668","text":"<ol> <li><code>docker build</code></li> <li><code>docker rm container_id_or_name</code>\uff0c\u200b\u5220\u9664\u200b\u8fd0\u884c\u200b\u6307\u5b9a\u200b docker \u200b\u5bb9\u5668\u200b</li> <li><code>docker run</code></li> <li><code>docker stop container_id_or_name</code>\uff0c\u200b\u505c\u6b62\u200b\u8fd0\u884c\u200b\u6307\u5b9a\u200b docker \u200b\u5bb9\u5668\u200b</li> <li><code>docker exec</code></li> </ol>"},{"location":"Programing/Container/Docker/index.html#_3","title":"\u4ed3\u5e93\u200b\u64cd\u4f5c","text":"<ol> <li><code>docker pull</code></li> <li><code>docker push</code></li> <li><code>docker login</code></li> <li><code>docker logout</code></li> <li><code>docker search</code></li> <li><code>docker tag</code></li> <li><code>docker inspect</code></li> <li><code>docker rmi</code></li> </ol>"},{"location":"Programing/Container/K8s/index.html","title":"K8s","text":"<p>K8s\uff0c\u200b\u5168\u200b\u79f0\u4e3a\u200b Kubernetes\uff0c8\u200b\u8868\u793a\u200b\u4e2d\u95f4\u200b8\u200b\u4f4d\u200b\u5b57\u6bcd\u200b\uff0c</p>"},{"location":"Programing/FTP/LFTP/index.html","title":"LFTP","text":""},{"location":"Programing/FTP/LFTP/index.html#_1","title":"\u767b\u5f55\u200b\u547d\u4ee4","text":"<pre><code>lftp &lt;user&gt;:&lt;pwd&gt;@&lt;ip&gt;:&lt;port&gt;\n\nlftp nisp:nisp163@sa-dianxin-ftp.hz.163.org\n</code></pre>"},{"location":"Programing/FTP/LFTP/index.html#_2","title":"\u8fdc\u7aef\u200b\u547d\u4ee4","text":"<pre><code>ls          # \u200b\u663e\u793a\u200b\u8fdc\u7aef\u200b\u6587\u4ef6\u200b\u5217\u8868\u200b\ncd          # \u200b\u5207\u6362\u200b\u8fdc\u7aef\u200b\u76ee\u5f55\u200b\npwd         # \u200b\u663e\u793a\u200b\u8fdc\u7aef\u200b\u76ee\u5f55\u200b     \nmv          # \u200b\u79fb\u52a8\u200b\u8fdc\u7aef\u200b\u6587\u4ef6\u200b(\u200b\u4e5f\u200b\u53ef\u200b\u8fdb\u884c\u200b\u8fdc\u7aef\u200b\u6587\u4ef6\u200b\u6539\u540d\u200b)\nmrm         # \u200b\u6279\u91cf\u200b\u5220\u9664\u200b\u591a\u4e2a\u200b\u8fdc\u7aef\u200b\u6587\u4ef6\u200b(\u200b\u652f\u6301\u200b\u901a\u914d\u7b26\u200b*)\nrm          # \u200b\u5220\u9664\u200b\u8fdc\u7aef\u200b\u6587\u4ef6\u200b\nmkdir       # \u200b\u65b0\u5efa\u200b\u8fdc\u7aef\u200b\u76ee\u5f55\u200b\nrmdir       # \u200b\u5220\u9664\u200b\u8fdc\u7aef\u200b\u76ee\u5f55\u200b\ndu          # \u200b\u8ba1\u7b97\u200b\u8fdc\u7aef\u200b\u76ee\u5f55\u200b\u5927\u5c0f\u200b\n</code></pre>"},{"location":"Programing/FTP/LFTP/index.html#_3","title":"\u672c\u5730\u200b\u547d\u4ee4","text":"<pre><code>!ls         # \u200b\u663e\u793a\u200b\u672c\u5730\u200b\u6587\u4ef6\u200b\u5217\u8868\u200b\n!rm         # \u200b\u5220\u9664\u200b\u672c\u5730\u200b\u6587\u4ef6\u200b\nlcd         # \u200b\u5207\u6362\u200b\u672c\u5730\u200b\u76ee\u5f55\u200b \nlpwd        # \u200b\u663e\u793a\u200b\u672c\u5730\u200b\u76ee\u5f55\u200b \n</code></pre>"},{"location":"Programing/FTP/LFTP/index.html#_4","title":"\u4e0b\u8f7d\u200b\u547d\u4ee4","text":"<pre><code>get         # \u200b\u4e0b\u8f7d\u200b\u8fdc\u7aef\u200b\u6587\u4ef6\u200b\nmget        # \u200b\u6279\u91cf\u200b\u4e0b\u8f7d\u200b\u8fdc\u7aef\u200b\u6587\u4ef6\u200b(\u200b\u652f\u6301\u200b\u901a\u914d\u7b26\u200b*)\uff0c\u200b\u5b8c\u5168\u200b\u517c\u5bb9\u200bget\npget        # \u200b\u4f7f\u7528\u200b\u591a\u4e2a\u200b\u7ebf\u7a0b\u200b\u6765\u200b\u4e0b\u8f7d\u200b\u8fdc\u7aef\u200b\u6587\u4ef6\u200b, \u200b\u9884\u8bbe\u200b\u4e3a\u200b\u4e94\u4e2a\u200b\u3002 \nmirror      # \u200b\u4e0b\u8f7d\u200b\u6574\u4e2a\u200b\u76ee\u5f55\u200b\n</code></pre>"},{"location":"Programing/FTP/LFTP/index.html#_5","title":"\u4e0a\u4f20\u200b\u547d\u4ee4","text":"<pre><code>put         # \u200b\u4e0a\u4f20\u200b\u6587\u4ef6\u200b\u81f3\u200b\u8fdc\u7aef\u200b\nmput        # \u200b\u6279\u91cf\u200b\u4e0a\u4f20\u200b\u591a\u4e2a\u200b\u6587\u4ef6\u200b(\u200b\u652f\u6301\u200b\u901a\u914d\u7b26\u200b*)\nmirror -R   # \u200b\u4e0a\u4f20\u200b\u6574\u4e2a\u200b\u76ee\u5f55\u200b\n</code></pre>"},{"location":"Programing/FTP/LFTP/index.html#_6","title":"\u9000\u51fa\u200b\u547d\u4ee4","text":"<pre><code>bye\nexit\n</code></pre>"},{"location":"Programing/Git/index.html","title":"Git","text":""},{"location":"Programing/Git/index.html#_1","title":"\u57fa\u672c\u6982\u5ff5","text":""},{"location":"Programing/Git/index.html#_2","title":"\u57fa\u672c\u64cd\u4f5c","text":"<ul> <li><code>git status</code></li> </ul>"},{"location":"Programing/Git/index.html#_3","title":"\u4ed3\u5e93\u200b\u64cd\u4f5c","text":""},{"location":"Programing/Git/index.html#_4","title":"\u5de5\u4f5c\u200b\u533a\u200b \u27f7 \u200b\u6682\u5b58\u533a","text":"<ol> <li><code>git add</code>\uff0c\u200b\u5c06\u200b\u5de5\u4f5c\u200b\u533a\u200b\u66f4\u65b0\u200b\u7684\u200b\u6587\u4ef6\u200b\u6dfb\u52a0\u200b\u5230\u200b\u6682\u5b58\u533a\u200b</li> <li> <p><code>git reset</code>\uff0c\u200b\u5c06\u200b\u6682\u5b58\u533a\u200b\u7684\u200b\u6587\u4ef6\u200b\u8fd8\u539f\u200b\u5230\u200b\u5de5\u4f5c\u200b\u533a\u200b\uff0c\u200b\u5c06\u200b\u6682\u5b58\u533a\u200b\u6307\u5b9a\u200b\u6587\u4ef6\u200b\u72b6\u6001\u200b\u56de\u9000\u200b</p> \u200b\u6a21\u5f0f\u200b Index WorkSpace \u200b\u5371\u9669\u6027\u200b <code>--soft</code> \u200b\u4e0d\u200b\u6539\u53d8\u200b \u200b\u4e0d\u200b\u6539\u53d8\u200b \u200b\u4f4e\u200b <code>--mixed</code> \u200b\u91cd\u7f6e\u200b \u200b\u4e0d\u200b\u6539\u53d8\u200b \u200b\u4e2d\u200b <code>--hard</code> \u200b\u91cd\u7f6e\u200b \u200b\u91cd\u7f6e\u200b \u200b\u9ad8\u200b <pre><code>&lt;!-- \u200b\u5c06\u200b\u7f13\u5b58\u200b\u533a\u200b(\u200b\u6307\u5b9a\u200b\u6587\u4ef6\u200b)\u200b\u56de\u9000\u200b\u81f3\u200b\u6307\u5b9a\u200b\u7248\u672c\u200b\u63d0\u4ea4\u200b\u72b6\u6001\u200b --&gt;\ngit reset (--mixed) (HEAD)\ngit reset HEAD~n                        # \u200b\u56de\u9000\u200b\u81f3\u4e0a\u200bn\u200b\u4e2a\u200b\u7248\u672c\u200b\ngit reset &lt;commit-hash&gt;\ngit reset &lt;commit-hash&gt; &lt;file_name&gt;     # \u200b\u64a4\u9500\u200b\u6587\u4ef6\u200b\u7f13\u5b58\u200b\n</code></pre> </li> <li> <p><code>git rm</code>\uff0c\u200b\u5c06\u200b\u6307\u5b9a\u200b\u6587\u4ef6\u200b\u4ece\u200b\u6682\u5b58\u533a\u200b\u79fb\u9664\u200b</p> <pre><code>\n</code></pre> </li> </ol>"},{"location":"Programing/Git/index.html#_5","title":"\u6682\u5b58\u533a\u200b \u27f7 \u200b\u672c\u5730\u200b\u4ed3\u5e93","text":""},{"location":"Programing/Git/index.html#_6","title":"\u672c\u5730\u200b\u4ed3\u5e93\u200b \u27f7 \u200b\u8fdc\u7a0b\u200b\u4ed3\u5e93","text":""},{"location":"Programing/Git/index.html#_7","title":"\u5206\u652f\u200b\u64cd\u4f5c","text":""},{"location":"Programing/Git/index.html#_8","title":"\u65e5\u5fd7\u200b\u76f8\u5173","text":""},{"location":"Programing/Git/index.html#_9","title":"\u914d\u7f6e\u6587\u4ef6","text":""},{"location":"Programing/Git/index.html#git","title":"\u5e38\u7528\u200bgit\u200b\u4ed3\u5e93","text":"<ol> <li>github  </li> <li>gitlab</li> </ol>"},{"location":"Programing/HTML/CSS/index.html","title":"CSS","text":""},{"location":"Programing/HTML/CSS/index.html#css","title":"\u591a\u7ea7\u200bcss","text":"<pre><code>&lt;!-- \u200b\u5c42\u7ea7\u200b\u5173\u7cfb\u200b\uff1ahighlight.ol.li --&gt;\n.highlight ol li {\n    ...\n}\n</code></pre> <ul> <li>.\u200b\u5f00\u5934\u200b\u8868\u793a\u200b class \u200b\u9009\u62e9\u5668\u200b\uff0c\u200b\u5982\u200b <code>.class {...}</code></li> <li> </li> <li>\u200b\u65e0\u200b\u5f00\u5934\u200b\u8868\u793a\u200b \u200b\u6807\u7b7e\u200b\u9009\u62e9\u9898\u200b\uff0c\u200b\u5982\u200b <code>p {...}</code></li> </ul>"},{"location":"Programing/HTML/CSS/index.html#id-id","title":"\u5f00\u5934\u200b\u8868\u793a\u200b id \u200b\u9009\u62e9\u5668\u200b\uff0c\u200b\u5982\u200b <code>#id {...}</code>","text":""},{"location":"Programing/HTML/CSS/index.html#_1","title":"\u81ea\u5b9a\u4e49\u200b\u6807\u7b7e","text":"<pre><code>abbr {\n  font-style: italic;\n  color: chocolate;\n}\n&lt;p&gt;\n  You can use &lt;abbr&gt;CSS&lt;/abbr&gt; (Cascading Style Sheets) to style your &lt;abbr&gt;HTML&lt;/abbr&gt; (HyperText Markup Language).\n&lt;/p&gt;\n</code></pre>"},{"location":"Programing/HTML/html/index.html","title":"html","text":""},{"location":"Programing/HTML/html/index.html#p","title":"P\u200b\u6807\u7b7e\u200b\u5185\u200b\u6362\u884c","text":"<pre><code>&lt;p&gt; a b &lt;br&gt; c d&lt;/p&gt;\n</code></pre>"},{"location":"Programing/HTML/html/index.html#_1","title":"\u5916\u90e8\u200b\u94fe\u63a5","text":"<pre><code>&lt;a href=\"https://www.example.com\"&gt;\u200b\u8bbf\u95ee\u200bExample\u200b\u7f51\u7ad9\u200b&lt;/a&gt;\n</code></pre>"},{"location":"Programing/HTML/html/index.html#_2","title":"\u56fe\u7247","text":"<ol> <li> <p>\u200b\u5355\u56fe\u200b </p><pre><code>&lt;div class=\"one-image-container\"&gt;\n    &lt;img src=\"https://fengyan-wby.fun/2023/11/15/%E5%AD%97%E5%BD%A2%E7%89%B9%E5%BE%81%E7%9A%84%E6%8F%90%E5%8F%96%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/3.png\" style=\"width: 80%;\"&gt;\n    &lt;p style=\"text-align: center;\"&gt;\u200b\u56fe\u7247\u200b\u6807\u9898\u200b&lt;/p&gt;\n&lt;/div&gt;\n</code></pre><p></p> </li> <li> <p>\u200b\u591a\u56fe\u200b </p><pre><code>&lt;!-- &lt;div style=\"text-align: center; display: block;\" class=\"image-container\"&gt; --&gt;\n&lt;div class=\"row-image-container\"&gt;\n    &lt;div&gt;\n        &lt;img src=\"https://fengyan-wby.fun/2023/11/15/%E5%AD%97%E5%BD%A2%E7%89%B9%E5%BE%81%E7%9A%84%E6%8F%90%E5%8F%96%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/3.png\"&gt;\n        &lt;p&gt;\u200b\u56fe\u7247\u200b1\u200b\u7684\u200b\u6807\u9898\u200b&lt;/p&gt;\n    &lt;/div&gt;\n    &lt;div&gt;\n        &lt;img src=\"https://fengyan-wby.fun/2023/11/15/%E5%AD%97%E5%BD%A2%E7%89%B9%E5%BE%81%E7%9A%84%E6%8F%90%E5%8F%96%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/3.png\"&gt;\n        &lt;p&gt;\u200b\u56fe\u7247\u200b2\u200b\u7684\u200b\u6807\u9898\u200b&lt;/p&gt;\n    &lt;/div&gt;\n    &lt;div&gt;\n        &lt;img src=\"https://fengyan-wby.fun/2023/11/15/%E5%AD%97%E5%BD%A2%E7%89%B9%E5%BE%81%E7%9A%84%E6%8F%90%E5%8F%96%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/3.png\"&gt;\n        &lt;p&gt;\u200b\u56fe\u7247\u200b2\u200b\u7684\u200b\u6807\u9898\u200b&lt;/p&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n&lt;!-- &lt;/div&gt; --&gt;\n</code></pre><p></p> </li> <li> <p>\u200b\u7f51\u56fe\u200b </p><pre><code>{{&lt;https://fengyan-wby.fun/2023/11/15/%E5%AD%97%E5%BD%A2%E7%89%B9%E5%BE%81%E7%9A%84%E6%8F%90%E5%8F%96%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/3.png&gt;}}\n</code></pre><p></p> </li> </ol>"},{"location":"Programing/HTML/html/index.html#list","title":"list","text":"<pre><code>&lt;div class=\"ol-test\" type=\"A\"&gt;\n    &lt;ol &gt;\n        &lt;li&gt;hello &lt;/li&gt;\n        &lt;li&gt;hello &lt;/li&gt;\n        &lt;li&gt;hello &lt;/li&gt;\n    &lt;/ol&gt;\n&lt;/div&gt;\n\n\n&lt;ul&gt;\n    &lt;li&gt;hello &lt;/li&gt;\n    &lt;li&gt;hello &lt;/li&gt;\n    &lt;li&gt;hello &lt;/li&gt;\n&lt;/ul&gt;\n</code></pre>"},{"location":"Programing/Java/index.html","title":"Java","text":""},{"location":"Programing/Java/index.html#_1","title":"\u591a\u7ebf\u7a0b","text":""},{"location":"Programing/Java/index.html#_2","title":"\u7ebf\u7a0b\u200b\u6c60","text":"<ul> <li>ExecutorService</li> </ul>"},{"location":"Programing/Java/index.html#_3","title":"\u8fdb\u9636\u200b\uff1a\u200b\u6587\u4ef6\u200b\u8bfb\u5199","text":""},{"location":"Programing/Java/index.html#_4","title":"\u6570\u636e\u683c\u5f0f","text":"<ul> <li>JSONObject\uff1ajson\u200b\u683c\u5f0f\u200b\u6570\u636e\u5904\u7406\u200b</li> </ul>"},{"location":"Programing/Java/index.html#_5","title":"\u8f93\u5165\u8f93\u51fa\u200b\u6d41","text":"<ul> <li>IOUtils\uff1aIO\u200b\u5de5\u5177\u200b\u7c7b\u200b</li> <li>Bufferedreader\uff1a\u200b\u7f13\u51b2\u200b\u8f93\u5165\u200b\u6d41\u200b</li> </ul>"},{"location":"Programing/Java/libs/file_format.html","title":"File format","text":""},{"location":"Programing/Java/libs/file_format.html#json","title":"JSON","text":"JSONObject<pre><code>// json.loads_map\uff0c\u200b\u5de6\u5f0f\u200b\u6307\u5b9a\u200b{\u200b\u952e\u200b: \u200b\u503c\u200b}\u200b\u7c7b\u578b\u200b\nMap&lt;String, String&gt; map = JSONObject.parseObject(line, Map.class)\n\n// json.loads_list\uff0c\u200b\u65b9\u6cd5\u200b\u4e2d\u200b\u6307\u5b9a\u200blist\u200b\u4e2d\u200b\u5143\u7d20\u200b\u7c7b\u578b\u200b\nList&lt;Integer&gt; list = JSONObject.parseArray(a, Integer.class)\n\n// json.dumps\nJSONObject.toJSONString(object)\n</code></pre>"},{"location":"Programing/Java/libs/iostream.html","title":"Iostream","text":""},{"location":"Programing/Java/libs/iostream.html#ioutils","title":"IOUtils","text":"<pre><code>// \u200b\u6587\u4ef6\u200b\u8bfb\u53d6\u200b\uff0cIOUtiles.readLines\u200b\u4e00\u6b21\u6027\u200b\u8bfb\u53d6\u200b\u4e86\u200b\u6240\u6709\u200b\u884c\u200b\u6570\u636e\u200b\nList&lt;String&gt; samples = new LinkedList&lt;&gt;();\nInputStream is = new FileInputStream(path);\nfor (String line : IOUtils.readLines(is, \"utf8\")) {\n    samples.add(JSON.parseObject(line, CorpusTextSample.class));\n}\n</code></pre>"},{"location":"Programing/Java/libs/iostream.html#bufferedreader","title":"BufferedReader","text":"<pre><code>// BufferedReader\u200b\u6bcf\u6b21\u200b\u8bfb\u200b\u4e00\u884c\u200b\u6570\u636e\u200b\nString path = \"\";\nString inFileName = \"\";\nString outFileName = \"\";\nString line;\ntry (InputStream in = new FileInputStream(path + inFileName);\n     BufferedReader reader = new BufferedReader(new InputStreamReader(in, StandardCharsets.UTF_8));\n     OutputStream out = new FileOutputStream(path + outFileName);\n     Writer writer = new OutputStreamWriter(out, StandardCharsets.UTF_8)) {\n    while ((line = reader.readLine()) != null) {\n\n    }\n}\n</code></pre>"},{"location":"Programing/Java/libs/thread_pool.html","title":"Thread pool","text":""},{"location":"Programing/Java/libs/thread_pool.html#executorservice","title":"Executorservice","text":"<pre><code>ExecutorService executor = Executors.newFixedThreadPool(poolSize);\n\n// \u200b\u63d0\u4ea4\u200b\u591a\u4e2a\u200b\u4efb\u52a1\u200b\u7ed9\u200b\u7ebf\u7a0b\u200b\u6c60\u200b\nfor (int i = 0; i &lt; poolSize; i++) {\n    // todo: \u200b\u6ce8\u610f\u200bi\u200b\u662f\u200b\u5c40\u90e8\u53d8\u91cf\u200b\uff0c\u200b\u533f\u540d\u200b\u51fd\u6570\u200b\u4e2d\u200b\u8bbf\u95ee\u200b\u4e0d\u5230\u200b\uff0c\u200b\u9700\u5728\u200b {} \u200b\u57df\u200b\u5185\u200b\u518d\u6b21\u200b\u58f0\u660e\u200b\n    executor.submit(() -&gt; {\n        // \u200b\u81ea\u5b9a\u4e49\u200b\u7684\u200b\u65b9\u6cd5\u200b\n    });\n}\n\n// \u200b\u5173\u95ed\u200b\u7ebf\u7a0b\u200b\u6c60\u200b\uff0c\u200b\u9632\u6b62\u200b\u7ed3\u675f\u200b\u540e\u200b\u4e0d\u200b\u5173\u95ed\u200b\u73b0\u8c61\u200b\nexecutor.shutdown();\n</code></pre> <p>Info</p> <p>\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u53ea\u80fd\u200b\u5728\u200bmain\u200b\u51fd\u6570\u200b\u4e2d\u200b\u8fd0\u884c\u200b</p>"},{"location":"Programing/MATLAB/index.html","title":"MATLAB","text":""},{"location":"Programing/Python/index.html","title":"Python","text":""},{"location":"Programing/Python/index.html#_1","title":"\u57fa\u7840\u200b\u90e8\u5206","text":"<ol> <li>\u200b\u89e3\u91ca\u5668\u200b\u547d\u4ee4\u884c\u200b\u9009\u9879\u200b</li> <li><code>class</code> \u200b\u7c7b\u200b</li> <li>\u200b\u5185\u7f6e\u200b\u65b9\u6cd5\u200b</li> <li>\u200b\u9759\u6001\u200b\u7c7b\u578b\u200b\u6ce8\u89e3\u200b</li> </ol>"},{"location":"Programing/Python/index.html#_2","title":"\u7ec6\u8282\u200b\u90e8\u5206","text":"<ol> <li><code>Container</code> \u200b\u5bb9\u5668\u200b\u7c7b\u200b\uff0c\u200b\u5305\u62ec\u200bIterable\u3001Iterator\u200b\u548c\u200bGenerator</li> <li><code>lambda</code> \u200b\u533f\u540d\u200b\u51fd\u6570\u200b </li> <li><code>Decorator</code> \u200b\u4fee\u9970\u7b26\u200b</li> <li> <p><code>fstring</code>, <code>Jinja2</code> \u200b\u5b57\u7b26\u4e32\u200b\u63d2\u503c\u200b</p> <pre><code>\"chat_template\": \"\n{% set system_message = 'You are a helpful assistant.' %}{% if messages[0]['role'] == 'system' %}\n    {% set loop_messages = messages[1:] %}\n    {% set system_message = messages[0]['content'] %}\n{% else %}\n    {% set loop_messages = messages %}\n{% endif %}\n{% if system_message is defined %}\n    {{ '&lt;|im_start|&gt;system\\n' + system_message + '&lt;|im_end|&gt;\\n' }}\n{% endif %}\n{% for message in loop_messages %}\n    {% set content = message['content'] %}\n    {% if message['role'] == 'user' %}{{ '&lt;|im_start|&gt;user\\n' + content + '&lt;|im_end|&gt;\\n&lt;|im_start|&gt;assistant\\n' }}\n    {% elif message['role'] == 'assistant' %}{{ content + '&lt;|im_end|&gt;' + '\\n' }}\n    {% endif %}\n{% endfor %}\n\"\n</code></pre> </li> </ol>"},{"location":"Programing/Python/index.html#_3","title":"\u81ea\u7528\u200b\u5e93","text":""},{"location":"Programing/Python/index.html#_4","title":"\u7b97\u6cd5\u200b\u7c7b","text":"<ul> <li><code>Aho-Corasick</code>\uff1aA-C\u200b\u7b97\u6cd5\u200b\uff0c\u200b\u591a\u200b\u6a21\u5f0f\u5339\u914d\u200b\u4e2d\u200b\u7684\u200b\u7ecf\u5178\u200b\u7b97\u6cd5\u200b</li> <li><code>collections</code>\uff1aPython\u200b\u5185\u5efa\u200b\u7684\u200b\u4e00\u4e2a\u200b\u96c6\u5408\u200b\u6a21\u5757\u200b\uff0c\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u8bb8\u591a\u200b\u6709\u7528\u200b\u7684\u200b\u96c6\u5408\u200b\u7c7b\u200b\u548c\u200b\u65b9\u6cd5\u200b\u3002</li> </ul>"},{"location":"Programing/Python/index.html#_5","title":"\u529f\u80fd\u200b\u7c7b","text":"<ul> <li><code>threading</code>\u3001<code>multiprocessing</code>\u3001<code>asyncio</code>\u3001<code>concurrent.futures</code>\uff1a\u200b\u5e76\u53d1\u200b\u7f16\u7a0b\u200b\uff08\u200b\u591a\u7ebf\u7a0b\u200b\uff0c\u200b\u591a\u200b\u8fdb\u7a0b\u200b\uff0c\u200b\u5f02\u6b65\u200b\u7f16\u7a0b\u200b\uff09</li> <li><code>functools</code>\uff1a\u200b\u63d0\u4f9b\u200b\u4e00\u4e9b\u200b\u9ad8\u9636\u200b\u51fd\u6570\u200b</li> <li><code>itertools</code></li> <li><code>os</code>\uff1a\u200b\u63d0\u4f9b\u200b\u4e00\u4e9b\u200b\u65b9\u4fbf\u4f7f\u7528\u200b\u64cd\u4f5c\u7cfb\u7edf\u200b\u76f8\u5173\u200b\u529f\u80fd\u200b\u7684\u200b\u51fd\u6570\u200b</li> <li><code>sys</code>\uff1a\u200b\u63d0\u4f9b\u200b\u4e00\u4e9b\u200b\u65b9\u4fbf\u200bPython\u200b\u89e3\u91ca\u5668\u200b</li> <li>[<code>atexit</code>]</li> <li><code>argparse</code>\u3001<code>tf.flags</code>\uff1a\u200b\u63a5\u53d7\u200b\u4ece\u200b\u7ec8\u7aef\u200b\u4f20\u5165\u200b\u7684\u200b\u547d\u4ee4\u884c\u200b\u53c2\u6570\u200b</li> <li><code>tqdm</code>\uff1aIterable\u200b\u7684\u200b\u904d\u5386\u200b\u8fdb\u5ea6\u200b\u663e\u793a\u200b\u5e93\u200b</li> </ul>"},{"location":"Programing/Python/index.html#_6","title":"\u7edf\u8ba1\u200b\u3001\u200b\u7ed8\u56fe","text":"<ul> <li><code>matplotlib</code>\uff1a\u200b\u63d0\u4f9b\u6570\u636e\u200b\u7ed8\u56fe\u200b\u529f\u80fd\u200b\u7684\u200b\u7b2c\u4e09\u65b9\u200b\u5e93\u200b</li> <li><code>wordlcoud</code>\uff1a\u200b\u7ed8\u5236\u200b\u8bcd\u6c47\u200b\u7ec4\u6210\u200b\u7c7b\u4f3c\u200b\u4e91\u200b\u7684\u200b\u5f69\u8272\u200b\u56fe\u5f62\u200b</li> </ul>"},{"location":"Programing/Python/index.html#_7","title":"\u8d44\u6e90\u5e93","text":"<ul> <li><code>emoji</code>\uff1a\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e9b\u200bemoji\u200b\u7684\u200b\u76f8\u5173\u200b\u64cd\u4f5c\u200b\uff0cemoji\u200b\u6536\u96c6\u200b\u65b0\u800c\u5168\u200b</li> <li><code>OpenCC</code>\uff1a\u200b\u5305\u542b\u200b\u4e2d\u6587\u200b\u7e41\u7b80\u4f53\u200b\u8f6c\u6362\u200b\u5e93\u200b</li> <li><code>pypinyin</code>\uff1a\u200b\u6c49\u5b57\u200b\u8f6c\u200b\u62fc\u97f3\u200b\u7684\u200b\u5e93\u200b</li> <li><code>unicodedata</code></li> <li><code>codecs</code></li> <li><code>googletrans</code>\uff1agoogle\u200b\u7ffb\u8bd1\u200bapi</li> </ul>"},{"location":"Programing/Python/index.html#utils","title":"utils","text":"<ul> <li><code>ahocorasick.py</code></li> <li><code>generate_regrex</code></li> <li><code>char_alpha_numeric.py</code></li> <li><code>random_methods.py</code></li> <li><code>general_dataset_utils.py</code>\u3001<code>torch_dataset_utils.py</code>\u3001<code>tf1_dataset_utils.py</code></li> <li><code>tokenization.py</code></li> </ul>"},{"location":"Programing/Python/index.html#_8","title":"\u8fdb\u9636\u200b\uff1a\u200b\u6587\u4ef6\u200b\u8bfb\u5199","text":""},{"location":"Programing/Python/index.html#_9","title":"\u6570\u636e\u683c\u5f0f","text":"<ul> <li><code>bin</code>\uff1a\u200b\u4e8c\u8fdb\u5236\u200b\u6587\u4ef6\u200b\u8bbf\u5b58\u200b</li> <li><code>json</code>\uff1a\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u5728\u200bJSON\u200b\u6570\u636e\u200b\u548c\u200bPython\u200b\u5bf9\u8c61\u200b\u4e4b\u95f4\u200b\u8fdb\u884c\u200b\u8f6c\u6362\u200b\u548c\u200b\u5e8f\u5217\u5316\u200b\u7684\u200b\u529f\u80fd\u200b\u3002</li> <li><code>pickle</code>\uff1aPython\u200b\u4e13\u7528\u200b\u81ea\u5b9a\u4e49\u200b\u5b58\u50a8\u200b\u6570\u636e\u683c\u5f0f\u200b</li> <li><code>pandas</code>\uff1a</li> <li><code>csv</code>\uff1aCSV\u200b\u6587\u4ef6\u200b\u8bfb\u5199\u200b</li> <li><code>xlsx</code>\uff1aexcel\u200b\u6587\u4ef6\u200b\u8bfb\u5199\u200b</li> <li><code>pdf</code></li> </ul>"},{"location":"Programing/Python/index.html#_10","title":"\u8fdb\u9636\u200b\uff1a\u200b\u6570\u636e\u5904\u7406","text":""},{"location":"Programing/Python/index.html#ai-libraries","title":"\u8fdb\u9636\u200b\uff1aAI Libraries","text":""},{"location":"Programing/Python/index.html#_11","title":"\u673a\u5668\u200b\u5b66\u4e60","text":"<ul> <li><code>sklearn</code></li> <li><code>gensim</code></li> <li><code>lightgbm</code></li> <li>[<code>fasttext</code>] pip install fasttext-wheel</li> </ul>"},{"location":"Programing/Python/index.html#_12","title":"\u5206\u8bcd\u200b\u65b9\u6cd5","text":"<ul> <li>BPE \u200b\u5206\u8bcd\u5668\u200b\uff1a<code>sentencepiece</code>\u3001<code>tokenization</code></li> <li><code>jieba</code></li> </ul>"},{"location":"Programing/Python/index.html#_13","title":"\u8fdb\u9636\u200b: \u200b\u722c\u866b","text":""},{"location":"Programing/Python/index.html#gui","title":"\u8fdb\u9636\u200b: GUI","text":"<ol> <li><code>tkinter</code></li> <li><code>pyqt</code></li> </ol>"},{"location":"Programing/Python/ai_libs/bpe_tokenizer.html","title":"Bpe tokenizer","text":""},{"location":"Programing/Python/ai_libs/bpe_tokenizer.html#tokenization","title":"tokenization","text":"<p><code>FullTokenizer</code>\u200b\u63d2\u5165\u200b<code>special_token</code></p> <ol> <li>variety_span_replace</li> <li>\u200b\u7279\u6b8a\u5b57\u7b26\u200b\u5207\u6362\u200b\u4e3a\u200b\u5df2\u7ecf\u200b\u66ff\u6362\u200b\u7684\u200b\u67d0\u4e2a\u200btoken\u200b\u4f5c\u4e3a\u200b<code>relay_token</code>\uff08<code>relay_token</code>\u200b\u4e3a\u5355\u200b\u5b57\u7b26\u200bunicode\u200b\u4e14\u200b\u5de6\u53f3\u200b\u5404\u200b\u589e\u52a0\u200b\u4e00\u4e2a\u200b\u7a7a\u683c\u200b\u4ee5\u200b\u786e\u4fdd\u200b\u6574\u4f53\u200b\u5206\u8bcd\u200b\u4e3a\u200b<code>relay_token</code>\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b<code>##relay_token</code>\uff09</li> <li>tokenize</li> <li>tokenized tokens\u200b\u8fd8\u539f\u200b\uff0c\u200b\u5373\u200b<code>relay_token</code> \u2192 map \u2192 <code>target_token</code> <p>recover\u200b\u73af\u8282\u200b\u4e0d\u662f\u200b\u5fc5\u9700\u200b\u7684\u200b\uff0c\u200b\u53ef\u200b\u76f4\u63a5\u200b\u7528\u8be5\u200btoken\u200b\u8868\u793a\u200b\u7279\u6b8a\u200b\u8bed\u4e49\u200b</p> </li> </ol> <p>Info</p> <ul> <li>\u200b\u6bcf\u79cd\u200b\u529f\u80fd\u200b\u7684\u200b<code>special_token</code>\u200b\u5c3d\u53ef\u80fd\u200b\u72ec\u7acb\u200b\uff0c\u200b\u6bd4\u5982\u200b<code>[SPACE]</code> \u200b\u4e0d\u200b\u548c\u200b <code>[PAD]</code>\u3001<code>[SEP]</code>\u200b\u5171\u7528\u200b</li> <li>\u200b\u5e8f\u5217\u200b\u5404\u200b\u90e8\u5206\u200b\u5212\u5206\u200btoken + \u200b\u9010\u7ea7\u200b\u62c6\u5206\u200btoken\uff0c\"\u200b\u516d\u6708\u200b\u56db\u200bri\" -&gt; <code>[\u200b\u516d\u200b, \u200b\u6708\u200b, \u200b\u56db\u200b, ri]</code>\u200b\u800c\u200b\u4e0d\u662f\u200b<code>[\u200b\u516d\u200b, \u200b\u6708\u200b, \u200b\u56db\u200b, r, i]</code> <pre><code>  # 1. _tokenize_chinese_chars\n  # 2. whitespace_tokenize\n  # 3. _run_split_on_punc\n  # 4. \u200b\u5148\u200btoken-level\uff0c\u200b\u518d\u200bchar-level\n  for token in above_token_seq:\n    if token in vocab:\n      output_tokens.append(token)\n    else:\n      for c in vocab:\n        output_tokens.append(c if c in vocab else unk_token)\n</code></pre></li> </ul>"},{"location":"Programing/Python/ai_libs/bpe_tokenizer.html#fulltokenizer","title":"FullTokenizer\u200b\u4f18\u5316","text":""},{"location":"Programing/Python/ai_libs/bpe_tokenizer.html#_1","title":"\u8c28\u614e\u200b\u4f7f\u7528\u200b\u58f0\u8c03\u200b\u4e0a\u4e0b\u200b\u6807\u200b\u53bb\u9664\u200b\u51fd\u6570","text":"<p>\u200b\u5c06\u200b\u6587\u672c\u200b\u7ecf\u8fc7\u200bNFD\u200b\u5206\u89e3\u200b\u4e3a\u200b<code>\u200b\u57fa\u672c\u200b\u5b57\u7b26\u200b + \u200b\u91cd\u97f3\u7b26\u53f7\u200b</code>\u200b\u540e\u200b\u53ea\u200b\u4fdd\u7559\u200b\u57fa\u7840\u200b\u5b57\u7b26\u200b\uff0c\u200b\u5982\u200b<code>\"\u0101 \u00e1 \u01ce \u00e0\"   -&gt; \"a a a a\"</code> </p> <ul> <li> \u200b\u53ef\u80fd\u200b\u76f4\u63a5\u200bignore\u200b\u91cd\u97f3\u7b26\u53f7\u200b\u4f1a\u200b\u9020\u6210\u200b\u4fe1\u606f\u200b\u8bed\u7d20\u200b\u7f3a\u5931\u200b\uff08\u200b\u5982\u200b\u5f62\u4f3c\u200b\u7684\u200b\u6570\u5b57\u200b\u3001\u200b\u5b57\u6bcd\u200b\u7b49\u200b\u53d8\u79cd\u200b\u5b57\u7b26\u200b\uff09 BasicTokenizer._run_strip_accents<pre><code># \u200b\u53bb\u9664\u200b\u5b57\u7b26\u200b\u58f0\u8c03\u200b \"\u0101 \u00e1 \u01ce \u00e0\"   -&gt; \"a a a a\"\ndef _run_strip_accents(text):\n    \"\"\"Strips accents from a piece of text.\"\"\"\n    text = unicodedata.normalize(\"NFD\", text)\n    output = []\n    for char in text:\n      cat = unicodedata.category(char)\n      if cat == \"Mn\":\n        continue\n      output.append(char)\n    return \"\".join(output)\n</code></pre></li> </ul>"},{"location":"Programing/Python/ai_libs/bpe_tokenizer.html#oov","title":"\u907f\u514d\u200boov\u200b\u6bd2\u6027\u200b\u6269\u6563","text":"WordpieceTokenizer.tokenize<pre><code># \u200b\u4f18\u5316\u200b\uff1a\u200b\u907f\u514d\u200bBPE\u200b\u5206\u8bcd\u200boov\u200b\u6bd2\u6027\u200b\u6269\u6563\u200b\u73b0\u8c61\u200b\uff0ce.g., \"\u200b\u73ab\u7470\u82b1\u200b\ud835\udd9fl\u1d24\u200b\u6735\u200b\u5411\u65e5\u8475\u200b3\u2c0b7\u200b\u6735\u200b\"\n## [\u200b\u73ab\u200b\uff0c\u200b\u7470\u200b\uff0c\u200b\u82b1\u200b\uff0cunk\uff0c\u200b\u6735\u200b\uff0c\u200b\u5411\u200b\uff0c\u200b\u65e5\u200b\uff0c\u200b\u8475\u200b\uff0cunk\uff0c\u200b\u6735\u200b] -&gt; \n## [\u200b\u73ab\u200b\uff0c\u200b\u7470\u200b\uff0c\u200b\u82b1\u200b\uff0cunk, 1, unk\uff0c\u200b\u6735\u200b\uff0c\u200b\u5411\u200b\uff0c\u200b\u65e5\u200b\uff0c\u200b\u8475\u200b\uff0c3, unk, ##7\uff0c\u200b\u6735\u200b]\ndef tokenize(self, text):\n    text = convert_to_unicode(text)\n\n    output_tokens = []\n    for token in whitespace_tokenize(text):\n      chars = list(token)\n      if len(chars) &gt; self.max_input_chars_per_word:\n        output_tokens.append(self.unk_token)\n        continue\n\n      # is_bad = False\n      start = 0\n      sub_tokens = []\n      while start &lt; len(chars):\n        end = len(chars)\n        cur_substr = None\n        while start &lt; end:\n          substr = \"\".join(chars[start:end])\n          if start &gt; 0:\n            substr = \"##\" + substr\n          if substr in self.vocab:\n            cur_substr = substr\n            break\n          end -= 1\n        # if cur_substr is None:\n        #   is_bad = True\n        #   break\n        # sub_tokens.append(cur_substr)\n        # start = end\n\n        if cur_substr is None:\n            if len(sub_tokens) == 0 \\\n              or sub_tokens[-1] != self.unk_token:  # unify multiple-unk_token or one_unk-to-one_token\n                sub_tokens.append(self.unk_token)\n            start += 1\n        else:\n            sub_tokens.append(cur_substr)\n            start = end\n\n      # if is_bad:\n      #   output_tokens.append(self.unk_token)\n      # else:\n      #   output_tokens.extend(sub_tokens)\n\n      output_tokens.extend(sub_tokens)\n    return output_tokens\n</code></pre>"},{"location":"Programing/Python/ai_libs/gensim/gensim.html","title":"Gensim","text":""},{"location":"Programing/Python/ai_libs/gensim/gensim.html#gensim","title":"Gensim","text":"<pre><code>from gensim.models import KeyedVectors\n</code></pre> Gensim \uff08Generate Similar\uff09\u200b\u6838\u5fc3\u200b\u76ee\u6807\u200b\u662f\u200b\u751f\u6210\u200b\u76f8\u4f3c\u200b\u5185\u5bb9\u200b\uff08\u200b\u5982\u200b\u6587\u6863\u200b\u76f8\u4f3c\u200b\u5ea6\u200b\u8ba1\u7b97\u200b\u3001\u200b\u8bcd\u200b\u5411\u91cf\u200b\u5efa\u6a21\u200b\u7b49\u200b\uff09\u3002"},{"location":"Programing/Python/ai_libs/gensim/gensim.html#embedding","title":"Embedding\u200b\u76f8\u5173","text":""},{"location":"Programing/Python/ai_libs/gensim/gensim.html#keyedvectors","title":"KeyedVectors","text":"<ol> <li> <p>\u200b\u52a0\u8f7d\u200b\u6a21\u578b\u200b <code>KeyedVectors.load_word2vec_format</code></p> \u200b\u793a\u4f8b\u200b\u5b9a\u4e49\u200b <pre><code>model = KeyedVectors.load_word2vec_format(r'E:\\Python\\projects\\secession\\data\\label_data\\v1/emojional.bin', binary=True)\nprint(e2v)\nfor key, value in model.vocab.items():\n    print(key, value, type(value), value.index, e2v.vectors[value.index])\n    break\nprint(e2v.vectors[value.index].shape, len(e2v.vocab))\n</code></pre> <pre><code>def load_word2vec_format(cls, \n    fname, \n    fvocab=None, \n    binary=False, \n    encoding='utf8', \n    unicode_errors='strict',\n    limit=None, \n    datatype=REAL\n)\n</code></pre> </li> <li> <p>\u200b\u8ba1\u7b97\u200b\u76f8\u4f3c\u200b\u5ea6\u200b <code>most_similar</code></p> \u200b\u793a\u4f8b\u200b\u5b9a\u4e49\u200b <p>sss</p> <pre><code>def most_similar(self,\n    positive=None, \n    negative=None, \n    topn=10, \n    restrict_vocab=None, \n    indexer=None)\n</code></pre> </li> </ol>"},{"location":"Programing/Python/ai_libs/sklearn/sklearn.html","title":"Sklearn","text":"<p><code>pip install scikit-learn</code></p>"},{"location":"Programing/Python/ai_libs/sklearn/sklearn.html#kmeans","title":"KMeans","text":"<pre><code>from sklearn.cluster import KMeans\n\n\nclass KMeans(_BaseKMeans):\n    def __init__(\n        self,\n        n_clusters=8,           # \u200b\u805a\u7c7b\u200b\u7c07\u6570\u200b\n        *,\n        init=\"k-means++\",       # \u200b\u521d\u59cb\u5316\u200b\u8d28\u5fc3\u200b\u65b9\u6cd5\u200b\n                                #   k-means++: \u200b\u667a\u80fd\u200b\u521d\u59cb\u5316\u200b\u8d28\u5fc3\u200b\uff0c\u200b\u4f7f\u200b\u521d\u59cb\u200b\u8d28\u5fc3\u200b\u5f7c\u6b64\u200b\u8fdc\u79bb\u200b \n                                #   random: \u200b\u968f\u673a\u200b\u521d\u59cb\u5316\u200b\u4e4b\u5fc3\u200b\n        n_init=\"warn\",\n        max_iter=300,           # \u200b\u6700\u5927\u200b\u8fed\u4ee3\u200b\u6b21\u6570\u200b\n        tol=1e-4,               # \u200b\u6536\u655b\u200b\u9608\u503c\u200b\n        verbose=0,\n        random_state=None,\n        copy_x=True,\n        algorithm=\"lloyd\",      # \u200b\u66f4\u65b0\u200b\u7b97\u6cd5\u200b\n                                # lloyd: \u200b\u6807\u51c6\u200bEM\u200b\u98ce\u683c\u200b\u7b97\u6cd5\u200b\n                                # elkan: \u200b\u5229\u7528\u200b\u4e09\u89d2\u200b\u4e0d\u200b\u7b49\u200b\u65f6\u200b\u52a0\u901f\u200b\n    ):\n</code></pre>"},{"location":"Programing/Python/ai_libs/sklearn/sklearn.html#metrics","title":"metrics","text":"<ol> <li>acc, f1, P, R, ROC_AUC <pre><code>from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\n\ndef accuracy_score(\n    y_true,                 # ndarray, shape=(n, )\n    y_pred,                 # ndarray, shape=(n, )\n    *,\n    normalize=True,         # {True: \u200b\u8fd4\u56de\u200bacc, False: \u200b\u8fd4\u56de\u200b TP + TN}\n    sample_weight=None      # Union[None, ndarray], \u200b\u6bcf\u4e2a\u200b\u6837\u672c\u200b\u7684\u200b\u6743\u91cd\u200b\n)\n\n\ndef f1/precision/recall_score(\n    y_true,                 # ndarray, shape=(n, )\n    y_pred,                 # ndarray, shape=(n, )\n    *,\n    labels=None,\n    pos_label=1,            # \u200b\u5f53\u200baverage=\"binary\"\u200b\u65f6\u200b\uff0c\u200b\u6307\u5b9a\u200b\u6b63\u200b\u6837\u672c\u200b\u7684\u200b\u6807\u7b7e\u200b\u8868\u793a\u200b\n    average=\"binary\",       # {\n                            #   'micro': \u200b\u5e73\u5747\u200b\u7ed3\u679c\u200b, 'macro': \u200b\u52a0\u6743\u200b\u5e73\u5747\u200b\u7ed3\u679c\u200b, \n                            #   'samples', 'weighted', \n                            #   'binary': \u200b\u62a5\u544a\u200bpos_label\u200b\u7684\u200b\u7ed3\u679c\u200b\n                            # }\n    sample_weight=None,\n    zero_division=\"warn\"\n)\n</code></pre> <p>\u200b\u53ef\u200b\u4f7f\u7528\u200b <code>np.argmax(probs\uff0c axis=-1)</code> \u200b\u83b7\u53d6\u200b <code>y_pred</code></p> </li> </ol>"},{"location":"Programing/Python/basic/builtins.html","title":"Builtins","text":""},{"location":"Programing/Python/basic/builtins.html#_1","title":"\u6570\u503c\u200b\u76f8\u5173","text":"<ol> <li><code>min/max</code>\uff1a\u200b\u83b7\u53d6\u200b<code>iterable</code>\u200b\u4e2d\u200b\u6700\u5c0f\u503c\u200b/\u200b\u6700\u5927\u503c\u200b <pre><code>def min/max(iterable, *, key=None)\ndef min/max(*args, key=None)\n</code></pre> <p>\u200b\u5982\u679c\u200b\u591a\u4e2a\u200b\u5143\u7d20\u200b\u7b26\u5408\u200b<code>key</code>\u200b\u5bf9\u5e94\u200b\u7684\u200b\u6761\u4ef6\u200b\uff0c\u200b\u8fd4\u56de\u200b\u7b2c\u4e00\u6b21\u200b\u51fa\u73b0\u200b\u7684\u200b\u5143\u7d20\u200b</p> </li> <li><code>sum</code>\uff1a\u200b\u8fd4\u56de\u200b<code>iterable</code>\u200b\u5143\u7d20\u200b\u503c\u200b\u7684\u200b\u548c\u200b\uff0c\u200b\u5373\u200b <pre><code>ret = 0\nfor e in iterable:\n    ret += e\nreturn ret\n</code></pre></li> <li> <p><code>pow</code>\uff1a\u200b\u6267\u884c\u200b\u5e42\u6307\u6570\u200b\u51fd\u6570\u200b\uff0c\u200b\u5982\u679c\u200b\u6307\u5b9a\u200b\u6c42\u6a21\u200b\u51fd\u6570\u200b\u5e95\u200b\uff0c\u200b\u8fdb\u4e00\u6b65\u200b\u6c42\u6a21\u200b </p><pre><code>def pow(\n    base,       # \u200b\u6307\u6570\u51fd\u6570\u200b\u5e95\u200b\n    exp,        # \u200b\u6307\u6570\u51fd\u6570\u200b\u5e42\u6307\u6570\u200b\n    mod=None    # \u200b\u6c42\u6a21\u200b\u51fd\u6570\u200b\u5e95\u200b\uff0c\u200b\u672a\u6307\u5b9a\u200b\u4e0d\u6c42\u6a21\u200b\n)\n</code></pre><p></p> </li> <li> <p><code>round</code> </p><pre><code>def round(\n    number,     # \u200b\u9700\u8981\u200b\u88ab\u200b\u820d\u5165\u200b\u7684\u200b\u6570\u5b57\u200b\uff0c\u200b\u820d\u5165\u200b\u7ed3\u679c\u200b\u5fae\u200b\u66f4\u200b\u63a5\u8fd1\u200b\u90a3\u4e2a\u200b\u503c\u200b\n    ndigits=0   # \u200b\u9700\u8981\u200b\u88ab\u200b\u8981\u200b\u7559\u200b\u7684\u200b\u4f4d\u6570\u200b\n)\n</code></pre><p></p> </li> </ol>"},{"location":"Programing/Python/basic/builtins.html#_2","title":"\u547d\u4ee4\u200b\u6267\u884c\u200b\u76f8\u5173","text":"<ol> <li> <p><code>eval/exec</code> </p><pre><code>def exec/eval(\n    expression,     # type(expression)=str\uff0c\u200b\u8868\u793a\u200b\u8981\u200b\u6267\u884c\u200b\u7684\u200b\u8bed\u53e5\u200b\n    globals=None,\n    locals=None,\n    /\n)\n# eval\u200b\u6267\u884c\u200b\u8fd4\u56de\u200b\u7ed3\u679c\u200b\uff0cexec\u200b\u6267\u884c\u200b\u4e0d\u200b\u8fd4\u56de\u200b\u7ed3\u679c\u200b\na = 1\nprint(exec('a+2'), a)   # &gt; None, 3\nprint(eval('a+2'), a)   # &gt; 3, 1\n</code></pre><p></p> <p><code>exec</code>\u200b\u51fd\u6570\u200b\u7684\u200b<code>expression</code>\u200b\u53c2\u6570\u200b\u51fa\u73b0\u200b<code>=</code>\u200b\u65f6\u4f1a\u200b\u62a5\u9519\u200b<code>SyntaxError</code> \u200b\u51fa\u73b0\u200b\u4fee\u6539\u200b\u4f20\u5165\u200b\u503c\u200b\u7684\u200b\u60c5\u51b5\u200b\u4e0b\u200b\u4e00\u822c\u200b\u4f1a\u200b\u9009\u62e9\u200b\u4f7f\u7528\u200b<code>eval</code>\u200b\u51fd\u6570\u200b</p> </li> <li> <p><code>callable</code>\uff1a\u200b\u5224\u65ad\u200b\u5bf9\u8c61\u200b\u662f\u5426\u662f\u200b\u53ef\u200b\u8c03\u7528\u200b\u7684\u200b </p><pre><code>def callable(\n    object\n) -&gt; bool\n</code></pre><p></p> <p>\u200b\u5f53\u200b<code>object</code>\u200b\u662f\u200b\u4e00\u4e2a\u200b\u65b9\u6cd5\u200b\u3001\u200b\u51fd\u6570\u200b\u6216\u8005\u200b\u7c7b\u65f6\u200b\u662f\u200b\u53ef\u200b\u8c03\u7528\u200b\u7684\u200b\uff1b\u200b\u5f53\u200b<code>object</code>\u200b\u662f\u200b\u4e2a\u200b\u7c7b\u200b\u5bf9\u8c61\u200b\u4e14\u200b\u7c7b\u200b\u4e2d\u200b\u5b9e\u73b0\u200b\u4e86\u200b <code>__call__</code> \u200b\u65b9\u6cd5\u200b\u65f6\u200b\u4e5f\u200b\u662f\u200b\u53ef\u200b\u8c03\u7528\u200b\u7684\u200b</p> </li> </ol>"},{"location":"Programing/Python/basic/builtins.html#_3","title":"\u7c7b\u578b\u200b\u76f8\u5173","text":"<ol> <li><code>chr/ord</code>\uff1a\u200b\u5c06\u200b\u5355\u4e2a\u200b\u6574\u578b\u200b\u6570\u503c\u200b/unicode\u200b\u5b57\u7b26\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u5bf9\u5e94\u200b\u7684\u200bunicode\u200b\u5b57\u7b26\u200b/\u200b\u6574\u578b\u200b\u6570\u503c\u200b <pre><code># chr\ndef chr(\n    i                   # type(i)=int, \u200b\u8868\u793a\u200b\u8981\u200b\u8f6c\u6362\u200b\u7684\u200b\u6574\u578b\u200b\u6570\u503c\u200b\uff0c0 &lt;= i &lt;= 0x10ffff\n) -&gt; str\n\n# ord\ndef ord(\n    c                   # type(c)=str, \u200b\u8868\u793a\u200b\u8981\u200b\u8f6c\u6362\u200b\u7684\u200bunicode\u200b\u5b57\u7b26\u200b\n) -&gt; int\n</code></pre> <p><code>ord</code> \u200b\u4e0e\u200b <code>chr</code> \u200b\u529f\u80fd\u200b\u76f8\u53cd\u200b</p> </li> <li><code>bin/hex/oct</code></li> <li><code>type</code></li> <li><code>isinstance</code></li> </ol>"},{"location":"Programing/Python/basic/builtins.html#_4","title":"\u5bb9\u5668\u200b\u76f8\u5173","text":"<ol> <li><code>len</code>\uff1a\u200b\u83b7\u53d6\u200b <code>iterable</code> \u200b\u4e2d\u200b\u5143\u7d20\u200b\u4e2a\u6570\u200b</li> <li><code>list</code></li> <li><code>tuple</code></li> <li><code>dict</code></li> <li><code>set</code></li> <li><code>zip</code></li> <li><code>range</code></li> <li><code>enumerate</code></li> <li><code>filter</code></li> <li><code>map</code>\uff1a\u200b\u5c06\u200b\u4e00\u4e2a\u200b\u6216\u200b\u591a\u4e2a\u200b <code>iterator</code> \u200b\u6620\u5c04\u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u65b0\u200b\u7684\u200b <code>iterable</code> \uff0c\u200b\u793a\u610f\u200b\u5982\u4e0b\u200b\u56fe\u200b\uff1a <pre><code>def map(\n    func,               # \u200b\u5177\u4f53\u200b\u6620\u5c04\u200b\u65b9\u6cd5\u200b\n    *iterables,         # iterator \u200b\u5e8f\u5217\u200b\uff0clen(iterables)\u200b\u7b49\u4e8e\u200bfunc\u200b\u4e2d\u200b\u8f93\u5165\u200b\u5f62\u53c2\u200b\u4e2a\u6570\u200b\n) -&gt; Iterable\n</code></pre></li> </ol> <ol> <li><code>iter</code></li> <li><code>next</code></li> <li><code>sorted</code></li> <li><code>reversed</code></li> <li><code>all/any</code></li> </ol> <p>\u200b\u5224\u65ad\u200b <code>Iterable</code> \u200b\u4e2d\u200b\u5143\u7d20\u200b\u72b6\u6001\u200b\uff0c\u200b\u5f53\u200b\u5143\u7d20\u200b\u4e3a\u200b\u4ee5\u4e0b\u200b\u503c\u200b\u4e4b\u4e00\u200b\uff0c\u200b\u5143\u7d20\u200b\u903b\u8f91\u200b\u72b6\u6001\u503c\u200b\u4e3a\u200b<code>False</code>\uff0c\u200b\u5426\u5219\u200b\u4e3a\u200b<code>True</code></p> <ul> <li><code>None</code></li> <li><code>0</code></li> <li><code>Iterable</code>\u200b\u4e2d\u200b\u5143\u7d20\u200b\u4e2a\u6570\u200b\u4e3a\u200b0</li> <li><code>False</code> <p><code>iterable</code> \u200b\u4e2d\u200b\u5404\u200b\u5143\u7d20\u200b\u53ef\u200b\u4e3a\u200b\u6761\u4ef6\u903b\u8f91\u200b\uff0c\u200b\u901a\u8fc7\u200b<code>all</code>\u200b\u6216\u200b<code>any</code>\u200b\u4ee5\u200b\u7ec4\u5efa\u200b\u4e3a\u200b<code>or</code>\u200b\u6216\u200b<code>and</code>\u200b\u903b\u8f91\u200b\u8868\u8fbe\u5f0f\u200b</p> </li> </ul>"},{"location":"Programing/Python/basic/class.html","title":"Class","text":"<pre><code>def fun_1(self, arg, *args):\n\n# obj.fun_1(...) \u200b\u8c03\u7528\u200b\u65f6\u200b\uff0c\u200b\u65b9\u6cd5\u200b\u81ea\u52a8\u200b\u8d4b\u503c\u200bself=obj\n# Class_Name.fun_1(obj, ...)\uff0c\u200b\u8c03\u7528\u200b\u65f6\u200b\uff0c\u200b\u624b\u52a8\u200b\u6307\u5b9a\u200bself=obj\n# \u200b\u4e8c\u8005\u200b\u7b49\u4ef7\u200b\n\n#@claclassmethod \u200b\u8c03\u7528\u200b\n# Class_name.class_method\n# obj.class_method\n# \u200b\u4e8c\u8005\u200b\u7b49\u4ef7\u200b\uff0c\u200b\u56e0\u4e3a\u200b\u7c7b\u200b\u5c5e\u6027\u200b\u548c\u200b\u4e0d\u200b\u968f\u200b\u5bf9\u8c61\u200b\u53d8\u5316\u200b\u800c\u200b\u6bd4\u200b\u53d8\u5316\u200b\n\n#\u200b\u6210\u5458\u200b\u5c5e\u6027\u200b\u53ea\u6709\u200b\u901a\u8fc7\u200b\u7c7b\u200b\u8bbf\u95ee\u200b\u624d\u200b\u53ef\u200b\u4fee\u6539\u200b\uff0c\u200b\u5373\u200b Class_name.val = 3\n</code></pre>"},{"location":"Programing/Python/basic/class.html#_1","title":"\u53d8\u91cf","text":""},{"location":"Programing/Python/basic/class.html#_2","title":"\u7c7b\u200b\u53d8\u91cf","text":""},{"location":"Programing/Python/basic/class.html#_3","title":"\u5b9e\u4f8b\u200b\u53d8\u91cf","text":""},{"location":"Programing/Python/basic/class.html#_4","title":"\u65b9\u6cd5","text":""},{"location":"Programing/Python/basic/class.html#_5","title":"\u7c7b\u200b\u65b9\u6cd5","text":""},{"location":"Programing/Python/basic/class.html#_6","title":"\u5b9e\u4f8b\u200b\u65b9\u6cd5","text":""},{"location":"Programing/Python/basic/class.html#_7","title":"\u7ee7\u627f","text":""},{"location":"Programing/Python/basic/class.html#_8","title":"\u9b54\u6cd5\u200b\u5c5e\u6027","text":"<ol> <li><code>__dict__</code>\uff0c<code>dict</code>\u200b\u7c7b\u578b\u200b\uff0c\u200b\u7528\u4e8e\u200b\u5b58\u653e\u200b\u5bf9\u8c61\u200b\u7684\u200b\u5c5e\u6027\u200b\u548c\u200b\u5bf9\u5e94\u200b\u7684\u200b\u503c\u200b</li> <li><code>__slots__</code>\uff0c<code>Option[str, tuple, list, set]</code>\uff0c\u200b\u7528\u4e8e\u200b\u9650\u5b9a\u200b\u5bf9\u8c61\u200b\u6700\u5927\u200b\u7684\u200b\u5c5e\u6027\u200b\u96c6\u5408\u200b\uff0c\u200b\u51cf\u5c11\u200b\u5185\u5b58\u200b\u6d88\u8017\u200b,\u200b\u63d0\u5347\u200b\u5c5e\u6027\u200b\u8bbf\u95ee\u901f\u5ea6\u200b <pre><code>class a:\n    __slots__ = ['x', 'y']\n</code></pre></li> <li><code>__class__</code>\uff0c<code>class</code>\u200b\u7c7b\u578b\u200b\uff0c\u200b\u5305\u542b\u200b\u5bf9\u8c61\u200b\u6240\u5c5e\u200b\u7c7b\u200b\u4fe1\u606f\u200b</li> </ol>"},{"location":"Programing/Python/basic/class.html#_9","title":"\u9b54\u6cd5\u200b\u65b9\u6cd5","text":""},{"location":"Programing/Python/basic/class.html#_10","title":"\u5bf9\u8c61\u200b\u76f8\u5173","text":"<ol> <li><code>__new__</code>\uff0c\u200b\u521b\u5efa\u200b\u7c7b\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u4e3a\u200b\u9759\u6001\u65b9\u6cd5\u200b\uff0c\u200b\u9700\u8981\u200b\u8fd4\u56de\u200b\u521b\u5efa\u200b\u7684\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u82e5\u200b\u672a\u200b\u91cd\u5199\u200b\u81ea\u52a8\u200b\u8c03\u7528\u200b\u7236\u7c7b\u200b\u8be5\u200b\u65b9\u6cd5\u200b     <pre><code>def __new__(cls, *args, **kwargs):  # *args\u200b\u548c\u200b**kwargs\u200b\u7b49\u540c\u4e8e\u200b`__init__`\u200b\u5bf9\u5e94\u200b\u7684\u200b\u5f62\u53c2\u200b\n    x = super().__new__(cls)\n    # x = super(Clazz, cls).__new__(cls) # \u200b\u57fa\u4e8e\u200b\u9759\u6001\u65b9\u6cd5\u200b\u7279\u6027\u200b\uff0c\u200b\u7b49\u540c\u4e8e\u200b\u4e0a\u8ff0\u200b\u5199\u6cd5\u200b\n    return x                        # \u200b\u8fd4\u56de\u200b\u7684\u200b `x` \u200b\u5373\u200b\u4e3a\u200b\u5176\u4f59\u200b\u65b9\u6cd5\u200b\u7684\u200b\u5f62\u53c2\u200b `self` \n</code></pre></li> <li> <p><code>__init__</code>\uff0c\u200b\u521d\u59cb\u5316\u200b\u521b\u5efa\u200b\u7684\u200b\u5bf9\u8c61\u200b     </p><pre><code>def __init__(self, *args, **kwargs)\n</code></pre><p></p> </li> <li> <p><code>__del__</code>\uff0c\u200b\u6790\u6784\u200b\u51fd\u6570\u200b     </p><pre><code>def __del__(self):\n    # \u200b\u5c06\u200b\u5bf9\u8c61\u200b\u4ece\u200b\u5185\u5b58\u200b\u4e2d\u200b\u9500\u6bc1\u200b\n    '''                   \n    # \u200b\u6b64\u65f6\u200b\u65e0\u6cd5\u200b\u8c03\u7528\u200bopen\u200b\u51fd\u6570\u200b\u5199\u51fa\u200b\u6570\u636e\u200b\uff0c\u200b\u5982\u9700\u200b\u5b8c\u6210\u200b\u7ed3\u679c\u200b\u5199\u51fa\u200b\uff0c\u200b\u53ef\u200b\u901a\u8fc7\u200b\u4e00\u4e0b\u200b\u65b9\u6cd5\u200b\n    import atexit\n\n    # in __init__\n    atexit.register(&lt;exit_function_name&gt;)   # \u200b\u5728\u200b\u5bf9\u8c61\u200b\u7ed3\u675f\u200b\u524d\u200b\u5b8c\u6210\u200b\u7ed3\u679c\u200b\u5199\u51fa\u200b\n    '''\n</code></pre><p></p> </li> <li> <p><code>__enter__</code>\uff0c\u200b\u4e0e\u200b <code>__exit__</code> \u200b\u642d\u914d\u200b\uff0cenable\u200b\u88ab\u200b <code>with</code> \u200b\u8bed\u53e5\u200b\u8c03\u7528\u200b     </p><pre><code>def __enter__(self):\n    self.file = open(self.file_name, self.mode)\n    return self.file\n</code></pre><p></p> </li> <li><code>__exit__</code>\uff0c\u200b\u4e0e\u200b <code>__enter__</code> \u200b\u642d\u914d\u200b\uff0cenable\u200b\u88ab\u200b <code>with</code> \u200b\u8bed\u53e5\u200b\u8c03\u7528\u200b     <pre><code># \u200b\u5b8c\u6210\u200b\u5728\u200b`__enter__`\u200b\u65b9\u6cd5\u200b\u4e2d\u200b\u5bf9\u5e94\u200b\u5185\u5bb9\u200b\u7684\u200b\u5173\u95ed\u200b\ndef __exit__(self, \n             exc_type,      # exit_type \n             exc_val,       # exit_vaule\n             exc_tb):       # exit_traceback\n    self.file.close()\n</code></pre></li> <li><code>__str__</code>\uff0c\u200b\u4f7f\u7528\u200b <code>str</code>\u3001<code>print</code> \u200b\u4ee5\u53ca\u200b <code>format</code> \u200b\u51fd\u6570\u200b\u65f6\u200b\u8c03\u7528\u200b\u7684\u200b\u65b9\u6cd5\u200b</li> <li><code>__repr__</code>\uff0c\u200b\u4f7f\u7528\u200b <code>repr</code> \u200b\u51fd\u6570\u200b\u65f6\u200b\u8c03\u7528\u200b\u7684\u200b\u65b9\u6cd5\u200b     <pre><code># \u200b\u8c03\u7528\u200b\u4f18\u5148\u7ea7\u200b\u4e3a\u200b `__str__ -&gt; __repr__`\ndef __str__(self) -&gt; str:\n# \u200b\u8c03\u7528\u200b\u4f18\u5148\u7ea7\u200b\u4e3a\u200b `__repr__`\ndef __repr__(self) -&gt; str:\n</code></pre></li> <li> <p><code>__call__</code>\uff0c\u200b\u76f4\u63a5\u200b\u4f7f\u7528\u200b <code>object_name()</code> \u200b\u65f6\u200b\u8c03\u7528\u200b     </p><pre><code>def __call__(self, *args, **kwargs)\n</code></pre><p></p> </li> <li> <p><code>__dir__</code>\uff0c\u200b\u8fd4\u56de\u200b\u5bf9\u8c61\u200b\u62e5\u6709\u200b\u7684\u200b\u6240\u6709\u200b(\u200b\u5305\u62ec\u200b\u9b54\u6cd5\u200b)\u200b\u65b9\u6cd5\u200b\u548c\u200b(\u200b\u5305\u62ec\u200b\u9b54\u6cd5\u200b)\u200b\u5c5e\u6027\u200b</p> <p>\u200b\u6b64\u65f6\u200b\u51fd\u6570\u200b <code>dir</code> \u200b\u5c06\u200b\u8c03\u7528\u200b\u8be5\u200b\u65b9\u6cd5\u200b</p> </li> </ol>"},{"location":"Programing/Python/basic/class.html#_11","title":"\u53d8\u91cf\u200b\u76f8\u5173","text":"<ol> <li><code>__getattribute__</code>\u3001<code>__getattr__</code>\uff0c\u200b\u8bbf\u95ee\u200b\u7c7b\u200b\u5c5e\u6027\u200b\u65f6\u200b\u81ea\u52a8\u200b\u8c03\u7528\u200b <pre><code># \u200b\u4f5c\u7528\u200b\u4e3a\u200b\u5c5e\u6027\u200b\u8bbf\u95ee\u200b\u62e6\u622a\u200b(\u200b\u5bf9\u200b\u90e8\u5206\u200b\u4e0d\u60f3\u200b\u66b4\u9732\u200b\u7684\u200b\u5c5e\u6027\u200b\u8bbf\u95ee\u200b\u8fdb\u884c\u200b\u62e6\u622a\u200b)\n# \u200b\u8c03\u7528\u200b\u4f18\u5148\u7ea7\u200b\u4e3a\u200b `__getattribute__ -&gt; __getattr__`\ndef __getattribute__(self, *args, **kwargs):\n    '''\n    if args or kwargs condition:\n        ...\n    else:\n        return object.__getattribute__(self, *args, **kwargs)\n    '''\n# \u200b\u8bbf\u95ee\u200b\u4e00\u4e2a\u200b\u4e0d\u200b\u5b58\u5728\u200b\u7684\u200b\u5c5e\u6027\u200b\u65f6\u200b(\u200b\u5df2\u200b\u6709\u65f6\u200b\u4e0d\u4f1a\u200b\u8c03\u7528\u200b)\uff0c\u200b\u4f1a\u200b\u7531\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u629b\u51fa\u200b\u5f02\u5e38\u200b\n# \u200b\u8c03\u7528\u200b\u4f18\u5148\u7ea7\u200b\u4e3a\u200b `__getattr__`\ndef __getattr__(self, key)\n</code></pre></li> <li><code>__setattr__</code>\uff0c\u200b\u5bf9\u7c7b\u200b\u5c5e\u6027\u200b\u8fdb\u884c\u200b\u8d4b\u503c\u200b\u65f6\u200b\u81ea\u52a8\u200b\u8c03\u7528\u200b <pre><code>def __setattr__(self, key, value):\n    self.__dict__[key] = value\n</code></pre></li> <li><code>__delattr__</code>\uff0c\u200b\u5220\u9664\u200b\u76f8\u5e94\u200b\u7684\u200b\u7c7b\u200b\u5c5e\u6027\u200b <pre><code># \u200b\u4e0d\u80fd\u200b\u5728\u200b`__delattr__`\u200b\u4e2d\u200b\u4f7f\u7528\u200bdel\u200b\u8fdb\u884c\u200b\u5220\u9664\u200b\uff0c\u200b\u5426\u5219\u200b\u4f1a\u200b\u65e0\u9650\u200b\u5faa\u73af\u200b\u8c03\u7528\u200b\u4ee5\u81f4\u200b\u997f\u6b7b\u200b\ndef __delattr__(self, key):\n    self.__dict__.pop(key)\n    # super().__dict__(key)\n</code></pre></li> </ol> <pre><code>def __get__(self, instance, owner)\ndef __set__(sefl, instance, value)\ndef __delete__(sefl, instance)\n</code></pre> <pre><code>__bool__\n__int__\n__float__\n__format__\n</code></pre>"},{"location":"Programing/Python/basic/class.html#_12","title":"\u5bb9\u5668\u200b\u76f8\u5173","text":"<ol> <li> <p><code>__iter__</code>\uff0c\u200b\u4f7f\u200b\u5bf9\u8c61\u200b\u5177\u6709\u200b\u53ef\u200b\u8fed\u4ee3\u200b\u5316\u200b\u5c5e\u6027\u200b\uff08\u200b\u9700\u200b\u540c\u65f6\u200b\u642d\u914d\u200b\u5b9e\u73b0\u200b<code>__next__</code>\u200b\u65b9\u6cd5\u200b\uff09 </p><pre><code>def __iter__(self) -&gt; Iterator[T_co]:\n    return self\n</code></pre><p></p> <p>\u200b\u53ea\u6709\u200b\u5b9e\u73b0\u200b\u4e86\u200b <code>__iter__</code> \u200b\u65b9\u6cd5\u200b\u7684\u200b\u7c7b\u200b\u624d\u80fd\u200b\u6210\u529f\u200b\u6267\u884c\u200b <code>iter</code> \u200b\u51fd\u6570\u200b</p> </li> <li> <p><code>__next__</code>\uff0c\u200b\u83b7\u53d6\u200b\u5e8f\u5217\u200b\u4e0b\u200b\u4e00\u4e2a\u200b\u5143\u7d20\u200b\uff0c\uff08\u200b\u9700\u200b\u540c\u65f6\u200b\u642d\u914d\u200b\u5b9e\u73b0\u200b<code>__iter__</code>\u200b\u65b9\u6cd5\u200b\uff09 </p><pre><code>def __next__(self) -&gt; T_co\n</code></pre><p></p> <p>\u200b\u5e8f\u5217\u5316\u200b\u7684\u200b\u65f6\u5019\u200b\u4f1a\u200b\u904d\u5386\u200b\u5f85\u200b\u5e8f\u5217\u5316\u200b\u7684\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u56e0\u6b64\u200b\u53ea\u6709\u200b\u5b9e\u73b0\u200b\u4e86\u200b\u540c\u65f6\u200b\u5b9e\u73b0\u200b\u4e86\u200b <code>__iter__</code>\u200b\u548c\u200b <code>__next__</code> \u200b\u65b9\u6cd5\u200b\u7684\u200b\u7c7b\u200b\u624d\u80fd\u200b\u6210\u529f\u200b\u5e8f\u5217\u5316\u200b \u200b\u53ea\u6709\u200b\u5b9e\u73b0\u200b\u4e86\u200b <code>__next__</code> \u200b\u65b9\u6cd5\u200b\u7684\u200b\u7c7b\u200b\u624d\u80fd\u200b\u6210\u529f\u200b\u6267\u884c\u200b <code>next</code> \u200b\u51fd\u6570\u200b</p> </li> <li> <p><code>__getitem__</code>\uff0c\u200b\u901a\u8fc7\u200b\u7d22\u5f15\u200b\u6216\u952e\u200b\u83b7\u53d6\u200b\u76f8\u5e94\u200b\u5143\u7d20\u200b </p><pre><code># \u200b\u901a\u8fc7\u200b\u7d22\u5f15\u200b\u83b7\u53d6\u200b\u5143\u7d20\u200b\uff0c\u200b\u5982\u200blist\u3001tuple\u3001str\u200b\u7b49\u200b\ndef __getitem__(self, index) -&gt; T_co\n\n# \u200b\u901a\u8fc7\u200b\u952e\u200b\u83b7\u53d6\u200b\u503c\u200b\u5143\u7d20\u200b\uff0c\u200b\u5982\u200bdict\u200b\u7b49\u200b\ndef __getitem__(self, key) -&gt; T_co\n</code></pre><p></p> <p>\u200b\u53ea\u6709\u200b\u5b9e\u73b0\u200b\u4e86\u200b <code>__getitem__</code> \u200b\u65b9\u6cd5\u200b\u7684\u200b\u7c7b\u200b\u624d\u80fd\u200b\u6210\u529f\u200b\u6267\u884c\u200b <code>[]</code> \u200b\u8fd0\u7b97\u7b26\u200b \u200b\u82e5\u7c7b\u200b\u4e2d\u200b\u672a\u200b\u5b9e\u73b0\u200b <code>__iter__</code>\u3001<code>__next__</code> \u200b\u65b9\u6cd5\u200b\uff0cPython\u200b\u89e3\u91ca\u5668\u200b\u4f1a\u200b\u627e\u200b <code>__getitem__</code> \u200b\u6765\u200b\u8fed\u4ee3\u200b</p> </li> <li> <p><code>__setitem__</code>\uff0c\u200b\u901a\u8fc7\u200b\u7d22\u5f15\u200b\u6216\u952e\u200b\u8bbe\u7f6e\u200b\u76f8\u5e94\u200b\u5143\u7d20\u200b </p><pre><code># \u200b\u8bbe\u7f6e\u200b\u7d22\u5f15\u200b\u5bf9\u5e94\u200b\u7684\u200b\u5143\u7d20\u200b\u503c\u200b\ndef __setitem__(self, index, value)\n\n# \u200b\u8bbe\u7f6e\u200b\u952e\u200b\u5bf9\u5e94\u200b\u7684\u200b\u5143\u7d20\u200b\u503c\u200b\ndef __setitem__(self, key, value)\n</code></pre><p></p> <p>\u200b\u53ea\u6709\u200b\u5b9e\u73b0\u200b\u4e86\u200b <code>__setitem__</code> \u200b\u65b9\u6cd5\u200b\u7684\u200b\u7c7b\u200b\u624d\u80fd\u200b\u6210\u529f\u200b\u6267\u884c\u200b <code>[]=</code> \u200b\u8fd0\u7b97\u7b26\u200b</p> </li> <li> <p><code>__len__</code>\uff0c\u200b\u8fd4\u56de\u200b\u5bf9\u8c61\u200b\u4e2d\u200b\u5143\u7d20\u200b\u4e2a\u6570\u200b </p><pre><code>def __len__(self) -&gt; int\n</code></pre><p></p> <p>\u200b\u53ea\u6709\u200b\u5b9e\u73b0\u200b\u4e86\u200b <code>__len__</code> \u200b\u65b9\u6cd5\u200b\u7684\u200b\u7c7b\u200b\u624d\u80fd\u200b\u6210\u529f\u200b\u6267\u884c\u200b <code>len</code> \u200b\u51fd\u6570\u200b</p> </li> <li> <p><code>__contains__</code>\uff0c\u200b\u5224\u65ad\u200b\u5bf9\u8c61\u200b\u4e2d\u200b\u662f\u5426\u200b\u5305\u542b\u200b\u67d0\u4e2a\u200b\u5143\u7d20\u200b </p><pre><code>def __contains__(self, item) -&gt; bool\n</code></pre><p></p> <p>\u200b\u53ea\u6709\u200b\u5b9e\u73b0\u200b\u4e86\u200b <code>__contains__</code> \u200b\u65b9\u6cd5\u200b\u7684\u200b\u7c7b\u200b\u624d\u80fd\u200b\u6210\u529f\u200b\u6267\u884c\u200b <code>in</code> \u200b\u8fd0\u7b97\u7b26\u200b</p> </li> </ol>"},{"location":"Programing/Python/basic/class.html#_13","title":"\u64cd\u4f5c\u7b26\u200b\u91cd\u8f7d","text":"<ol> <li> <p><code>__le/lt/eq/ne/gt/ge__</code>\uff1a\u200b\u6570\u503c\u200b\u6bd4\u8f83\u200b </p><pre><code>def __le/lt/eq/ne/gt/ge__(self, other) -&gt; bool\n</code></pre><p></p> <p>\u200b\u5206\u522b\u200b\u91cd\u8f7d\u200b\u4e86\u200b\u4e8c\u5143\u200b\u64cd\u4f5c\u7b26\u200b <code>&lt;=</code>\u3001<code>&lt;</code>\u3001<code>==</code>\u3001<code>!=</code>\u3001<code>&gt;</code>\u3001<code>&gt;=</code></p> </li> <li> <p><code>__add/sub_mul/div/mod__</code>\uff1a\u200b\u6570\u503c\u200b\u8fd0\u7b97\u200b </p><pre><code>def __add/sub_mul/div/mod__(self, other) -&gt; T_co\n</code></pre><p></p> <p>\u200b\u5206\u522b\u200b\u91cd\u8f7d\u200b\u4e86\u200b\u4e8c\u5143\u200b\u64cd\u4f5c\u7b26\u200b <code>+</code>\u3001<code>-</code>\u3001<code>*</code>\u3001<code>/</code>\u3001<code>%</code></p> </li> <li><code>__or/and/xor__</code>\uff1a\u200b\u6309\u4f4d\u200b\u8fd0\u7b97\u200b <pre><code>def __or/and/xor__(self, other) -&gt; T_co\n</code></pre> <p>\u200b\u5206\u522b\u200b\u91cd\u8f7d\u200b\u4e86\u200b\u6309\u4f4d\u200b\u64cd\u4f5c\u7b26\u200b <code>|</code>\u3001<code>&amp;</code>\u3001<code>^</code></p> </li> <li><code>__lshift/rshift__</code>\uff1a\u200b\u79fb\u4f4d\u200b\u8fd0\u7b97\u200b <pre><code>def __lshift/rshift__(self, other) -&gt; T_co\n</code></pre> <p>\u200b\u5206\u522b\u200b\u91cd\u8f7d\u200b\u4e86\u200b\u79fb\u4f4d\u200b\u64cd\u4f5c\u7b26\u200b <code>&lt;&lt;</code>\u3001<code>&gt;&gt;</code></p> </li> </ol>"},{"location":"Programing/Python/basic/commond_line.html","title":"Commond line","text":""},{"location":"Programing/Python/basic/commond_line.html#-c","title":"-c","text":"<p>\u200b\u5141\u8bb8\u200b\u4f60\u200b\u76f4\u63a5\u200b\u5728\u200b\u547d\u4ee4\u884c\u200b\u4e2d\u200b\u6267\u884c\u200b\u4e00\u6bb5\u200b Python \u200b\u4ee3\u7801\u200b\uff0c\u200b\u591a\u884c\u200b\u4ee3\u7801\u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u5206\u200b\u53f7\u200b ; \u200b\u5206\u9694\u200b\uff0c\u200b\u6216\u8005\u200b\u4f7f\u7528\u200b\u4e09\u200b\u5f15\u53f7\u200b ''' \u200b\u6216\u200b \"\"\" \u200b\u6765\u200b\u5305\u542b\u200b\u591a\u884c\u200b\u5b57\u7b26\u4e32\u200b\u3002 </p><pre><code>python -c \"import tensorflow as tf; print(tf.test.is_gpu_available())\"\n</code></pre><p></p>"},{"location":"Programing/Python/basic/commond_line.html#-u","title":"-u","text":""},{"location":"Programing/Python/details/Container.html","title":"Container","text":"<p>Python\u200b\u5bb9\u5668\u200b\u5173\u7cfb\u200b\u56fe\u200b</p>"},{"location":"Programing/Python/details/Container.html#_1","title":"\u5bb9\u5668\u200b\u95f4\u200b\u7684\u200b\u5173\u7cfb","text":"<p><code>Iterable</code>\u200b\u6d3e\u200b\u751f\u51fa\u200b<code>Iterator</code>\uff0c<code>Iterator</code>\u200b\u6d3e\u200b\u751f\u51fa\u200b<code>Generator</code></p> <ul> <li>\u200b\u53ea\u6709\u200b <code>Iterable</code> \u200b\u53ef\u4ee5\u200b\u901a\u8fc7\u200b\u5185\u7f6e\u200b\u51fd\u6570\u200b <code>len</code> \u200b\u8bbf\u95ee\u200b\u5bb9\u5668\u200b\u5143\u7d20\u200b\u4e2a\u6570\u200b</li> <li><code>Iterator</code> \u200b\u548c\u200b <code>Generator</code>\u200b\u53ea\u80fd\u200b\u901a\u8fc7\u200b\u5185\u7f6e\u200b\u51fd\u6570\u200b <code>next</code> \u200b\u6216\u200b\u8fed\u4ee3\u200b\u65b9\u6cd5\u200b\u904d\u5386\u200b\u5143\u7d20\u200b</li> <li><code>Iterable</code> \u200b\u53ef\u200b\u901a\u8fc7\u200b\u5185\u7f6e\u200b\u51fd\u6570\u200b <code>iter</code> \u200b\u751f\u6210\u200b\u4e00\u4e2a\u200b <code>Iterator</code>\uff0c\u200b\u4e14\u200b\u6ee1\u8db3\u200b<ul> <li><code>id(iter(Iterator)) == id(iter(Iterator))</code></li> <li><code>id(iter(Iterable)) != id(iter(Iterable))</code></li> </ul> </li> <li><code>Iterable</code> \u200b\u548c\u200b <code>Generator</code> \u200b\u662f\u200b\u6d88\u8d39\u578b\u200b\u7684\u200b\uff0c\u200b\u6bcf\u200b\u904d\u5386\u200b\u4e00\u6b21\u200b\u90fd\u200b\u4f1a\u200b\u66f4\u65b0\u200b\u72b6\u6001\u200b\uff0c\u200b\u5373\u200b\u94fe\u8868\u200b\uff1b\u200b\u800c\u200b <code>Iterable</code> \u200b\u662f\u200b\u6052\u5b9a\u200b\u7684\u200b\uff0c\u200b\u5373\u200b\u6570\u7ec4\u200b\u3002</li> </ul>"},{"location":"Programing/Python/details/Container.html#iteratable","title":"<code>Iteratable</code>","text":""},{"location":"Programing/Python/details/Container.html#iterator","title":"<code>Iterator</code>","text":""},{"location":"Programing/Python/details/Container.html#generator","title":"<code>Generator</code>","text":"<p>https://www.jianshu.com/p/8c29f88952e7</p>"},{"location":"Programing/Python/details/Decorator.html","title":"Decorator","text":""},{"location":"Programing/Python/details/Decorator.html#_1","title":"\u7c7b\u5185\u200b\u88c5\u9970\u200b\u5668","text":""},{"location":"Programing/Python/details/Decorator.html#staticmethod","title":"@staticmethod","text":"<p>\u200b\u53ef\u4ee5\u200b\u5355\u72ec\u200b\u6458\u51fa\u200b\u7c7b\u4e2d\u200b\uff0c\u200b\u53ea\u662f\u200b\u4e3a\u4e86\u200b\u4fbf\u4e8e\u200b\u5206\u7c7b\u200b\u76ee\u7684\u200b\u653e\u5165\u200b\u5230\u200b\u7c7b\u200b\u4e2d\u200b\uff0c\u200b\u672c\u8d28\u200b\u8fd8\u662f\u200b\u548c\u200b\u7c7b\u200b\u72ec\u7acb\u200b\uff08\u200b\u4e0d\u7528\u200b\u7528\u5230\u200b\u7c7b\u200b\u5bf9\u8c61\u200b\u3001\u200b\u5bf9\u8c61\u200b\u5c5e\u6027\u200b\u4ee5\u53ca\u200b\u7c7b\u200b\u5c5e\u6027\u200b\uff09</p>"},{"location":"Programing/Python/details/Decorator.html#classmethod","title":"@classmethod","text":"<p>\u200b\u53ea\u80fd\u200b\u8bbf\u95ee\u200b\u7c7b\u200b\u5c5e\u6027\u200b\uff0c\u200b\u4e0d\u80fd\u200b\u8bbf\u95ee\u200b\u5bf9\u8c61\u200b\u5c5e\u6027\u200b</p>"},{"location":"Programing/Python/details/Decorator.html#property","title":"@property","text":"<p>\u200b\u5728\u200b\u65b9\u6cd5\u200b\u5b9a\u4e49\u200b\u4e0a\u9762\u200b\u52a0\u200b\u4e00\u4e2a\u200b <code>@property</code> \u200b\u88c5\u9970\u200b\u5668\u200b\uff0c\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u628a\u200b\u65b9\u6cd5\u200b\u53d8\u6210\u200b\u4e00\u4e2a\u200b\u5c5e\u6027\u200b\uff0c\u200b\u5373\u200b\u901a\u8fc7\u200b <code>object_name.property_name</code> \u200b\u6765\u200b\u8bbf\u95ee\u200b </p><pre><code>class Person:\n    ...\n    @property\n    def fullname(self):\n        return self.first + ' ' + self.last\n</code></pre><p></p>"},{"location":"Programing/Python/details/Decorator.html#property_namesetter","title":"@&lt;property_name&gt;.setter","text":"<p>\u200b\u5bf9\u4e8e\u200b<code>@property</code>\u200b\u4fee\u9970\u200b\u7684\u200b\u5bf9\u8c61\u200b\u5c5e\u6027\u200b\u7684\u200b\u8d4b\u503c\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u7528\u200b<code>@&lt;property_name&gt;.setter</code>\u200b\u4fee\u9970\u200b\u7684\u200b\u65b9\u6cd5\u200b\u6765\u200b\u5b9e\u73b0\u200b </p><pre><code>class Person:\n    ...\n    @fullname.setter\n    def fullname(self, name):\n        first, last = name.split(' ', 1)\n        self.first = first\n        self.last = last\n</code></pre><p></p>"},{"location":"Programing/Python/details/fstring.html","title":"Fstring","text":"<p><code>\" %s %d\"</code></p>"},{"location":"Programing/Python/details/fstring.html#strformat","title":"<code>str.format()</code>","text":"<p>\u200b\u4f7f\u7528\u200b {} \u200b\u548c\u200b : \u200b\u6765\u200b\u66ff\u4ee3\u200b\u4ee5\u524d\u200b\u7684\u200b %</p> <ol> <li>\u200b\u4f20\u53c2\u200b <pre><code># \u200b\u4e0d\u200b\u8bbe\u7f6e\u200b\u6307\u5b9a\u200b\u4f4d\u7f6e\u200b\uff0c\u200b\u6309\u200b\u9ed8\u8ba4\u200b\u987a\u5e8f\u200b\u4f20\u53c2\u200b\n\"{} {}\".format(\"hello\", \"world\")            # 'hello world'\n\n# \u200b\u8bbe\u7f6e\u200b\u6307\u5b9a\u200b\u4f4d\u7f6e\u200b\u4f20\u53c2\u200b\n\"{1} {0}\".format(\"hello\", \"world\")          # 'world hello'\n\n# \u200b\u5173\u952e\u5b57\u200b\u4f20\u53c2\u200b                                    \n\"{v1} {v0}\".format(v0=\"hello\", v1=\"world\")  # 'world hello'\n\n# \u200b\u7d22\u5f15\u200b\u4f20\u53c2\u200b\nvars = ['\u200b\u83dc\u9e1f\u200b\u6559\u7a0b\u200b', 'www.runoob.com']\n\"{0[1]} {0[0]}\".format(vars)                # 'world hello'\n</code></pre></li> <li>\u200b\u6307\u5b9a\u200b\u683c\u5f0f\u200b &amp; \u200b\u81ea\u52a8\u200b\u8865\u5168\u200b &amp; \u200b\u4f4d\u6570\u200b\u4fdd\u7559\u200b <pre><code># \u200b\u6574\u578b\u200b\n{:c/&lt;/&gt;/^/nd}\n                    # c\uff1a\u200b\u586b\u5145\u200b\u5b57\u7b26\u200b\uff0c\u200b\u7f3a\u7701\u200b\u4e3a\u200b\u7a7a\u683c\u200b\n                    # \u200b\u65b9\u5411\u200b\uff0c{&lt;: \u200b\u53f3\u4fa7\u200b\u586b\u5145\u200b; &gt;: \u200b\u5de6\u4fa7\u200b\u586b\u5145\u200b; ^: \u200b\u5de6\u53f3\u200b(\u200b\u5947\u6570\u200b\u65f6\u200b\u53f3\u4fa7\u200b\u591a\u200b)\u200b\u586b\u5145\u200b\uff0c\u200b\u4e2d\u95f4\u200b\u5bf9\u9f50\u200b}\n                    # n\uff1a\u200b\u6700\u5c0f\u200b\u4f4d\u6570\u200b\n                    # d\uff1a\u200b\u6307\u5b9a\u200b\u4e3a\u200b\u6574\u578b\u200b\n\n# \u200b\u6d6e\u70b9\u200b\u578b\u200b\n{.nf}               # n\uff1a\u200b\u5c0f\u6570\u200b\u4fdd\u7559\u200b\u4f4d\u6570\u200b\n                    # f\uff1a\u200b\u6307\u5b9a\u200b\u4e3a\u200b\u6d6e\u70b9\u200b\u578b\u200b\n\n# \u200b\u5176\u4f59\u200b\u8fdb\u5236\u200b\n{:b}                # \u200b\u65e0\u200b\u524d\u7f00\u200b0b\u200b\u7684\u200b2\u200b\u8fdb\u5236\u200b\u5f62\u5f0f\u200b\n{:#b}               # \u200b\u6709\u200b\u524d\u7f00\u200b0b\u200b\u7684\u200b2\u200b\u8fdb\u5236\u200b\u5f62\u5f0f\u200b\n{:o}                # \u200b\u65e0\u200b\u524d\u7f00\u200b0o\u200b\u7684\u200b8\u200b\u8fdb\u5236\u200b\u5f62\u5f0f\u200b\n{:#o}               # \u200b\u6709\u200b\u524d\u7f00\u200b0o\u200b\u7684\u200b8\u200b\u8fdb\u5236\u200b\u5f62\u5f0f\u200b\n{:x}                # \u200b\u65e0\u200b\u524d\u7f00\u200b0x\u200b\u7684\u200b16\u200b\u8fdb\u5236\u200b + \u200b\u5b57\u6bcd\u200b\u5c0f\u5199\u200b \u200b\u5f62\u5f0f\u200b\n{:#x}               # \u200b\u6709\u200b\u524d\u7f00\u200b0x\u200b\u7684\u200b16\u200b\u8fdb\u5236\u200b + \u200b\u5b57\u6bcd\u200b\u5c0f\u5199\u200b \u200b\u5f62\u5f0f\u200b\n{:X}                # \u200b\u65e0\u200b\u524d\u7f00\u200b0x\u200b\u7684\u200b16\u200b\u8fdb\u5236\u200b + \u200b\u5b57\u6bcd\u200b\u5927\u5199\u200b \u200b\u5f62\u5f0f\u200b\n{:#X}               # \u200b\u6709\u200b\u524d\u7f00\u200b0x\u200b\u7684\u200b16\u200b\u8fdb\u5236\u200b + \u200b\u5b57\u6bcd\u200b\u5927\u5199\u200b \u200b\u5f62\u5f0f\u200b\n</code></pre></li> </ol> <p>\u200b\u5728\u200b\u4fdd\u7559\u200b\u5c0f\u6570\u70b9\u200b\u540e\u200bn\u200b\u4f4d\u65f6\u200b\uff0c\u200b\u83b7\u53d6\u200b\u4fdd\u7559\u200b\u5c0f\u6570\u200b\u7684\u200b\u4f4d\u6570\u200b <code>f'{val:.{n}f}'</code> </p><pre><code>import numpy as np\ndef get_str_length(val):\n    val_str = np.format_float_positional(val, trim='-')\n    n = len(val_str.split('.')[-1])\n    return n\n</code></pre><p></p>"},{"location":"Programing/Python/details/fstring.html#fstring","title":"fstring","text":"<p>\u200b\u7b49\u4ef7\u200b\u4e8e\u200b str.format() \u200b\u7684\u200b\u5173\u952e\u5b57\u200b\u4f20\u53c2\u200b\u65b9\u5f0f\u200b\uff0c\u200b\u533a\u522b\u200b\u5728\u4e8e\u200b \u200b\u5b57\u7b26\u4e32\u200b\u5de6\u4fa7\u200b\u4f7f\u7528\u200b <code>f\"\"</code>\u200b\u4fee\u9970\u200b\u4e14\u200b\u4e0d\u200b\u9700\u8981\u200b\u540e\u9762\u200b\u7684\u200b <code>.format()</code></p>"},{"location":"Programing/Python/details/lambda.html","title":"Lambda","text":"<pre><code>lambda *x: sum(x)\n</code></pre> <pre><code>import functools\n\n# \u200b\u7531\u4e8e\u200bcallable\u200b\u7684\u200b\u8f93\u5165\u200b\u662f\u200b\u4e00\u4e2a\u200b\u51fd\u6570\u200b\uff0c\u200b\u4e14\u200b\u4e0d\u200b\u5b58\u5728\u200b\u53c2\u6570\u200b\u5217\u8868\u200b\uff0c\u200b\u6240\u4ee5\u200b\u53ef\u200b\u501f\u52a9\u200bfunctools.partial\u200b\u5b9e\u73b0\u200b\u4f20\u53c2\u200b\nnew_fun_name = functools.partial(sum, x)\n</code></pre>"},{"location":"Programing/Python/libs/ahocorasick.html","title":"Ahocorasick","text":"<p><code>Aho\u2013Corasick</code>\u200b\u7b97\u6cd5\u200b\u662f\u200b\u7531\u200bAlfred V. Aho\u200b\u548c\u200bMargaret J.Corasick \u200b\u53d1\u660e\u200b\u7684\u200b\u5b57\u7b26\u4e32\u200b\u641c\u7d22\u7b97\u6cd5\u200b\uff0c\u200b\u7528\u4e8e\u200b\u5728\u200b\u8f93\u5165\u200b\u7684\u200b\u4e00\u4e32\u200b\u5b57\u7b26\u4e32\u200b\u4e2d\u200b\u5339\u914d\u200b\u6709\u9650\u200b\u7ec4\u200b\u5b57\u5178\u200b\u6811\u4e2d\u200b\u7684\u200b\u5b50\u4e32\u200b\u3002</p>"},{"location":"Programing/Python/libs/ahocorasick.html#_1","title":"\u4f7f\u7528\u200b\u65b9\u6cd5","text":"<pre><code>from ahocorasick import Trie\ntrie = Trie(\n    allow_overlaps=True,            # False\uff1a\u200b\u53ea\u200b\u8fd4\u56de\u200b\u5339\u914d\u200b\u5b57\u5178\u200b\u6811\u200b\u6700\u957f\u200b\u7684\u200b\u5173\u952e\u5b57\u200b\n                                    # True\uff1a\u200b\u5141\u8bb8\u200b\u8fd4\u56de\u200b\u6240\u6709\u200b\u5339\u914d\u200b\u7684\u200b\u5173\u952e\u5b57\u200b\n    case_sensitive=False            # \u200b\u662f\u5426\u200b\u5927\u5c0f\u5199\u200b\u654f\u611f\u200b\n)\ntrie.build_trie(keyword_list)       # \u200b\u5411\u200b\u5b57\u5178\u200b\u6811\u4e2d\u200b\u6dfb\u52a0\u200b\u5173\u952e\u5b57\u200b\u8bcd\u5178\u200b\nemits = trie.parse_text(text)       # \u200b\u57fa\u4e8e\u200b\u65e2\u6709\u200b\u5173\u952e\u5b57\u200b\u8bcd\u5178\u200b\u548c\u200bahocorasick\u200b\u7b97\u6cd5\u200b\u5b9e\u73b0\u200b\u5173\u952e\u5b57\u200b\u5339\u914d\u200b\n                                    # emit.start, emit.end, emit.keyword\n\ndef replace_span(text):\n    intervals = trie.parse_text(text)\n    text_new = []\n    idx = 0\n\n    for interval in intervals:\n        text_new += text[idx: interval.start]\n        span = text[interval.start: interval.end + 1]\n        replace_span = replace_map[span]\n        text_new.append(replace_span)\n        idx = interval.end + 1\n\n    text_new.append(text[idx:])\n    return \"\".join(text_new)\n</code></pre>"},{"location":"Programing/Python/libs/argparser.html","title":"Argparser","text":""},{"location":"Programing/Python/libs/argparser.html#argparse","title":"argparse","text":""},{"location":"Programing/Python/libs/argparser.html#_1","title":"\u57fa\u672c\u200b\u7528\u6cd5","text":"<pre><code>import argparse\n\nparser = argparse.ArgumentParser()\n\nparser.add_argument(...)\n\nargs = parser.parse_args()      # \u200b\u901a\u8fc7\u200b`args.var_name` \u200b\u8c03\u7528\u200b\u76f8\u5e94\u200b\u53c2\u6570\u200b\n</code></pre>"},{"location":"Programing/Python/libs/argparser.html#argumentparser","title":"ArgumentParser","text":"<pre><code># \u200b\u683c\u5f0f\u200b\ndef add_argument(\n    'var_name',                 # \u200b\u4ee3\u7801\u200b\u4f20\u53c2\u65f6\u200b\u4e0d\u80fd\u200b\u901a\u8fc7\u200bkey\u200b\u6307\u5b9a\u200b\uff0c\u200b\u53ea\u80fd\u200b\u4f4d\u7f6e\u200b\u5339\u914d\u200b\uff0c\u200b\u4e0d\u200b\u5efa\u8bae\u200b\u4f7f\u7528\u200b                                                          \n    '--var_name',               # \u200b\u4ee3\u7801\u200bvar_name\u200b\u4f20\u53c2\u65f6\u200bkey\u200b\u53ef\u7528\u200b`var_name`\u200b\u6307\u5b9a\u200b\n    '-var_abbr',                # \u200b\u4ee3\u7801\u200bvar_name\u200b\u4f20\u53c2\u65f6\u200bkey\u200b\u53ef\u7528\u200b\u7b80\u5199\u200b`var_abbr`\u200b\u6307\u5b9a\u200b\n\n    type,                       # \u200b\u6307\u5b9a\u200b\u53c2\u6570\u200bvar_name\u200b\u7684\u200b\u7c7b\u578b\u200b\n    default,                    # \u200b\u6307\u5b9a\u200b\u53c2\u6570\u200bvar_name\u200b\u7684\u200b\u7f3a\u7701\u503c\u200b\n    required=False,             # \u200b\u53c2\u6570\u200bvar_name\u200b\u662f\u5426\u200b\u5fc5\u987b\u200b\u3010\u200b\u4f20\u53c2\u200b\u6216\u200b\u6709\u200b\u521d\u59cb\u503c\u200b\u3011\n    help,                       # type(help) == str, \u200b\u53c2\u6570\u200bvar_name\u200b\u7684\u200b\u63cf\u8ff0\u200b\u4fe1\u606f\u200b\n)\n\n## int\nparser.add_argument('-v', '--var', type=int, default=0, required=False, help='var description')\n\n## float\nparser.add_argument('-v', '--var', type=float, default=0, required=False, help='var description')\n\n## Iterable, \u200b\u8f93\u5165\u200btuple\uff0c\u200b\u5982\u200b\uff1a --var 1 2 3\nparser.add_argument('-v', '--var', type=int, nargs=3, required=False, help='var description')    # nargs\u200b\u6307\u5b9a\u200b\u8f93\u5165\u200b\u7684\u200b\u5143\u7d20\u200b\u4e2a\u6570\u200b\n\n## str\nparser.add_argument('-v', '--var', type=str, default='', required=False, help='var description')\n\n## bool, stroe_true\u200b\u4f20\u53c2\u65f6\u200b\u53ea\u200b\u9700\u8981\u200b\u4f20\u5165\u200b\u52a8\u4f5c\u200b\uff1a\u3010-v/--var\u3011 \u200b\u5373\u53ef\u200b\u5b9e\u73b0\u200b var=action.split('_')[-1]\nparser.add_argument('-v', '--var', action='store_true', required=False, help='var description')\n</code></pre>"},{"location":"Programing/Python/libs/argparser.html#tfflags","title":"tf.flags","text":""},{"location":"Programing/Python/libs/argparser.html#_2","title":"\u57fa\u672c\u200b\u7528\u6cd5","text":"<pre><code>import tensorflow as tf\n\nflags = tf.flags\n\nflag.DEFINE_integer/float/string/boole(...)\n\nFLAGS = flags.FLAGS             # \u200b\u901a\u8fc7\u200bFLAGS.var_name \u200b\u8c03\u7528\u200b\u76f8\u5e94\u200b\u53c2\u6570\u200b\n</code></pre>"},{"location":"Programing/Python/libs/argparser.html#flags","title":"flags\u200b\u65b9\u6cd5","text":"<pre><code># \u200b\u683c\u5f0f\u200b\ndef DEFINE_integer/float/string/bool(\n    'var_name',                 # \u200b\u4ee3\u7801\u200b\u4f20\u53c2\u65f6\u200b\u53ef\u200b\u901a\u8fc7\u200bkey\u200b\u6307\u5b9a\u200b\uff0c\u200b\u7b49\u4ef7\u200b\u4e8e\u200bargparse\u200b\u7684\u200b --var_name\n    'var_value',                # var_name\u200b\u7684\u200b\u7f3a\u7701\u503c\u200b\n    'var_description',          # var_name\u200b\u7684\u200b\u63cf\u8ff0\u200b\u4fe1\u606f\u200b\n)\n\n\n## int\nflags.DEFINE_integer('var_name', 0, 'var description')\n\n## float\nflag.DEFINE_float('var_name', 0.0, 'var description')\n\n## str\nflag.DEFINE_string('var_name', '', 'var description')\n\n## bool\nflag.DEFINE_bool('var_name', False, 'var description')\n\n\n## \u200b\u5176\u4ed6\u200b\u7279\u6027\u200b\uff1a\u200b\u662f\u5426\u200b\u5fc5\u987b\u200b\u4f20\u53c2\u200b\nflags.mark_flag_as_required(\"var_name\")\nflags.mark_flags_as_requred([\"var_name1\", \"var_name2\", ...])\n</code></pre>"},{"location":"Programing/Python/libs/codecs.html","title":"Codecs","text":""},{"location":"Programing/Python/libs/codecs.html#_1","title":"\u53cd\u200b\u659c\u6760\u200b\u8f6c\u4e49\u200b\u95ee\u9898","text":"<pre><code>import codecs\ncnt = \"\u200b\u4ee8\u200b\u7afa\u200b\u6c43\u200b\u6617\u200b\u5b8d\u200b\u7afa\u200b\u8a35\u200b\u5b8d\u200b\u6cd7\u200b\\\\n\u200b\u85e4\u8bad\u200b\u53f7\u200b\\\\n\"\n\ncnt = codecs.escape_decode(cnt)[0].decode(\"utf-8\")  # escape_decode\u200b\u8fd4\u56de\u200b(bytes, len(bytes))\n                                                    # \"\u200b\u4ee8\u200b\u7afa\u200b\u6c43\u200b\u6617\u200b\u5b8d\u200b\u7afa\u200b\u8a35\u200b\u5b8d\u200b\u6cd7\u200b\\n\u200b\u85e4\u8bad\u200b\u53f7\u200b\\n\"\n</code></pre>"},{"location":"Programing/Python/libs/codecs.html#_2","title":"\u5355\u5b57\u8282\u200b\u7f16\u7801","text":"<pre><code># unicode\u200b\u8f6c\u200bbytearray\nmulti_byte_stream = s.encode(\"utf-8\")\n# \u200b\u5355\u5b57\u8282\u200b\u8f6c\u200bbytearray\nsingle_byte_stream = s.encode(\"latin-1\")            # \u200b\u5b57\u7b26\u4e32\u200bs\u200b\u91cc\u200b\u7684\u200bUnicode\u200b\u503c\u5e94\u200b\u90fd\u200b\u5904\u4e8e\u200b0~255\u200b\u8303\u56f4\u200b\u5185\u200b\n\n# bytearray\u200b\u8f6c\u200bunicode\nunicode_str = byte_stream.decode(\"utf-8\")           # \u200b\u8f6c\u5316\u200b\u4e3a\u200bunicode\u200b\u5e94\u200b\u4e25\u683c\u200b\u7b26\u5408\u200bbytearray2unicode\u200b\u89c4\u5219\u200b\n# bytearray\u200b\u8f6c\u200b\u5355\u5b57\u8282\u200b\u5f62\u5f0f\u200b\nsingle_byte_str = byte_stream.decode(\"latin-1\")     # \u200b\u5f88\u591a\u200bBBPE\u200b\u8bcd\u8868\u200b\u5c31\u662f\u200b\u4ee5\u8be5\u200b\u5f62\u5f0f\u200b\u4fdd\u5b58\u200b\n</code></pre>"},{"location":"Programing/Python/libs/codecs.html#bytearray2unicode","title":"bytearray2unicode","text":"<p>\u200b\u5728\u200b\u5b57\u8282\u200b\u8f6c\u200bunicode\u200b\u8bbe\u8ba1\u200b\u4e2d\u200b\uff0c\u200b\u4e3a\u200b\u4f7f\u200b\u4e92\u76f8\u200b\u8f6c\u6362\u200b\u65e0\u200b\u6b67\u4e49\u200b\uff0c\u200b\u8bbe\u8ba1\u200b\u4e86\u200b\u4ee5\u4e0b\u200b\u89c4\u5219\u200b\uff1a</p> \u200b\u5b57\u8282\u200b\u7c7b\u578b\u200b \u200b\u9996\u200b\u5b57\u8282\u200b\u524d\u7f00\u200b \u200b\u540e\u7eed\u200b\u5b57\u8282\u200b\u524d\u7f00\u200b Unicode\u200b\u8303\u56f4\u200b \u200b\u5355\u5b57\u8282\u200b <code>0b0xxxxxxx</code> \u200b\u65e0\u200b <code>U+0000</code> ~ <code>U+007F</code> \u200b\u53cc\u200b\u5b57\u8282\u200b <code>0b110xxxxx</code> <code>0b10xxxxxx</code> <code>U+0000</code> ~ <code>U+07FF</code> \u200b\u4e09\u200b\u5b57\u8282\u200b <code>0b1110xxxx</code> <code>0b10xxxxxx</code> <code>U+0000</code> ~ <code>U+FFFF</code> \u200b\u56db\u200b\u5b57\u8282\u200b <code>0b11110xxx</code> <code>0b10xxxxxx</code> <code>U+10000</code> ~ <code>U+10FFFF</code> <p>\u200b\u5404\u200b\u5b57\u8282\u200b\u53bb\u9664\u200b\u524d\u7f00\u200b\u540e\u200b\u7684\u200b\u6bd4\u7279\u200b\u4f4d\u200b <code>cancat</code> \u200b\u5373\u200b\u4e3a\u200b\u6700\u7ec8\u200bunicode\u200b\u7ed3\u679c\u200b</p> <ol> <li>\u200b\u524d\u7f00\u200b\u7801\u200b\u7cfb\u7edf\u200b\uff1a\u200b\u9996\u200b\u5b57\u8282\u200b\u4ee5\u200b<code>0b0</code>\u200b\u5f00\u5934\u200b\u8868\u793a\u200b\u8be5\u200bunicode\u200b\u662f\u200b\u5355\u5b57\u8282\u200b\u5b57\u7b26\u200b\uff1b\u200b\u4ee5\u200b<code>0b</code> + <code>1*n</code> + <code>0</code>\u200b\u5f00\u5934\u200b\u8868\u793a\u200b\u4e3a\u200bn\u200b\u5b57\u8282\u200b\u5b57\u7b26\u200b</li> <li>\u200b\u540e\u7eed\u200b\u5b57\u8282\u200b\u6807\u8bb0\u200b\uff1a\u200b\u4e3a\u200b\u907f\u514d\u200b\u4e0e\u200b\u9996\u200b\u5b57\u8282\u200b\u51b2\u7a81\u200b\uff0cunicode\u200b\u6240\u6709\u200b\u540e\u7eed\u200b\u5b57\u8282\u200b\u524d\u200b\u4e24\u200bbit\u200b\u5747\u200b\u4ee5\u200b<code>0b10</code>\u200b\u5f00\u5934\u200b</li> <li>\u200b\u4e25\u683c\u200b\u5408\u6cd5\u6027\u68c0\u67e5\u200b\uff1adecode\u200b\u4f1a\u200b\u62d2\u7edd\u200b\u6240\u6709\u200b\u4e0d\u200b\u5408\u6cd5\u200b\u7684\u200b\u5b57\u8282\u200b\u5e8f\u5217\u200b\uff08\u200b\u4e0d\u200b\u7b26\u5408\u200b\u524d\u7f00\u200b\u89c4\u7ea6\u200b\u5373\u200b\u62a5\u9519\u200b\uff09</li> </ol> <pre><code>byte_stream = bytearray()   # \u200b\u5b58\u653e\u200b\u5b57\u8282\u200b\u7801\u200b\uff08\u200b\u5143\u7d20\u200b\u503c\u4e3a\u200b\u6574\u578b\u200b\uff09\nbyte_stream.decode(\"utf-8\") # bytearray\u200b\u89e3\u7801\u200b\u6620\u5c04\u200b\u4e3a\u200bunicode\n</code></pre>"},{"location":"Programing/Python/libs/collections.html","title":"Collections","text":""},{"location":"Programing/Python/libs/concurrent_programming.html","title":"Concurrent programming","text":"<ol> <li>threading\uff1a\u200b\u591a\u7ebf\u7a0b\u200b\u4e32\u884c\u200b\uff0c\u200b\u53ef\u200b\u901a\u8fc7\u200b<code>global</code>\u200b\u76f4\u63a5\u200b\u5171\u4eab\u200b\u5168\u5c40\u53d8\u91cf\u200b</li> <li>multiprocessing\uff1a\u200b\u591a\u200b\u8fdb\u7a0b\u200b\u5e76\u884c\u200b</li> </ol>"},{"location":"Programing/Python/libs/concurrent_programming.html#threading","title":"threading","text":""},{"location":"Programing/Python/libs/concurrent_programming.html#threading_1","title":"threading\u200b\u51fd\u6570","text":"<pre><code># \u200b\u8fd4\u56de\u200b\u4e3b\u7ebf\u200b\u7a0b\u200b\nthreading.main_thread()\n\n# \u200b\u679a\u4e3e\u200b\u5b58\u6d3b\u200b\u7684\u200b\u7ebf\u7a0b\u200b list[threading.Thread]\nthreading.enumerate()\n\n# \u200b\u8fd4\u56de\u200b\u5b58\u6d3b\u200b\u7684\u200b threading.Thread \u200b\u4e2a\u6570\u200b\uff0c\u200b\u7b49\u4ef7\u200b\u4e8e\u200blen(threading.enumerate())\nthreading.active_count()\n</code></pre> <p>\u200b\u517c\u5bb9\u200b2.x\u200b\u7248\u672c\u200b\uff08\u200b\u5bf9\u5e94\u200b\u7684\u200b\u65b9\u6cd5\u200b\u4f7f\u7528\u200b\u7684\u200b\u662f\u200b\u9a7c\u5cf0\u200b\u547d\u4ee4\u200b\u6cd5\u200b\uff09</p>"},{"location":"Programing/Python/libs/concurrent_programming.html#threading_2","title":"threading\u200b\u5e38\u91cf","text":"<pre><code># \u200b\u6307\u5b9a\u200b\u963b\u585e\u200b\u51fd\u6570\u200b\uff08\u200b\u5982\u200bLock.acquire()\u3001RLock.acquire()\u3001Condition.wait()\u200b\u7b49\u200b\uff09\u200b\u4e2d\u200b\u53c2\u6570\u200btimeout\nthreading.TIMEOUT_MAX\n</code></pre>"},{"location":"Programing/Python/libs/concurrent_programming.html#threadingthread","title":"<code>threading.Thread</code>","text":"<pre><code>def __init__(\n    self, \n    group=None, \n    target=None,    # \u200b\u8c03\u7528\u200b\u7684\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u7ebf\u7a0b\u200b\u6267\u884c\u200b\u7684\u200b\u4efb\u52a1\u200b \n    name=None,      # \u200b\u7ebf\u7a0b\u200b\u540d\u5b57\u200b\n    args=(),        # \u200b\u8c03\u7528\u200b\u5bf9\u8c61\u200b\u7684\u200b\u4f4d\u7f6e\u200b\u53c2\u6570\u200b\u5143\u7ec4\u200b\n    kwargs=None,    # \u200b\u8c03\u7528\u200b\u5bf9\u8c61\u200b\u7684\u200b\u5173\u952e\u5b57\u200b\u53c2\u6570\u200b\u5b57\u5178\u200b\n    *, \n    daemon=None     # bool, \u200b\u662f\u5426\u200b\u4e3a\u200b\u5b88\u62a4\u200b\u7ebf\u7a0b\u200b\n    )\n</code></pre> <ul> <li><code>start</code>\uff1a\u200b\u542f\u52a8\u200b\u7ebf\u7a0b\u200b (\u200b\u7531\u4e8e\u200b\u8bbe\u7f6e\u200b\u4e86\u200bflag, \u200b\u8be5\u200b\u65b9\u6cd5\u200b\u53ea\u80fd\u200b\u542f\u52a8\u200b\u4e00\u6b21\u200b)\uff0c\u200b\u8c03\u7528\u200b<code>run</code> \u200b\u65b9\u6cd5\u200b</li> <li><code>run</code>\uff1a\u200b\u7ebf\u7a0b\u200b\u8fd0\u884c\u200b\u7684\u200b\u51fd\u6570\u200b\u4f53\u200b\uff08\u200b\u8fd0\u884c\u200b\u4f20\u5165\u200b\u7684\u200b\u8c03\u7528\u200b\u5bf9\u8c61\u200b\u6216\u200b\u7ee7\u627f\u200b\u7c7b\u200b<code>Thread</code>\u200b\u91cd\u5199\u200b\u65b9\u6cd5\u200brun\uff09</li> <li><code>join(timeout=None)</code> \u200b\u7b49\u5f85\u200b\u7ebf\u7a0b\u200b\u6267\u884c\u200b\u5b8c\u518d\u200b\u7ed3\u675f\u200b\u4e3b\u7ebf\u200b\u7a0b\u200b<ul> <li>\u200b\u4e00\u822c\u200b\u7edf\u4e00\u200b<code>start</code>\uff0c\u200b\u518d\u200b\u7edf\u4e00\u200b<code>join</code>\uff0c\u200b\u5426\u5219\u200b<code>start</code>\u200b\u548c\u200b<code>join</code>\u200b\u7a7f\u63d2\u200b\u5c31\u662f\u200b\u6b63\u5e38\u200b\u7684\u200b\u4e32\u884c\u200b <pre><code>[t.start() for t in threads]\n[t.join() for t in threads]\n</code></pre></li> </ul> </li> <li><code>name</code>\uff1a\u200b\u7ebf\u7a0b\u200b\u540d\u200b</li> <li><code>ident</code>\uff1a\u200b\u7ebf\u7a0b\u200bid</li> <li><code>daemon</code></li> </ul>"},{"location":"Programing/Python/libs/concurrent_programming.html#threadinglock","title":"<code>threading.Lock</code>","text":"<p>\u200b\u4e92\u65a5\u200b\u9501\u200b\u88ab\u200b\u7528\u6765\u200b\u5b9e\u73b0\u200b\u540c\u65f6\u200b\u53ea\u6709\u200b\u4e00\u4e2a\u200b\u7ebf\u7a0b\u200b\u65b9\u5bf8\u200b\u5171\u4eab\u8d44\u6e90\u200b\uff0c\u200b\u4ee5\u200b\u907f\u514d\u200b\u65e0\u6548\u200b\u8d4b\u503c\u200b\uff08\u200b\u5982\u200b\u591a\u4e2a\u200b\u7ebf\u7a0b\u200b\u540c\u65f6\u200b\u8bfb\u53d6\u200b\u4e86\u200b\u8d4b\u503c\u200b\u524d\u200b\u7684\u200b\u503c\u200b\uff09 </p><pre><code>x = 0\nlock = Lock()\n\ndef func():\n    global x\n    lock.acquire()              # \u200b\u4fdd\u8bc1\u200b\u5bf9\u200b\u5171\u4eab\u8d44\u6e90\u200b`x`\u200b\u64cd\u4f5c\u200b\u662f\u200b\u7ebf\u7a0b\u200b\u5b89\u5168\u200b\u7684\u200b\n    for i in range(6000):\n        x = x+1\n    lock.release()\n\ndef lock_main():\n    for i in range(3):\n        t = Thread(target=func)\n        t.start()\n        t.join()\n    print(x)\n\nlock_main()\nprint(x)                        # 3*6000 = 18000\n</code></pre><p></p>"},{"location":"Programing/Python/libs/concurrent_programming.html#threadingrlock","title":"<code>threading.RLock</code>","text":""},{"location":"Programing/Python/libs/concurrent_programming.html#threadingcondition","title":"<code>threading.Condition</code>","text":"<p>\u200b\u6761\u4ef6\u200b\u9501\u200b</p>"},{"location":"Programing/Python/libs/concurrent_programming.html#threadingsemaphore","title":"<code>threading.Semaphore</code>","text":"<p>\u200b\u63a7\u5236\u200b\u540c\u65f6\u200b\u8bbf\u95ee\u5171\u4eab\u200b\u8d44\u6e90\u200b\u7684\u200b\u7ebf\u7a0b\u200b\u6570\u91cf\u200b</p>"},{"location":"Programing/Python/libs/concurrent_programming.html#threadingevent","title":"<code>threading.Event</code>","text":"<p>\u200b\u4e00\u4e2a\u200b\u6216\u200b\u591a\u4e2a\u200b\u7ebf\u7a0b\u200b\u9700\u8981\u200b\u77e5\u9053\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u7ebf\u7a0b\u200b\u7684\u200b\u72b6\u6001\u200b\u624d\u80fd\u200b\u8fdb\u884c\u200b\u4e0b\u200b\u4e00\u6b65\u200b\u64cd\u4f5c\u200b</p> <ul> <li><code>is_set</code>\uff1a\u200b\u5224\u65ad\u200bevent\u200b\u662f\u5426\u200benable</li> <li><code>set</code>\uff1a\u200b\u7f6e\u200b\u4e3a\u200benable</li> <li><code>clear</code>\uff1a\u200b\u7f6e\u200b\u4e3a\u200bdisable</li> <li><code>wait(timeout=None)</code>\uff1a\u200b\u7b49\u5f85\u200bevent\u200b\u72b6\u6001\u200b\u4e3a\u200benable 1 <pre><code>event = threading.Event()\n\ndef student_exam(student_id):\n    print(f'\u200b\u5b66\u751f\u200b{student_id}\u200b\u7b49\u200b\u76d1\u8003\u200b\u8001\u5e08\u200b\u53d1\u5377\u200b')\n    event.wait()\n    print(f'\u200b\u5b66\u751f\u200b{student_id}\u200b\u5f00\u59cb\u200b\u8003\u8bd5\u200b\u4e86\u200b')\n\ndef invigilate_teacher():\n    time.sleep(3)\n    print('\u200b\u8003\u8bd5\u200b\u65f6\u95f4\u200b\u5230\u200b\u4e86\u200b\uff0c\u200b\u5b66\u751f\u200b\u4eec\u200b\u53ef\u4ee5\u200b\u8003\u8bd5\u200b\u4e86\u200b')\n    event.set()\n\ndef event_main():\n    for student_id in range(3):\n        threading.Thread(target=student_exam, args=(student_id+1,)).start()\n    threading.Thread(target=invigilate_teacher).start()\n\nevent_main()        # \u200b\u5b66\u751f\u200b1\u200b\u7b49\u200b\u76d1\u8003\u200b\u8001\u5e08\u200b\u53d1\u5377\u200b\n                    # \u200b\u5b66\u751f\u200b2\u200b\u7b49\u200b\u76d1\u8003\u200b\u8001\u5e08\u200b\u53d1\u5377\u200b\n                    # \u200b\u5b66\u751f\u200b3\u200b\u7b49\u200b\u76d1\u8003\u200b\u8001\u5e08\u200b\u53d1\u5377\u200b\n                    # \u200b\u8003\u8bd5\u200b\u65f6\u95f4\u200b\u5230\u200b\u4e86\u200b\uff0c\u200b\u5b66\u751f\u200b\u4eec\u200b\u53ef\u4ee5\u200b\u8003\u8bd5\u200b\u4e86\u200b\n                    # \u200b\u5b66\u751f\u200b1\u200b\u5f00\u59cb\u200b\u8003\u8bd5\u200b\u4e86\u200b\n                    # \u200b\u5b66\u751f\u200b3\u200b\u5f00\u59cb\u200b\u8003\u8bd5\u200b\u4e86\u200b\n                    # \u200b\u5b66\u751f\u200b2\u200b\u5f00\u59cb\u200b\u8003\u8bd5\u200b\u4e86\u200b\n</code></pre></li> </ul>"},{"location":"Programing/Python/libs/concurrent_programming.html#multiprocessing","title":"multiprocessing","text":""},{"location":"Programing/Python/libs/concurrent_programming.html#porcessinngprocess","title":"porcessinng.Process","text":"<pre><code>def __init__(\n    self, \n    group=None,\n    target=None,    # \u200b\u8c03\u7528\u200b\u7684\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u8fdb\u7a0b\u200b\u6267\u884c\u200b\u7684\u200b\u4efb\u52a1\u200b \n    name=None,      # \u200b\u8fdb\u7a0b\u200b\u540d\u5b57\u200b\n    args=(),        # \u200b\u8c03\u7528\u200b\u5bf9\u8c61\u200b\u7684\u200b\u4f4d\u7f6e\u200b\u53c2\u6570\u200b\u5143\u7ec4\u200b\n    kwargs={},      # \u200b\u8c03\u7528\u200b\u5bf9\u8c61\u200b\u7684\u200b\u5173\u952e\u5b57\u200b\u53c2\u6570\u200b\u5b57\u5178\u200b\n    *, \n    daemon=None     # bool, \u200b\u662f\u5426\u200b\u4e3a\u200b\u5b88\u62a4\u200b\u8fdb\u7a0b\u200b\n    )\n</code></pre> <ul> <li><code>start</code>\uff1a\u200b\u542f\u52a8\u200b\u8fdb\u7a0b\u200b\uff0c\u200b\u8c03\u7528\u200b<code>run</code>\u200b\u65b9\u6cd5\u200b</li> <li><code>run</code>\uff1a\u200b\u8fdb\u7a0b\u200b\u8fd0\u884c\u200b\u7684\u200b\u51fd\u6570\u200b\u4f53\u200b</li> <li><code>join(timeout=None)</code>\uff1a\u200b\u7b49\u5f85\u200b\u8fdb\u7a0b\u200b\u6267\u884c\u200b\u5b8c\u518d\u200b\u7ed3\u675f\u200b\u4e3b\u200b\u8fdb\u7a0b\u200b<ul> <li>\u200b\u4e00\u822c\u200b\u7edf\u4e00\u200b<code>start</code>\uff0c\u200b\u518d\u200b\u7edf\u4e00\u200b<code>join</code>\uff0c\u200b\u5426\u5219\u200b<code>start</code>\u200b\u548c\u200b<code>join</code>\u200b\u7a7f\u63d2\u200b\u5c31\u662f\u200b\u6b63\u5e38\u200b\u7684\u200b\u4e32\u884c\u200b <pre><code>[p.start() for p in processes]\n[p.join() for p in processes]\n</code></pre></li> </ul> </li> <li><code>terminate</code>\uff1a\u200b\u5f3a\u5236\u200b\u7ec8\u6b62\u200b\u8fdb\u7a0b\u200b\uff0c\u200b\u4e0d\u200b\u8fdb\u884c\u200b\u6e05\u7406\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u4e14\u200b\u5176\u5b50\u200b\u8fdb\u7a0b\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u53d8\u6210\u200b\u50f5\u5c38\u200b\u8fdb\u7a0b\u200b</li> <li><code>kill</code>\uff1a\u200b\u540c\u200b<code>terminate</code></li> <li><code>close</code>\uff1a\u200b\u5173\u95ed\u200b\u8fdb\u7a0b\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u5e76\u200b\u6e05\u7406\u200b\u8d44\u6e90\u200b\uff0c\u200b\u5982\u679c\u200b\u8fdb\u7a0b\u200b\u4ecd\u200b\u5728\u200b\u8fd0\u884c\u200b\u5219\u200b\u8fd4\u56de\u200b\u9519\u8bef\u200b</li> </ul>"},{"location":"Programing/Python/libs/concurrent_programming.html#processingpool","title":"processing.Pool","text":""},{"location":"Programing/Python/libs/concurrent_programming.html#processingqueue","title":"processing.Queue","text":""},{"location":"Programing/Python/libs/concurrent_programming.html#asyncio","title":"asyncio","text":""},{"location":"Programing/Python/libs/concurrent_programming.html#concurrentfeatures","title":"concurrent.features","text":""},{"location":"Programing/Python/libs/emoji.html","title":"Emoji","text":"<pre><code>import emoji    # pip install emoji\n</code></pre>"},{"location":"Programing/Python/libs/emoji.html#_1","title":"\u5e38\u7528\u200b\u529f\u80fd","text":"<ol> <li> <p><code>is_emoji</code> \u200b\u5224\u65ad\u200b\u8f93\u5165\u200b\u7684\u200b <code>string</code> \u200b\u662f\u5426\u200b\u4e3a\u200b\u5355\u4e2a\u200bemoji</p> </li> <li> <p><code>emojize</code> \u200b\u5c06\u200b\u5e26\u6709\u200b\u5de6\u53f3\u200b\u5192\u53f7\u200b\u7684\u200b\u82f1\u6587\u200b\u8868\u793a\u200b\u8f6c\u5316\u200b\u4e3a\u200bemoji</p> <p><code>:thumbs_up: -&gt; \ud83d\udc4d</code></p> </li> <li><code>demojize</code> \u200b\u5c06\u200bemoji\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u5e26\u6709\u200b\u5de6\u53f3\u200b\u5192\u53f7\u200b\u7684\u200b\u82f1\u6587\u200b\u8868\u793a\u200b <p><code>\ud83d\udc4d -&gt; :thumbs_up:</code></p> </li> <li><code>emoji_list()</code> \u200b\u8fd4\u56de\u200blist\uff0c\u200b\u5305\u542b\u200b\u5b57\u7b26\u4e32\u200b\u4e2d\u200b\u6240\u6709\u200bemoji\u200b\u53ca\u5176\u200b\u4f4d\u7f6e\u200b\u4fe1\u606f\u200b    <pre><code>for emj in emoji.emoji_list(input_str):\n    print(emj['emoji'], emj['match_start'], emj['match_end'])   # [match_start, match_end)\n</code></pre></li> <li><code>emoji.EMOJI_DATA</code> \u200b\u5b57\u5178\u200b\uff0ckey\u200b\u4e3a\u200bemoji\u200b\u5b57\u7b26\u4e32\u200b</li> </ol> <ul> <li>emoji\u200b\u5b58\u5728\u200b\u989c\u8272\u200b\u53d8\u79cd\u200b\uff0c\u200b\u5373\u200b{\u200b\u672c\u8272\u200b, \u200b\u5fae\u6d45\u200b, \u200b\u6d45\u8272\u200b, \u200b\u4e2d\u7b49\u200b, \u200b\u5fae\u6df1\u200b, \u200b\u6df1\u8272\u200b}\u200b\u516d\u79cd\u200b\uff0c\u200b\u53ef\u200b\u901a\u8fc7\u200b <code>re.sub('_(?:dark|medium-dark|medium|medium-light|light)_skin_tone', '', de_emoji_str)</code> \u200b\u8fdb\u884c\u200b\u5f52\u4e00\u5316\u200b</li> </ul>"},{"location":"Programing/Python/libs/file_format.html","title":"File format","text":"<p>Python\u200b\u4e2d\u200b <code>file.write()</code> \u200b\u65b9\u6cd5\u200b\u53ea\u80fd\u200b\u5199\u5165\u200b\u5b57\u7b26\u4e32\u200b\uff0c\u200b\u8c03\u7528\u200b\u8be5\u200b\u65b9\u6cd5\u200b\u5199\u5165\u200b\u6570\u636e\u200b\u65f6\u200b\u90fd\u200b\u8981\u200b\u8f6c\u5316\u200b\u4e3a\u200b <code>str</code> \u200b\u7c7b\u578b\u200b\u3002</p> <p><code>file</code> \u200b\u4e3a\u200b <code>open()</code> \u200b\u65b9\u6cd5\u200b\u8fd4\u56de\u200b\u7684\u200b\u6587\u4ef6\u200b\u5bf9\u8c61\u200b</p>"},{"location":"Programing/Python/libs/file_format.html#bin","title":"bin","text":"<pre><code># \u200b\u8bfb\u53d6\u200bbin\u200b\u6587\u4ef6\u200b\nwith open(file_name, mode='rb') as file:    # mode=\u2019rb' \u200b\u63a7\u5236\u200b\u4ee5\u200b\u5b57\u8282\u200b\u65b9\u5f0f\u200b\u8bfb\u53d6\u200b\uff0cbin\u200b\u6587\u4ef6\u200b\u4e0d\u200b\u8bbe\u7f6e\u200bencoding\n    line = f.read().decode(encoding)        # \u200b\u901a\u8fc7\u200bdecode\u200b\u65b9\u6cd5\u200b\u5c06\u200b\u8bfb\u53d6\u200b\u7684\u200bbytes\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u5b57\u7b26\u4e32\u200b\u5f62\u5f0f\u200b\uff0c\u200b\u4fbf\u4e8e\u200b\u5904\u7406\u200b\n\n# \u200b\u5199\u5165\u200bbin\u200b\u6587\u4ef6\u200b\nwith open(file_name, mode='wb') as file:    # mode=\u2019wb' \u200b\u63a7\u5236\u200b\u4ee5\u200b\u5b57\u8282\u200b\u65b9\u5f0f\u200b\u5199\u5165\u200b\uff0cbin\u200b\u6587\u4ef6\u200b\u4e0d\u200b\u8bbe\u7f6e\u200bencoding\n    f.write(string.encode(encoding))        # \u200b\u901a\u8fc7\u200bencode\u200b\u65b9\u6cd5\u200b\u5c06\u200b\u5f85\u200b\u5199\u5165\u200bbytes\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u5b57\u7b26\u4e32\u200b\u5f62\u5f0f\u200b (\u200b\u6587\u4ef6\u200b\u53ea\u80fd\u200b\u5199\u5165\u200b\u5b57\u7b26\u4e32\u200b)\n</code></pre>"},{"location":"Programing/Python/libs/file_format.html#json","title":"json","text":"<p>JavaScript Object Notation </p><pre><code>import json\n\n# \u200b\u5b57\u7b26\u4e32\u200b\u8bfb\u5199\u200b\uff0c\u200b\u5b57\u7b26\u4e32\u200b  &lt;-\u200b\u8f6c\u5316\u200b-&gt; json\u200b\u5b57\u5178\u200b\ndef json.loads(\n    s,\n    encoding=None,                 # \u200b\u7f16\u7801\u65b9\u5f0f\u200b\n)\n\ndef json.dumps(\n    obj,\n    ensure_ascii=True,             # \u200b\u662f\u5426\u200b\u5c06\u200bjson\u200b\u5b57\u7b26\u4e32\u200b\u8f6c\u5316\u200b\u4e3a\u200bascii\u200b\u7f16\u7801\u200b\uff0c\u200b\u4e3a\u4e86\u200b\u53ef\u89c6\u5316\u200b\u4e00\u822c\u200b\u4e0d\u200b\u8f6c\u5316\u200b\n    sort_keys=Fals,                # \u200b\u8f93\u51fa\u200b\u5b57\u5178\u200b\u524d\u200b\u662f\u5426\u200b\u5bf9\u952e\u200b key \u200b\u8fdb\u884c\u200b\u6392\u5e8f\u200b\u6392\u5e8f\u200b\n    allow_nan=True,                # \n)\n\n\n# \u200b\u6587\u4ef6\u200b\u8bfb\u5199\u200b\uff0c\u200b\u6587\u4ef6\u200b &lt;-\u200b\u8f6c\u5316\u200b-&gt; json\u200b\u5b57\u5178\u200b\ndef json.load()\ndef json.dump()\n</code></pre><p></p> <ul> <li>\u200b\u5f53\u200b\u76f4\u63a5\u200b\u5199\u5165\u200b\u6216\u200b\u8bfb\u53d6\u200b\u7684\u200b\u6587\u4ef6\u200b\u8fc7\u5927\u65f6\u200b\uff0c\u200b\u901f\u5ea6\u200b\u5f88\u200b\u6162\u200b\uff0cjson\u200b\u6587\u4ef6\u200b\u8bfb\u5199\u200b\u65b9\u6cd5\u200b\u6548\u7387\u200b\u4f4e\u200b</li> <li>\u200b\u4e14\u200b\u6587\u4ef6\u200b\u5185\u5bb9\u200b\u4e00\u822c\u200b\u5355\u884c\u200b\u4e3a\u200b\u4e00\u4e2a\u200bjson\u200b\u5b57\u5178\u200b\uff0c\u200b\u4e00\u822c\u200b\u9010\u884c\u200b\u8bfb\u53d6\u200b\u5e76\u200b\u6d88\u8017\u200b\uff0c\u200b\u8f83\u200b\u5c11\u200b\u8003\u8651\u200bjson\u200b\u6587\u4ef6\u200b\u8bfb\u5199\u200b\u65b9\u6cd5\u200b</li> </ul>"},{"location":"Programing/Python/libs/file_format.html#pkl","title":"pkl","text":"<pre><code>import pickle as pkl\n\n# \u200b\u6587\u4ef6\u200b\u8bfb\u5199\u200b\ndef pkl.load(\n    file,                          # open(&lt;file_name&gt;, mode='rb')\n    fix_imports=True,\n    encoding=\"ASCII\",\n    errors=\"strict\",\n)\n\n# \u200b\u6587\u4ef6\u200b\u5199\u5165\u200b\ndef pkl.dump(\n    obj,                           # \u200b\u5f85\u200b\u5199\u5165\u200b\u7684\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u662f\u200b\u4efb\u4f55\u200b\u53ef\u200b\u5e8f\u5217\u5316\u200b\u7684\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u65e0\u9700\u200b\u624b\u52a8\u200b\u8f6c\u5316\u200b\u4e3a\u200b`str`\u200b\u7c7b\u578b\u200b\n    file,                          # open(&lt;file_name&gt;, mode='wb')\n    protocol=None,\n    fix_imports=True,\n)\n</code></pre>"},{"location":"Programing/Python/libs/functools.html","title":"Functools","text":""},{"location":"Programing/Python/libs/functools.html#iterable","title":"<code>iterable</code>\u200b\u64cd\u4f5c","text":""},{"location":"Programing/Python/libs/functools.html#cmp_to_key","title":"cmp_to_key","text":"<p>\u200b\u5c06\u200b\u6bd4\u8f83\u200b\u51fd\u6570\u200b\u8f6c\u5316\u200b\u4e3a\u200b<code>key</code>\u200b\u51fd\u6570\u200b </p><pre><code># \u200b\u8bbe\u7f6e\u200b\u6bd4\u8f83\u200b\u51fd\u6570\u200b\ndef my_cmp(a, b):\n    ...\n# \u200b\u91cd\u5199\u200b\u6bd4\u8f83\u200b\u51fd\u6570\u200b\nmy_list.sort(key=cmp_to_key(my_cmp))\n</code></pre><p></p>"},{"location":"Programing/Python/libs/functools.html#reduce","title":"reduce","text":"<p>\u200b\u5c06\u200b\u4e00\u4e2a\u200b\u5e8f\u5217\u200b\u5f52\u7eb3\u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u8f93\u51fa\u200b </p><pre><code>def reduce(\n    function,       # \u200b\u5f52\u7eb3\u200b\u51fd\u6570\u200b\n    sequence,       # \u200b\u53c2\u4e0e\u200b\u5f52\u7eb3\u200b\u7684\u200b\u5e8f\u5217\u200b\uff0c\u200b\u5373\u200b `[y1, y2, y3, ...]`\n    initial=None)   # \u200b\u521d\u59cb\u503c\u200b\uff0c\u200b\u5373\u200b `x`\uff0c\u200b\u672a\u6307\u5b9a\u200b\u65f6\u200b\u901a\u8fc7\u200b`sequence` \u200b\u8fdb\u884c\u200b\u521d\u59cb\u5316\u200b `x, *y = sequence`\n\nalist = range(1, 50)\nprint(reduce(lambda x, y: x + y, alist))  # (1+50)*50/2 - 1225\n</code></pre><p></p>"},{"location":"Programing/Python/libs/functools.html#function","title":"function \u200b\u64cd\u4f5c","text":""},{"location":"Programing/Python/libs/functools.html#partial","title":"partial","text":"<p>\u200b\u521b\u5efa\u200b\u504f\u200b\u51fd\u6570\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u5373\u200b\u57fa\u4e8e\u200b\u4e00\u4e2a\u200b\u5df2\u6709\u200b\u7684\u200b\u51fd\u6570\u200b\uff08\u200b\u901a\u8fc7\u200b\u9884\u8bbe\u200b\u8be5\u200b\u51fd\u6570\u200b\u7684\u200b\u4e00\u4e9b\u200b\u53c2\u6570\u200b\u6216\u200b\u5173\u952e\u5b57\u200b\uff09\uff0c\u200b\u751f\u6210\u200b\u4e00\u4e2a\u200b\u65b0\u200b\u7684\u200b\u51fd\u6570\u200b </p><pre><code>def func(a, b, c):\n    return a + b + c\n\n# \u200b\u4f7f\u7528\u200bpartial\u200b\u51bb\u7ed3\u200b\u90e8\u5206\u200b\u53c2\u6570\u200b\nnew_func = partial(func, 1, 2)\n\n# \u200b\u8c03\u7528\u200b\u65b0\u200b\u51fd\u6570\u200b\uff0c\u200b\u53ea\u200b\u9700\u8981\u200b\u63d0\u4f9b\u200b\u672a\u200b\u51bb\u7ed3\u200b\u7684\u200b\u53c2\u6570\u200b\nresult = new_func(3)    # \u200b\u7b49\u540c\u4e8e\u200b func(1, 2, 3)\nprint(result)           # \u200b\u8f93\u51fa\u200b6\n</code></pre><p></p>"},{"location":"Programing/Python/libs/functools.html#partialmethod","title":"partialmethod","text":"<p>\u200b\u4e0e\u200b<code>partial</code>\u200b\u7c7b\u4f3c\u200b\uff0c\u200b\u4f46\u662f\u200b\u5b83\u200b\u5e94\u7528\u200b\u4e8e\u200b\u65b9\u6cd5\u200b\u800c\u200b\u4e0d\u662f\u200b\u51fd\u6570\u200b </p><pre><code>class Greeter:\n    def __init__(self, greeting):\n        self.greeting = greeting\n\n    def greet(self, name, *args):\n        return f\"{self.greeting}, {name} {''.join(args)}\"\n\n    # \u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b`partialmethod`\u200b\u7684\u200b\u65b9\u6cd5\u200b\n    greet_hello = functools.partialmethod(greet, 'Hello')\n\n\n# \u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b Greeter \u200b\u5b9e\u4f8b\u200b\ngreeter = Greeter('Bonjour')\n\n# \u200b\u6b63\u786e\u200b\u8c03\u7528\u200b`partialmethod`\u200b\u7684\u200b\u65b9\u6cd5\u200b\nprint(greeter.greet_hello(\"Alice!\"))  # \u200b\u8f93\u51fa\u200b: Bonjour, HelloAlice!\n</code></pre><p></p>"},{"location":"Programing/Python/libs/functools.html#_1","title":"\u88c5\u9970\u200b\u5668","text":""},{"location":"Programing/Python/libs/functools.html#total_ordering","title":"total_ordering","text":"<p>\u200b\u5728\u200b\u5b9a\u4e49\u200b\u7c7b\u65f6\u200b\u53ea\u200b\u5b9a\u4e49\u200b\u4e00\u5c0f\u90e8\u5206\u200b\u6bd4\u8f83\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u7136\u540e\u200b\u5b83\u4f1a\u200b\u81ea\u52a8\u200b\u8865\u5168\u200b\u5176\u4f59\u200b\u7684\u200b\u6bd4\u8f83\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u8fd9\u4e2a\u200b\u88c5\u9970\u200b\u5668\u200b\u8981\u6c42\u200b</p> <ul> <li>\u200b\u7c7b\u4e2d\u200b\u81f3\u5c11\u200b\u5b9a\u4e49\u200b\u4e86\u200b\u4e00\u4e2a\u200b <code>__lt__</code>\u3001<code>__le__</code>\u3001<code>__gt__</code> \u200b\u6216\u200b <code>__ge__</code> \u200b\u4e2d\u200b\u7684\u200b\u4e00\u4e2a\u200b\u65b9\u6cd5\u200b</li> <li>\u200b\u5fc5\u987b\u200b\u5b9a\u4e49\u200b <code>__eq__</code> \u200b\u65b9\u6cd5\u200b</li> </ul> <pre><code>@total_ordering\nclass Student:\n    def __init__(self, name, grade):\n        self.name = name\n        self.grade = grade\n\n    def __eq__(self, other):\n        return self.grade == other.grade\n\n    def __lt__(self, other):\n        return self.grade &lt; other.grade\n</code></pre>"},{"location":"Programing/Python/libs/functools.html#wraps","title":"wraps","text":""},{"location":"Programing/Python/libs/functools.html#update_wrapper","title":"update_wrapper","text":""},{"location":"Programing/Python/libs/functools.html#singledispatch","title":"singledispatch","text":""},{"location":"Programing/Python/libs/functools.html#singledispatchmethod","title":"singleDispatchMethod","text":""},{"location":"Programing/Python/libs/googletrans.html","title":"Googletrans","text":"<pre><code># pip install googletrans==4.0.0-rc1\nfrom googletrans import Translator\ntranslator = Translator()\n</code></pre> <ol> <li>\u200b\u7ffb\u8bd1\u200b <pre><code># Translated.text \u200b\u4e3a\u200b\u7ffb\u8bd1\u200b\u540e\u200b\u7684\u200b\u6587\u672c\u200b\ndef translate(self, text, dest='en', src='auto') -&gt; Translated:\n\n# \u200b\u83b7\u53d6\u200b\u7ffb\u8bd1\u200b\u7ed3\u679c\u200b\uff0c`dest`\u200b\u6307\u5b9a\u200b\u7ffb\u8bd1\u200b\u7684\u200b\u76ee\u6807\u8bed\u8a00\u200b\ntranslator.translate(content, dest='zh-cn').text\n</code></pre></li> <li>\u200b\u5e38\u7528\u200b\u8bed\u79cd\u200b <pre><code>LANGUAGES = {\n    'en': 'english',\n    'zh-cn': 'chinese (simplified)',\n    'zh-tw': 'chinese (traditional)',\n    ...\n}\n</code></pre></li> <li>\u200b\u8bed\u79cd\u200b\u8bc6\u522b\u200b <pre><code># Detected.lang \u200b\u4e3a\u200b\u68c0\u6d4b\u200b\u7684\u200b\u8bed\u79cd\u200b\ndef detect(self, text) -&gt; Detected:\n    pass\n</code></pre></li> </ol>"},{"location":"Programing/Python/libs/itertools.html","title":"Itertools","text":"<ul> <li>product</li> </ul>"},{"location":"Programing/Python/libs/matplotlib.html","title":"Matplotlib","text":"<pre><code>import matplotlib.pyplot as plt\nfrom matplotlib.pyplot import MultipleLocator   # \u200b\u5bfc\u5165\u200b\u5750\u6807\u8f74\u200b\u63a7\u5236\u200b\u5e93\u200b\n\nplt.rcParams['font.sans-serif']=['SimHei']      # \u200b\u663e\u793a\u200b\u4e2d\u6587\u200b\u4e0d\u200b\u4e71\u7801\u200b\nplt.rcParams['axes.unicode_minus']=False        # \u200b\u663e\u793a\u200b\u8d1f\u53f7\u200b\u4e0d\u200b\u4e71\u7801\u200b\n</code></pre>"},{"location":"Programing/Python/libs/matplotlib.html#_1","title":"\u7ed8\u56fe","text":"<pre><code># **kwargs\nlinewidth=3             # \u200b\u7ebf\u6761\u200b\u7c97\u5ea6\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u200b\u4f7f\u7528\u200b `lw` \u200b\u8868\u793a\u200b\nlinestyle='solid'       # \u200b\u7ebf\u6761\u200b\u683c\u5f0f\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u200b\u4f7f\u7528\u200b `ls` \u200b\u8868\u793a\u200b {'solid', 'dashed', 'dashdot', 'dotted'}\ncolor='red'             # \u200b\u7ebf\u6761\u200b\u989c\u8272\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u7528\u200brgb\u200b\u5f62\u5f0f\u200b\u8868\u793a\u200b\uff0c\u200b\u5982\u200b '#1f77b4'\nmarker='.'              # \u200b\u70b9\u200b\u7684\u200b\u683c\u5f0f\u200b\uff0c{'.', ',', 'o', '*', '+'}\nalpha=0.5               # \u200b\u4e0d\u200b\u900f\u660e\u5ea6\u200b\n</code></pre>"},{"location":"Programing/Python/libs/matplotlib.html#plot","title":"\u6298\u7ebf\u56fe\u200b <code>plot</code>","text":"<p>\u200b\u4ee3\u7801\u200b\u683c\u5f0f\u200b\uff1a<code>plot([x], y, [fmt], [x2], y2, [fmt2], ..., **kwargs)</code> </p><pre><code>def plot(\n        *args,          # [x], y, [fmt]\n                        # \u200b\u53ea\u6709\u200b`y`\u200b\u65f6\u200b\uff0c\u200b\u5bf9\u5e94\u200b`x = range(len(y))`  \n                        # `fmt : str`\uff0c\u200b\u7ed8\u56fe\u200b,\u200b\u7f3a\u7701\u200b\u4e3a\u200b 'b-'\n        scalex=True,\n        scaley=True,\n        data=None,\n        **kwargs):\n</code></pre><p></p>"},{"location":"Programing/Python/libs/matplotlib.html#sactter","title":"\u6563\u70b9\u56fe\u200b <code>sactter</code>","text":"<pre><code>def scatter(\n        x,              # \u200b\u6a2a\u5750\u6807\u200b\u5e8f\u5217\u200b\n        y,              # \u200b\u5bf9\u5e94\u200b\u7684\u200b\u7eb5\u5750\u6807\u200b\u5e8f\u5217\u200b\n        s=None,         # \u200b\u6563\u70b9\u200b\u9762\u79ef\u200b\uff0c\u200b\u5e8f\u5217\u200b\u957f\u5ea6\u200b\u4e0e\u200b `x` \u200b\u4e00\u81f4\u200b\n        c=None,         # \u200b\u6563\u70b9\u200b\u989c\u8272\u200b\uff0c\u200b\u7f3a\u7701\u200b\u4e3a\u200b 'b'\n        marker=None,    # \u200b\u6563\u70b9\u200b\u6807\u8bb0\u200b\u6837\u5f0f\u200b\uff0c\u200b\u7f3a\u7701\u200b\u4e3a\u200b 'o'\n)\n</code></pre>"},{"location":"Programing/Python/libs/matplotlib.html#hist","title":"\u76f4\u65b9\u56fe\u200b <code>hist</code>","text":"<p>\u200b\u5bf9\u200b\u4e00\u7ef4\u200b\u5e8f\u5217\u200b\u6216\u200b\u4e8c\u7ef4\u200b\u6570\u5217\u200b\u9891\u6570\u200b\u8fdb\u884c\u200b\u7edf\u8ba1\u200b\uff0c\u200b\u7eb5\u5750\u6807\u200b\u8868\u793a\u200b\u9891\u6570\u200b</p> <pre><code>def hist(\n        x,              # \u200b\u4e00\u7ef4\u200b\u5e8f\u5217\u200b\u6216\u8005\u200b2\u200b\u7ef4\u200b\u5e8f\u5217\u200b seq([int,seq])\n        bins=None,      # \u200b\u76f4\u65b9\u56fe\u200b\u6761\u5f62\u200b\u4e2a\u6570\u200b\uff0c\u200b\u7f3a\u7701\u200b\u4e3a\u200b 10\n        range=None,     # \u200b\u6a2a\u5750\u6807\u200b\u663e\u793a\u200b\u8303\u56f4\u200b\uff0c\uff08left, right)\uff0c\u200b\u7f3a\u7701\u200b\u4e3a\u200bx\u200b\u4e2d\u200b\u7684\u200b\u6700\u5927\u503c\u200b\u548c\u200b\u6700\u5c0f\u503c\u200b\n        log=False,      # \u200b\u7eb5\u5750\u6807\u200b\u7edf\u8ba1\u200b\u503c\u200b\u662f\u5426\u200b\u53d6\u200b\u5bf9\u6570\u200b\n        color=None, density=False, weights=None, cumulative=False, bottom=None, \n        histtype='bar', align='mid', orientation='vertical', rwidth=None, \n        label=None, stacked=False, *, data=None, **kwargs):\n</code></pre>"},{"location":"Programing/Python/libs/matplotlib.html#bar","title":"\u6761\u5f62\u56fe\u200b <code>bar</code>","text":"<pre><code>def bar( \n        x,              # \u200b\u6a2a\u5750\u6807\u200b\u5e8f\u5217\u200b\n        height,         # \u200b\u5bf9\u5e94\u200b\u7684\u200b\u7eb5\u5750\u6807\u200b\u5e8f\u5217\u200b\n        width=0.8,      # \u200b\u6761\u5f62\u200b\u5bbd\u5ea6\u200b\n        bottom=0,       # \u200b\u7eb5\u5750\u6807\u200b`offset`\u200b\u503c\u200b\n        *, \n        align=\"center\", # \u200b\u6761\u5f62\u200b\u5bf9\u9f50\u200b\u65b9\u5f0f\u200b {'center': \u200b\u523b\u5ea6\u200b\u5c45\u4e2d\u200b, 'edge': \u200b\u523b\u5ea6\u200b\u5c45\u200b\u5de6\u200b}\n        **kwargs)\n</code></pre> <p>\u200b\u53ef\u4ee5\u200b\u7406\u89e3\u200b\u4e3a\u200b\u9009\u62e9\u6027\u200b\u7684\u200b <code>hist</code> \u200b\u56fe\u200b</p>"},{"location":"Programing/Python/libs/matplotlib.html#_2","title":"\u56fe\u5f62\u754c\u9762","text":""},{"location":"Programing/Python/libs/matplotlib.html#_3","title":"\u753b\u5e03","text":"<pre><code>def figure(\n        figsize=(24,8), # \u200b\u5bbd\u200b\uff0c\u200b\u957f\u200b\uff0c\u200b\u5355\u4f4d\u200b\u4e3a\u5bf8\u200binch\n        dpi=300)        # \u200b\u5206\u8fa8\u7387\u200b\n</code></pre>"},{"location":"Programing/Python/libs/matplotlib.html#_4","title":"\u5b50\u56fe","text":"<ol> <li><code>plt.subplot</code>\uff0c\u200b\u81ea\u52a8\u200b\u5207\u6362\u200b\u5b50\u56fe\u200b</li> <li><code>plt.subplots</code>\uff0c\u200b\u624b\u52a8\u200b\u8bbf\u95ee\u200b\u5b50\u56fe\u200b</li> </ol>"},{"location":"Programing/Python/libs/matplotlib.html#_5","title":"\u6807\u9898","text":""},{"location":"Programing/Python/libs/matplotlib.html#_6","title":"\u56fe\u4f8b","text":"<p>\u200b\u4f9d\u6b21\u200b\u4e3a\u200b\u7ed8\u5236\u200b\u7684\u200b\u56fe\u200b\u589e\u52a0\u200b\u56fe\u4f8b\u200b\u8bf4\u200bing </p><pre><code>''' plt.legend(['hello', 'world']) '''\ndef legend(\n        *args,\n        **kwargs)   \n        # handles\uff0cisinstanceof(handles, Iterable)\uff0c\u200b\u5143\u7d20\u200b\u4e3a\u200b\u7ed8\u5236\u200b\u7684\u200b\u56fe\u8868\u200bartist\n        # labels\uff0cisinstanceof(handles, Iterable)\uff0c\u200b\u5143\u7d20\u200b\u7ed8\u5236\u200b\u7684\u200b\u56fe\u8868\u200bartist\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u6587\u672c\u200b\u89e3\u91ca\u200b\n            #&gt; \u200b\u4e0e\u200bhandlers\u200b\u4e2d\u200b\u5143\u7d20\u200b\u4e00\u4e00\u5bf9\u5e94\u200b\uff0c\u200b\u672a\u6307\u5b9a\u200bhandlers\u200b\u5219\u200b\u5bf9\u5e94\u200bartist\u200b\u7ed8\u5236\u200b\u987a\u5e8f\u200b\n        # loc in {'best', 'upper left', 'upper center', 'upper right', 'lower left', 'lower center', 'lower right', 'center left', 'center right', 'center', (x, y)}\n            #&gt; best\u200b\u8868\u793a\u200b\u81ea\u52a8\u200b\u5b89\u7f6e\u200b\u5728\u200b\u56fe\u8868\u200b\u6700\u5c11\u200b\u7684\u200b\u4f4d\u7f6e\u200b\n            #&gt; (x, y)\u200b\u8868\u793a\u200b\u56fe\u8868\u200b\u5185\u200b\u4f4d\u7f6e\u200b\uff0cx, y \u2208 [0, 1]\n</code></pre><p></p>"},{"location":"Programing/Python/libs/matplotlib.html#_7","title":"\u7f51\u683c\u7ebf","text":"<pre><code>def grid(\n        b=None,         # bool\u200b\u503c\u200b, \u200b\u662f\u5426\u200b\u663e\u793a\u200b\u7f51\u683c\u200b\n        which='major',  # str, {major, minor, both}, \u200b\u5206\u522b\u200b\u8868\u793a\u200b\u663e\u793a\u200b\u4e3b\u8981\u200b\u503c\u5904\u200b\u3001\u200b\u4e0d\u200b\u663e\u793a\u200b\u3001\u200b\u5168\u200b\u663e\u793a\u200b\u7f51\u683c\u200b\n        axis='both',    # str, {both, x, y}\n        **kwargs)\n</code></pre>"},{"location":"Programing/Python/libs/matplotlib.html#text","title":"\u6587\u672c\u200b <code>text</code>","text":""},{"location":"Programing/Python/libs/matplotlib.html#_8","title":"\u5750\u6807\u8f74","text":""},{"location":"Programing/Python/libs/matplotlib.html#_9","title":"\u5750\u6807\u8f74","text":"<p>\u200b\u83b7\u53d6\u200b\u5f53\u524d\u200b\u5750\u6807\u8f74\u200b (get current axes) </p><pre><code>ax = plt.gca()\n</code></pre><p></p>"},{"location":"Programing/Python/libs/matplotlib.html#xlabelylabel","title":"\u5750\u6807\u8f74\u200b\u6587\u672c\u200b <code>xlabel/ylabel</code>","text":""},{"location":"Programing/Python/libs/matplotlib.html#xticksyticks","title":"\u5750\u6807\u8f74\u200b\u523b\u5ea6\u200b\u6587\u672c\u200b <code>xticks/yticks</code>","text":""},{"location":"Programing/Python/libs/matplotlib.html#_10","title":"\u5750\u6807\u8f74\u200b\u523b\u5ea6\u200b\u8303\u56f4","text":"<pre><code># \u200b\u8bbe\u7f6e\u200b xlim, ylim\nplt.xlim(xmin, xmax)                            # or plt.xlim([xmin, xmax])\nplt.xlim(bottom=1)\nplt.xlim(top=2)\n# \u200b\u83b7\u53d6\u200b xlim, ylim\nplt.xlim()                                      # (bottom, top)\n</code></pre>"},{"location":"Programing/Python/libs/matplotlib.html#_11","title":"\u5750\u6807\u8f74\u200b\u523b\u5ea6\u200b\u95f4\u9694","text":"<pre><code>x_major_locator=MultipleLocator(1)              # x\u200b\u8f74\u200b\u523b\u5ea6\u200b\u503c\u200b\u95f4\u9694\u200b\uff0c\u200b\u4e3a\u200b1\u200b\u7684\u200b\u500d\u6570\u200b\ny_major_locator=MultipleLocator(2)              # y\u200b\u8f74\u200b\u523b\u5ea6\u200b\u503c\u200b\u95f4\u9694\u200b\uff0c\u200b\u4e3a\u200b2\u200b\u7684\u200b\u500d\u6570\u200b\nax = plt.gca()\nax.xaxis.set_major_locator(x_major_locator)     # x\u200b\u8f74\u523b\u200b\u8bbe\u7f6e\u200b\u5e94\u7528\u200b\nax.yaxis.set_major_locator(y_major_locator)     # y\u200b\u8f74\u523b\u200b\u8bbe\u7f6e\u200b\u5e94\u7528\u200b\n</code></pre>"},{"location":"Programing/Python/libs/matplotlib.html#_12","title":"\u901a\u7528\u200b\u7ec4\u4ef6","text":""},{"location":"Programing/Python/libs/matplotlib.html#font","title":"<code>font</code>","text":""},{"location":"Programing/Python/libs/matplotlib.html#marker","title":"<code>marker</code>","text":""},{"location":"Programing/Python/libs/matplotlib.html#c","title":"<code>c</code>","text":""},{"location":"Programing/Python/libs/opencc.html","title":"Opencc","text":"<p>OpenCC\uff1aOpen Chinese Convert</p> <pre><code>from opencc import OpenCC       # pip install OpenCC\n\ncc = OpenCC(config=\"t2s\")       # t2s: \u200b\u7e41\u4f53\u200b\u8f6c\u200b\u7b80\u4f53\u200b;      s2t: \u200b\u7b80\u4f53\u200b\u8f6c\u200b\u7e41\u4f53\u200b;\n                                # tw2s: \u200b\u53f0\u6e7e\u200b\u6b63\u4f53\u200b\u8f6c\u200b\u7b80\u4f53\u200b; s2tw: \u200b\u7b80\u4f53\u200b\u8f6c\u200b\u53f0\u6e7e\u200b\u6b63\u4f53\u200b;\n                                # hk2s: \u200b\u9999\u6e2f\u200b\u7e41\u4f53\u200b\u8f6c\u200b\u7b80\u4f53\u200b; s2hk: \u200b\u7b80\u4f53\u200b\u8f6c\u200b\u9999\u6e2f\u200b\u7e41\u4f53\u200b;\n                                # t2jp: \u200b\u7e41\u4f53\u200b\u8f6c\u65b0\u200b\u65e5\u6587\u200b;   jp2t: \u200b\u65b0\u200b\u65e5\u6587\u200b\u8f6c\u200b\u7e41\u4f53\u200b;\n\ntext = cc.convert(text)\n</code></pre>"},{"location":"Programing/Python/libs/os.html","title":"Os","text":""},{"location":"Programing/Python/libs/pandas.html","title":"Pandas","text":""},{"location":"Programing/Python/libs/pdf.html","title":"Pdf","text":""},{"location":"Programing/Python/libs/pdf.html#pypdf","title":"PyPDF","text":"<ul> <li>load()\uff0c\u200b\u4e00\u6b21\u200b\u8bfb\u5b8c\u200b</li> <li>alzay_load()\uff0c\u200b\u6309\u9875\u200b\u8bfb\u200b</li> <li>\u200b\u5b57\u200b\u6bb5\u200b\uff1a</li> <li>page_content: \u200b\u9875\u9762\u200b\u6587\u672c\u200b\u5185\u5bb9\u200b</li> </ul>"},{"location":"Programing/Python/libs/pypinyin.html","title":"Pypinyin","text":"<pre><code>from pypinyin import pinyin, Style\n\ndef pinyin(\n    hans,                            # Union(List[str], str), \u200b\u5f85\u200b\u62fc\u97f3\u5316\u200b\u7684\u200b\u6c49\u5b57\u200b\u5b57\u7b26\u4e32\u200b\u6216\u200b\u5b57\u7b26\u4e32\u200b\u5217\u8868\u200b\n    style=Style.TONE,                # \u200b\u6307\u5b9a\u200b\u62fc\u97f3\u200b\u98ce\u683c\u200b, TONE\u200b\u8868\u793a\u200b\u58f0\u8c03\u200b\u5728\u200b\u97f5\u6bcd\u200b\u4e0a\u9762\u200b\n    heteronym=False,                 # \u200b\u662f\u5426\u200b\u542f\u7528\u200b\u591a\u97f3\u5b57\u200b, False\u200b\u53ea\u200b\u8fd4\u56de\u200b\u5e38\u7528\u200b\u8bfb\u97f3\u200b\n    errors='default',                # Union(Callable, str)\uff0c\u200b\u65e0\u200b\u62fc\u97f3\u200b\u5b57\u7b26\u200b\u5904\u7406\u200b\u65b9\u5f0f\u200b, {default: \u200b\u4fdd\u7559\u200b; ignore: \u200b\u5ffd\u7565\u200b; replace: \u200b\u66ff\u6362\u200b\u4e3a\u200b}\n    strict=False,                    # \u200b\u662f\u5426\u200b\u6839\u636e\u200b\u4e0a\u4e0b\u6587\u200b\u6765\u200b\u9009\u62e9\u200b\u6700\u5408\u9002\u200b\u7684\u200b\u62fc\u97f3\u200b\u8bfb\u6cd5\u200b\n    v_to_u=False,                    # \u200b\u662f\u5426\u200b\u7528\u200bv\u200b\u66ff\u4ee3\u200b\u00fc\n    neutral_tone_with_five=False,    # \u200b\u8f7b\u58f0\u200b\u662f\u5426\u200b\u7528\u200b5\u200b\u8868\u793a\u200b\n) -&gt; List[List[Str]]:\n\ndef lazy_pinyin(\n    hans,                            # Union(List[str], str), \u200b\u5f85\u200b\u62fc\u97f3\u5316\u200b\u7684\u200b\u6c49\u5b57\u200b\u5b57\u7b26\u4e32\u200b\u6216\u200b\u5b57\u7b26\u4e32\u200b\u5217\u8868\u200b\n    style=Style.NORMAL,              # \u200b\u6307\u5b9a\u200b\u62fc\u97f3\u200b\u98ce\u683c\u200b, NORMAL\u200b\u8868\u793a\u200b\u4e0d\u5e26\u200b\u58f0\u8c03\u200b\n    errors='default',                # Union(Callable, str)\uff0c\u200b\u65e0\u200b\u62fc\u97f3\u200b\u5b57\u7b26\u200b\u5904\u7406\u200b\u65b9\u5f0f\u200b, {default: \u200b\u4fdd\u7559\u200b; ignore: \u200b\u5ffd\u7565\u200b; replace: \u200b\u66ff\u6362\u200b\u4e3a\u200b}\n    strict=False,                    # \u200b\u662f\u5426\u200b\u6839\u636e\u200b\u4e0a\u4e0b\u6587\u200b\u6765\u200b\u9009\u62e9\u200b\u6700\u5408\u9002\u200b\u7684\u200b\u62fc\u97f3\u200b\u8bfb\u6cd5\u200b\n    v_to_u=True,                     # \u200b\u662f\u5426\u200b\u7528\u200bv\u200b\u66ff\u4ee3\u200b\u00fc\n    neutral_tone_with_five=False,    # \u200b\u8f7b\u58f0\u200b\u662f\u5426\u200b\u7528\u200b5\u200b\u8868\u793a\u200b\n) -&gt; List[List[Str]]:\n</code></pre>"},{"location":"Programing/Python/libs/pypinyin.html#has_pinyin","title":"has_pinyin","text":"has_pinyin<pre><code>letter_offset_map = {'semi-lower': ord('a'), 'semi-upper': ord('A'), 'full-lower': ord('\uff41'), 'full-upper': ord('\uff21')}\nnumeric_offset_map = {'semi-numeric': ord('0'), 'full-numeric': ord('\uff10')}\n\n\ndef has_pinyin(\n    text, \n    pattern,                # \u200b\u62fc\u97f3\u200b\u683c\u5f0f\u200b\uff0c\u200b\u652f\u6301\u200b\u6b63\u5219\u200b\u5339\u914d\u200b\n    style=Style.NORMAL, \n    remain_letter=False,    # \u200b\u662f\u5426\u200b\u4fdd\u7559\u200b\u6587\u672c\u200b\u4e2d\u539f\u200b\u6709\u200b\uff08\u200b\u5927\u200b\u3001\u200b\u5c0f\u5199\u200b\uff0c\u200b\u5168\u200b\u534a\u89d2\u200b\uff09\u200b\u5b57\u6bcd\u200b\n    remain_numeric=False    # \u200b\u662f\u5426\u200b\u4fdd\u7559\u200b\u6587\u672c\u200b\u4e2d\u539f\u200b\u6709\u200b\uff08\u200b\u5168\u200b\u534a\u89d2\u200b\uff09\u200b\u6570\u5b57\u200b\n    ):\n    text_pinyin = get_pinyin(text, style=style, remain_letter=remain_letter, remain_numeric=remain_numeric)\n    if '|' in pattern or \\\n            '?' in pattern or \\\n            isinstance(pattern, str) and re.findall('^[a-z\\?\\)\\(:]+$', pattern, re.I):\n        pattern_pinyin = pattern\n    else:\n        pattern_pinyin = get_pinyin(pattern, style=style, remain_letter=remain_letter, remain_numeric=remain_numeric)\n\n    return len(re.findall(pattern_pinyin, text_pinyin, re.I)) &gt; 0\n\n\ndef get_pinyin(text, style=Style.NORMAL, remain_letter=False, remain_numeric=False):\n    if remain_letter or remain_numeric:\n        # {default: \u200b\u4fdd\u7559\u200b\u539f\u200b\u5b57\u7b26\u200b; ignore: \u200b\u5ffd\u7565\u200b\u5e76\u200b\u8df3\u200b\u8fc7\u200b}\n        pinyin_list = pinyin(text, style=style, errors='default')\n\n        if remain_letter:\n            pinyin_list = [\n                [chr(ord('a') + ord(py[0]) - letter_offset_map[is_letter(py[0])])] if is_letter(py[0]) else py for py in\n                pinyin_list]\n        else:\n            pinyin_list = [py for py in pinyin_list if not is_letter(py[0])]\n\n        if remain_numeric:\n            pinyin_list = [\n                [chr(ord('0') + ord(py[0]) - numeric_offset_map[is_numeric(py[0])])] if is_numeric(py[0]) else py for py\n                in pinyin_list]\n        else:\n            pinyin_list = [py for py in pinyin_list if not is_numeric(py[0])]\n\n    else:\n        pinyin_list = pinyin(text, style=style, errors='ignore')\n\n    return ''.join([py[0] for py in pinyin_list])\n\n\ndef is_letter(c):\n    if len(c) != 1: # \u200b\u4fdd\u7559\u200b\u7684\u200b\u975e\u200b\u62fc\u97f3\u200b\u5b57\u7b26\u200b\u53ea\u200b\u53ef\u80fd\u200b\u4e3a\u200blen=1\u200b\u7684\u200blist\n        return 0\n    if ord('a') &lt;= ord(c) &lt;= ord('z'):\n        return 'semi-lower'\n    elif ord('A') &lt;= ord(c) &lt;= ord('Z'):\n        return 'semi-upper'\n    elif ord('\uff41') &lt;= ord(c) &lt;= ord('\uff5a'):\n        return 'full-lower'\n    elif ord('\uff21') &lt;= ord(c) &lt;= ord('\uff3a'):\n        return 'full-upper'\n    else:\n        return 0\n\n\ndef is_numeric(c):\n    if len(c) != 1: # \u200b\u4fdd\u7559\u200b\u7684\u200b\u975e\u200b\u62fc\u97f3\u200b\u5b57\u7b26\u200b\u53ea\u200b\u53ef\u80fd\u200b\u4e3a\u200blen=1\u200b\u7684\u200blist\n        return 0\n    if ord('0') &lt;= ord(c) &lt;= ord('9'):\n        return 'semi-numeric'\n    elif ord('\uff10') &lt;= ord(c) &lt;= ord('\uff19'):\n        return 'full-numeric'\n    else:\n        return 0\n</code></pre>"},{"location":"Programing/Python/libs/pypinyin.html#count_part_elements","title":"count_part_elements","text":"<pre><code># \u200b\u6bcf\u200b\u6bb5\u200b\u9996\u5b57\u6bcd\u200b\u4e3a\u200b\u6570\u5b57\u200b\u8c10\u97f3\u200b\u7684\u200b\u4e2a\u6570\u200b\ndef count_part_elements(text):\n    text_no_punct = re.sub(punctuation, ' ', text)\n    text_uni_space = re.sub(white_space_pattern, ' ', text_no_punct.strip())\n    parts = text_uni_space.strip().split()\n    flags = [has_pinyin(part.lower(), '(?:lin|yi|yao|er|lia|shan|sa|sh?i|wu|li?u|qi|ba|bie|jiu)|[0-9\uff10-\uff19]', remain_numeric=True, remain_letter=True) for part in parts]\n    return sum(flags)\n\n# \u200b\u6bcf\u200b\u6bb5\u200b\u9996\u5b57\u6bcd\u200b\u662f\u5426\u200b\u8fde\u7eed\u200b\ndef count_subsequent_part_elements(text):\n    subsequent_pattern = '(?:yi|1|\uff11)(?:er|liang|lia|2|\uff12)(?:san?|sh?an|3|\uff13)' \\\n                         '|(?:er|liang|2|\uff12)(?:san?|sh?an|3|\uff13)(?:sh?i|4|\uff14)' \\\n                         '|(?:san?|sh?an|3|\uff13)(?:sh?i|4|\uff14)(?:wu|5|\uff15)' \\\n                         '|(?:sh?i|4|\uff14)(?:wu|5|\uff15)(?:li?u|6|\uff16)' \\\n                         '|(?:wu|5|\uff15)(?:li?u|6|\uff16)(?:qi|7|\uff17)' \\\n                         '|(?:li?u|6|\uff16)(?:qi|7|\uff17)(?:ba|8|\uff18)' \\\n                         '|(?:qi|7|\uff17)(?:ba|8|\uff18)(?:jiu|9|\uff19)' \\\n                         '|(?:ba|8|\uff18)(?:jiu|9|\uff19)shi'\n    # punct.split + white_space.split\n    text_no_punct = re.sub(punctuation, ' ', text)\n    text_no_space_punct = re.sub(white_space_pattern, ' ', text_no_punct.strip())\n    parts = text_no_space_punct.strip().split()\n    elements = ''.join([p[0] for p in parts])\n\n    flag = has_pinyin(elements.lower(), subsequent_pattern, remain_numeric=True, remain_letter=True)\n    if flag:\n        return flag\n    # white_space.split\n    text_no_space_punct = re.sub(white_space_pattern, ' ', text.strip())\n    parts = text_no_space_punct.strip().split()\n    elements = ''.join([p[0] for p in parts])\n    flag = has_pinyin(elements.lower(),\n                      subsequent_pattern,\n                      remain_numeric=True, remain_letter=True)\n    return flag\n</code></pre>"},{"location":"Programing/Python/libs/sys.html","title":"Sys","text":""},{"location":"Programing/Python/libs/sys.html#_1","title":"\u5bfc\u5165\u200b\u672c\u5730\u200b\u5e93","text":"<pre><code>sys.path.append('..')               # \u200b\u76f8\u5bf9\u8def\u5f84\u200b\nsys.path.append('project_path')     # \u200b\u7edd\u5bf9\u8def\u5f84\u200b\n</code></pre>"},{"location":"Programing/Python/libs/tqdm.html","title":"Tqdm","text":""},{"location":"Programing/Python/libs/tqdm.html#tqdm","title":"tqdm","text":"<pre><code>from tqdm import tqdm\n\nclass tqdm(Comparable):\n    def __init__(self, \n            iterable=None,  # \u200b\u5f85\u200b\u8ba1\u6570\u200b\n            desc=None,      # \u200b\u8ba1\u6570\u200b/\u200b\u8fdb\u5ea6\u6761\u200b\u5237\u65b0\u200b\u65f6\u200b\u7684\u200b\u63cf\u8ff0\u200b\u6587\u672c\u200b\n            total=None,     # \u200b\u767e\u5206\u6bd4\u200b\u8fdb\u5ea6\u6761\u200b\u5206\u6bcd\u200b\n            ...,\n            **kwargs):\n</code></pre>"},{"location":"Programing/Python/libs/tqdm.html#1-iteratorgenerator","title":"1. <code>Iterator</code>\u200b\u548c\u200b<code>Generator</code>\uff1a\u200b\u8ba1\u6570\u200b\u663e\u793a","text":"<p>\u200b\u65e0\u6cd5\u200b\u76f4\u63a5\u200b\u83b7\u53d6\u200b\u957f\u5ea6\u200b<code>total</code>\u200b\u7684\u200b<code>iterable</code>\u200b\u6267\u884c\u200b\u8ba1\u6570\u200b\u663e\u793a\u200b </p><pre><code># \u200b\u65e0\u6cd5\u200b\u786e\u5b9a\u200b\u53c2\u6570\u503c\u200btotal\nfor element in tqdm(iterable=iterator_var):  # \u200b\u6bcf\u6b21\u200b\u8ba1\u200b\u6570\u503c\u200b +1\nfor element in tqdm(iterable=generator_var): # \u200b\u6bcf\u6b21\u200b\u8ba1\u200b\u6570\u503c\u200b +1\n</code></pre><p></p>"},{"location":"Programing/Python/libs/tqdm.html#2-iterable","title":"2. <code>Iterable</code>\uff1a\u200b\u767e\u5206\u6bd4\u200b\u663e\u793a","text":"<p>\u200b\u53ef\u200b\u76f4\u63a5\u200b\u83b7\u53d6\u200b\u957f\u5ea6\u200b<code>total</code>\u200b\u7684\u200b<code>iterable</code>\u200b\u6267\u884c\u200b\u8fdb\u5ea6\u200b\u767e\u5206\u6bd4\u200b\u663e\u793a\u200b </p><pre><code># \u200b\u76f4\u63a5\u200b\u5b9a\u4e49\u200b\u53c2\u6570\u200btotal\npbar = tqdm(total=total_num)\npbar.update(n)                               # \u200b\u6bcf\u6b21\u200b\u66f4\u65b0\u200b n/total_num * 100%\n\n# \u200b\u901a\u8fc7\u200blen(iterable)\u200b\u5b9a\u4e49\u200b\u53c2\u6570\u200btotal\nfor element in tqdm(iterable=iterable_var):  # \u200b\u6bcf\u6b21\u200b\u66f4\u65b0\u200b 1/len(iterable) * 100%\n</code></pre><p></p>"},{"location":"Programing/Python/libs/tqdm.html#trange","title":"trange","text":"<pre><code>from tqdm imprt trange\n\ndef trange(*args, **kwargs):\n    \"\"\"\n    A shortcut for tqdm(xrange(*args), **kwargs).\n    On Python3+ range is used instead of xrange.\n    \"\"\"\n    return tqdm(_range(*args), **kwargs)\n</code></pre> <ul> <li><code>assert len(args) == 1 or len(args) == 2 or len(args) == 3</code> </li> <li><code>trange</code> \u200b\u53ea\u200b\u8f93\u5165\u200b\u7531\u200b<code>[left: right: step]</code>\u200b\u7684\u200b\u5e8f\u5217\u200b\uff0c<code>tqdm(iterable)</code>\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u6027\u9ad8\u200b</li> <li><code>range</code>\u200b\u8fd4\u56de\u200b\u7684\u200b\u662f\u200b\u4e00\u4e2a\u200b<code>Iterable</code>\uff0c\u200b\u6240\u4ee5\u200b\u7ed3\u679c\u200b\u4e5f\u200b\u662f\u200b\u767e\u5206\u6bd4\u200b\u8fdb\u5ea6\u6761\u200b\u663e\u793a\u200b</li> </ul>"},{"location":"Programing/Python/libs/unicodedata.html","title":"Unicodedata","text":""},{"location":"Programing/Python/libs/unicodedata.html#category","title":"category","text":""},{"location":"Programing/Python/libs/unicodedata.html#other","title":"Other","text":"<ul> <li>[Cc] Control</li> <li>[Cf] Format</li> <li>[Cn] Not Assigned (no characters in the file have this property)</li> <li>[Co] Private Use</li> <li>[Cs] Surrogate</li> </ul>"},{"location":"Programing/Python/libs/unicodedata.html#letter","title":"Letter","text":"<ul> <li>[LC] Cased</li> <li>[Ll] Lowercase\uff0c\u200b\u5c0f\u5199\u5b57\u6bcd\u200b</li> <li>[Lu] Uppercase\uff0c\u200b\u5927\u5199\u5b57\u6bcd\u200b</li> <li>[Lm] Modifier</li> <li>[Lt] Titlecase</li> <li>[Lo] Other</li> </ul>"},{"location":"Programing/Python/libs/unicodedata.html#mark","title":"Mark","text":"<ul> <li>[Mc] Spacing Combining</li> <li>[Me] Enclosing</li> <li>[Mn] Nonspacing</li> </ul>"},{"location":"Programing/Python/libs/unicodedata.html#number","title":"Number","text":"<ul> <li>[Nd] Decimal Digit\uff0c\u200b\u5341\u8fdb\u5236\u200b\u6570\u200b</li> <li>[Nl] Letter\uff0c\u200b\u8868\u793a\u200b\u6570\u503c\u200b\u7684\u200b\u5b57\u6bcd\u200b</li> <li>[No] Other\uff0c\u200b\u5269\u4f59\u200b\u5176\u4ed6\u200b\u8868\u793a\u200b\u6570\u503c\u200b\u7684\u200b\u5b57\u7b26\u200b</li> </ul>"},{"location":"Programing/Python/libs/unicodedata.html#punctuation","title":"Punctuation","text":"<ul> <li>[Pc] Connector\uff0c\u200b\u8fde\u63a5\u200b\u7b26\u53f7\u200b\uff0c\u200b\u5982\u200b\u4e0b\u5212\u7ebf\u200b _</li> <li>[Pd] Dash\uff0c\u200b\u7834\u6298\u53f7\u200b</li> <li>[Pi] Initial quote\uff0c\u200b\u521d\u59cb\u200b\u5f15\u53f7\u200b\uff0c\u200b\u5176\u4e2d\u200b\u82f1\u6587\u200b\u5355\u200b\u53cc\u5f15\u53f7\u200b ' \" \u200b\u5c5e\u4e8e\u200b Po</li> <li>[Pf] Final quote\uff0c\u200b\u7ed3\u675f\u200b\u5f15\u53f7\u200b\uff0c\u200b\u5176\u4e2d\u200b\u82f1\u6587\u200b\u5355\u200b\u53cc\u5f15\u53f7\u200b ' \" \u200b\u5c5e\u4e8e\u200b Po</li> <li>[Ps] Open\uff0c\u200b\u5f00\u59cb\u200b\u62ec\u53f7\u200b</li> <li>[Pe] Close\uff0c\u200b\u7ed3\u675f\u200b\u62ec\u53f7\u200b</li> <li>[Po] Other\uff0c\u200b\u5269\u4f59\u200b\u5176\u4ed6\u200b\u6807\u70b9\u7b26\u53f7\u200b</li> </ul>"},{"location":"Programing/Python/libs/unicodedata.html#symbol","title":"Symbol","text":"<ul> <li>[Sc] Currency\uff0c\u200b\u8d27\u5e01\u200b\u7b26\u53f7\u200b</li> <li>[Sk] Modifier</li> <li>[Sm] Math\uff0c\u200b\u6570\u5b66\u200b\u7b26\u53f7\u200b</li> <li>[So] Other</li> </ul>"},{"location":"Programing/Python/libs/unicodedata.html#seperator","title":"Seperator","text":"<ul> <li>[Zl] Line\uff0c\u200b\u884c\u200b\u5206\u5272\u200b\u7b26\u200b</li> <li>[Zp] Paragraph\uff0c\u200b\u6bb5\u843d\u200b\u5206\u5272\u200b\u7b26\u200b</li> <li>[Zs] Space\uff0c\u200b\u7a7a\u767d\u200b\u5b57\u7b26\u200b</li> </ul>"},{"location":"Programing/Python/libs/wordcloud.html","title":"Wordcloud","text":""},{"location":"Programing/Python/libs/xlsx.html","title":"Xlsx","text":""},{"location":"Programing/Python/libs/xlsx.html#csv","title":"csv","text":"<p>Comma-Separated Values </p><pre><code>import csv\n\nwith open(&lt;file_name&gt;, 'r', encoding='utf-8') as f:\n    reader = csv.reader(f)      # \u200b\u8fd4\u56de\u200bfile_iterator\n                                # \u200b\u53ef\u200b\u901a\u8fc7\u200b `delimiter='\\t'` \u200b\u6307\u5b9a\u200b\u5206\u9694\u7b26\u200b\n    for line in reader:\n        ...\n</code></pre><p></p>"},{"location":"Programing/Python/libs/xlsx.html#xlsx","title":"xlsx","text":"<pre><code>import xlwt     # pip install xlwt\n\nworkbook = xlwt.Workbook(encoding='utf-8')\nsheet = workbook.add_sheet(&lt;sheet_name&gt;, cell_overwrite_ok=True)\nsheet.write(row_idx, col_idx, dump_content)\nworkbook.save(&lt;file_name&gt;)\n\nimport xlrd     # pip install xlrd\nworkbook = xlrd.open_workbook(&lt;file_name&gt;)\nsheet = workbook.sheet_by_name(&lt;sheet_name&gt;)\n    # sheet.rows\uff1a\u200b\u6570\u636e\u8868\u200b\u884c\u200b\u6570\u200b\n    # sheet.cols\uff1a\u200b\u6570\u636e\u8868\u200b\u5217\u6570\u200b\n    # sheet.row_values(idx)\uff1a\u200b\u6570\u636e\u8868\u200bidx-th\u200b\u884c\u200b\u6570\u636e\u200b\n</code></pre>"},{"location":"Programing/Python/libs/%E5%8F%82%E6%95%B0%E4%BC%A0%E5%85%A5.html","title":"\u53c2\u6570\u200b\u4f20\u5165","text":""},{"location":"Programing/Python/libs/%E5%9B%BE%E5%BD%A2%E7%BB%98%E5%88%B6.html","title":"\u56fe\u5f62\u200b\u7ed8\u5236","text":"<p>\u200b\u56fe\u5f62\u200b\u7ed8\u5236\u200b</p>"},{"location":"Programing/Python/utils/ahocorasick.html","title":"Ahocorasick","text":"ahocorasick.py<pre><code># coding=utf-8\nimport collections\nimport queue\n\n\nclass State(object):\n    def __init__(self, depth=0):\n        self.depth = depth\n        self.root_state = self if depth == 0 else None\n        self.success = collections.OrderedDict()\n        self.failure = None\n        self.emits = set()\n\n    def add_emit(self, keyword):\n        self.emits.add(keyword)\n\n    def add_emits(self, emits):\n        for emit in emits:\n            self.add_emit(emit)\n\n    def set_failure(self, fail_state):\n        self.failure = fail_state\n\n    def get_next_state(self, token, ignore_root_state=False):\n        next_state = self.success.get(token)\n        if not ignore_root_state and next_state is None and self.root_state is not None:\n            next_state = self.root_state\n        return next_state\n\n    def add_state(self, token):\n        next_state = self.get_next_state(token, ignore_root_state=True)\n        if next_state is None:\n            next_state = State(self.depth + 1)\n            self.success[token] = next_state\n        return next_state\n\n    def get_states(self):\n        return self.success.values()\n\n    def get_transitions(self):\n        return self.success.keys()\n\n\nclass Trie(object):\n    def __init__(self, allow_overlaps=True, case_insensitive=False):\n        self.root_state = State()\n        self.failure_states_constructed = False\n        self.allow_overlaps = allow_overlaps\n        self.case_insensitive = case_insensitive\n\n    def build_trie(self, keyword_list):\n        for keyword in keyword_list:\n            self._add_key_word(keyword)\n        self._constructed_failure_states()\n\n    def parse_text(self, text):\n        current_state = self.root_state\n        collected_intervals = []\n        for i, token in enumerate(text):\n            if self.case_insensitive:\n                token = token.lower()\n            current_state = self._get_state(current_state, token)\n            self._store_intervals(i, current_state, collected_intervals)\n\n        if not self.allow_overlaps:\n            interval_tree = IntervalTree(collected_intervals)\n            interval_tree.remove_overlaps(collected_intervals)\n        return collected_intervals\n\n    def has_keyword(self, text):\n        current_state = self.root_state\n        for token in text:\n            if self.case_insensitive:\n                token = token.lower()\n            next_state = self._get_state(current_state, token)\n            if next_state is not None and next_state != current_state and len(next_state.emits) != 0:\n                return True\n            current_state = next_state\n        return False\n\n    def _add_key_word(self, keyword):\n        if keyword is None or len(keyword) == 0:\n            return\n        current_state = self.root_state\n        for token in keyword:\n            if self.case_insensitive:\n                token = token.lower()\n            current_state = current_state.add_state(token)\n        current_state.add_emit(keyword)\n\n    def _get_state(self, current_state, token):\n        # \u200b\u5148\u200b\u6309\u7167\u200bsuccess\u200b\u8df3\u8f6c\u200b\n        new_current_state = current_state.get_next_state(token, ignore_root_state=False)\n        # \u200b\u8df3\u8f6c\u200b\u5931\u8d25\u200b\u7684\u8bdd\u200b\uff0c\u200b\u6309\u200bfailure\u200b\u8df3\u8f6c\u200b\n        while new_current_state is None:\n            current_state = current_state.failure\n            new_current_state = current_state.get_next_state(token, ignore_root_state=False)\n        return new_current_state\n\n    def _constructed_failure_states(self):\n        queue_state = queue.Queue()\n\n        # \u200b\u7b2c\u4e00\u6b65\u200b\uff0c\u200b\u5c06\u200b\u6df1\u5ea6\u200b\u4e3a\u200b1\u200b\u7684\u200b\u8282\u70b9\u200b\u7684\u200bfailure\u200b\u8bbe\u4e3a\u200b\u6839\u200b\u8282\u70b9\u200b\n        for depth_one_state in self.root_state.get_states():\n            depth_one_state.set_failure(self.root_state)\n            queue_state.put(depth_one_state)\n\n        # \u200b\u7b2c\u4e8c\u6b65\u200b\uff0c\u200b\u4e3a\u200b\u6df1\u5ea6\u200b&gt;1\u200b\u7684\u200b\u8282\u70b9\u200b\u5efa\u7acb\u200bfailure\u200b\u8868\u200b\uff08\u200b\u901a\u8fc7\u200bbfs\u200b\u5b9e\u73b0\u200b\uff09\n        while not queue_state.empty():\n            current_state = queue_state.get()\n\n            for transition in current_state.get_transitions():\n                target_state = current_state.get_next_state(transition, ignore_root_state=False)\n                queue_state.put(target_state)\n\n                trace_failure_state = current_state.failure\n                while trace_failure_state.get_next_state(transition, ignore_root_state=False) is None:\n                    trace_failure_state = trace_failure_state.failure\n                new_failure_state = trace_failure_state.get_next_state(transition, ignore_root_state=False)\n                target_state.set_failure(new_failure_state)\n                target_state.add_emits(new_failure_state.emits)\n        self.failure_states_constructed = True\n\n    def _store_intervals(self, position, current_state, collected_intervals):\n        emits = current_state.emits\n        for emit in emits:\n            collected_intervals.append(Interval(position - len(emit) + 1, position, emit))\n\n\nclass IntervalTree(object):\n    def __init__(self, intervals):\n        self.root_node = IntervalNode(intervals)\n\n    def remove_overlaps(self, intervals):\n        intervals.sort(key=lambda interval: (-interval.size(), interval.start))\n\n        remove_intervals = set()\n        for interval in intervals:\n            if interval in remove_intervals:\n                continue\n            overlaps = self.find_overlaps(interval)\n            for overlap in overlaps:\n                remove_intervals.add(overlap)\n\n        for remove_interval in remove_intervals:\n            intervals.remove(remove_interval)\n\n        intervals.sort(key=lambda interval: interval.start)\n        return intervals\n\n    def find_overlaps(self, interval):\n        return self.root_node.find_overlaps(interval)\n\n\nclass IntervalNode(object):\n    def __init__(self, intervals):\n        self.left = None\n        self.right = None\n        self.intervals = []\n\n        self.point = self.determine_median(intervals)\n\n        # \u200b\u4ee5\u4e2d\u70b9\u200b\u4e3a\u754c\u200b\u9760\u5de6\u200b\u7684\u200b\u533a\u95f4\u200b\n        to_left = []\n        # \u200b\u4ee5\u4e2d\u70b9\u200b\u4e3a\u754c\u200b\u9760\u53f3\u200b\u7684\u200b\u533a\u95f4\u200b\n        to_right = []\n\n        for interval in intervals:\n            if interval.end &lt; self.point:\n                to_left.append(interval)\n            elif interval.start &gt; self.point:\n                to_right.append(interval)\n            else:\n                self.intervals.append(interval)\n\n        if len(to_left) &gt; 0:\n            self.left = IntervalNode(to_left)\n        if len(to_right) &gt; 0:\n            self.right = IntervalNode(to_right)\n\n    def determine_median(self, intervals):\n        start = -1\n        end = -1\n        for interval in intervals:\n            current_start = interval.start\n            current_end = interval.end\n            if start == -1 or current_start &lt; start:\n                start = current_start\n            if end == -1 or current_end &gt; end:\n                end = current_end\n        return (start + end) / 2\n\n    def find_overlaps(self, interval):\n        overlaps = []\n\n        if self.point &lt; interval.start:\n            self.add_to_overlaps(interval, overlaps, self.find_overlapping_ranges(self.right, interval))\n            self.add_to_overlaps(interval, overlaps, self.check_for_overlaps_to_the_right(interval))\n        elif self.point &gt; interval.end:\n            self.add_to_overlaps(interval, overlaps, self.find_overlapping_ranges(self.left, interval))\n            self.add_to_overlaps(interval, overlaps, self.check_for_overlaps_to_the_left(interval))\n        else:\n            self.add_to_overlaps(interval, overlaps, self.intervals)\n            self.add_to_overlaps(interval, overlaps, self.find_overlapping_ranges(self.left, interval))\n            self.add_to_overlaps(interval, overlaps, self.find_overlapping_ranges(self.right, interval))\n        return overlaps\n\n    def add_to_overlaps(self, interval, overlaps, new_overlaps):\n        for current_interval in new_overlaps:\n            if current_interval != interval:\n                overlaps.append(current_interval)\n\n    def check_for_overlaps_to_the_left(self, interval):\n        overlaps = []\n        for current_interval in self.intervals:\n            if current_interval.start &lt;= interval.end:\n                overlaps.append(current_interval)\n        return overlaps\n\n    def check_for_overlaps_to_the_right(self, interval):\n        overlaps = []\n        for current_interval in self.intervals:\n            if current_interval.end &gt;= interval.start:\n                overlaps.append(current_interval)\n        return overlaps\n\n    def find_overlapping_ranges(self, node, interval):\n        if node is not None:\n            return node.find_overlaps(interval)\n        return []\n\n\nclass Interval(object):\n    def __init__(self, start, end, keyword=\"\"):\n        self.start = start\n        self.end = end\n        self.keyword = keyword\n\n    def size(self):\n        return self.end - self.start + 1\n\n    def overlaps_with_interval(self, other):\n        return self.start &lt;= other.end and self.end &gt;= other.start\n\n    def overlaps_with_point(self, point):\n        return self.start &lt;= point &lt;= self.end\n\n    def __eq__(self, other):\n        if not isinstance(other, Interval):\n            return False\n        return self.start == other.start and self.end == other.end\n\n    def __hash__(self):\n        return self.start % 100 + self.end % 100\n\n    def __cmp__(self, other):\n        if not isinstance(other, Interval):\n            return -1\n        comparison = self.start - other.start\n        return comparison if comparison != 0 else (self.end - other.end)\n\n    def __str__(self):\n        return str(self.start) + \":\" + str(self.end) + \"=\" + self.keyword\n</code></pre>"},{"location":"Programing/Python/utils/char_alpha_numeric.html","title":"Char alpha numeric","text":"<pre><code>import unicodedata\nimport codecs\nimport string\nimport numpy as np\nimport json\nfrom zhon import hanzi\nimport pypinyin\nimport re\nfrom ahocorasick import Trie\nimport random\n\n## StringUtils ##\n\"\"\"\n    # staticmethod &amp;&amp; classmethod #\n        - parse_escape_text: \u200b\u5c06\u200b\u672a\u200b\u8f6c\u4e49\u200b\u7684\u200b\u5b57\u7b26\u4e32\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u8f6c\u4e49\u200b\u540e\u200b\u7684\u200b\u7ed3\u679c\u200b\n        - get_max_repeat_element: \u200b\u83b7\u53d6\u200b\u5b57\u7b26\u4e32\u200b\u4e2d\u200b\u6700\u957f\u200b\u8fde\u7eed\u200b\u5b57\u7b26\u200b\u957f\u5ea6\u200b\n        - has_subsequent_spans: span_list\u200b\u4e2d\u200b\u7684\u200b\u5b57\u7b26\u4e32\u200b\u662f\u5426\u200b\u987a\u5e8f\u200b\u5b58\u5728\u200b\u4e8e\u200btext\u200b\u4e2d\u200b\n        - has_all_spans\n        - get_continue_arabic: \u200b\u8fd4\u56de\u200b\u6570\u5b57\u200b\u5e8f\u5217\u200b\u4e2d\u200b\u8fde\u7eed\u200b\u7684\u200b\u5e8f\u5217\u200b\n        - get_continue_alpha: \u200b\u8fd4\u56de\u200b\u5b57\u6bcd\u200b\u5e8f\u5217\u200b\u4e2d\u200b\u8fde\u7eed\u200b\u7684\u200b\u5355\u200b\u5b57\u6bcd\u200b\u5e8f\u5217\u200b\n        - get_continues: \u200b\u8fd4\u56de\u200b\u8fde\u7eed\u200b\u7684\u200b\u6b63\u200b\u3001\u200b\u9006\u5e8f\u200b\u6570\u5b57\u200b\u548c\u200b\u6b63\u200b\u3001\u200b\u9006\u5e8f\u200b\u5355\u200b\u5b57\u6bcd\u200b\n        - slice_text: \u200b\u5bf9\u957f\u200b\u6587\u672c\u200btext\u200b\u8fdb\u884c\u200b\u5207\u7247\u200b\u5904\u7406\u200b\n        - is_chinese\n        - is_japanese\n        - is_korean\n\n\n    # class &amp;&amp; private_class\n        - SpanReplacement\n\"\"\"\n\n\nclass StringUtils:\n    @staticmethod\n    def parse_escape_text(text):\n        return codecs.escape_decode(text)[0].decode(\"utf-8\")\n\n    @staticmethod\n    def get_max_repeat_element_num(text, do_lower_case=True):\n        if do_lower_case:\n            text = text.lower()\n        if len(text) == 0:\n            return 0\n        num = 1\n        max_num = 1\n        for i in range(1, len(text)):\n            if text[i - 1] != text[i]:\n                max_num = max(max_num, num)\n                num = 1\n            else:\n                num += 1\n        return max(max_num, num)\n\n    @staticmethod\n    def has_subsequent_spans(span_list, text, flags=re.I):\n        if not isinstance(span_list, (tuple, list)):\n            raise ValueError(f\"span_list is not tuple or list, but {type(span_list)}\")\n        if len(span_list) == 0 or len(text) == 0:\n            return False\n        cur_idx = 0\n        for span in span_list:\n            g = re.search(span, text, flags)\n            if not g:\n                return False\n            cur_idx += g.end()\n            text = text[g.end():]\n        return True\n\n    @staticmethod\n    def has_all_spans(span_list, text, flags=re.I):\n        if not isinstance(span_list, (tuple, list, set)):\n            raise ValueError(f\"span_list is not tuple or list or set, but {type(span_list)}\")\n        for span in set(span_list):\n            if not re.search(span, text, flags):\n                return False\n        return True\n\n    @staticmethod\n    def count_match_spans(text, span_list):\n        if not isinstance(span_list, (tuple, list, set)):\n            raise ValueError(f\"span_list is not tuple or list or set, but {type(span_list)}\")\n        num = 0\n        for span in set(span_list):\n            if re.search(span, text):\n                num += 1\n        return num\n\n    @staticmethod\n    def has_continues(text, n=3, step=1):\n        ret1 = StringUtils.get_continue_arabic(text, n, step)\n        reverse_ret1 = StringUtils.get_continue_arabic(text[::-1], n, step)\n        ret2 = StringUtils.get_continue_alpha(text, n)\n        reverse_ret2 = StringUtils.get_continue_alpha(text[::-1], n)\n        return ret1 + reverse_ret1 + ret2 + reverse_ret2\n\n    @staticmethod\n    def get_continue_arabic(text, n=3, step=1):\n        arabic_spans = [int(v) for v in re.findall('[0-9]+', text)]\n        if not arabic_spans:\n            return []\n\n        sequences = [[arabic_spans[0]]]\n        for span in arabic_spans[1:]:\n            en_queue = False\n            for seq in sequences:\n                if seq[-1] + step == span:\n                    seq.append(span)\n                    en_queue = True\n                    break\n            if not en_queue:\n                sequences.append([span])\n\n        ret = [seq for seq in sequences if len(seq) &gt;= n]\n        return ret\n\n    @staticmethod\n    def get_continue_alpha(text, n=3):\n        alpha_chars = [v for v in re.findall('[a-z]+', text) if len(v) == 1]\n        if not alpha_chars:\n            return []\n\n        sequences = [[alpha_chars[0]]]\n        for char in alpha_chars[1:]:\n            en_queue = False\n            for seq in sequences:\n                if ord(seq[-1]) + 1 == ord(char):\n                    seq.append(char)\n                    en_queue = True\n                    break\n            if not en_queue:\n                sequences.append([char])\n\n        ret = [seq for seq in sequences if len(seq) &gt;= n]\n        return ret\n\n    @staticmethod\n    def slice_text(text, slice_len=128, seps={'\\n', '\uff01', '\uff1f', '\u3002', '?', '!', '.'}):\n        # \u200b\u53ef\u200b\u5c42\u7ea7\u200b\u9012\u5f52\u200b\u5207\u7247\u200b\uff0c\u200b\u5148\u200b (N*slice_len) \u200b\u5206\u6bb5\u200b\u3001\u200b\u518d\u200b (1*slice_len) \u200b\u5206\u53e5\u200b\n        pieces = set()\n        pre_idx = 0         # left_idx\n\n        while pre_idx &lt; len(text):\n            # rfind\u200b\u8fd4\u56de\u200btext\u200b\u4e2d\u200b\u7684\u200b\u771f\u5b9e\u200bidx\n            sep_idx = max([text.rfind(sep, pre_idx, pre_idx + slice_len) for sep in seps])\n\n            if sep_idx == -1 or pre_idx + slice_len &gt;= len(text):\n                part = text[pre_idx: pre_idx+slice_len]\n                pre_idx += slice_len\n            else:\n                part = text[pre_idx: sep_idx+1]\n                pre_idx = sep_idx + 1\n\n            pieces.add(part)\n        return pieces\n\n    @staticmethod\n    def is_chinese(cp):\n        if (cp &gt;= 0x4E00 and cp &lt;= 0x9FFF) \\\n            or (cp &gt;= 0x3400 and cp &lt;= 0x4DBF) \\\n            or (cp &gt;= 0x20000 and cp &lt;= 0x2A6DF) \\\n            or (cp &gt;= 0x2A700 and cp &lt;= 0x2B73F) \\\n            or (cp &gt;= 0x2B740 and cp &lt;= 0x2B81F) \\\n            or (cp &gt;= 0x2B820 and cp &lt;= 0x2CEAF) \\\n            or (cp &gt;= 0xF900 and cp &lt;= 0xFAFF) \\\n            or (cp &gt;= 0x2F800 and cp &lt;= 0x2FA1F):\n            return True\n        return False\n\n    @staticmethod\n    def is_japanese(cp):\n        if (0x3000 &lt;= cp and cp &lt;= 0x303f\n            or 0x3040 &lt;= cp and cp &lt;= 0x309f\n            or 0x30a0 &lt;= cp and cp &lt;= 0x30ff):\n            return True\n        return False\n\n    @staticmethod\n    def is_korean(cp):\n        if (0x1100 &lt;= cp and cp &lt;= 0x11ff\n            or 0x3130 &lt;= cp and cp &lt;= 0x318f\n            or 0xac00 &lt;= cp and cp &lt;= 0xd7af\n            or 0xa960 &lt;= cp and cp &lt;= 0xa97f\n            or 0xd7b0 &lt;= cp and cp &lt;= 0xd7ff):\n            return True\n        return False\n\n\n    class SpanReplacement:\n        def __init__(self, replace_span_file, allow_overlaps=False, case_insensitive=False):\n            self.trie = Trie(allow_overlaps=allow_overlaps, case_insensitive=case_insensitive)\n            self.replace_map = dict()\n            self.replace_span_file = replace_span_file\n            self.load_replace_file()\n\n        def load_replace_file(self):\n            span_set = set()\n            with open(self.replace_span_file, 'r', encoding='utf-8') as f:\n                for line in f:\n                    if line.startswith('#'):\n                        continue\n                    line = line.strip()\n                    if len(line) == 0:\n                        continue\n                    line_split = line.split('\\t', maxsplit=1)\n                    assert len(line_split) == 2\n                    if line_split[0] in span_set:\n                        print('---' * 10, 'duplicate_span', '---' * 10)\n                        print(line)\n                    span_set.add(line_split[0])\n                    self.replace_map[line_split[0]] = line_split[1]\n                self.trie.build_trie(self.replace_map)\n            print(f\"SpanReplacement loads {len(self.replace_map)} replace tokens\")\n\n        def replace_span(self, text):\n            intervals = self.trie.parse_text(text)\n            text_new = []\n            idx = 0\n            for interval in intervals:\n                text_new += text[idx: interval.start]\n                span = text[interval.start: interval.end + 1]\n                replace_span = self.replace_map[span]\n                text_new.append(replace_span)\n                idx = interval.end + 1\n            text_new.append(text[idx:])\n            return \"\".join(text_new)\n\n        def add_keywords(self, keywords):\n            self.trie.build_trie(keywords)\n\n\n## AlphaUtils ##\n\"\"\"\n    # staticmethod &amp;&amp; classmethod #\n        - full_to_half\n        - half_to_full\n        - count_full_width_chars\n        - is_half_alpha\n        - is_full_alpha\n        - is_alpha\n\"\"\"\n\n\nclass AlphaUtils:\n    @staticmethod\n    def full_to_half(s):\n        return unicodedata.normalize(\"NFKC\", s)\n\n    @staticmethod\n    def half_to_full(s):\n        n = []\n        for char in s:\n            num = ord(char)\n            if 0x21 &lt;= num &lt;= 0x7e:\n                num += 0xfee0\n            num = chr(num)\n            n.append(num)\n        return ''.join(n)\n\n    @staticmethod\n    def count_full_width_chars(s):\n        return sum([AlphaUtils.full_to_half(c) != c for c in s])\n\n    @staticmethod\n    def is_half_alpha(c):\n        if len(c) != 1:\n            return False\n        elif ord('a') &lt;= ord(c) &lt;= ord('z') or ord('A') &lt;= ord(c) &lt;= ord('Z'):\n            return True\n        return False\n\n    @staticmethod\n    def is_full_alpha(c):\n        if len(c) != 1:\n            return False\n        if ord('\uff41') &lt;= ord(c) &lt;= ord('\uff5a') or ord('\uff21') &lt;= ord(c) &lt;= ord('\uff3a'):\n            return True\n        return False\n\n    @staticmethod\n    def is_alpha(c):\n        return AlphaUtils.is_half_alpha(c) or AlphaUtils.is_full_alpha(c)\n\n\n## PyTokenizer ##\n\"\"\"\n    # staticmethod &amp;&amp; classmethod #\n        - pinyin\n        - has_pinyin\n        - has_subsequent_pinyins: pinyin_list\u200b\u4e2d\u200b\u7684\u200bpinyin\u200b\u5b50\u4e32\u200b\u662f\u5426\u200b\u987a\u5e8f\u200b\u5b58\u5728\u200b\u4e8e\u200btext\u200b\u4e2d\u200b\n        - has_all_pinyins\n        - split_un_pinyin: \u200b\u5c06\u200b\u65e0\u200b\u62fc\u97f3\u200b\u7684\u200b\u5b57\u7b26\u4e32\u200b\u5212\u5206\u200b\uff08\u200b\u4ee5\u200b##\u200b\u4e3a\u200b\u524d\u7f00\u200b\u4e0e\u200b\u5355\u200b\u5b57\u6bcd\u200b\u62fc\u97f3\u200b\u533a\u5206\u200b\uff09\n        - strip_pinyin_tone\n        - arabic_to_pinyin\n\n    # class &amp;&amp; private_class\n        - __init__: \u200b\u4f7f\u7528\u200b\u81ea\u5b9a\u4e49\u200b\u7684\u200bpinyin\u200b\u6587\u4ef6\u200b\u8fdb\u884c\u200bpinyin\u200b\u8f6c\u6362\u200b\n\"\"\"\n\n\nclass PyTokenizer:\n    number_pinyin_map = {\n        \"0\": \"ling2\", \"\uff10\": \"ling2\",\n        \"1\": \"yi1\", \"\uff11\": \"yi1\",\n        \"2\": \"er4\", \"\uff12\": \"er4\",\n        \"3\": \"san1\", \"\uff13\": \"san1\",\n        \"4\": \"si4\", \"\uff14\": \"si4\",\n        \"5\": \"wu3\", \"\uff15\": \"wu3\",\n        \"6\": \"liu4\", \"\uff16\": \"liu4\",\n        \"7\": \"qi1\", \"\uff17\": \"qi1\",\n        \"8\": \"ba1\", \"\uff18\": \"ba1\",\n        \"9\": \"jiu3\", \"\uff19\": \"jiu3\",\n\n    }\n\n    @staticmethod\n    def pinyin(\n            text,\n            remain_alpha=False,\n            remain_arabic=False,\n            arabic_to_pinyin=False,\n            white_list_chars={},\n            py_tokenizer=None\n    ):\n        # split un-pinyin span\n        if py_tokenizer == None:\n            pinyins = pypinyin.lazy_pinyin(text, errors=lambda x: PyTokenizer.split_un_pinyin(x))\n        else:\n            pinyins = py_tokenizer.lazy_pinyin(text)\n        new_pinyin = []\n        for py in pinyins:\n            if py.startswith('##'):\n                if remain_alpha and AlphaUtils.is_alpha(py[-1]) \\\n                        or remain_arabic and NumericUtils.is_arabic(py[-1]) \\\n                        or py[-1] in white_list_chars:\n                    py = py[-1]\n                else:\n                    continue\n            new_pinyin.append(py)\n        if remain_arabic and arabic_to_pinyin:\n            new_pinyin = PyTokenizer.arabic_to_pinyin(new_pinyin)\n        return new_pinyin\n\n    @staticmethod\n    def has_pinyin(\n            text,\n            pattern,\n            match_type=\"fuzzy\",  # strict or fuzzy\n            arabic_to_pinyin=False,\n            remain_alpha=False,\n            remain_arabic=False,\n            white_list_chars={},\n            py_tokenizer=None):\n        text_pinyin = PyTokenizer.pinyin(text, remain_alpha=remain_alpha, remain_arabic=remain_arabic,\n                                         arabic_to_pinyin=arabic_to_pinyin,\n                                         white_list_chars=white_list_chars, py_tokenizer=py_tokenizer)\n\n        if match_type == \"strict\":\n            text_pinyin = \" \".join(text_pinyin)\n        elif match_type == \"fuzzy\":\n            text_pinyin = \"\".join(text_pinyin)\n        else:\n            raise ValueError(\"match_type must in {strict, fuzzy}\")\n        return re.findall(pattern, text_pinyin, re.I)\n\n    @staticmethod\n    def has_subsequent_pinyins(\n            text,\n            pinyin_list,\n            match_type=\"fuzzy\",  # strict or fuzzy\n            arabic_to_pinyin=False,\n            remain_alpha=False,\n            remain_arabic=False,\n            white_list_chars={},\n            py_tokenizer=None\n    ):\n        if not isinstance(pinyin_list, (tuple, list)):\n            raise ValueError(f\"pinyin_list is not tuple or list, but {type(pinyin_list)}\")\n        if len(pinyin_list) == 0:\n            return False\n        text_pinyin = PyTokenizer.pinyin(text, remain_alpha=remain_alpha, remain_arabic=remain_arabic,\n                                         arabic_to_pinyin=arabic_to_pinyin,\n                                         white_list_chars=white_list_chars, py_tokenizer=py_tokenizer)\n        if len(text_pinyin) == 0:\n            return False\n        if match_type not in {\"strict\", \"fuzzy\"}:\n            raise ValueError(\"match_type must in {strict, fuzzy}\")\n        elif match_type == \"strict\":\n            cur_idx = 0\n            text_pinyin = \" \".join(text_pinyin)\n            for py_span in pinyin_list:\n                g = re.search(f'(?:^| ){py_span}(?:$| )', text_pinyin)\n                if not g:\n                    return False\n                cur_idx += g.end() + 1\n                text_pinyin = text_pinyin[g.end():]\n            return True\n        elif match_type == \"fuzzy\":\n            text_pinyin = \"\".join(text_pinyin)\n            return StringUtils.has_subsequent_spans(text_pinyin, pinyin_list)\n\n    @staticmethod\n    def has_all_pinyins(\n            text,\n            pinyin_list,\n            match_type=\"fuzzy\",  # strict or fuzzy\n            arabic_to_pinyin=False,\n            remain_alpha=False,\n            remain_arabic=False,\n            white_list_chars={},\n            py_tokenizer=None\n    ):\n        if not isinstance(pinyin_list, (tuple, list, set)):\n            raise ValueError(f\"pinyin_list is not tuple or list or set, but {type(pinyin_list)}\")\n        if len(pinyin_list) == 0:\n            return True\n        text_pinyin = PyTokenizer.pinyin(text, remain_alpha=remain_alpha, remain_arabic=remain_arabic,\n                                         arabic_to_pinyin=arabic_to_pinyin,\n                                         white_list_chars=white_list_chars, py_tokenizer=py_tokenizer)\n        if len(text_pinyin) == 0:\n            return False\n        if match_type not in {\"strict\", \"fuzzy\"}:\n            raise ValueError(\"match_type must in {strict, fuzzy}\")\n        elif match_type == \"strict\":\n            text_pinyin = \" \".join(text_pinyin)\n            for py_span in pinyin_list:\n                g = re.search(f'(?:^| ){py_span}(?:$| )', text_pinyin)\n                if not g:\n                    return False\n            return True\n        elif match_type == \"fuzzy\":\n            text_pinyin = \"\".join(text_pinyin)\n            return StringUtils.has_all_spans(pinyin_list, text_pinyin)\n\n    @staticmethod\n    def find_all_span_by_pinyins(text, pinyin_list):\n        char_to_pinyin = {i: (c, \"\".join(lazy_pinyin(c))) for i, c in enumerate(text)}\n        matches = []\n        for py_span in pinyin_list:\n            flag = False\n            for start in range(len(text)):\n                for end in range(start + 1, len(text) + 1):\n                    substring = text[start:end]\n                    sub_pinyin = ''.join([char_to_pinyin[i][1] for i in range(start, end) if\n                                          i in char_to_pinyin and re.search('[\\u4e00-\\u9fffa-zA-Z0-9]', text[i])])\n                    if re.fullmatch(py_span, sub_pinyin):\n                        matches.append([substring, start, end])\n                        flag = True\n                        break\n                if flag:\n                    break\n            if not flag:\n                return []\n        return matches\n\n    @staticmethod\n    def find_subsquent_span_by_pinyins(text, pinyin_list):\n        char_to_pinyin = {i: (c, \"\".join(lazy_pinyin(c))) for i, c in enumerate(text)}\n        matches = []\n        start = 0\n        for py_span in pinyin_list:\n            flag = False\n            while start &lt; len(text):\n                for end in range(start + 1, len(text) + 1):\n                    substring = text[start:end]\n                    sub_pinyin = ''.join([char_to_pinyin[i][1] for i in range(start, end) if\n                                          i in char_to_pinyin and re.search('[\\u4e00-\\u9fffa-zA-Z0-9]', text[i])])\n                    if re.fullmatch(py_span, sub_pinyin):\n                        matches.append([substring, start, end])\n                        flag = True\n                        break\n\n                start += 1\n                if flag:\n                    break\n            if not flag:\n                return []\n        return matches\n\n    @staticmethod\n    def replace_span_with_homophones(text, matches, sound2char):\n        homophones = []\n        for span in matches:\n            same_sound_span = []\n            for c in span[0]:\n                c_pinyin = lazy_pinyin(c)[0]\n                target_set = {c_pinyin}\n                target_set.update(sound2char.get(c_pinyin, {c}))\n                same_sound_span.append(random.choice(list(target_set)))\n        homophones.append(span + [''.join(same_sound_span)])\n\n        for span in reversed(homophones):\n            text = text[:span[1]] + span[-1] + text[span[2]:]\n        return text\n\n    @staticmethod\n    def split_un_pinyin(text):\n        new_pinyin = []\n        for c in text:\n            new_pinyin.append('##' + c)\n        return new_pinyin\n\n    @staticmethod\n    def strip_pinyin_tone(py):\n        if py.endswith('1') or py.endswith('2') or py.endswith('3') or py.endswith('4'):\n            py = py[:-1]\n        return py\n\n    @classmethod\n    def arabic_to_pinyin(cls, text, ignore_tone=True):\n        new_pinyin = []\n        for c in text:\n            if c not in cls.number_pinyin_map:\n                c = c\n            else:\n                c = cls.number_pinyin_map[c]\n                if ignore_tone:\n                    c = PyTokenizer.strip_pinyin_tone(c)\n            new_pinyin.append(c)\n        return new_pinyin\n\n    def __init__(self,\n                 pinyin_file,\n                 ignore_tone=True,\n                 file_type=\"JSON\"  # JSON or CSV_key-idx_py_idx\n                 ):\n        self.ignore_tone = ignore_tone\n        self.pinyin_map = self.load_pinyin_file(pinyin_file, file_type)\n\n    def load_pinyin_file(self, pinyin_file, file_type):\n        pinyin_map = dict()\n        key_idx = -1\n        py_idx = -1\n        if file_type.lower().startswith(\"csv\"):\n            parts = file_type.split('_')\n            key_idx = int(parts[1])\n            py_idx = int(parts[-1])\n        elif file_type.lower() == \"json\":\n            pass\n        else:\n            raise ValueError(f\"pinyin file type must be json or CSV_key-idx_py_idx\")\n        with open(pinyin_file, 'r', encoding='utf-8') as f:\n            for line in f:\n                if key_idx &lt; 0:\n                    line = json.loads(line)\n                else:\n                    parts = line.split()\n                    key = parts[key_idx]\n                    val = parts[py_idx].split(';')[0]\n                    # skip non-pinyin token\n                    if val == \"null\":\n                        continue\n                    if self.ignore_tone:\n                        val = PyTokenizer.strip_pinyin_tone(val)\n                    line = {key: val}\n                for key, val in line.items():\n                    if key in pinyin_map:\n                        print(\n                            f'{key} has already in current pinyin file\\n\\tprevious: {pinyin_map[key]}\\n\\tcurrent: {val}')\n                    pinyin_map[key] = val\n        print(f'pinyin file loads {len(pinyin_map)} samples')\n        return pinyin_map\n\n    def lazy_pinyin(self, text):\n        text = text.lower()\n        pinyins = []\n        for c in text:\n            if c in self.pinyin_map:\n                c = self.pinyin_map.get(c)\n            else:\n                c = \"##\" + c\n            pinyins.append(c)\n        return pinyins\n\n\n## NumericUtils ##\n\"\"\"\n    # staticmethod &amp;&amp; classmethod #\n        - uni_to_arabic\n        - is_half_arabic\n        - is_full_arabic\n        - is_arabic\n        - get_float_length: \u200b\u8fd4\u56de\u200b\u6d6e\u70b9\u200b\u578b\u200b\u53d8\u91cf\u200b\u5c0f\u6570\u70b9\u200b\u4f4d\u6570\u200b\n\"\"\"\n\n\nclass NumericUtils:\n    number_map = {\n        \"\u200b\u96f6\u200b\": \"0\",\n        \"\u200b\u4e00\u200b\": \"1\", \"\u200b\u58f9\u200b\": \"1\",\n        \"\u200b\u4e8c\u200b\": \"2\", \"\u200b\u8d30\u200b\": \"2\",\n        \"\u200b\u4e09\u200b\": \"3\", \"\u200b\u53c1\u200b\": \"3\",\n        \"\u200b\u56db\u200b\": \"4\", \"\u200b\u8086\u200b\": \"4\",\n        \"\u200b\u4e94\u200b\": \"5\", \"\u200b\u4f0d\u200b\": \"5\",\n        \"\u200b\u516d\u200b\": \"6\", \"\u200b\u9646\u200b\": \"6\",\n        \"\u200b\u4e03\u200b\": \"7\", \"\u200b\u67d2\u200b\": \"7\",\n        \"\u200b\u516b\u200b\": \"8\", \"\u200b\u634c\u200b\": \"8\",\n        \"\u200b\u4e5d\u200b\": \"9\", \"\u200b\u7396\u200b\": \"9\",\n        \"\u200b\u62fe\u200b\": \"\u200b\u5341\u200b\",\n        \"\u200b\u4f70\u200b\": \"\u200b\u767e\u200b\",\n        \"\u200b\u4edf\u200b\": \"\u200b\u5343\u200b\",\n    }\n\n    @classmethod\n    def uni_to_arabic(cls, text, extra_number_map=dict(), extra_first=True):\n        new_text = []\n        for c in text:\n            if extra_first:\n                c = extra_number_map.get(c, cls.number_map.get(c, c))\n            else:\n                c = cls.number_map.get(c, extra_number_map.get(c, c))\n            new_text.append(c)\n        return \"\".join(new_text)\n\n    @staticmethod\n    def is_half_arabic(c):\n        if len(c) != 1:\n            return False\n        elif ord('0') &lt;= ord(c) &lt;= ord('9'):\n            return True\n        return False\n\n    @staticmethod\n    def is_full_arabic(c):\n        if len(c) != 1:\n            return False\n        elif ord('\uff10') &lt;= ord(c) &lt;= ord('\uff19'):\n            return True\n        return False\n\n    @staticmethod\n    def is_arabic(c):\n        return NumericUtils.is_half_arabic(c) or NumericUtils.is_full_arabic(c)\n\n    @staticmethod\n    def get_float_length(val):\n        val_str = np.format_float_positional(val, trim='-')\n        n = len(val_str.split('.')[-1])\n        return n\n\n\n## PunctuationUtils ##\n\"\"\"\n    # staticmethod &amp;&amp; classmethod #\n        - strip_punctuation\n        - strip_white_space\n\"\"\"\n\n\nclass PunctuationUtils:\n    all_punctuation = set(list(string.punctuation + hanzi.punctuation))\n    all_punctuation.remove(\"\\u3000\")\n\n    @classmethod\n    def strip_punctuation(cls, text, white_list_punctuation={}):\n        ret = []\n        for c in text:\n            if c not in white_list_punctuation \\\n                    and (c in cls.all_punctuation or\n                         unicodedata.category(c).startswith(\"P\")):\n                continue\n            ret.append(c)\n        return \"\".join(ret)\n\n    @staticmethod\n    def strip_white_space(text, white_list_space={}, replace_token=\"\"):\n        ret = []\n        for c in text:\n            cp = ord(c)\n            if c not in white_list_space and \\\n                    (\n                            0x00 &lt;= cp &lt;= 0x20 or cp == 0x3000\n                            or 0x7f &lt;= cp &lt;= 0xa0\n                            or cp == 0x034f\n                            or 0x2000 &lt;= cp &lt;= 0x200f or cp == 0x2011 or 0x2028 &lt;= cp &lt;= 0x202f or 0x205f &lt;= cp &lt;= 0x206f\n                            or 0xfe00 &lt;= cp &lt;= 0xfe0f\n                            or 0xe0100 &lt;= cp &lt;= 0xe01ef\n                            or cp == 0xfeff\n                            or cp == 0x115f or cp == 0x1160 or cp == 0x3164 or cp == 0xffa0\n                            or 0xfff0 &lt;= cp &lt;= 0xffff\n                            or 0xe0000 &lt;= cp &lt;= 0xe007f\n                            or unicodedata.category(c) in (\"Zs\",)\n                            # Cc/Cf\n                    ):\n                c = replace_token\n            ret.append(c)\n        return \"\".join(ret)\n</code></pre>"},{"location":"Programing/Python/utils/general_dataset_utils.html","title":"General dataset utils","text":"<pre><code>import random\nimport json\nimport tqdm\nfrom wheel_utils.char_alpha_numeric import *\n\n\ndef uni_label(label):\n    if label in {'0', 0, 'normal', 'other'}:\n        return 0\n    elif label in {'1', 1}:\n        return 1\n    else:\n        raise ValueError(f\"{label} is not a valid label\")\n\n\ndef uni_labels(example):\n    example[\"label\"] = uni_label(example.get(\"label\", \"0\"))\n    return example\n\n\ndef pre_process_content(example, trie, t2s, case_sensitive):\n    cnt = example.get(\"content\", example.get(\"Content\", example.get(\"c\")))\n\n    if trie:\n        cnt = trie.replace_span(cnt)\n    if t2s:\n        cnt = t2s.convert(cnt)\n    if not case_sensitive:\n        cnt = cnt.lower()\n\n    cnt = PunctuationUtils.strip_white_space(cnt, replace_token=\" \")\n    example[\"content\"] = cnt\n    return example\n\n\ndef pre_process(example, trie, t2s, case_sensitive):\n    example = uni_labels(example)\n    example = pre_process_content(example, trie, t2s, case_sensitive)\n    return example\n\n\ndef split_corpus(data_file, train_data_file, valid_data_file, valid_percent=0.1):\n    with open(data_file, 'r', encoding='utf-8') as f_in, \\\n            open(train_data_file, 'w', encoding='utf-8') as f_train, \\\n            open(valid_data_file, 'w', encoding='utf-8') as f_valid:\n        train_part, valid_part = [], []\n        for line in f_in:\n            line = json.loads(line)\n            if random.uniform(0, 1) &lt; valid_percent:\n                valid_part.append(line)\n            else:\n                train_part.append(line)\n        random.shuffle(valid_part)\n        for line in valid_part:\n            f_valid.write(json.dumps(line, ensure_ascii=False) + '\\n')\n            f_valid.flush()\n\n        random.shuffle(train_part)\n        for line in train_part:\n            f_train.write(json.dumps(line, ensure_ascii=False) + '\\n')\n            f_train.flush()\n\n        print(f\"after splitting,there are\"\n              f\"\\n{len(train_part)} samples in train set\"\n              f\"\\n{len(valid_part)} samples in valid set\")\n\n\ndef generate_distill_data(object_file, parts_num=12, pp=8, threshold=.5, label_type=\"soft\", ignore_teacher_data=True):\n    tmp_data = set()\n    if ignore_teacher_data:\n        with open('../data.json', 'r', encoding='utf-8') as f_line:\n            for line in f_line:\n                line = json.loads(line)\n                tmp_data.add(line.get('content', line.get(\"c\")))\n\n    neg_num, pos_num = 0, 0\n    total_num = 0\n    for i in range(1, parts_num + 1):\n        with open(f'../{object_file}/result_{i:&gt;02d}.txt', 'r', encoding='utf-8') as f_prob:\n            for prob in tqdm(f_prob, f\"scan part_{i} positives\"):\n                prob = json.loads(prob)\n                if prob['prob'] &gt;= threshold:\n                    pos_num += 1\n                total_num += 1\n    target_neg_num = pp * pos_num\n    neg_keep_rate = target_neg_num / (total_num - pos_num)\n\n    with open('./data_distill.json', 'w', encoding='utf-8') as f:\n        for i in range(1, parts_num + 1):\n            with open(f'../{object_file}/result_{i:&gt;02d}.txt', 'r', encoding='utf-8') as f_prob, \\\n                    open(f'../{object_file}/{object_file}{i:&gt;02d}', 'r', encoding='utf-8') as f_line:\n                for k, (line, prob) in tqdm(enumerate(zip(f_line, f_prob), 1), f\"dump part_{i} samples\"):\n                    prob = json.loads(prob)\n                    if prob['prob'] &gt;= threshold or random.uniform(0, 1) &lt; neg_keep_rate:\n                        line = json.loads(line)\n                        content = line.get('content', line.get(\"c\"))\n\n                        if content in tmp_data:\n                            continue\n\n                        if label_type == \"soft\":\n                            probs = [1 - prob[\"prob\"], prob[\"prob\"]]\n                        elif label_type == \"hard\":\n                            probs = [ 1-int(prob[\"prob\"]  &gt;= threshold) , int(prob[\"prob\"]  &gt;= threshold)]\n                        else:\n                            raise ValueError(\"label type error\")\n\n                        sample = {\n                            \"content\": content,\n                            \"probs\": probs\n                        }\n\n                        neg_num += prob['prob'] &lt; threshold\n                        f.write(json.dumps(sample, ensure_ascii=False) + \"\\n\")\n                        f.flush()\n\n    print(f\"distill_data has:\\n\\t{pos_num} positives\\n\\t{neg_num} negatives\")\n</code></pre>"},{"location":"Programing/Python/utils/generate_regrex.html","title":"Generate regrex","text":"<pre><code>import copy\n\n\ndef read_regrex(txt, flag=0):\n    i = 0\n    pre_seq = [[]]\n    while i &lt; len(txt):\n        c = txt[i]\n        if c == '(':\n            # print(txt[i:], txt)\n            cur = 1\n            for j in range(i+1, len(txt)):\n                if txt[j] == '(':\n                    cur += 1\n                elif txt[j] == ')':\n                    cur -= 1\n                if cur == 0:\n                    r = j\n                    break\n            # r = txt[i:].index(')') + i\n            try:\n                ret = read_regrex(txt[i + 3: r], flag + 1)\n            except e:\n                raise Exception(f'{txt}')\n            # ret = read_regrex(txt[i+3: r], flag + 1)\n            i = r+1\n            if i &lt; len(txt) and txt[i] == '{':\n                r = txt[i:].index('}') + i\n                try:\n                    v = int(txt[i+1: r])\n                except Exception:\n                    raise Exception(f'can not generate indefinite time of {txt[i+1: r]}')\n            else:\n                v = 1\n            for k in range(v):\n                for seq in pre_seq:\n                    seq.append(ret)\n            i = r+1\n        elif c == '[':\n            cur = 1\n            for j in range(i + 1, len(txt)):\n                if txt[j] == '[':\n                    cur += 1\n                elif txt[j] == ']':\n                    cur -= 1\n                if cur == 0:\n                    r = j\n                    break\n            # r = txt[i:].index(']') + i\n            try:\n                tmp_t = '|'.join(list(txt[i+1: r]))\n            except:\n                raise Exception(f'{txt}')\n            ret = read_regrex(tmp_t, flag)\n            i = r+1\n            if i &lt; len(txt) and txt[i] == '{':\n                r = txt[i:].index('}') + i\n                try:\n                    v = int(txt[i+1: r])\n                except Exception:\n                    raise Exception(f'can not generate indefinite time of {txt[i+1: r]}')\n            else:\n                v = 1\n            for k in range(v):\n                for seq in pre_seq:\n                    seq.append(ret)\n            i = r+1\n        elif c == '|':\n            r = len(txt)\n            cur = 0\n            for j in range(i + 1, len(txt)):\n                if txt[j] in ['[', '(']:\n                    cur += 1\n                elif txt[j] in [']', ')']:\n                    if cur == 0:\n                        r = j\n                        break\n                    else:\n                        cur -= 1\n                elif txt[j] == '|' and cur == 0:\n                    r = j\n                    break\n            # r = txt[i+1:].find('|') + i+1\n            if r == i or '(' in txt[i:r]:\n                r = len(txt)\n            # print('right |', txt[r:])\n            ret = read_regrex(txt[i+1:r], flag)\n            for seq in ret:\n                pre_seq.append(seq)\n            i = r\n        elif c == '?':\n            # print('pre', pre_seq)\n            pre_seq.append(pre_seq[-1][:-1])\n            flag = max(2, flag+1)\n            # print('pre', pre_seq)\n            i += 1\n        else:\n            # print(flag, i, c)\n            if flag &lt;= 1:\n                pre_seq[-1].append(c)\n            else:\n                for seq in pre_seq:\n                    seq.append(c)\n            i += 1\n    return pre_seq\n\n\ndef traverse_regrex(txt):\n    ret = read_regrex(txt)\n    # print('regrex', ret)\n    ret_str = []\n    # print(len(ret))\n    for r in ret:\n        t_ret = get_regrex(r)\n        ret_str += t_ret\n    return ret_str\n\n\ndef get_regrex(obj):\n    ret = []\n    for i in range(len(obj)):\n        if isinstance(obj[i], str):\n            if len(ret) == 0:\n                ret.append('')\n            for k in range(len(ret)):\n                ret[k] += obj[i]\n            # print(ret)\n        else:\n            t_ret = [get_regrex(ele) for ele in obj[i]]\n            if len(ret) == 0:\n                ret.append('')\n            ret_counter_part = copy.deepcopy(ret)\n            # print(t_ret, ret_counter_part)\n            ret = []\n            for s in ret_counter_part:\n                for t_s in t_ret:\n                    for tt_s in t_s:\n                        ret.append(s + tt_s)\n            # print(ret)\n    return ret\n\n\nif __name__ == \"__main__\":\n    s = traverse_regrex('[mn][ .]?[1i][ .]?c[ .]?k')\n    print(len(s), s)\n</code></pre>"},{"location":"Programing/Python/utils/metrics.html","title":"Metrics","text":"<pre><code>from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\nimport numpy as np\n\n\ndef compute_metrics(logit_label_pairs):\n    logits, labels = logit_label_pairs\n    predictions = np.argmax(logits, axis=-1)\n    return {\n        \"accuracy\": accuracy_score(labels, predictions),\n        \"f1\": f1_score(labels, predictions, average=\"macro\"),\n        \"recall\": recall_score(labels, predictions),\n        \"precision\": precision_score(labels, predictions),\n    }\n</code></pre>"},{"location":"Programing/Python/utils/random_methods.html","title":"Random methods","text":"<pre><code>import random\n\n\n## sample ##\n\"\"\"\n    - geometric_sample: \u200b\u51e0\u4f55\u200b\u5206\u5e03\u200b\u91c7\u6837\u200b\u51fa\u200bn\n    - random.uniform: [l, r] \u200b\u4e4b\u95f4\u200b\u5747\u5300\u5206\u5e03\u200b\u91c7\u6837\u200b\u51fa\u200bv\n\"\"\"\nclass random_sample:\n    @staticmethod\n    def geometric_sample(p, v=0, max_v=6):\n        if v &lt; 0 or p &lt; 0 or p &gt; 1:\n            raise ValueError(f\"v should \u2208 [1, {max_v}], p should \u2208 [0, 1]\")\n        if v &gt;= max_v or random.uniform(0, 1) &lt;= p:\n            return v\n        return random_sample.geometric_sample(p, v + 1, max_v)\n\n    @staticmethod\n    def uniform_sample(l=0, r=1):\n        return random.uniform(l, r)\n\n\n## choice ##\n\"\"\"\n    - random.choice: \u200b\u7b49\u200b\u6982\u7387\u200b\u9009\u53d6\u200bseq\u200b\u4e2d\u200b\u7684\u200b1\u200b\u4e2a\u200b\u5143\u7d20\u200b\n    - random.choices: \uff08\u200b\u6307\u5b9a\u200b\u5404\u200b\u5143\u7d20\u200b\u6743\u91cd\u200b\u4e14\u200b\uff09\u200b\u6709\u653e\u200b\u56de\u5730\u200b\u9009\u53d6\u200bpopulation\u200b\u4e2d\u200b\u7684\u200bk\u200b\u4e2a\u200b\u5143\u7d20\u200b\n    - random.sample: \u200b\u65e0\u653e\u200b\u56de\u5730\u200b\u7b49\u200b\u6982\u7387\u200b\u9009\u53d6\u200bpopulation\u200b\u4e2d\u200b\u7684\u200bk\u200b\u4e2a\u200b\u5143\u7d20\u200b\n\"\"\"\nclass random_choice:\n    @staticmethod\n    def random_choice(seq):\n        return random.choice(seq)\n\n    @staticmethod\n    def random_choices(\n            seq,\n            weights=None,       # \u200b\u6bcf\u4e2a\u200b\u5143\u7d20\u200b\u88ab\u200b\u9009\u4e2d\u200b\u7684\u200b\u76f8\u5bf9\u200b\u6743\u91cd\u200b\uff0c\u200b\u5bf9\u5e94\u200b\u4e8e\u200bpopulation\u200b\u4e2d\u200b\u7684\u200b\u5143\u7d20\u200b\n            *,\n            cum_weights=None,   # \u200b\u622a\u81f3\u200bidx-th\u200b\u5143\u7d20\u200b\u7684\u200b\u7d2f\u8ba1\u200b\u6743\u91cd\u200b\uff0c\u200b\u5bf9\u5e94\u200b\u4e8e\u200bsum(weights[:idx])\n            k=1                 # \u200b\u6307\u5b9a\u200b\u62bd\u6837\u200b\u7684\u200b\u5143\u7d20\u200b\u4e2a\u6570\u200b\n        ):\n        return random.choices(seq, weights=weights, cum_weights=cum_weights, k=k)\n\n    @staticmethod\n    def random_sample(seq, k):\n        return random.sample(seq, k)\n</code></pre>"},{"location":"Programing/Python/utils/tf1_dataset_utils.html","title":"Tf1 dataset utils","text":"<pre><code>import tensorflow as tf\nfrom wheel_utils.general_dataset_utils import *\n\n\nclass DataResource:\n    def __init__(\n            self,\n            data_file,\n            tokenizer=None,\n            trie=None,\n            t2s=None,\n            case_sensitive=False,\n    ):\n        self.data_file = data_file\n        self.example_num = self._count()\n        self.trie = trie\n        self.t2s = t2s\n        self.case_sensitive = case_sensitive\n        self.tokenizer = tokenizer\n\n    def _count(self):\n        with open(self.data_file, 'r', encoding='utf-8') as f:\n            for i, _ in enumerate(f, 1):\n                pass\n        return i\n\n    def __len__(self):\n        return self.example_num\n\n    def generator(self):\n        f = open(self.input_file, \"r\", encoding=\"utf-8\")\n        for line in f:\n            try:\n                line = json.loads(line)\n            except:\n                print(json.dumps(line, ensure_ascii=False))\n                raise ValueError\n\n            line = pre_process(self.trie, self.t2s, self.case_sensitive, line)\n            inputs = self.tokenizer(line[\"content\"])\n\n            # \u200b\u751f\u6210\u200b\u7684\u200btuple\u200b\u6bcf\u4e00\u9879\u200b\u90fd\u200b\u5e94\u8be5\u200b\u662f\u200b\u4e00\u4e2a\u200blist\n            yield (\n                [line[\"content\"]],\n                [line[\"label\"]],\n                inputs[\"input_token_ids\"],\n                inputs[\"input_sound_ids\"],\n                inputs[\"input_shape_ids\"],\n                # inputs[\"input_mask\"],\n            )\n\n    def next_batch(\n            self,\n            epochs,\n            batch_size,\n            shuffle=False,\n            drop_remainder=False,\n    ):\n        dataset = tf.data.Dataset.from_generator(\n            self.generator,\n            output_types=(                      # \u200b\u5bf9\u5e94\u200b\u53c2\u6570\u200bgenerator\u200b\u7684\u200b\u6570\u636e\u200b\u8fd4\u56de\u200b\u7c7b\u578b\u200b\n                tf.string,\n                tf.int32,\n                tf.int32,\n                tf.int32,\n                tf.int32,\n            )\n        )\n\n        # dataset repeats by epochs times\n        dataset = dataset.repeat(epochs)\n\n        # \u200b\u8bbe\u7f6e\u200b\u9884\u53d6\u200b\u6c60\u200b\u548c\u200b\u6270\u52a8\u200b\u6c60\u200b\u5927\u5c0f\u200b\u7528\u4e8e\u200b\u6837\u672c\u200b\u968f\u673a\u200b\u62bd\u53d6\u200b #\n        # 1. \u200b\u9884\u53d6\u200b prefetch_size \u200b\u4e2a\u200b\u6837\u672c\u200b\u8fdb\u5165\u200b\u9884\u53d6\u200b\u6c60\u200b\n        # 2. \u200b\u5f53\u200b\u9884\u53d6\u200b\u6c60\u6ee1\u65f6\u200b\uff0c\u200b\u4ece\u200b\u5176\u4e2d\u200b shuffle_size \u200b\u4e2a\u200b\u6837\u672c\u200b\u4e2d\u200b\u968f\u673a\u200b\u62bd\u53d6\u200b\u4e00\u4e2a\u200b\u6837\u672c\u200b\n        #    `idx = random.randint(shuffle_size)` \n        #    `choose prefetch_reservoir[idx]`\n        #    `prefetch_reservoir[idx] = current_line`\n        # &gt; prefetch_size \u200b\u548c\u200b shuffle_size \u200b\u8d8a\u5927\u200b\u968f\u673a\u200b\u6548\u679c\u200b\u8d8a\u200b\u8d8b\u8fd1\u200b\u4e8e\u200b\u5168\u5c40\u200b\u6270\u52a8\u200b\n        if shuffle:\n            dataset = dataset.shuffle(buffer_size=100 * batch_size)\n        dataset = dataset.prefetch(buffer_size=100 * batch_size)\n\n        dataset = dataset.padded_batch(\n            batch_size,\n            padded_shapes=(\n                [None], [None], [None], [None], [None]\n            ),                      # None \u200b\u8868\u793a\u200b `pad_to_longest`, [] \u200b\u8868\u793a\u200b\u4e0d\u200b\u586b\u5145\u200b\n            padding_values=None,    # pad_to_longest\n                                    # None \u200b\u8868\u793a\u200b\u7f3a\u7701\u200bPAD {int\u21920, str\u2192\"\"}\n                                    # [PAD] idx\u22600 \u200b\u65f6\u200b\u53ef\u200b\u81ea\u5b9a\u4e49\u200b\u5bf9\u5e94\u200b\u7684\u200bpad_value\n                                    # \u200b\u81ea\u5b9a\u4e49\u200bpad_values\u200b\u65f6\u9700\u200b\u5bf9\u9f50\u200boutput_types\n            drop_remainder=drop_remainder,\n        )\n\n        # \u200b\u8f6c\u5316\u200b\u4e3a\u200biterator\n        iterator = dataset.make_initializable_iterator()\n        return iterator.get_next(), iterator.initializer\n</code></pre>"},{"location":"Programing/Python/utils/tf1_dataset_utils.html#data_loader","title":"data_loader","text":"<pre><code>import tensorflow as tf\n\n\n# session + config\nsaver = tf.train.Saver(max_to_keep=3)\nconfig = tf.ConfigProto()\nconfig.allow_soft_placement = True\nconfig.gpu_options.allow_growth = True\n# config.gpu_options.per_process_gpu_memory_fraction = .1\nsess = tf.Session(config=config)\n\n# prepare dataset\ndataset = DataResource(\"./\")\ndataset_next_batch, dataset_initializer = dataset.next_batch()\nsess.run(dataset_initializer)           # \u200b\u6bcf\u6b21\u200b\u8fd0\u884c\u200b\u8be5\u200b\u547d\u4ee4\u200b\u4f1a\u200b\u91cd\u65b0\u200b\u751f\u6210\u200bdataset_generator\n                                        # \u200b\u56e0\u6b64\u200b\u53ef\u200b\u91cd\u590d\u200bvalid_dataset_initializer\u200b\u7528\u4e8e\u200b\u6548\u679c\u200b\u9a8c\u8bc1\u200b\nwhile True:\n    try:\n        generated_batch = sess.run(dataset_next_batch)\n    except tf.errors.OutOfRangeError:   # generator\u200b\u904d\u5386\u200b\u5b8c\u6210\u200b\n        saver.save(sess, dump_model_dir, global_step=cur_step)\n</code></pre>"},{"location":"Programing/Python/utils/tokenization.html","title":"Tokenization","text":"<pre><code>import collections\nimport re\nimport unicodedata\nimport six\nimport tensorflow as tf\n\n\ndef convert_to_unicode(text):\n    \"\"\"Converts `text` to Unicode (if it's not already), assuming utf-8 input.\"\"\"\n    if six.PY3:\n        if isinstance(text, str):\n            return text\n        elif isinstance(text, bytes):\n            return text.decode(\"utf-8\", \"ignore\")\n        else:\n            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n    elif six.PY2:\n        if isinstance(text, str):\n            return text.decode(\"utf-8\", \"ignore\")\n        elif isinstance(text, unicode):\n            return text\n        else:\n            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n    else:\n        raise ValueError(\"Not running on Python2 or Python 3?\")\n\n\ndef printable_text(text):\n    \"\"\"Returns text encoded in a way suitable for print or `tf.logging`.\"\"\"\n\n    # These functions want `str` for both Python2 and Python3, but in one case\n    # it's a Unicode string and in the other it's a byte string.\n    if six.PY3:\n        if isinstance(text, str):\n            return text\n        elif isinstance(text, bytes):\n            return text.decode(\"utf-8\", \"ignore\")\n        else:\n            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n    elif six.PY2:\n        if isinstance(text, str):\n            return text\n        elif isinstance(text, unicode):\n            return text.encode(\"utf-8\")\n        else:\n            raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n    else:\n        raise ValueError(\"Not running on Python2 or Python 3?\")\n\n\ndef load_vocab(vocab_file):\n    \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n    vocab = collections.OrderedDict()\n    index = 0\n    with tf.gfile.GFile(vocab_file, \"r\") as reader:\n        while True:\n            token = convert_to_unicode(reader.readline())\n            if not token:\n                break\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n\ndef convert_by_vocab(vocab, items):\n    \"\"\"Converts a sequence of [tokens|ids] using the vocab.\"\"\"\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output\n\n\ndef convert_tokens_to_ids(vocab, tokens):\n    return convert_by_vocab(vocab, tokens)\n\n\ndef convert_ids_to_tokens(inv_vocab, ids):\n    return convert_by_vocab(inv_vocab, ids)\n\n\ndef whitespace_tokenize(text):\n    \"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"\n    text = text.strip()\n    if not text:\n        return []\n    tokens = text.split()\n    return tokens\n\n\ndef _is_control(char):\n    \"\"\"Checks whether `chars` is a control character.\"\"\"\n    # These are technically control characters but we count them as whitespace\n    # characters.\n    if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n        return False\n    cat = unicodedata.category(char)\n    if cat in (\"Cc\", \"Cf\"):\n        return True\n    return False\n\n\ndef _is_punctuation(char):\n    \"\"\"Checks whether `chars` is a punctuation character.\"\"\"\n    cp = ord(char)\n    # We treat all non-letter/number ASCII as punctuation.\n    # Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\n    # Punctuation class but we treat them as punctuation anyways, for\n    # consistency.\n    if ((cp &gt;= 33 and cp &lt;= 47) or (cp &gt;= 58 and cp &lt;= 64) or\n            (cp &gt;= 91 and cp &lt;= 96) or (cp &gt;= 123 and cp &lt;= 126)):\n        return True\n    cat = unicodedata.category(char)\n    if cat.startswith(\"P\"):\n        return True\n    return False\n\n\ndef _is_whitespace(char):\n    \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n    # \\t, \\n, and \\r are technically contorl characters but we treat them\n    # as whitespace since they are generally considered as such.\n    if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n        return True\n    cat = unicodedata.category(char)\n    if cat == \"Zs\":\n        return True\n    return False\n\n\nclass BasicTokenizer(object):\n    \"\"\"\n    Runs basic tokenization\n        - punctuation splitting,\n        - lower casing\n\n    \"\"\"\n\n    def __init__(self, do_lower_case=True, do_strip_accents=True):\n        \"\"\"Constructs a BasicTokenizer.\n        Args:\n          do_lower_case: Whether to lower case the input.\n        \"\"\"\n        self.do_lower_case = do_lower_case\n        self.do_strip_accents = do_strip_accents\n\n    def tokenize(self, text):\n        \"\"\"Tokenizes a piece of text.\"\"\"\n        text = convert_to_unicode(text)\n        text = self._clean_text(text)               # \u200b\u53bb\u9664\u200binvalid\u200b\u5b57\u7b26\u200b\uff0c\u200b\u5f52\u4e00\u5316\u200b\u7a7a\u767d\u200b\u5b57\u7b26\u200b\n\n        text = self._tokenize_chinese_chars(text)   # chinese_char-split\n\n        orig_tokens = whitespace_tokenize(text)     # white_space-split\n        split_tokens = []\n        for token in orig_tokens:                   # punctuation-split\n            if self.do_lower_case:\n                token = token.lower()\n            if self.do_strip_accents:               # \u200b\u53bb\u9664\u200b\u5b57\u7b26\u200b\u4e0a\u4e0b\u200b\u6807\u200b\uff0c\u200b\u5982\u200b \u0120\u2192G\n                token = self._run_strip_accents(token)\n            split_tokens.extend(self._run_split_on_punc(token))\n\n        output_tokens = whitespace_tokenize(\" \".join(split_tokens))\n        return output_tokens\n\n    def _run_strip_accents(self, text):\n        \"\"\"Strips accents from a piece of text.\"\"\"\n        text = unicodedata.normalize(\"NFD\", text)\n        output = []\n        for char in text:\n            cat = unicodedata.category(char)\n            if cat == \"Mn\":\n                continue\n            output.append(char)\n        return \"\".join(output)\n\n    def _run_split_on_punc(self, text):\n        \"\"\"Splits punctuation on a piece of text.\"\"\"\n        chars = list(text)\n        i = 0\n        start_new_word = True\n        output = []\n        while i &lt; len(chars):\n            char = chars[i]\n            if _is_punctuation(char):\n                output.append([char])\n                start_new_word = True\n            else:\n                if start_new_word:\n                    output.append([])\n                start_new_word = False\n                output[-1].append(char)\n            i += 1\n\n        return [\"\".join(x) for x in output]\n\n    def _tokenize_chinese_chars(self, text):\n        \"\"\"Adds whitespace around any CJK character.\"\"\"\n        output = []\n        for char in text:\n            cp = ord(char)\n            if self._is_chinese_char(cp):\n                output.append(\" \")\n                output.append(char)\n                output.append(\" \")\n            else:\n                output.append(char)\n        return \"\".join(output)\n\n    def _is_chinese_char(self, cp):\n        \"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"\n        # This defines a \"chinese character\" as anything in the CJK Unicode block:\n        #   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)\n        #\n        # Note that the CJK Unicode block is NOT all Japanese and Korean characters,\n        # despite its name. The modern Korean Hangul alphabet is a different block,\n        # as is Japanese Hiragana and Katakana. Those alphabets are used to write\n        # space-separated words, so they are not treated specially and handled\n        # like the all of the other languages.\n        if ((cp &gt;= 0x4E00 and cp &lt;= 0x9FFF) or  #\n                (cp &gt;= 0x3400 and cp &lt;= 0x4DBF) or  #\n                (cp &gt;= 0x20000 and cp &lt;= 0x2A6DF) or  #\n                (cp &gt;= 0x2A700 and cp &lt;= 0x2B73F) or  #\n                (cp &gt;= 0x2B740 and cp &lt;= 0x2B81F) or  #\n                (cp &gt;= 0x2B820 and cp &lt;= 0x2CEAF) or\n                (cp &gt;= 0xF900 and cp &lt;= 0xFAFF) or  #\n                (cp &gt;= 0x2F800 and cp &lt;= 0x2FA1F)):  #\n            return True\n\n        return False\n\n    def _clean_text(self, text):\n        \"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n        output = []\n        for char in text:\n            cp = ord(char)\n            if cp == 0 or cp == 0xfffd or _is_control(char):\n                continue\n            if _is_whitespace(char):\n                output.append(\" \")\n            else:\n                output.append(char)\n        return \"\".join(output)\n\n\nclass WordpieceTokenizer(object):\n    \"\"\"Runs WordPiece tokenziation.\"\"\"\n\n    def __init__(self, vocab, unk_token=\"[UNK]\", max_input_chars_per_word=200, remain_oov_part=False, uni_unk=False):\n        self.vocab = vocab\n        self.unk_token = unk_token\n        self.max_input_chars_per_word = max_input_chars_per_word\n        self.remain_oov_part = remain_oov_part          # \u200b\u5047\u8bbe\u200b\u0120\u200b\u4e3a\u200boov: l\u0120c \u2192 l, [UNK], ##c \u200b\u800c\u200b\u4e0d\u662f\u200b\u6574\u4f53\u200b [UNK]\n        self.uni_unk = uni_unk                          # \u200b\u5c06\u200b\u591a\u4e2a\u200b[UNK]\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u4e00\u4e2a\u200b[UNK]\uff0c\u200b\u4ec5\u5f53\u200bremain_oov_part\u200b\u6210\u7acb\u200b\u65f6\u200b\u751f\u6548\u200b\n\n    def tokenize(self, text):\n        \"\"\"Tokenizes a piece of text into its word pieces.\n\n        This uses a greedy longest-match-first algorithm to perform tokenization\n        using the given vocabulary.\n\n        For example:\n          input = \"unaffable\"\n          output = [\"un\", \"##aff\", \"##able\"]\n\n        Args:\n          text: A single token or whitespace separated tokens. This should have\n            already been passed through `BasicTokenizer.\n\n        Returns:\n          A list of wordpiece tokens.\n        \"\"\"\n\n        text = convert_to_unicode(text)\n\n        output_tokens = []\n        for token in whitespace_tokenize(text):\n            chars = list(token)\n            if len(chars) &gt; self.max_input_chars_per_word:\n                output_tokens.append(self.unk_token)\n                continue\n\n            is_bad = False\n            start = 0\n            sub_tokens = []\n            while start &lt; len(chars):\n                end = len(chars)\n                cur_substr = None\n                # \u200b\u8d2a\u5fc3\u200b\u7b97\u6cd5\u200b\u5206\u8bcd\u200b\n                while start &lt; end:\n                    substr = \"\".join(chars[start:end])\n                    if start &gt; 0:\n                        substr = \"##\" + substr\n                    if substr in self.vocab:\n                        cur_substr = substr\n                        break\n                    end -= 1\n                if cur_substr is None:\n                    if self.remain_oov_part:\n                        # uni_unk\n                        if self.uni_unk:\n                            if len(sub_tokens) == 0 or sub_tokens[-1] != self.unk_token:\n                                sub_tokens.append(self.unk_token)\n                        else:\n                            sub_tokens.append(self.unk_token)\n                        start += 1\n                    else:\n                        is_bad = True\n                        break\n                else:\n                    sub_tokens.append(cur_substr)\n                    start = end\n\n            if is_bad:\n                output_tokens.append(self.unk_token)\n            else:\n                output_tokens.extend(sub_tokens)\n        return output_tokens\n\n\nclass FullTokenizer(object):\n    \"\"\"Runs end-to-end tokenziation.\"\"\"\n\n    def __init__(self,\n                 vocab_file, do_lower_case=True, do_strip_accents=True,\n                 unk_token=\"[UNK]\", max_input_chars_per_word=200, remain_oov_part=False, uni_unk=False):\n        self.vocab = load_vocab(vocab_file)\n        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n        self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case,\n                                              do_strip_accents=do_strip_accents)\n        self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab,\n                                                      unk_token=unk_token,\n                                                      max_input_chars_per_word=max_input_chars_per_word,\n                                                      remain_oov_part=remain_oov_part,\n                                                      uni_unk=uni_unk)\n\n    def tokenize(self, text):\n        split_tokens = []\n        for token in self.basic_tokenizer.tokenize(text):\n            for sub_token in self.wordpiece_tokenizer.tokenize(token):\n                split_tokens.append(sub_token)\n\n        return split_tokens\n\n    def convert_tokens_to_ids(self, tokens):\n        return convert_by_vocab(self.vocab, tokens)\n\n    def convert_ids_to_tokens(self, ids):\n        return convert_by_vocab(self.inv_vocab, ids)\n\n\nclass BPETokenizer(object):\n    def __init__(\n            self,\n            ):\n        \"\"\"Initialize BPE tokenizer.\"\"\"\n        self.vocab = {}\n        self.inv_vocab = {}\n        self.merges = {}\n        self.special_tokens = {}\n        # \u200b\u5bf9\u200b\u8f93\u5165\u200b\u6587\u672c\u200b\u8fdb\u884c\u200b\u5212\u5206\u200b\n        # 1. `'(?!:[sdmt]|ll|ve|re)`  \u2192  \u200b\u5339\u914d\u200b\u8fde\u5199\u200b, 's, 'd, 'm, 't, 'll, 've \u200b\u4ee5\u53ca\u200b 're\n        # 2. ` ?\\p{L}+`  \u2192  \u200b\u6309\u200b\u8bed\u8a00\u200b\u5b57\u6bcd\u200b\u5339\u914d\u200b\uff0c\u200b\u5982\u200b \"hello\u200b\u4f60\u597d\u200b\"\u200b\u5339\u914d\u200b\u7ed3\u679c\u200b\u4e3a\u200b [\"hello\", \"\u200b\u4f60\u597d\u200b\"]\n        # 3. ` ?\\p{N}+`  \u2192  \n        self.pattern = re.compile(r\"\"\"'(?i:[sdmt]|ll|ve|re)|[^\\r\\n\\p{L}\\p{N}]?+\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*|\\s*[\\r\\n]|\\s+(?!\\S)|\\s+\"\"\")\n\n    def apply_merge(self, element_list):\n        # \u200b\u6267\u884c\u200b\u5408\u5e76\u200b\u7b56\u7565\u200b\uff0c\u200b\u4e00\u76f4\u200b\u8fed\u4ee3\u200b\u81f3\u200b\u6ca1\u6709\u200b\u5f85\u200b\u5408\u5e76\u200b\u7684\u200b subword-pair\n        # char-level, element_list = list(input_str)\n        # byte-level, element_list = list(map(chr, input_str(encoding=\"utf-8\")))\n        pass\n\n    def convert_tokens_to_ids(self, tokens):\n        return convert_by_vocab(self.vocab, tokens)\n\n    def convert_ids_to_tokens(self, ids):\n        return convert_by_vocab(self.inv_vocab, ids)\n</code></pre>"},{"location":"Programing/Python/utils/torch_dataset_utils.html","title":"Torch dataset utils","text":"<pre><code>from torch.utils.data import Dataset\nimport os\nfrom tqdm import tqdm\nfrom wheel_utils.general_dataset_utils import *\n\n\nclass MyDataset(Dataset):\n    def __init__(\n            self,\n            data_file,\n            trie=None,\n            t2s=None,\n            case_sensitive=False\n    ):\n        self.trie = trie\n        self.t2s = t2s\n        self.case_sensitive = case_sensitive\n        self.data, self.labels = self._read_data_file(data_file)\n\n    def _read_data_file(self, data_file):\n        base_name = os.path.basename(data_file)\n        data, labels = [], []\n        with open(data_file, 'r', encoding='utf-8') as f:\n            for line in tqdm(f, desc=f\"parsing {base_name}\"):\n                try:\n                    line = json.loads(line)\n                except:\n                    print(json.dumps(line, ensure_ascii=False))\n                    raise ValueError\n\n                line = pre_process_content(line, self.trie, self.t2s, self.case_sensitive)\n                label = uni_label(line.get(\"label\", \"0\"))\n                data.append(line[\"content\"])\n                labels.append(label)\n\n        print(f\"{base_name} has {len(data)} samples\")\n        return data, labels\n\n    def __len__(self):              # \u200b\u91cd\u5199\u200b__len__\u200b\u9b54\u6cd5\u200b\u65b9\u6cd5\u200b\n        return len(self.data)\n\n    def __getitem__(self, idx):     # \u200b\u91cd\u5199\u200b__item__\u200b\u6570\u636e\u200b\u8bbf\u5b58\u200b\u65b9\u6cd5\u200b\n        return self.data[idx], self.labels[idx]\n</code></pre>"},{"location":"Programing/Python/utils/torch_dataset_utils.html#dataloader","title":"DataLoader","text":"<pre><code>from torch.utils.data import DataLoader\n</code></pre>"},{"location":"Programing/Python/utils/torch_dataset_utils.html#datasets","title":"datasets","text":"<pre><code>from datasets import load_dataset\n</code></pre>"},{"location":"Programing/SQL/index.html","title":"SQL","text":""},{"location":"Programing/Shell/Bash/index.html","title":"Bash","text":""},{"location":"Programing/Shell/Bash/index.html#_1","title":"\u6587\u4ef6\u200b\u64cd\u4f5c","text":""},{"location":"Programing/Shell/Bash/index.html#_2","title":"\u6587\u4ef6\u200b\u4fe1\u606f\u200b\u67e5\u770b","text":"<ul> <li>\u200b\u4fe1\u606f\u200b\u67e5\u770b\u200b\uff1a<code>ls</code></li> <li>\u200b\u5185\u5bb9\u200b\u7edf\u8ba1\u200b\uff1a<code>wc</code></li> </ul>"},{"location":"Programing/Shell/Bash/index.html#_3","title":"\u6587\u4ef6\u200b\u5185\u5bb9\u200b\u67e5\u770b","text":"<ul> <li>\u200b\u539f\u59cb\u200b\u6587\u672c\u200b\uff1a<code>less/more</code>\u3001<code>head/tail</code> tail -f </li> <li>\u200b\u6761\u4ef6\u200b\u9009\u62e9\u200b\uff1a<code>awk</code></li> <li>\u200b\u5185\u5bb9\u200b\u8fc7\u6ee4\u200b\uff1a<code>grep</code></li> <li>\u200b\u5185\u5bb9\u200b\u6bd4\u8f83\u200b\uff1a<code>diff</code></li> </ul>"},{"location":"Programing/Shell/Bash/index.html#_4","title":"\u6570\u636e\u683c\u5f0f\u200b\u5904\u7406","text":"<ul> <li>json\uff1a<code>jq</code></li> <li>xlsx\uff1a<code>xlsx2csv</code></li> </ul>"},{"location":"Programing/Shell/Bash/index.html#_5","title":"\u6587\u4ef6\u200b\u4fee\u6539","text":"<ul> <li>\u200b\u4fe1\u606f\u200b\u4fee\u6539\u200b\uff1a<code>mv</code>\u3001<code>cp</code>\u3001<code>rm</code>\u3001<code>mkdir</code></li> <li>\u200b\u5185\u5bb9\u200b\u8fde\u63a5\u200b\uff1a<code>cat</code> (\u200b\u6587\u4ef6\u200b\u672b\u200b\u65e0\u200b\\n\u200b\u4f1a\u200b\u540c\u884c\u200b\u8fde\u63a5\u200b)</li> <li>\u200b\u5185\u5bb9\u200b\u5408\u5e76\u200b\uff1a<code>join</code>\u3001<code>paste</code></li> <li>\u200b\u5185\u5bb9\u200b\u5206\u5272\u200b\uff1a<code>cut</code></li> <li>\u200b\u5185\u5bb9\u200b\u62c6\u5206\u200b\uff1a<code>split</code></li> <li>\u200b\u5185\u5bb9\u200b\u53bb\u200b\u91cd\u200b\uff1a<code>sort</code> + <code>uniq</code></li> <li>\u200b\u5185\u5bb9\u200b\u66ff\u6362\u200b\uff1a<code>tr</code>\u3001<code>sed</code></li> <li>\u200b\u5185\u5bb9\u200b\u6270\u52a8\u200b\uff1a<code>shuf</code></li> <li>\u200b\u6587\u4ef6\u4f20\u8f93\u200b\uff1a<code>nc</code></li> <li>\u200b\u8f93\u5165\u8f93\u51fa\u200b\u91cd\u5b9a\u5411\u200b\uff1a<code>&lt;</code>\u3001<code>&gt;(&gt;)</code></li> </ul>"},{"location":"Programing/Shell/Bash/index.html#_6","title":"\u6570\u503c\u200b\u64cd\u4f5c","text":"<ul> <li>format\u200b\u8f93\u51fa\u200b\uff1a<code>printf</code></li> </ul>"},{"location":"Programing/Shell/Bash/index.html#_7","title":"\u8f6f\u4ef6\u200b\u5b89\u88c5","text":""},{"location":"Programing/Shell/Bash/index.html#_8","title":"\u4e0b\u8f7d\u5de5\u5177","text":"<ul> <li><code>rpm</code>\u3001<code>yum</code>\u3001<code>apt</code></li> </ul>"},{"location":"Programing/Shell/Bash/index.html#_9","title":"\u8fdb\u7a0b\u200b\u76f8\u5173","text":"<ul> <li>\u200b\u67e5\u770b\u200b\u8fdb\u7a0b\u200b: <code>top</code>\u3001<code>ps</code></li> <li>\u200b\u7ec8\u6b62\u200b\u8fdb\u7a0b\u200b: <code>kill</code></li> <li>watch -n 1</li> </ul>"},{"location":"Programing/Shell/Bash/index.html#_10","title":"\u8fdb\u7a0b\u200b\u8c03\u5ea6","text":"<ul> <li>\u200b\u591a\u7ebf\u7a0b\u200b\uff1a\u200b\u5e76\u53d1\u200b\u3001\u200b\u5e76\u884c\u200b</li> </ul>"},{"location":"Programing/Shell/Bash/index.html#_11","title":"\u8fdc\u7a0b\u200b\u64cd\u4f5c","text":"<ul> <li><code>curl</code></li> </ul>"},{"location":"Programing/Shell/Bash/file_related/awk.html","title":"Awk","text":"<p><code>awk</code>\uff1a\u200b\u5176\u200b\u540d\u79f0\u200b\u5f97\u200b\u81ea\u4e8e\u200b\u5b83\u200b\u7684\u200b\u521b\u59cb\u4eba\u200b\u963f\u5c14\u4f5b\u200b\u96f7\u5fb7\u200b\u00b7\u200b\u827e\u4faf\u200b\u3001\u200b\u5f7c\u5f97\u200b\u00b7\u200b\u6e29\u4f2f\u683c\u200b\u548c\u200b\u5e03\u83b1\u6069\u200b\u00b7\u200b\u67ef\u6797\u200b\u6c49\u200b\u59d3\u6c0f\u200b\u7684\u200b\u9996\u4e2a\u200b\u5b57\u6bcd\u200b</p>"},{"location":"Programing/Shell/Bash/file_related/awk.html#_1","title":"\u8bed\u6cd5\u200b\u683c\u5f0f","text":"<p><code>awk [options] '\u200b\u6761\u4ef6\u200b {\u200b\u52a8\u4f5c\u200b} \u200b\u6761\u4ef6\u200b {\u200b\u52a8\u4f5c\u200b} ...' file_1 file_2 ...</code></p> <p><code>\u200b\u6761\u4ef6\u200b {\u200b\u52a8\u4f5c\u200b}</code> \u200b\u90e8\u5206\u200b\u662f\u200b\u5b57\u7b26\u4e32\u200b\uff0c\u200b\u5176\u200b\u5185\u5bb9\u200b\u65e0\u200b\u8f6c\u4e49\u5b57\u7b26\u200b<code>$0\u3001$n</code>\u200b\u65f6\u200b\u5355\u5f15\u53f7\u200b\u53ef\u4ee5\u200b\u7528\u200b\u53cc\u5f15\u53f7\u200b\u6765\u200b\u8fdb\u884c\u200b\u5f62\u53c2\u200b\u66ff\u6362\u200b</p>"},{"location":"Programing/Shell/Bash/file_related/awk.html#_2","title":"\u53d8\u91cf","text":""},{"location":"Programing/Shell/Bash/file_related/awk.html#_3","title":"\u5185\u7f6e\u200b\u53d8\u91cf","text":"\u53d8\u91cf\u540d\u200b \u200b\u63cf\u8ff0\u200b <code>FILENAME</code> \u200b\u5f53\u524d\u200b\u8f93\u5165\u200b\u6587\u6863\u200b\u7684\u200b\u540d\u79f0\u200b <code>FNR</code> File Number of the Current Record\uff0c\u200b\u5f53\u524d\u200b\u8f93\u5165\u200b\u6587\u6863\u200b\u7684\u200b\u5f53\u524d\u200b\u884c\u53f7\u200b\uff0c\u200b\u5f53\u6709\u200b\u591a\u4e2a\u200b\u8f93\u5165\u200b\u6587\u6863\u200b\u65f6\u200b\uff0c<code>FNR</code>\u200b\u7684\u200b\u503c\u4f1a\u200b\u4ece\u200b1\u200b\u91cd\u65b0\u200b\u5f00\u59cb\u200b <code>NR</code> Number of the Current Record\uff0c\u200b\u8f93\u5165\u200b\u6570\u636e\u6d41\u200b\u7684\u200b\u5f53\u524d\u200b\u884c\u53f7\u200b\uff0c\u200b\u5f53\u6709\u200b\u591a\u4e2a\u200b\u8f93\u5165\u200b\u6587\u6863\u200b\u65f6\u4f1a\u200b\u6301\u7eed\u200b\u8ba1\u6570\u200b\uff0c\u200b\u4e0d\u200b\u4ece\u200b1\u200b\u5f00\u59cb\u200b <code>$0</code> \u200b\u5f53\u524d\u200b\u884c\u200b\u7684\u200b\u5168\u90e8\u200b\u6570\u636e\u200b\u5185\u5bb9\u200b\uff0c\u200b\u9700\u7528\u200b\u5355\u5f15\u53f7\u200b\u8868\u793a\u200b\u4ee5\u200b\u9632\u6b62\u200b\u8f6c\u4e49\u200b\uff0c<code>'{print $0}'</code> <code>$n...</code> \u200b\u5f53\u524d\u200b\u884c\u200b\u7684\u200b\u7b2c\u200b\\(n\\)\u200b\u4e2a\u200b\u5b57\u200b\u6bb5\u200b\u7684\u200b\u5185\u5bb9\u200b(\\(n\\ge 1\\))\uff0c\uff0c\u200b\u9700\u7528\u200b\u5355\u5f15\u53f7\u200b\u8868\u793a\u200b\u4ee5\u200b\u9632\u6b62\u200b\u8f6c\u4e49\u200b\uff0c<code>'{print $1\uff0c $2, $3}'</code> <code>NF</code> Number of Fileds\uff0c\u200b\u5f53\u524d\u200b\u8bb0\u5f55\u200b\uff08\u200b\u884c\u200b\uff09\u200b\u7684\u200b\u5b57\u200b\u6bb5\u200b\uff08\u200b\u5217\u200b\uff09\u200b\u4e2a\u6570\u200b <code>FS</code> Field Separator\uff0c\u200b\u5b57\u200b\u6bb5\u200b\u5206\u9694\u7b26\u200b\uff0c\u200b\u9ed8\u8ba4\u200b\u4e3a\u200b\u7a7a\u683c\u200b\u6216\u8005\u200bTab\u200b\u5236\u8868\u7b26\u200b <code>OFS</code> Output Field Separator\uff0c\u200b\u8f93\u51fa\u200b\u5b57\u200b\u6bb5\u200b\uff08\u200b\u5217\u200b\uff09\u200b\u5206\u9694\u7b26\u200b\uff0c\u200b\u9ed8\u8ba4\u200b\u4e3a\u200b\u7a7a\u683c\u200b <code>ORS</code> Output Record Separator\uff0c\u200b\u8f93\u51fa\u200b\u8bb0\u5f55\u200b\uff08\u200b\u884c\u200b\uff09\u200b\u5206\u9694\u7b26\u200b\uff0c\u200b\u9ed8\u8ba4\u200b\u4e3a\u200b\u6362\u884c\u7b26\u200b\\n <code>RS</code> Record Separator\uff0c\u200b\u8bbe\u7f6e\u200b\u8bb0\u5f55\u200b\uff08\u200b\u884c\u200b\uff09\u200b\u5206\u9694\u7b26\u200b\uff0c\u200b\u9ed8\u8ba4\u200b\u4e3a\u200b\u6362\u884c\u7b26\u200b\\n <ul> <li>\u200b\u8bb0\u5f55\u200bRecord\u200b\u8868\u793a\u200b\u884c\u200b\uff0c\u200b\u5b57\u200b\u6bb5\u200bField\u200b\u8868\u793a\u200b\u5217\u200b\uff0cField\u200b\u4e4b\u95f4\u200b\u7528\u200b<code>FS</code>\u200b\u5206\u9694\u200b\uff0cRecord\u200b\u4e4b\u95f4\u200b\u7528\u200b<code>RS</code>\u200b\u5206\u9694\u200b  </li> <li>NR\u200b\u5c06\u200b\u6240\u6709\u200b\u6587\u4ef6\u200b\u89c6\u4f5c\u200b\u4e00\u4e2a\u200b\u6570\u636e\u6d41\u200b\uff0cNFR\u200b\u5c06\u200b\u5404\u4e2a\u200b\u6587\u4ef6\u200b\u5206\u522b\u200b\u89c6\u4f5c\u200b\u4e00\u4e2a\u200b\u6570\u636e\u6d41\u200b</li> </ul>"},{"location":"Programing/Shell/Bash/file_related/awk.html#_4","title":"\u81ea\u5b9a\u4e49\u200b\u53d8\u91cf","text":""},{"location":"Programing/Shell/Bash/file_related/awk.html#awk","title":"\u5e38\u7528\u200bawk\u200b\u547d\u4ee4","text":"<pre><code>awk \"NR==6\" file_name               # \u200b\u663e\u793a\u200b\u7b2c\u200b6\u200b\u884c\u200b\u5185\u5bb9\u200b\nawk \u201cNR&lt;=6\u201d file_name               # \u200b\u663e\u793a\u200b\u524d\u200b6\u200b\u884c\u200b\u5185\u5bb9\u200b\nawk \"NR&gt;4 &amp;&amp; NR&lt;11\" file_name       # \u200b\u663e\u793a\u200b5-10\u200b\u884c\u200b\nawk \"NR%2==0\" file_name             # \u200b\u663e\u793a\u200b\u5947\u6570\u200b\u884c\u200b\n\nawk -F ' '  '{print $1}' file_name  # \u200b\u663e\u793a\u200b\u7531\u200b ' ' \u200b\u5206\u5272\u200b\u7684\u200b\u7b2c\u4e00\u9879\u200b\uff08\u200b\u9879\u200b\u4e0b\u6807\u200b\u7531\u200b1\u200b\u5f00\u59cb\u200b\uff09\n                                    # -F ' '\u200b\u53ef\u200b\u7b80\u5199\u200b\u4e3a\u200b -F' '\nawk '$1 &gt; .5 {count++} END {print count}' file_name\n                                    # \u200b\u7edf\u8ba1\u200b\u6570\u503c\u200b\u884c\u200b\u5927\u4e8e\u200b0.5\u200b\u7684\u200b\u884c\u6570\u200b\n</code></pre>"},{"location":"Programing/Shell/Bash/file_related/diff.html","title":"Diff","text":""},{"location":"Programing/Shell/Bash/file_related/diff.html#_1","title":"\u547d\u4ee4\u200b\u683c\u5f0f","text":"<p><code>diff [option] ... file1 file2</code></p> <p>\u200b\u53c2\u6570\u200boption</p> <ul> <li><code>-s</code>\uff1a\u200b\u53ea\u200b\u663e\u793a\u200b\u5dee\u5f02\u200b\u7684\u200b\u884c\u200b</li> <li><code>-c</code>\uff1a\u200b\u4ee5\u200b\u6613\u4e8e\u200b\u9605\u8bfb\u200b\u4f46\u200b\u8f83\u200b\u957f\u200b\u7684\u200b\u683c\u5f0f\u200b\u8f93\u51fa\u200b\uff0c\u200b\u9ed8\u8ba4\u200b\u663e\u793a\u200b\u5dee\u5f02\u200b\u4e0a\u4e0b\u6587\u200b2\u200b\u884c\u200b</li> <li><code>-u</code>\uff1a\u200b\u548c\u200b<code>-c</code>\u200b\u5dee\u4e0d\u591a\u200b</li> <li><code>-y</code>\uff1a\u200b\u5e76\u6392\u200b\u683c\u5f0f\u200b\u8f93\u51fa\u200b\u4e24\u200b\u6587\u4ef6\u200b\u5bf9\u6bd4\u200b\u7ed3\u679c\u200b</li> </ul>"},{"location":"Programing/Shell/Bash/file_related/grep.html","title":"Grep","text":"<p>grep (global search regular expression and print out the line)\uff0c\u200b\u5229\u7528\u200b\u6b63\u5219\u8868\u8fbe\u5f0f\u200b\u5168\u5c40\u200b\u641c\u7d22\u200b\u5e76\u6253\u5370\u200b\u76ee\u6807\u200b\u884c\u200b</p>"},{"location":"Programing/Shell/Bash/file_related/grep.html#grep","title":"<code>grep</code>","text":""},{"location":"Programing/Shell/Bash/file_related/grep.html#options","title":"options","text":"<ul> <li><code>--color</code> \u200b\u5f69\u8272\u200b\u7740\u91cd\u200b\u663e\u793a\u200b\u5339\u914d\u200b\u90e8\u5206\u200b</li> <li><code>-i</code> \u200b\u6b63\u5219\u200b\u5339\u914d\u200b\u5ffd\u7565\u200b\u5927\u5c0f\u5199\u200b</li> <li><code>-v</code> \u200b\u6761\u4ef6\u200b\u53d6\u53cd\u200b</li> </ul>"},{"location":"Programing/Shell/Bash/file_related/grep.html#_1","title":"\u591a\u200b\u6761\u4ef6","text":"<ol> <li>or <pre><code># \u200b\u641c\u7d22\u200b\u5305\u542b\u200b\u5173\u952e\u5b57\u200b \u3010'apple'\u3011 \u200b\u6216\u200b \u3010\u200b\u4ee5\u200b\u5173\u952e\u5b57\u200b'banana'\u200b\u7ed3\u5c3e\u200b\u3011 \u200b\u7684\u200b\u884c\u200b\ngrep 'apple\\|banana$'\ngrep -e 'apple' -e 'banana$'\n</code></pre></li> <li>and <pre><code># \u200b\u641c\u7d22\u200b\u5305\u542b\u200b\u5173\u952e\u5b57\u200b \u3010'apple'\u3011 \u200b\u4e14\u200b \u3010\u200b\u4ee5\u200b\u5173\u952e\u5b57\u200b'banana'\u200b\u7ed3\u5c3e\u200b\u3011 \u200b\u7684\u200b\u884c\u200b\ngrep 'apple' | grep 'banana$'\n</code></pre></li> <li>not <pre><code># \u200b\u641c\u7d22\u200b\u4e0d\u200b\u5305\u542b\u200b\u5173\u952e\u5b57\u200b \u3010'apple'\u3011 \u200b\u7684\u200b\u884c\u200b\ngrep -v 'apple'\n</code></pre></li> </ol>"},{"location":"Programing/Shell/Bash/file_related/grep.html#egrep","title":"<code>egrep</code>","text":""},{"location":"Programing/Shell/Bash/file_related/grep.html#fgrep","title":"<code>fgrep</code>","text":""},{"location":"Programing/Shell/Bash/file_related/jq.html","title":"Jq","text":"<p>jq\uff1acommadline JSON processor</p>"},{"location":"Programing/Shell/Bash/file_related/jq.html#_1","title":"\u5b89\u88c5","text":""},{"location":"Programing/Shell/Bash/file_related/jq.html#windows","title":"windows","text":"<ol> <li>\u200b\u4e0b\u8f7d\u200b\u7f51\u5740\u200b\uff1a{AMD64: 64\u200b\u4f4d\u200b; i386: 32\u200b\u4f4d\u200b}</li> <li><code>~/.bash_profile</code> \u200b\u4e2d\u200b\u8bbe\u7f6e\u200b <code>alias jq=jqexe_absoulte_path'</code></li> <li>\u200b\u52a0\u8f7d\u200b\u914d\u7f6e\u200b <code>source ~/.bash_profile</code></li> </ol>"},{"location":"Programing/Shell/Bash/file_related/jq.html#_2","title":"\u4f7f\u7528\u200b\u65b9\u6cd5","text":"<p><code>jq [options] filter [file]</code></p>"},{"location":"Programing/Shell/Bash/file_related/jq.html#options","title":"<code>options</code> \u200b\u9009\u9879","text":"<ul> <li><code>-c/--compact-output</code>\uff1a\u200b\u7d27\u51d1\u200b\u8f93\u51fa\u200b\uff0c\u200b\u5373\u200b\u628a\u200b\u4e00\u4e2a\u200bJSON\u200b\u5bf9\u8c61\u200b\u8f93\u51fa\u200b\u5728\u200b\u4e00\u884c\u200b <p>\u200b\u901a\u8fc7\u200b\u7d27\u51d1\u200b\u8f93\u51fa\u200b\u5904\u7406\u200b\u7684\u200b\u884c\u4e2d\u200b\uff0c\u200b\u53d6\u6d88\u200b\u4e86\u200b\u952e\u200b\u4e0e\u200b\u503c\u200b\u4e4b\u95f4\u200b\u7684\u200b\u7a7a\u683c\u200b\uff0c\u200b\u5373\u200b <code>\"key\":\"value\"</code></p> </li> </ul>"},{"location":"Programing/Shell/Bash/file_related/jq.html#filter","title":"<code>filter</code> \u200b\u8fc7\u6ee4\u5668","text":"<ul> <li><code>keys</code>\uff1a\u200b\u83b7\u53d6\u200b\u5f53\u524d\u200b\u5bf9\u8c61\u200b\u7684\u200b\u952e\u200b</li> <li><code>.</code>\uff1a\u200b\u83b7\u53d6\u200b\u5f53\u524d\u200b\u5bf9\u8c61\u200b</li> <li><code>[]</code>\uff1a\u200b\u83b7\u53d6\u200b\u6574\u4e2a\u200b\u6570\u7ec4\u200b\uff0c\u200b\u652f\u6301\u200b\u5207\u7247\u200b</li> <li><code>select(condition)</code>\uff1a\u200b\u8fc7\u6ee4\u200b\u6761\u4ef6\u200b</li> </ul>"},{"location":"Programing/Shell/Bash/file_related/jq.html#filter_1","title":"<code>filter</code> \u200b\u5b9e\u7528\u200b\u547d\u4ee4","text":"<ol> <li> <p>\u200b\u952e\u503c\u200b\u9009\u53d6\u200b\u3001\u200b\u7ec4\u5408\u200b </p><pre><code># {\"c\", \"xxx\u201d, \"logits\": [xxx, ...], \"prob\": [xxx, xxx]}\n\n# \u200b\u6570\u636e\u200b\u8bbf\u95ee\u200b\njq -c .prob | jq .[]                    # \u200b\u9010\u5c42\u200b\u64cd\u4f5c\u200b\uff0c\u200b\u83b7\u53d6\u200blist: [prob_1, ..., prob_n]\njq -c .prob[]                           # \u200b\u76f4\u63a5\u200b\u89e3\u6790\u200b\uff0c\u200b\u83b7\u53d6\u200bn\u200b\u884c\u200bprob\n\n# \u200b\u6570\u503c\u200b\u4fee\u6539\u200b\njq -c '.name=\"luo\"'                     # \u200b\u5c06\u952e\u200bname\u200b\u7684\u200b\u503c\u200b\u4fee\u6539\u200b\u4e3a\u200b \"luo\"\njq -c '.name=.name+\"luo\"'               # \u200b\u5c06\u952e\u200bname\u200b\u7684\u200b\u503c\u200b\u5728\u200b\u7ed3\u5c3e\u200b\u65b0\u589e\u200b \"luo\"\n\n\n# \u200b\u6570\u636e\u200b\u91cd\u7ec4\u200b\njq -c '[.a, .b]'\njq -c '{\"content\": .c}'\n</code></pre><p></p> </li> <li> <p>\u200b\u6570\u503c\u200b\u9009\u62e9\u200b </p><pre><code>jq -c select(.prob[2] &gt; 0.5)             # \u200b\u9009\u62e9\u200b\u6982\u7387\u200b\u5927\u4e8e\u200b0.5\u200b\u7684\u200b\u884c\u200b\njq -c 'select(.c | tostring | length &gt; 10)'\n                                         # \u200b\u5c06\u200b\u6570\u5b57\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u5b57\u7b26\u4e32\u200b\u5f62\u5f0f\u200b\u518d\u200b\u6bd4\u8f83\u200b\n</code></pre><p></p> </li> <li> <p>\u200b\u5b57\u7b26\u200b\u64cd\u4f5c\u200b </p><pre><code># \u200b\u5b57\u7b26\u4e32\u200b\u5339\u914d\u200b\njq -c 'select(.c == \"lxc\")'                 # \u200b\u5b8c\u5168\u200b\u5339\u914d\u200b\njq -c 'select(.c | contains(\"lxc\"))'        # \u200b\u5305\u542b\u200b\u5b50\u4e32\u200b\njq -c 'select(.c | contains(\"lxc\") | not)'  # \u200b\u4e0d\u200b\u5305\u542b\u200b\u5b50\u4e32\u200b\n\njq -c 'select(.c | length &gt; 200)'        # \u200b\u9009\u62e9\u200b\u6570\u636e\u200b\u4e2d\u5b57\u6bb5\u200bc\u200b\u957f\u5ea6\u200b\u5927\u4e8e\u200b200\u200b\u7684\u200b\u884c\u200b\njq -c '.c | select(length &gt; 200)'        # \u200b\u9009\u62e9\u200b\u5b57\u200b\u6bb5\u200bc\u200b\u957f\u5ea6\u200b\u5927\u4e8e\u200b200\u200b\u7684\u200b\u5b57\u200b\u6bb5\u200b\njq -c 'select(.c | length &gt; 200) | .c'   # \u200b\u7b49\u4ef7\u200b\u4e8e\u200b\u2191\njq -c 'select(.c | tonumber &gt; 100)'      # \u200b\u5c06\u200b\u5b57\u7b26\u4e32\u200b\u8f6c\u5316\u200b\u4e3a\u200b\u6570\u5b57\u200b\u5f62\u5f0f\u200b\u518d\u200b\u6bd4\u8f83\u200b\uff08\u200b\u8981\u6c42\u200b\u80fd\u591f\u200b\u8868\u793a\u200b\u4e3a\u200b\u6570\u5b57\u200b\uff09\n</code></pre><p></p> </li> <li> <p>\u200b\u4e0e\u200b\u5176\u5b83\u200b\u547d\u4ee4\u200b\u7ec4\u5408\u200b\u64cd\u4f5c\u200b </p><pre><code># \u200b\u901a\u8fc7\u200b`paste`\u200b\u548c\u200b`awk`\u200b\u547d\u4ee4\u200b\u5c06\u200b raw_content \u200b\u4e0e\u200b prob \u200b\u7ed3\u679c\u200b\u5408\u5e76\u200b\u4e3a\u200b\u4e00\u4e2a\u200b\u6570\u7ec4\u200b\n# + \u200b\u8fc7\u6ee4\u200b\u76f8\u5e94\u200b\u6807\u7b7e\u200b\u6982\u7387\u200b\u5927\u4e8e\u200b0.5\u200b\u7684\u200b\u884c\u200b\n# + \u200b\u6700\u7ec8\u200bJSON\u200b\u5bf9\u8c61\u200b\u5355\u884c\u200b\u8f93\u51fa\u200b\npaste test1.txt result1.txt | awk -F '\\t' '{print \"[\" $1 \", \"$2 \"]\" }' | jq -c 'select(.[1].prob[1] &gt; 0.5)'\n\n# \u200b\u591a\u200b\u6761\u4ef6\u200b\u8fc7\u6ee4\u200b and/or\njq -c 'select((.s | tonumber &gt; 0.92) and (.c | length &gt; 10))'\n\n\n# unique_by(.file_name) \u200b\u9002\u7528\u200b\u4e8e\u200b\u5355\u4e2a\u200bjson list\u200b\u7684\u200b\u5173\u952e\u5b57\u200b\u53bb\u200b\u91cd\u200b\n# \u200b\u53bb\u200b\u91cd\u200b + \u200b\u5e76\u200b\u9009\u62e9\u200b\u5185\u5bb9\u200b\u957f\u5ea6\u200b\u5904\u4e8e\u200b (0, 200] \u200b\u533a\u95f4\u200b\u7684\u200b\u6837\u672c\u200b\njq -c 'unique_by(.c) | .[] | select(.c | lenght &gt; 0 and length &lt;= 200)'\n\n# \u200b\u5bf9\u200b\u952e\u503c\u200bc\u200b\u53bb\u200b\u91cd\u200b\nsed -e '1i[' -e '2,$i ,' -e '$a]' | jq -c 'unique_by(.c) | .[]'\n</code></pre><p></p> </li> <li> <p>tostring</p> </li> <li>tonumber</li> </ol>"},{"location":"Programing/Shell/Bash/file_related/nc.html","title":"Nc","text":"<p>Netcat</p> <pre><code># \u200b\u63a5\u6536\u200b\nnc -q 10 -lp 5678 | tar x\n\n# \u200b\u4f20\u8f93\u200b\nip addr  # \u200b\u67e5\u770b\u200b\u63a5\u6536\u200b\u65b9\u200bip address\ntar c &lt;sended_file_name&gt; | nc -q 10 &lt;receiver_ip_address&gt; 5678\n</code></pre>"},{"location":"Programing/Shell/Bash/file_related/redirection.html","title":"Redirection","text":""},{"location":"Programing/Shell/Bash/file_related/redirection.html#input","title":"input","text":"<ol> <li> <p><code>&lt; log</code> \u200b\u91cd\u5b9a\u5411\u200b\u8f93\u5165\u200b\uff0c\u200b\u529f\u80fd\u200b\u548c\u200b\u6548\u679c\u200b\u53ef\u200b\u7701\u7565\u200b\uff0c\u200b\u53ea\u662f\u200b\u4e3a\u4e86\u200b\u66f4\u200b\u660e\u786e\u200b\u5730\u200b\u8868\u793a\u200b\u8f93\u5165\u200b\u91cd\u5b9a\u5411\u200b\uff0c\u200b\u5373\u200b<code>cat log</code> \u200b\u7b49\u4ef7\u200b\u4e8e\u200b <code>cat &lt; log</code></p> </li> <li> <p><code>&lt;&lt;</code> </p> </li> <li><code>&lt;&lt;&lt;</code></li> </ol>"},{"location":"Programing/Shell/Bash/file_related/redirection.html#output","title":"output","text":"<ol> <li><code>&gt;(&gt;) log</code>     \u200b\u8986\u76d6\u200b(\u200b\u8ffd\u52a0\u200b)\u200b\u8f93\u51fa\u200b\uff0c\u200b\u5373\u5c06\u200bstdout\u200b\u7ed3\u679c\u200b\u4ee5\u200b\u8986\u76d6\u200b(\u200b\u8ffd\u52a0\u200b)\u200b\u65b9\u5f0f\u200b\u5199\u5165\u200b\u76ee\u6807\u200b\u6587\u4ef6\u200b  </li> <li><code>&amp;&gt;(&gt;) log</code>     \u200b\u5c06\u200bstdout\u200b\u548c\u200bstderr\u200b\u4e00\u8d77\u200b\u8986\u76d6\u200b(\u200b\u8ffd\u52a0\u200b)\u200b\u5199\u5165\u200b\u76ee\u6807\u200b\u6587\u4ef6\u200b</li> <li><code>&gt;&amp;</code>     \u200b\u5c06\u200b\u4e00\u4e2a\u200b\u6587\u4ef6\u200b\u63cf\u8ff0\u7b26\u200b\u5bf9\u5e94\u200b\u7684\u200b\u7ed3\u679c\u200b\u8ffd\u52a0\u200b\u81f3\u200b\u53e6\u200b\u4e00\u4e2a\u200b\u6587\u4ef6\u200b\u63cf\u8ff0\u7b26\u200b\u5bf9\u5e94\u200b\u7ed3\u679c\u200b\u4e2d\u200b\u4f5c\u4e3a\u200b\u6574\u4f53\u200b\uff0c\u200b\u5982\u200b<code>2&gt;&amp;1</code>\u200b\u548c\u200b<code>1&gt;&amp;1</code></li> <li><code>1&gt;(&gt;) log</code>     \u200b\u7b49\u4ef7\u200b\u4e8e\u200b <code>&gt;(&gt;) log</code>\uff0c\u200b\u5373\u5c06\u200bstdout\u200b\u4ee5\u200b\u8986\u76d6\u200b(\u200b\u8ffd\u52a0\u200b)\u200b\u65b9\u5f0f\u200b\u5199\u5165\u200b\u76ee\u6807\u200b\u6587\u4ef6\u200b  </li> <li><code>2&gt;(&gt;) log</code>     \u200b\u5c06\u200bstderr\u200b\u4ee5\u200b\u8986\u76d6\u200b(\u200b\u8ffd\u52a0\u200b)\u200b\u65b9\u5f0f\u200b\u5199\u5165\u200b\u76ee\u6807\u200b\u6587\u4ef6\u200b  </li> </ol> <ul> <li>file operator 1\uff1astdout\uff0c\u200b\u5373\u200bstandard output</li> <li>file operator 2\uff1astderr\uff0c\u200b\u5373\u200bstandard error output</li> <li>\u200b\u529f\u80fd\u200b\u4e0a\u200b <code>2&gt;&amp;1 &gt; log</code> \u200b\u7b49\u4ef7\u200b\u4e8e\u200b <code>&amp;&gt; log</code></li> </ul>"},{"location":"Programing/Shell/Bash/file_related/sed.html","title":"Sed","text":"<p>sed (stream editer for filtering and transforming text) \u200b\u662f\u200b\u4ee5\u4e3a\u200b\u5355\u4f4d\u200b\u5904\u7406\u200b\u6587\u672c\u200b\u6570\u636e\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u5bf9\u200b\u6570\u636e\u200b\u8fdb\u884c\u200b\u8fc7\u6ee4\u200b\u3001\u200b\u66ff\u6362\u200b\u3001\u200b\u5220\u9664\u200b\u548c\u200b\u63d2\u5165\u200b\u7b49\u200b\u529f\u80fd\u200b\u3002</p>"},{"location":"Programing/Shell/Bash/file_related/sed.html#_1","title":"\u5b89\u88c5","text":""},{"location":"Programing/Shell/Bash/file_related/sed.html#windows","title":"windows","text":"<ol> <li>\u200b\u4e0b\u8f7d\u200b\u7f51\u5740\u200b</li> <li>\u200b\u9009\u62e9\u200b\u7248\u672c\u200b\u7684\u200b\u5bf9\u5e94\u200b\u7684\u200b <code>setup.exe</code> \u200b\u8fdb\u884c\u200b\u5b89\u88c5\u200b\u5373\u53ef\u200b</li> </ol>"},{"location":"Programing/Shell/Bash/file_related/sed.html#sed","title":"sed","text":"<p><code>sed [OPTION] ... {script-only-if-no-other-script} [input-file] ...</code></p>"},{"location":"Programing/Shell/Bash/file_related/sed.html#option","title":"<code>OPTION</code>","text":"<ul> <li><code>-n/--quiet/--silent</code>\uff1a\u200b\u53d6\u6d88\u200b\u9ed8\u8ba4\u200b\u6253\u5370\u200b\u6240\u6709\u200b\u5185\u5bb9\u200b\uff0c\u200b\u800c\u662f\u200b\u53ea\u200b\u6253\u5370\u200b\u7ecf\u8fc7\u200bsed\u200b\u5904\u7406\u200b\u540e\u200b\u7684\u200b\u884c\u200b</li> <li><code>-e script/--expression=script</code>\uff0c\u200b\u6267\u884c\u200b\u7684\u200b\u811a\u672c\u200b\uff0c\u200b\u591a\u4e2a\u200b <code>-e</code> \u200b\u8868\u793a\u200b\u975e\u200b\u77ed\u8def\u200b\u903b\u8f91\u200b\u6216\u200b\uff0c\u200b\u53ef\u200b\u501f\u52a9\u200b <code>uniq</code> \u200b\u5b9e\u73b0\u200b\u8f93\u51fa\u200b\u53bb\u200b\u91cd\u200b</li> <li><code>-f script-file/--file=script-file</code>\uff0c\u200b\u6267\u884c\u200b\u6587\u4ef6\u200b\u5185\u200b\u7684\u200b\u811a\u672c\u200b\uff0c\u200b\u548c\u200b <code>-e</code> \u200b\u533a\u522b\u200b\u5728\u4e8e\u200b\u8be5\u200b\u65b9\u5f0f\u200b\u811a\u672c\u200b\u5b58\u653e\u200b\u5728\u200b\u5df2\u6709\u200b\u6587\u4ef6\u200b</li> <li><code>-i[SUFFIX]/--in-place[=SUFFIX]</code>\uff1a\u200b\u76f4\u63a5\u200b\u4fee\u6539\u200b\u8bfb\u53d6\u200b\u7684\u200b\u6587\u4ef6\u200b\u5185\u5bb9\u200b\uff08\u200b\u672a\u8fc7\u200bsed\u200b\u7684\u200b\u539f\u5c01\u4e0d\u52a8\u200b\uff09\uff0c\u200b\u800c\u200b\u4e0d\u662f\u200b\u8f93\u51fa\u200b\u5230\u200b\u7ec8\u7aef\u200b</li> </ul>"},{"location":"Programing/Shell/Bash/file_related/sed.html#script","title":"<code>script</code>","text":"<p>\u200b\u683c\u5f0f\u200b <code>[address[,address]]s/pattern-find/replacement-pattern/[g,p,w,n,i]</code></p> <p>\u200b\u5176\u4e2d\u200b\u6700\u540e\u200b\u4e00\u6bb5\u200b\u4e3a\u200b\u66ff\u6362\u200b\u64cd\u4f5c\u200bs\u200b\u7684\u200b\u5b9e\u9645\u64cd\u4f5c\u200b\uff0c\u200b\u5305\u62ec\u200b\uff1a</p> <ul> <li>g\uff1a\u200b\u884c\u5185\u200b\u5339\u914d\u200b\u9879\u200b\u5168\u90e8\u200b\u8fdb\u884c\u200b\u66ff\u6362\u200b</li> <li>p\uff1a\u200b\u6253\u5370\u200b\u5339\u914d\u200b\u7684\u200b\u884c\u200b</li> <li>i\uff1a\u200b\u5ffd\u7565\u200b\u5927\u5c0f\u5199\u200b</li> <li>&amp;\uff1a\u200b\u5339\u914d\u200b\u5230\u200b\u7684\u200b\u5185\u5bb9\u200b <p><code>sed 's/l..e/&amp; no/gi'</code> \u200b\u5c06\u200b\u6240\u6709\u200b\u4e0d\u200b\u533a\u5206\u200b\u5927\u5c0f\u5199\u200b\u5339\u914d\u200b\u5230\u200b\u7684\u200b\u5185\u5bb9\u200b\u589e\u52a0\u200b\u5b57\u7b26\u4e32\u200b \" no\"</p> </li> </ul> <pre><code># \u200b\u524d\u200b/\u200b\u540e\u200b\u63d2\u5165\u200b i, a # \nsed 'a lxc'             # \u200b\u5728\u200b\u6bcf\u200b\u4e00\u884c\u200b \u200b\u540e\u200b \u200b\u63d2\u5165\u200b lxc\uff0c\u200b\u540c\u7406\u200ba\u200b\u64cd\u4f5c\u200b\u53ef\u4ee5\u200b\u6539\u4e3a\u200bi\u200b\u64cd\u4f5c\u200b\nsed '2a lxc'            # \u200b\u4ece\u200b\u7b2c\u200b2\u200b\u884c\u200b\u5f00\u59cb\u200b\u5728\u200b\u6bcf\u200b\u4e00\u884c\u200b \u200b\u540e\u200b \u200b\u63d2\u5165\u200b lxc\uff0c\u200b\u540c\u7406\u200ba\u200b\u64cd\u4f5c\u200b\u53ef\u4ee5\u200b\u6539\u4e3a\u200bi\u200b\u64cd\u4f5c\u200b \nsed '$a lxc'            # \u200b\u53ea\u200b\u5728\u200b\u6700\u540e\u200b\u4e00\u884c\u200b \u200b\u540e\u200b \u200b\u63d2\u5165\u200b lxc\uff0c\u200b\u540c\u7406\u200ba\u200b\u64cd\u4f5c\u200b\u53ef\u4ee5\u200b\u6539\u4e3a\u200bi\u200b\u64cd\u4f5c\u200b\nsed '/a/a lxc'          # \u200b\u5728\u200b\u542b\u6709\u200b\u5b57\u7b26\u200b a \u200b\u7684\u200b\u884c\u540e\u200b\u63d2\u5165\u200b lxc\uff0c\u200b\u540c\u7406\u200ba\u200b\u64cd\u4f5c\u200b\u53ef\u4ee5\u200b\u6539\u4e3a\u200bi\u200b\u64cd\u4f5c\u200b\n\n# \u200b\u5220\u9664\u200b d #\nsed '2,10d'             # \u200b\u5220\u9664\u200b [2, 10) \u200b\u884c\u200b\nsed '1~2d'              # \u200b\u5220\u9664\u200b 1+2n\u200b\u884c\u200b\nsed '2,10!d'            # !\u200b\u53d6\u53cd\u200b\uff0c\u200b\u5373\u200b\u5220\u9664\u200b all - [2, 10) = [1, 2) + [10, len] \u200b\u884c\u200b\nsed '2,10{/^$/d}'       # \u200b\u5220\u9664\u200b[2, 10) \u200b\u884c\u5185\u200b\u7684\u200b\u7a7a\u884c\u200b\n                        # \u200b\u7531\u4e8e\u200b {} \u200b\u662f\u200b\u7279\u6b8a\u7b26\u53f7\u200b\uff0c\u200b\u56e0\u6b64\u200b\u6b63\u5219\u8868\u8fbe\u5f0f\u200b\u65f6\u200b\u9700\u8981\u200b\u8f6c\u4e49\u200b\nsed '{/^$/d}'           # \u200b\u5220\u9664\u200b\u6240\u6709\u200b\u7a7a\u884c\u200b\n\n# \u200b\u4fee\u6539\u200b s #\nsed '2,5s/a/8/'         # [2, 5) \u200b\u884c\u5185\u200b\u7684\u200b a \u200b\u4fee\u6539\u200b\u4e3a\u200b 8\n\n# \u200b\u66ff\u6362\u200b c #\nsed '2c lxc'            # \u200b\u7b2c\u200b2\u200b\u884c\u200b\u5185\u5bb9\u200b\u66ff\u6362\u200b\u4e3a\u200b lxc\nsed '2,$c lxc'          # \u200b\u7b2c\u200b2\u200b\u81f3\u200b\u6700\u540e\u200b\u4e00\u884c\u200b\u5185\u5bb9\u200b\u66ff\u6362\u200b\u4e3a\u200b lxc\n\n# \u200b\u67e5\u770b\u200b p, = #\nsed -n 's/a/8/p'        # \u200b\u67e5\u770b\u200b\u6240\u6709\u200b a \u200b\u6539\u4e3a\u200b 8 \u200b\u7684\u200b\u884c\u200b\nsed -n '/a/='           # \u200b\u67e5\u770b\u200b\u6240\u6709\u200b\u542b\u200b\u5b57\u7b26\u200b a \u200b\u7684\u200b\u884c\u53f7\u200b\nsed -n '/^[A-Z]\\{3\\}/p' # \u200b\u67e5\u770b\u200b\u6240\u6709\u200b\u4ee5\u200b3\u200b\u4e2a\u200b\u5927\u5199\u5b57\u6bcd\u200b\u5f00\u5934\u200b\u7684\u200b\u884c\u200b\n</code></pre> <p><code>!</code> \u200b\u8868\u793a\u200b\u6761\u4ef6\u200b\u53d6\u53cd\u200b\uff0c\u200b\u7528\u4e8e\u200b command \u200b\u524d\u200b <code>;</code> \u200b\u8868\u793a\u200b\u4e0d\u200b\u77ed\u8def\u200b\u7684\u200b\u6761\u4ef6\u200b\u6216\u200b\uff0c\u200b\u53ef\u200b\u501f\u52a9\u200b <code>uniq</code> \u200b\u547d\u4ee4\u200b\u5b9e\u73b0\u200b\u53bb\u200b\u91cd\u200b  </p>"},{"location":"Programing/Shell/Bash/file_related/sed.html#_2","title":"\u7279\u6b8a\u200b\u8f6c\u4e49\u5b57\u7b26","text":"<ul> <li><code>{</code> \u200b\u8868\u793a\u200b\u539f\u59cb\u200b\u5b57\u7b26\u200b\uff0c<code>\\{</code> \u200b\u8868\u793a\u200b\u6b63\u5219\u200b\u4e2d\u200b\u8868\u200b\u6570\u91cf\u200b\u7684\u200b\u8f6c\u4e49\u5b57\u7b26\u200b</li> <li><code>?</code> \u200b\u8868\u793a\u200b\u539f\u59cb\u200b\u5b57\u7b26\u200b\uff0c<code>\\?</code> \u200b\u8868\u793a\u200b\u6b63\u5219\u200b\u4e2d\u200b\u8f6c\u4e49\u5b57\u7b26\u200b</li> </ul>"},{"location":"Programing/Shell/Bash/file_related/sort.html","title":"Sort","text":""},{"location":"Programing/Shell/Bash/file_related/sort.html#_1","title":"\u4f7f\u7528\u200b\u65b9\u6cd5","text":"<ul> <li><code>sort [OPTION] ... [FILE] ...</code></li> </ul>"},{"location":"Programing/Shell/Bash/file_related/sort.html#option","title":"OPTION","text":"<ol> <li><code>-f, --ignore-case</code> \u200b\u5927\u5c0f\u5199\u200b\u4e0d\u200b\u654f\u611f\u200b</li> <li><code>-k &lt;start&gt;[.[offset]],&lt;end&gt;[.&lt;offset&gt;] --key</code>\uff0c\u200b\u6307\u5b9a\u200b\u952e\u200b\u7528\u4e8e\u200b\u6392\u5e8f\u200b\uff0c\u200b\u5176\u4e2d\u200boffset\u200b\u8868\u793a\u200b\u952e\u200b\u7684\u200b\u5b57\u7b26\u200b\u504f\u79fb\u200b\u6570\u200b     <pre><code>&lt;!-- \u200b\u4ee5\u200b\u7b2c\u200b1\u200b\u5217\u200b\u5b57\u7b26\u200b2\u200b\u81f3\u200b\u5b57\u7b26\u200b4\u200b\u4e3a\u952e\u200b\u6392\u5e8f\u200b, $1[2:4+1] --&gt;\nsort -k 1.2,1.4 file.txt        \nsort --key=1.2,1.4 file.txt\n</code></pre></li> <li><code>-n</code> \u200b\u6309\u200b\u6570\u503c\u200b\u5927\u5c0f\u200b\u5347\u5e8f\u200b\u6392\u5e8f\u200b</li> <li><code>-r</code> \u200b\u964d\u5e8f\u200b\u6392\u5e8f\u200b\uff0c<code>-nr</code> \u200b\u6309\u200b\u6570\u503c\u200b\u65b9\u5f0f\u200b\u964d\u5e8f\u200b\u6392\u5e8f\u200b</li> </ol>"},{"location":"Programing/Shell/Bash/file_related/split.html","title":"Split","text":""},{"location":"Programing/Shell/Bash/file_related/split.html#_1","title":"\u8bed\u6cd5\u200b\u683c\u5f0f","text":"<p><code>split [option] ... file_name [new_file_prefix]</code></p> <p>\u200b\u53c2\u6570\u200boption</p> <ul> <li><code>-b storage</code>\uff1a\u200b\u6309\u7167\u200b\u5b57\u8282\u200b\u5927\u5c0f\u200b\u62c6\u200b\u5206\u4e3a\u200b\u591a\u4e2a\u200b<code>storage</code> B \u200b\u7684\u200b\u6587\u4ef6\u200b</li> <li><code>-l line_num</code>\uff1a\u200b\u6309\u7167\u200b\u884c\u6570\u200b\u62c6\u200b\u5206\u4e3a\u200b\u591a\u4e2a\u200b\u884c\u6570\u200b\u4e3a\u200b<code>line_num</code>\u200b\u7684\u200b\u6587\u4ef6\u200b</li> <li><code>-d</code>\uff1a\u200b\u4f7f\u7528\u200b\u6570\u5b57\u200b\u4f5c\u4e3a\u200b\u8f93\u51fa\u200b\u6587\u4ef6\u540d\u200b\u7684\u200b\u540e\u7f00\u200b\uff08\u200b\u65e0\u8be5\u200b\u9009\u9879\u200b\u65f6\u200b\u540e\u7f00\u200b\u4e3a\u200b\u5b57\u6bcd\u200b\uff09\uff0c\u200b\u4ece\u200b0\u200b\u5f00\u59cb\u200b\uff0c\u200b\u4e0d\u53ef\u200b\u6307\u5b9a\u200b   <p><code>--numeric-suffixes=from_idx</code>: \u200b\u4f7f\u7528\u200b\u6570\u5b57\u200b\u4f5c\u4e3a\u200b\u8f93\u51fa\u200b\u6587\u4ef6\u540d\u200b\u7684\u200b\u540e\u7f00\u200b\uff0c<code>from</code>\u200b\u7f3a\u7701\u200b\u4ece\u200b0\u200b\u5f00\u59cb\u200b</p> </li> <li><code>-a suffix_length</code>\uff1a\u200b\u6307\u5b9a\u200b\u751f\u6210\u200b\u7684\u200b\u6587\u4ef6\u540d\u200b\u540e\u7f00\u200b\u957f\u5ea6\u200b\uff0c<code>suffix_length</code>\u200b\u7f3a\u7701\u200b\u4e3a\u200b2</li> <li><code>--additional-suffix=suffix_name</code>: \u200b\u7ed9\u200b\u5206\u5272\u200b\u540e\u200b\u7684\u200b\u6587\u4ef6\u540d\u200b\u589e\u52a0\u200b\u540e\u7f00\u200b\uff0c\u200b\u5373\u200b\u6700\u7ec8\u200b\u540d\u5b57\u200b\u4e3a\u200b <code>prefix + num_idx + suffix</code></li> <li><code>--verbose</code>\uff1a\u200b\u663e\u793a\u200b\u62c6\u5206\u200b\u8fc7\u7a0b\u200b\u7684\u200b\u8be6\u7ec6\u4fe1\u606f\u200b</li> </ul>"},{"location":"Programing/Shell/Bash/file_related/uniq.html","title":"Uniq","text":""},{"location":"Programing/Shell/Bash/file_related/uniq.html#_1","title":"\u4f7f\u7528\u200b\u65b9\u6cd5","text":"<ul> <li><code>sort [OPTION] ... [INPUT [OUTPUT]]</code></li> </ul>"},{"location":"Programing/Shell/Bash/file_related/uniq.html#option","title":"OPTION","text":"<ol> <li><code>-c</code> \u200b\u7edf\u8ba1\u200b\u8fde\u7eed\u200b\u884c\u200b\u51fa\u73b0\u200b\u6b21\u6570\u200b,\u200b\u8f93\u51fa\u200b\u65f6\u200bcount\u200b\u5728\u200b\u524d\u200b</li> <li><code>-D</code> \u200b\u4ec5\u200b\u4fdd\u7559\u200b\u8fde\u7eed\u200b\u51fa\u73b0\u200b\u7684\u200b\u884c\u200b,\u200b\u4e14\u200b\u4e0d\u200b\u53bb\u200b\u91cd\u200b</li> <li><code>-d</code> \u200b\u4ec5\u200b\u4fdd\u7559\u200b\u8fde\u7eed\u200b\u51fa\u73b0\u200b\u7684\u200b\u884c\u200b,\u200b\u4e14\u200b\u53bb\u200b\u91cd\u200b</li> <li><code>-u, --unique</code> \u200b\u4ec5\u200b\u4fdd\u7559\u200b\u4e0d\u200b\u8fde\u7eed\u200b\u91cd\u590d\u200b\u7684\u200b\u884c\u200b</li> <li><code>-i, --ignore-case</code> \u200b\u5927\u5c0f\u5199\u200b\u4e0d\u200b\u654f\u611f\u200b</li> </ol>"},{"location":"Programing/Shell/Bash/numeric_operation/printf.html","title":"Printf","text":"<ol> <li>pad <code>padded_num=$(printf \"%010d\" $num)</code> <p>printf\u200b\u547d\u4ee4\u200b\u4e0d\u4f1a\u200b\u5728\u200b\u884c\u5c3e\u200b\u6dfb\u52a0\u200b\u6362\u884c\u7b26\u200b \"\\n\"</p> </li> </ol>"},{"location":"Programing/Shell/Bash/process_related/top.html","title":"Top","text":"<p>top\u200b\u547d\u4ee4\u200b\u7ed3\u679c\u200b\u89e3\u8bfb\u200b</p>"},{"location":"Programing/Shell/Bash/process_related/top.html#line_3","title":"line_3","text":"<p><code>%Cpu(s): 9.6 us, 0.8 sy, 0.0 ni, 89.6 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st</code>\uff0c\u200b\u8868\u793a\u200bCPU\u200b\u4f7f\u7528\u200b\u60c5\u51b5\u200b\uff0c\u200b\u5747\u200b\u4e3a\u200b\u767e\u5206\u6bd4\u200b</p> <ul> <li><code>9.6 us</code> \u200b\u7528\u6237\u200b\u7a7a\u95f4\u200b\uff08user\uff09\u200b\u5360\u7528\u200bCPU\u200b\u767e\u5206\u6bd4\u200b</li> <li><code>0.8 sy</code> \u200b\u5185\u6838\u200b\u7a7a\u95f4\u200b\uff08system\uff09\u200b\u5360\u7528\u200bCPU\u200b\u767e\u5206\u6bd4\u200b</li> <li><code>0.0%ni</code> \u200b\u7528\u6237\u200b\u8fdb\u7a0b\u200b\u7a7a\u95f4\u200b\u5185\u200b\u6539\u53d8\u200b\u8fc7\u200b\u4f18\u5148\u7ea7\u200b\u7684\u200b\u8fdb\u7a0b\u200b\u5360\u7528\u200bCPU\u200b\u767e\u5206\u6bd4\u200b</li> <li><code>89.6 id</code> \u200b\u7a7a\u95f2\u200bCPU\u200b\u767e\u5206\u6bd4\u200b</li> <li><code>0.0%wa</code> \u200b\u7b49\u5f85\u200b\uff08wait\uff09\u200b\u8f93\u5165\u8f93\u51fa\u200b\u7684\u200bCPU\u200b\u65f6\u95f4\u200b\u767e\u5206\u6bd4\u200b</li> <li><code>0.0%hi</code> \u200b\u786c\u200b\u4e2d\u65ad\u200b\uff08Hardware IRQ\uff09\u200b\u5360\u7528\u200bCPU\u200b\u7684\u200b\u767e\u5206\u6bd4\u200b</li> <li><code>0.0%si</code> \u200b\u8f6f\u200b\u4e2d\u65ad\u200b\uff08Software Interrupts\uff09\u200b\u5360\u7528\u200bCPU\u200b\u7684\u200b\u767e\u5206\u6bd4\u200b</li> <li><code>0.0 st</code> \u200b\u7528\u4e8e\u200b\u6709\u200b\u865a\u62df\u200bcpu\u200b\u7684\u200b\u60c5\u51b5\u200b\uff0c\u200b\u7528\u6765\u200b\u6307\u793a\u200b\u88ab\u200b\u865a\u62df\u673a\u200b\u5077\u6389\u200b\u7684\u200bcpu\u200b\u65f6\u95f4\u200b</li> </ul>"},{"location":"Programing/Shell/Bash/process_related/top.html#line_4-5","title":"line_4-5","text":"<pre><code>KiB Mem : 65807304 total, 432360 free, 37334904 used, 28040040 buff/cache\nKiB Swap: 0 total, 0 free, 0 used. 26442184 avail Mem\n</code></pre> \u200b\u4e24\u884c\u200b\u5747\u200b\u4e3a\u200b\u4e3a\u200b\u5185\u5b58\u200b\u7edf\u8ba1\u200b\u60c5\u51b5\u200b\uff0c - <code>KiB</code> \u200b\u5355\u4f4d\u200b\uff0c\u200b\u6709\u65f6\u200b\u4e5f\u200b\u4f1a\u200b\u663e\u793a\u200b <code>MiB</code> - <code>Mem</code> \u200b\u4e3a\u200b\u5b9e\u9645\u200b\u7269\u7406\u200b\u5185\u5b58\u200b\u4f7f\u7528\u200b\u60c5\u51b5\u200b\uff0c<code>Swap</code>\u200b\u662f\u200b\u865a\u62df\u5185\u5b58\u200bswap\u200b\u7684\u200b\u60c5\u51b5\u200b - <code>total</code> \u200b\u603b\u200b\u5185\u5b58\u7a7a\u95f4\u200b - <code>free</code> \u200b\u7a7a\u95f4\u200b\u5185\u5b58\u7a7a\u95f4\u200b - <code>used</code> \u200b\u5df2\u200b\u4f7f\u7528\u200b\u5185\u5b58\u7a7a\u95f4\u200b - <code>buff/cache</code> \u200b\u7528\u4f5c\u200b\u5185\u5b58\u200b\u7f13\u5b58\u200b\u7684\u200b\u5185\u5b58\u200b\u91cf"},{"location":"Programing/Shell/Bash/process_related/top.html#line_6","title":"line_6","text":"<p><code>PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND</code>\uff0c\u200b\u6bcf\u5217\u200b\u53c2\u6570\u200b\u610f\u4e49\u200b</p> <ul> <li><code>USER</code> \u200b\u8fdb\u7a0b\u200b\u62e5\u6709\u8005\u200b</li> <li><code>PR</code> \u200b\u8fdb\u7a0b\u200b\u4f18\u5148\u7ea7\u200bPR=20+NI\uff0c\u200b\u9ed8\u8ba4\u200b\u4e3a\u200b20</li> <li><code>NI</code> nice\u200b\u597d\u4eba\u200b\u503c\u200b\uff0c\u200b\u503c\u8d8a\u200b\u5927\u8d8a\u200b\u5bb9\u6613\u200b\u88ab\u200b\u63d2\u961f\u200b\uff0c\u200b\u9ed8\u8ba4\u200b0</li> <li><code>VIRT</code> \u200b\u8fdb\u7a0b\u200b\u4f7f\u7528\u200b\u865a\u62df\u5185\u5b58\u200b\u603b\u91cf\u200b\uff0cVIRT=SWAP+RES</li> <li><code>SHR</code> \u200b\u5171\u4eab\u5185\u5b58\u200b\u5927\u5c0f\u200b</li> <li><code>S</code> \u200b\u8fdb\u7a0b\u200b\u72b6\u6001\u200b\uff0c{D: \u200b\u4e0d\u53ef\u200b\u4e2d\u65ad\u200b\u7684\u200b\u7761\u7720\u200b\u72b6\u6001\u200b, R: \u200b\u8fd0\u884c\u200b, S: \u200b\u7761\u7720\u200b, T: \u200b\u8ddf\u8e2a\u200b/\u200b\u505c\u6b62\u200b, Z: \u200b\u50f5\u5c38\u200b\u8fdb\u7a0b\u200b, I: \u200b\u7a7a\u95f4\u200b\u8fdb\u7a0b\u200b}</li> <li><code>%CPU</code> \u200b\u4e0a\u6b21\u200b\u66f4\u65b0\u200b\u5230\u200b\u73b0\u5728\u200b\u7684\u200bCPU\u200b\u65f6\u95f4\u200b\u5360\u7528\u200b\u767e\u5206\u6bd4\u200b</li> <li><code>%MEM</code> \u200b\u8fdb\u7a0b\u200b\u4f7f\u7528\u200b\u7684\u200b\u7269\u7406\u200b\u5185\u5b58\u200b\u767e\u5206\u6bd4\u200b</li> </ul>"},{"location":"Programing/Shell/Bash/process_scheduling/concurrent.html","title":"Concurrent","text":"<pre><code>#!/bin/bash\n\n\n# \u200b\u8bbe\u7f6e\u200b\u8fd0\u884c\u200b\u6b21\u6570\u200b\u6216\u200b\u4e0e\u200b\u8fd0\u884c\u200b\u5bf9\u8c61\u200b\nnum_runs=5\n\n# \u200b\u5faa\u73af\u200b\u6267\u884c\u7a0b\u5e8f\u200b\nfor ((i=1; i&lt;=$num_runs; i++))\ndo\n    # \u3010nohup(no hang up) \u200b\u7ec8\u7aef\u200b\u5173\u95ed\u200b\u4e0d\u6302\u200b\u8d77\u200b\u800c\u200b\u7ee7\u7eed\u200b\u8fd0\u884c\u200b(\u200b\u7c7b\u4f3c\u200b\u4e8e\u200bscreen)\u3011 \n    # + \u200b\u8fd0\u884c\u200b\u7a0b\u5e8f\u200b + \u200b\u4f20\u5165\u200b\u53c2\u6570\u200b + \u30102&gt;&amp;1 \u200b\u65e5\u5fd7\u200b\u91cd\u5b9a\u5411\u200b\u3011\n    # +\u3010&amp; \u200b\u540e\u53f0\u200b\u8fd0\u884c\u200b\u5b9e\u73b0\u200b\u5e76\u53d1\u200b\u3011\n    nohup python run.py $i &gt; log_${i}.txt 2&gt;&amp;1 &amp;\ndone\n\n# \u200b\u7b49\u5f85\u200b\u6240\u6709\u200b\u5b50\u200b\u7ebf\u7a0b\u200b\u5b8c\u6210\u200b\u540e\u200b\u5728\u200b\u7ee7\u7eed\u200b\u4e3b\u7ebf\u200b\u7a0b\u200b\uff0c\u200b\u5426\u5219\u200b\u4f1a\u200b\u5728\u200b\u4e3b\u7ebf\u200b\u7a0b\u200b\u7ed3\u675f\u200b\u65f6\u200b\u76f4\u63a5\u200b\u7ed3\u675f\u200b\u6240\u6709\u200b\u5b50\u200b\u7ebf\u7a0b\u200b\nwait\n\n# \u200b\u8f93\u51fa\u200b\u63d0\u793a\u4fe1\u606f\u200b\necho \"\u200b\u6240\u6709\u200b\u7a0b\u5e8f\u6267\u884c\u200b\u5b8c\u6210\u200b\u3002\"\n</code></pre>"},{"location":"Programing/Shell/Bash/process_scheduling/parallel.html","title":"Parallel","text":""},{"location":"Programing/Shell/Bash/remote_operation/curl.html","title":"Curl","text":"<p>curl\uff08Client URL\uff09\u200b\u662f\u200b\u4e00\u4e2a\u200b\u529f\u80fd\u200b\u6781\u5176\u200b\u5f3a\u5927\u200b\u7684\u200b\u547d\u4ee4\u884c\u200b\u5de5\u5177\u200b\u548c\u200b\u5e93\u200b\uff0c\u200b\u7528\u4e8e\u200b\u4f7f\u7528\u200b\u5404\u79cd\u200b\u7f51\u7edc\u534f\u8bae\u200b\u5728\u200b\u670d\u52a1\u5668\u4e4b\u95f4\u200b\u6216\u200b\u4e0e\u200b\u670d\u52a1\u5668\u200b\u4f20\u8f93\u6570\u636e\u200b\u3002\u200b\u5b83\u200b\u88ab\u200b\u79f0\u4e3a\u200b\u201c\u200b\u4e92\u8054\u7f51\u200b\u7684\u200b\u745e\u58eb\u519b\u5200\u200b\u201d\uff0c\u200b\u56e0\u4e3a\u200b\u5176\u200b\u529f\u80fd\u4e30\u5bcc\u200b\u3001\u200b\u7528\u9014\u200b\u5e7f\u6cdb\u200b\u3002</p>"},{"location":"Programing/Shell/PowerShell/index.html","title":"PowerShell","text":""},{"location":"Programing/Tex/Latex/index.html","title":"Latex","text":"<ul> <li>\u200b\u6b63\u4e0b\u200b\u7b26\u53f7\u200b\\(\\mathop{lxc}\\limits_{test}\\) <pre><code>\\mathop{obj}\\limits_{content}\n</code></pre></li> <li><code>\\mathop</code>\u200b\u8868\u793a\u200b\u5c06\u200b\u76ee\u6807\u200b\u8f6c\u5316\u200b\u8f6c\u4e3a\u200b\u6570\u5b66\u200b\u7b26\u53f7\u200b</li> <li><code>limits_</code>\u200b\u5bf9\u200b\u6570\u5b66\u200b\u7b26\u53f7\u200b\u8fdb\u884c\u200b\u6b63\u4e0b\u65b9\u200b\u4e0b\u6807\u200b\u8868\u793a\u200b</li> </ul>"},{"location":"Programing/Tex/Markdown/index.html","title":"Markdown","text":""},{"location":"Programing/Tex/MkDocs/index.html","title":"MkDocs","text":""},{"location":"Programing/Tex/MkDocs/index.html#medadata","title":"MedaData","text":"<p>slug: bigluo            # \u200b\u522b\u540d\u200b\uff0c\u200b\u81ea\u5b9a\u4e49\u200bpost\u200b\u7684\u200b\u6587\u4ef6\u540d\u200b title: luomou           # post\u200b\u7684\u200b\u9875\u9762\u200b\u6807\u9898\u200b categories:             # \u200b\u5206\u914d\u200b post \u200b\u7684\u200b\u7c7b\u522b\u200b   - \u200b\u6559\u7a0b\u200b   - MkDocs tags:                   # \u200b\u5206\u914d\u200b post \u200b\u7684\u200b\u6807\u7b7e\u200b   - \u200b\u535a\u5ba2\u200b   - \u200b\u6559\u7a0b\u200b   - \u200b\u5165\u95e8\u200b date: yyyy-MM-dd        # post\u200b\u521b\u5efa\u200b\u65e5\u671f\u200b readtime: 15            # \u200b\u624b\u52a8\u200b\u6307\u5b9a\u200bpost\u200b\u6240\u200b\u9700\u200b\u9605\u8bfb\u200b\u65f6\u95f4\u200b\uff0cmin description: \u200b\u5b66\u4e60\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b MkDocs \u200b\u548c\u200b mkdocs-blog-plugin \u200b\u521b\u5efa\u200b\u81ea\u5df1\u200b\u7684\u200b\u6280\u672f\u200b\u535a\u5ba2\u200b</p> <ul> <li>https://zhuanlan.zhihu.com/p/613038183/</li> </ul>"},{"location":"Programing/Tex/MkDocs/index.html#_1","title":"\u9875\u9762\u200b\u5c5e\u6027","text":"<p>https://squidfunk.github.io/mkdocs-material/setup/setting-up-tags/</p>"},{"location":"Programing/Tex/MkDocs/index.html#_2","title":"\u535a\u5ba2","text":"<ol> <li>\u200b\u6fc0\u6d3b\u200b <pre><code>plugins:\n    - blog  # \u200b\u9700\u200b\u63d0\u524d\u200b pip install mkdocs-blog-plugin\n</code></pre></li> </ol>"},{"location":"Programing/Tex/MkDocs/index.html#_3","title":"\u6807\u9898","text":"<p>\u200b\u6267\u884c\u200b\u7f51\u9875\u200b\u6807\u9898\u200b</p> <ol> <li>\u200b\u4f7f\u7528\u200b <ul> <li><code>title</code>\uff1a\u200b\u7f51\u9875\u200b\u6807\u9898\u200b\uff0c\u200b\u7eaf\u200bstr <pre><code>---\ntitle: Hello_World\n---\n</code></pre></li> </ul> </li> </ol>"},{"location":"Programing/Tex/MkDocs/index.html#_4","title":"\u6807\u7b7e","text":"<p>\u200b\u6307\u5b9a\u200b\u7f51\u9875\u200b\u6807\u7b7e\u200b\u4fe1\u606f\u200b</p> <ol> <li> <p>\u200b\u6fc0\u6d3b\u200b </p><pre><code>plugins:\n    - tags\n</code></pre><p></p> </li> <li> <p>\u200b\u4f7f\u7528\u200b </p> <ul> <li><code>tags</code>\uff1a\u200b\u7f51\u9875\u200b\u6807\u7b7e\u200b\uff0c\u200b\u7eaf\u200bstr list\uff0c\u200b\u53ef\u200b\u81ea\u5b9a\u4e49\u200b\u6807\u7b7e\u200b <pre><code>---\ntags:\n  - HTML5\n  - JavaScript\n  - CSS\n---\n</code></pre></li> </ul> </li> </ol>"},{"location":"Programing/Tex/MkDocs/index.html#_5","title":"\u8bc4\u8bba\u200b\u663e\u793a","text":"<ul> <li><code>giscus</code>, <code>pip install mkdocs-giscus</code></li> </ul>"},{"location":"Programing/Tex/MkDocs/index.html#_6","title":"\u9875\u9762\u200b\u6210\u5206\u200b\u663e\u793a","text":"<p>\u200b\u63a7\u5236\u200b\u9875\u9762\u200b\u4e2d\u200b\u7684\u200b\u663e\u793a\u200b\u6210\u5206\u200b</p> <ol> <li>\u200b\u4f7f\u7528\u200b<ul> <li><code>hide</code>\uff1a\u200b\u9700\u8981\u200b\u9690\u85cf\u200b\u7684\u200b\u6210\u5206\u200b <pre><code>---\nhide:\n  - navigation # \u200b\u9690\u85cf\u200b\u5de6\u4fa7\u200b\u76ee\u5f55\u200b\u5bfc\u822a\u200b\n  - toc        # \u200b\u9690\u85cf\u200b\u53f3\u4fa7\u200b\u9875\u9762\u200b\u5bfc\u822a\u200b\n  - footer\n---\n</code></pre></li> </ul> </li> </ol>"},{"location":"Programing/Tex/MkDocs/index.html#_7","title":"\u4e3b\u9898","text":""},{"location":"Programing/Tex/MkDocs/index.html#_8","title":"\u90e8\u4ef6","text":"<ul> <li> <p>admonition</p> </li> <li> <p>content tabs</p> </li> </ul> CC++ <pre><code>#include &lt;stdio.h&gt;\n\nint main(void) {\n  printf(\"Hello world!\\n\");\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre> lxc<pre><code>print(\"hello world\")\n</code></pre>"},{"location":"Programing/Tex/MkDocs/index.html#xxx","title":"xxx","text":"<p>https://squidfunk.github.io/mkdocs-material/reference/code-blocks/</p> <p>\u200b\u6307\u5b9a\u200b\u884c\u5185\u200b\u4ee3\u7801\u200b\u8bed\u8a00\u200b\u7c7b\u578b\u200b </p><pre><code>`#!python range()`\n</code></pre><p></p> lxc<pre><code>print('hello world')\na = tf.zeros([3, 3], dtype=tf.float32)\n</code></pre> <ul> <li>This was marked</li> <li>a<sup>T</sup>\uff0ca<sub>T</sub></li> <li>+++</li> <li>This was inserted</li> <li>This was deleted</li> <li>{deleted}</li> <li>Text can be deleted and replacement text  added . This can also be combined into onea single operation. Highlighting is also possible and comments can be added inline.</li> </ul> <pre><code># (1)!\n</code></pre> <ol> <li>Look ma, less line noise!</li> </ol> <pre><code>| \u200b\u5de6\u200b\u5bf9\u9f50\u200b | \u200b\u53f3\u200b\u5bf9\u9f50\u200b | \u200b\u5c45\u4e2d\u200b\u5bf9\u9f50\u200b |\n| :-----| ----: | :----: |\n| \u200b\u5355\u5143\u683c\u200b | \u200b\u5355\u5143\u683c\u200b | \u200b\u5355\u5143\u683c\u200b |\n| \u200b\u5355\u5143\u683c\u200b | \u200b\u5355\u5143\u683c\u200b | \u200b\u5355\u5143\u683c\u200b |\n</code></pre> \u200b\u5de6\u200b\u5bf9\u9f50\u200b \u200b\u53f3\u200b\u5bf9\u9f50\u200b \u200b\u5c45\u4e2d\u200b\u5bf9\u9f50\u200b \u200b\u5355\u5143\u683c\u200b \u200b\u5355\u5143\u683c\u200b \u200b\u5355\u5143\u683c\u200b \u200b\u5355\u5143\u683c\u200b \u200b\u5355\u5143\u683c\u200b \u200b\u5355\u5143\u683c"},{"location":"Programing/Tex/MkDocs/index.html#_9","title":"\u76f8\u5bf9\u8def\u5f84","text":"<pre><code># in mkdocs.yml\nuse_directory_urls: false\n\n# link resource\n\"can use relative path and absolute path\"\n\n# link file\n\"for .md: add file_name suffix\"\n\"for .md head: file_name.suffix#head_name\"\n</code></pre>"},{"location":"Programing/Tex/MkDocs/index.html#_10","title":"\u56fe\u7247","text":"one-image<pre><code>&lt;div class=\"one-image-container\"&gt;\n    &lt;img src=\"image/FP32_demo.png\" style=\"width: 80%;\"&gt;\n    &lt;!-- &lt;p&gt;LoRA\u200b\u5728\u200bAttention\u200b\u5404\u200b\u90e8\u5206\u200b\u6743\u91cd\u200b\u4e0a\u200b\u7684\u200b\u6d88\u878d\u200b\u5b9e\u9a8c\u200b\u6548\u679c\u200b&lt;/p&gt; --&gt;\n    &lt;!-- &lt;figcaption&gt;\u200b\u8fd9\u662f\u200b\u56fe\u7247\u200b\u7684\u200b\u6807\u9898\u200b\u6216\u200b\u63cf\u8ff0\u200b\u3002&lt;/figcaption&gt; --&gt;\n&lt;/div&gt;\n</code></pre> row-image<pre><code>&lt;div class=\"row-image-container\"&gt;\n    &lt;div&gt;\n        &lt;img src=\"image/FP32_demo.png\" style=\"width: 80%;\"&gt;\n        &lt;!-- &lt;p&gt;LoRA\u200b\u5728\u200bAttention\u200b\u5404\u200b\u90e8\u5206\u200b\u6743\u91cd\u200b\u4e0a\u200b\u7684\u200b\u6d88\u878d\u200b\u5b9e\u9a8c\u200b\u6548\u679c\u200b&lt;/p&gt; --&gt;\n        &lt;!-- &lt;figcaption&gt;\u200b\u8fd9\u662f\u200b\u56fe\u7247\u200b\u7684\u200b\u6807\u9898\u200b\u6216\u200b\u63cf\u8ff0\u200b\u3002&lt;/figcaption&gt; --&gt;\n    &lt;/div&gt;\n\n    &lt;div&gt;\n        &lt;img src=\"image/FP32_demo.png\" style=\"width: 80%;\"&gt;\n        &lt;!-- &lt;p&gt;LoRA\u200b\u5728\u200bAttention\u200b\u5404\u200b\u90e8\u5206\u200b\u6743\u91cd\u200b\u4e0a\u200b\u7684\u200b\u6d88\u878d\u200b\u5b9e\u9a8c\u200b\u6548\u679c\u200b&lt;/p&gt; --&gt;\n        &lt;!-- &lt;figcaption&gt;\u200b\u8fd9\u662f\u200b\u56fe\u7247\u200b\u7684\u200b\u6807\u9898\u200b\u6216\u200b\u63cf\u8ff0\u200b\u3002&lt;/figcaption&gt; --&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre>"},{"location":"Programing/Tex/MkDocs/theme_related/admonition.html","title":"Admonition","text":""},{"location":"Programing/Tex/MkDocs/theme_related/admonition.html#_1","title":"\u5b89\u88c5","text":"<pre><code>markdown_extensions:\n  - admonition\n\n# \u200b\u8bbe\u7f6e\u200b\u4e0d\u540c\u200b\u7c7b\u578b\u200b\u7684\u200bicons https://squidfunk.github.io/mkdocs-material/reference/admonitions/#admonition-icons-octicons\ntheme:\n  icon:\n    admonition:\n      note: octicons/tag-16\n      abstract: octicons/checklist-16\n      info: octicons/info-16\n      tip: octicons/squirrel-16\n      success: octicons/check-16\n      question: octicons/question-16\n      warning: octicons/alert-16\n      failure: octicons/x-circle-16\n      danger: octicons/zap-16\n      bug: octicons/bug-16\n      example: octicons/beaker-16\n      quote: octicons/quote-16\n</code></pre>"},{"location":"Programing/Tex/MkDocs/theme_related/admonition.html#_2","title":"\u4f7f\u7528","text":"<pre><code># \u200b\u4e0d\u53ef\u200b\u6298\u53e0\u200b\u5f62\u5f0f\u200b\uff0ctitle\u200b\u7f3a\u7701\u200b\u4e3a\u200btype_qualifier\n!!! type_qualifier \"qualifier_title\"\n    content\n# \u200b\u53ef\u6298\u53e0\u200b\u5f62\u5f0f\u200b\uff0c\u200b\u7f3a\u7701\u200b ???\u200b\u6298\u53e0\u200b\u5f62\u5f0f\u200b, ???+ \u200b\u4e3a\u200b\u4e0d\u200b\u6298\u53e0\u200b\u5f62\u5f0f\u200b\n??? type_qualifier \"qualifier_title\"\n    content\n# \u200b\u884c\u5185\u200b\u5757\u200b\uff0c\u200b\u7f3a\u7701\u200b\u884c\u5185\u200b\u5de6\u4fa7\u200b\u5bf9\u9f50\u200b\uff0cend\u200b\u63a7\u5236\u200b\u53f3\u4fa7\u200b\u5bf9\u9f50\u200b\n# \u200b\u884c\u5185\u200b\u5757\u200b\u9700\u200b\u5728\u200b\u6b63\u6587\u200b\u5185\u5bb9\u200b\u4e4b\u524d\u200b\u5b9a\u4e49\u200b\n!!! type_qualifier inline end \"qualifier_title\"\n    content\n\n# html\u200b\u683c\u5f0f\u200b\uff0c\u200b\u53ef\u7528\u200b\u6765\u200b\u63a7\u5236\u200b\u7f29\u8fdb\u200b\u63d0\u793a\u200b\n&lt;div class=\"admonition note\" style=\"margin-left: 20px;\"&gt;\n    &lt;p class=\"admonition-title\"&gt;qualifier_title&lt;/p&gt;\n    &lt;p&gt;content&lt;/p&gt;\n&lt;/div&gt;  \n</code></pre> <p>lxc</p> <p>hello world</p> <p>lxc</p> <p>hello world</p> lxc <p>hello world</p> <p>hello world</p> <p>lxc</p> <p>xxx</p> <p>\\(\\sum\\frac{\\pi }{\\sigma }-sin(x)\\)</p> <p>This is an admonition box without a title.</p> <pre><code>&lt;div class=\"admonition note\" style=\"margin-left: 20px;\"&gt;\n    &lt;p class=\"admonition-title\"&gt;qualifier_title&lt;/p&gt;\n    &lt;p&gt;content&lt;/p&gt;\n&lt;/div&gt;  \n</code></pre>"},{"location":"Programing/Tex/MkDocs/theme_related/admonition.html#_3","title":"\u81ea\u5b9a\u4e49\u200b\u8b66\u793a\u200b\u7c7b\u578b","text":""},{"location":"Programing/wheel/index.html","title":"\u8f6e\u5b50","text":""},{"location":"Programing/wheel/index.html#_1","title":"\u5b57\u7b26\u200b\u76f8\u5173","text":""},{"location":"Programing/wheel/index.html#_2","title":"\u7a7a\u767d\u200b\u5b57\u7b26","text":"PythonJava <pre><code>white_space_pattern = re.compile(\n    \"[\"\n    \"\\u0000-\\u001f\"        # ASCII 0~31 \u200b\u63a7\u5236\u5b57\u7b26\u200b\u6216\u200b\u901a\u4fe1\u200b\u4e13\u7528\u200b\u5b57\u7b26\u200b\n    \"\\\\s\\u0020\\u3000\"      # \u200b\u5168\u200b\u534a\u89d2\u200b\u7a7a\u683c\u200b + \\\\s\n    \"\\u007f-\\u00a0\"        # DEL-NBSP\n    \"\\u034f\"               # \u200b\u7ec4\u5408\u200b\u7528\u200b\u5b57\u5f62\u200b\u8fde\u63a5\u7b26\u200b\n    \"\\u2000-\\u200f\\u2011\\u2028-\\u202f\\u205f-\\u206f\"\n                           # NQSP-\u200b\u53f3\u81f3\u200b\u5de6\u200b\u6807\u8bb0\u200b + BN_ + LSEP-NNBSEP + MMSP-\u200b\u540d\u4e49\u200b\u6570\u5b57\u200b\u5f62\u72b6\u200b\n    \"\\ufe00-\\ufe0f\"        # \u200b\u53d8\u4f53\u200b\u9009\u62e9\u5668\u200b\n    \"\\U000e0100-\\U000e01ef\"# \u200b\u53d8\u4f53\u200b\u9009\u62e9\u5668\u200b\u8865\u5145\u200b\n    \"\\ufeff\"               # ZWNBSP\n    \"\\u115f\\u1160\\u3164\\uffa0\"   \n                           # \u200b\u671d\u9c9c\u6587\u200b\u521d\u58f0\u200b\u586b\u5145\u200b\u7b26\u200bHCF + \u200b\u671d\u9c9c\u6587\u200b\u4e2d\u58f0\u200b\u586b\u5145\u200b\u7b26\u200bHJF + \u200b\u671d\u9c9c\u6587\u200b\u586b\u5145\u200b\u7b26\u200bHF + \u200b\u671d\u9c9c\u6587\u200b\u534a\u5bbd\u200b\u586b\u5145\u200b\u7b26\u200bHWHF\n    \"\\ufff0-\\uffff\"        # \u200b\u7279\u6b8a\u5b57\u7b26\u200b\n    \"\\U000e0000-\\U000e007f\"# \u200b\u6807\u7b7e\u200b\n    \"]+\"\n)\n</code></pre> <pre><code>String WHITE_CHAR =\n    \"[\" +\n    \"\\u0000-\\u001f\" +\n    \"\\\\s\\u0020\\u3000\" +\n    \"\\u007f-\\u00a0\" +\n    \"\\u2000-\\u200f\\u2011\\u2028-\\u202f\\u205f-\\u206f\" +\n    \"\\ufe00-\\ufe0f\" +\n    \"\\ufeff\" +\n    \"\\u115f\\u1160\\u3164\\uffa0\" +\n    \"\\ufff0-\\uffff\" +\n    \"\\uDB40\\uDC00-\\uDB40\\uDC7F\" +\n    \"\\uDB40\\uDD00-\\uDB40\\uDDEF\" +\n    \"]+\";\n</code></pre>"},{"location":"Programing/wheel/index.html#_3","title":"\u6807\u70b9\u7b26\u53f7","text":"Python <pre><code>punctuation = re.compile(\n    \"[\"\n    \"\u2013\u2014\uff3f_\u3000\u3003\u3003\u301f\u303e\u303f\u201e\u2026\u2027\ufe4f\ufe51\u00b7\uff61\"\n    \"\\\\\uff3c\"\n    \"\uff0b\\+\uff0d\\-\uff0a\\*\uff0f/\uff1d=\"\n    \"\uff03#\uff04\\$\uff05%\uff06&amp;\uff20@\u3030\uff5e\u301c~\uff3e\\^\"\n    \"\uff01!\uff1f\\?\uff5c\\|\"\n    \"\uff1a\uff1b\ufe54:;\uff0c,\u3002 \\.\u3001\uff64\"\n    \"\\(\\)\uff08\uff09\uff3b\uff3d\\[\\]\uff5b\uff5d\\{\\}\uff62\uff63\u3008\u3009&lt;&gt;\uff1c\uff1e\uff5f\uff60\u300a\u300b\u300c\u300d\u300e\u300f\u3010\u3011\u3014\u3015\u3016\u3017\u3018\u3019\u301a\u301b\"\n    \"\uff02\uff40\uff07\u2018\u2019\u301d\u301e\u201c\u201d'\\\"\u201f\u201b`\"\n    \"]\"\n)\n\ndef strip_punctuation(text, white_list_punct={}):\n    ret = []\n    for c in text:\n        cp = ord(c)\n        if c not in white_list_punct and \\\n            (33 &lt;= cp &lt;= 47 or\n            58 &lt;= cp &lt;= 64 or\n            91 &lt;= cp &lt;= 96 or\n            123 &lt;= cp &lt;= 126 or\n            unicodedata.category(c).startswith(\"P\")):\n            continue\n        ret.append(c)\n    return ''.join(ret)\n</code></pre>"},{"location":"Programing/wheel/index.html#cjk","title":"CJK\u200b\u5b57\u7b26","text":"PythonJava <pre><code>def is_chinese(cp):\n    if (cp &gt;= 0x4E00 and cp &lt;= 0x9FFF) or\n        (cp &gt;= 0x3400 and cp &lt;= 0x4DBF) or\n        (cp &gt;= 0x20000 and cp &lt;= 0x2A6DF) or\n        (cp &gt;= 0x2A700 and cp &lt;= 0x2B73F) or\n        (cp &gt;= 0x2B740 and cp &lt;= 0x2B81F) or\n        (cp &gt;= 0x2B820 and cp &lt;= 0x2CEAF) or\n        (cp &gt;= 0xF900 and cp &lt;= 0xFAFF) or\n        (cp &gt;= 0x2F800 and cp &lt;= 0x2FA1F):\n        return True\n    return False\n\ndef is_japanese(cp):\n    if (0x3000 &lt;= cp and cp &lt;= 0x303f or\n        0x3040 &lt;= cp and cp &lt;= 0x309f or\n        0x30a0 &lt;= cp and cp &lt;= 0x30ff):\n        return True\n    return False\n\ndef is_korean(cp):\n    if (0x1100 &lt;= cp and cp &lt;= 0x11ff or\n        0x3130 &lt;= cp and cp &lt;= 0x318f or\n        0xac00 &lt;= cp and cp &lt;= 0xd7af or\n        0xa960 &lt;= cp and cp &lt;= 0xa97f or\n        0xd7b0 &lt;= cp and cp &lt;= 0xd7ff):\n        return True\n    return False\n</code></pre> <pre><code>boolean is_chinese_char(int cp) {\n    if ((cp &gt;= 0x4E00 &amp;&amp; cp &lt;= 0x9FFF) || \n        (cp &gt;= 0x3400 &amp;&amp; cp &lt;= 0x4DBF) || \n        (cp &gt;= 0x20000 &amp;&amp; cp &lt;= 0x2A6DF) || \n        (cp &gt;= 0x2A700 &amp;&amp; cp &lt;= 0x2B73F) || \n        (cp &gt;= 0x2B740 &amp;&amp; cp &lt;= 0x2B81F) || \n        (cp &gt;= 0x2B820 &amp;&amp; cp &lt;= 0x2CEAF) ||\n        (cp &gt;= 0xF900 &amp;&amp; cp &lt;= 0xFAFF) || \n        (cp &gt;= 0x2F800 &amp;&amp; cp &lt;= 0x2FA1F)) {\n            return true;\n    }\n    return false;\n}\n\nboolean is_japanese(int cp) {\n    if (0x3000 &lt;= cp &amp;&amp; cp &lt;= 0x303f ||\n        0x3040 &lt;= cp &amp;&amp; cp &lt;= 0x309f ||\n        0x30a0 &lt;= cp &amp;&amp; cp &lt;= 0x30ff) {\n        return true;\n    }\n    return false;\n}\n\nboolean is_korean(int cp) {\n    if (0x1100 &lt;= cp &amp;&amp; cp &lt;= 0x11ff ||\n        0x3130 &lt;= cp &amp;&amp; cp &lt;= 0x318f ||\n        0xac00 &lt;= cp &amp;&amp; cp &lt;= 0xd7af ||\n        0xa960 &lt;= cp &amp;&amp; cp &lt;= 0xa97f ||\n        0xd7b0 &lt;= cp &amp;&amp; cp &lt;= 0xd7ff) {\n        return true;\n    }\n    return false;\n}\n</code></pre>"},{"location":"Programing/wheel/index.html#_4","title":"\u6587\u4ef6\u200b\u5904\u7406","text":""},{"location":"Programing/wheel/index.html#shuf","title":"\u5927\u200b\u6570\u636e\u91cf\u200b\u6587\u4ef6\u200bshuf","text":"Bash <pre><code>if [ $# != 1 ]; then\n    echo \"ERROR: \u200b\u9700\u8981\u200b\u6307\u5b9a\u200bshuf\u200b\u7684\u200b\u6587\u4ef6\u540d\u200b file_name\"\n    exit 1\nfi\nfile_name=$1\nsplit -l 100000 ${file_name} ${file_name}_part_\nfor f in `ls ${file_name}_part_* | shuf`; do\n    # \u200b\u5212\u5206\u200b\u6210\u200b\u8db3\u591f\u200b\u5c0f\u200b\u7684\u200b\u5757\u200b\u65e0\u9700\u200b\u518d\u200bshuf\n    cat $f &gt;&gt; shuffled_${file_name}\n    rm $f\ndone\nmv shuffled_${file_name} ${file_name}\n# python -u a.py -f ${file_name} -n 0 &gt; log 2&gt;&amp;1 &amp;\n</code></pre>"},{"location":"Programing/wheel/index.html#json","title":"JSON\u200b\u6587\u4ef6\u200b\u53bb\u200b\u91cd","text":"BashPython <pre><code># 1. \u200b\u5934\u5c3e\u200b\u5206\u522b\u200b\u63d2\u5165\u200b[ \u200b\u548c\u200b ]\uff0c\u200b\u6bcf\u884c\u200b\u63d2\u5165\u200b\u5206\u5272\u200b\u7b26\u200b\uff0c\u200b\u5f62\u6210\u200b\u4e00\u4e2a\u200blist\n# 2. unique_by\u200b\u53ea\u200b\u5728\u200blist\u200b\u4e2d\u200b\u751f\u6548\u200b\n# 3. \u200b\u81ea\u884c\u200b\u6307\u5b9a\u200b`file_name` \u200b\u548c\u200b `key_name`\ncat &lt;file_name&gt; | sed -e '1i[' -e '2,$i ,' -e '$a]' | jq -c 'unique_by(.&lt;key_name&gt;) | .[]'  &gt; unique_result.json\n</code></pre> <pre><code>import argparse\nimport json\nfrom tqdm import tqdm\n\n\nparser = argparse.ArgumentParser()\nparser.add_argument('-n', '--slice_len', type=int, required=True, help='sclie length, 0 means disable slice')\nparser.add_argument('-f', '--file_name', type=str, required=True, help='the file name to be unified')\n\nargs = parser.parse_args()  # \u200b\u901a\u8fc7\u200b`args.var_name` \u200b\u8c03\u7528\u200b\u76f8\u5e94\u200b\u53c2\u6570\u200b\n\ndef slice_text(text, slice_len=128, seps={'\\n', '\uff01', '\uff1f', '\u3002', '?', '!', '.'}):\n    pieces = set()\n    pre_idx = 0         # left_idx\n\n    while pre_idx &lt; len(text):\n        # rfind\u200b\u8fd4\u56de\u200btext\u200b\u4e2d\u200b\u7684\u200b\u771f\u5b9e\u200bidx\n        sep_idx = max([text.rfind(sep, pre_idx, pre_idx + slice_len) for sep in seps])\n\n        if sep_idx == -1 or pre_idx + slice_len &gt;= len(text):\n            part = text[pre_idx: pre_idx+slice_len]\n            pre_idx += slice_len\n        else:\n            part = text[pre_idx: sep_idx+1]\n            pre_idx = sep_idx + 1\n\n        pieces.add(part)\n    return pieces\n\n\nif __name__ == \"__main__\":\n    dump_lines = set()\n    total_line = 0\n    with open(args.file_name, 'r', encoding='utf-8') as f, \\\n            open(f'./{args.file_name}_unique_result.json', 'w', encoding='utf-8') as fout:\n        for i, line in enumerate(tqdm(f), 1):\n            try:\n                line = json.loads(line)\n            except:\n                print(line)\n                raise ValueError(f\"{i}-th line\")\n            cnt = line.get('content', line.get('c'))\n            if args.slice_len:\n                cnts = slice_text(cnt, args.slice_len)\n            else:\n                cnts = {cnt}\n\n            for cnt in cnts:\n                if cnt in dump_lines:\n                    continue\n                dump_lines.add(cnt)\n                total_line += 1\n                line['c'] = cnt                         # text_piece \u200b\u66ff\u4ee3\u200b\u539f\u6587\u200b\u672c\u200b\n                if args.slice_len and len(cnts) &gt; 1:    # \u200b\u8bb0\u5f55\u200b\u5207\u7247\u200b\u6240\u5c5e\u200b\u7684\u200b\u6587\u672c\u200b\n                    line['p'] = i\n                fout.write(json.dumps(line, ensure_ascii=False) + '\\n')\n                fout.flush()\n                if len(dump_lines) &gt;= 80000000:\n                    dump_lines.clear()\n    print(\"#line:\", total_line)\n</code></pre>"},{"location":"Programing/wheel/index.html#bash","title":"\u5b9e\u7528\u200bBash\u200b\u7ec4\u5408\u200b\u547d\u4ee4","text":""},{"location":"Programing/wheel/index.html#kill","title":"\u6279\u91cf\u200bkill\u200b\u8fdb\u7a0b","text":"\u6279\u91cf\u200bkill python pids<pre><code># 1. \u200b\u9009\u62e9\u200b\u5bf9\u5e94\u200b\u8fdb\u884c\u200b\u4fe1\u606f\u200b\n# 2. \u200b\u9009\u53d6\u200b\u8fdb\u7a0b\u200b\u4fe1\u606f\u200b\u7684\u200b\u7b2c\u4e8c\u5217\u200b(pid)\u200b\u8fdb\u884c\u200b\u6279\u91cf\u200bkill\nkill `ps -ux | grep python | grep '&lt;common_process_info&gt;' | awk -F' ' '{print $2}'`\n</code></pre>"},{"location":"Programing/wheel/index.html#cat","title":"\u6279\u91cf\u200bcat\u200b\u6587\u4ef6\u200b\u5185\u5bb9","text":"\u6279\u91cf\u200bcat\u200b\u6587\u4ef6\u200b\u5185\u5bb9\u200b<pre><code># 1. \u200b\u6279\u91cf\u200bcat\u200b\u4ee5\u200b\"part_\"\u200b\u5f00\u5934\u200b\u7684\u200bjson\u200b\u6587\u4ef6\u200b\ncat `ls part_*.json`\n</code></pre>"},{"location":"Programing/wheel/index.html#json_1","title":"\u83b7\u53d6\u200bjson\u200b\u6587\u4ef6\u200b\u7684\u200b\u952e\u200b\u7684\u200b\u53d6\u503c\u200b\u8303\u56f4","text":"<pre><code># 1. .key_name\u200b\u83b7\u53d6\u200b\u952e\u200b\u7684\u200b\u503c\u200b\n# 2. sort + uniq \u200b\u5b9e\u73b0\u200b\u53bb\u200b\u91cd\u200b\u76f8\u540c\u200b\u7684\u200b\u8fde\u7eed\u200b\u884c\u200b\ncat &lt;json_file_name&gt; | jq -c .&lt;key_name&gt; | sort | uniq\n</code></pre>"},{"location":"Resource/Media/index.html","title":"\u591a\u5a92\u4f53","text":"<p>\u200b\u591a\u5a92\u4f53\u200b\u5728\u7ebf\u200b\u5236\u4f5c\u200b\u7f51\u9875\u200b\uff1ahttps://ezgif.com/</p>"},{"location":"Resource/Tool/index.html","title":"\u5de5\u5177","text":""},{"location":"Resource/Tool/index.html#_1","title":"\u8f85\u52a9\u5de5\u5177","text":""},{"location":"Resource/Tool/index.html#_2","title":"\u7cfb\u7edf\u200b\u76f8\u5173","text":"<ul> <li>\u200b\u955c\u50cf\u200b\u4e0b\u8f7d\u200b\uff1aI Tell you\u3001ITELLYOU</li> <li>\u200b\u542f\u52a8\u76d8\u200b\u5236\u4f5c\u200b\uff1a\u200b\u5fae\u200bPE</li> </ul>"},{"location":"Resource/Tool/index.html#_3","title":"\u6587\u4ef6\u200b\u76f8\u5173","text":"<ul> <li>\u200b\u6587\u4ef6\u200b\u538b\u7f29\u200b\uff1a7-Zip</li> <li>\u200b\u6587\u4ef6\u200b\u67e5\u627e\u200b\uff1aEverything</li> <li>\u200b\u6587\u4ef6\u200b\u5378\u8f7d\u200b\uff1aGeek</li> <li>\u200b\u6587\u4ef6\u200b\u89e3\u9501\u200b\uff1aFreeMyPDF\u3001</li> </ul>"},{"location":"Resource/Tool/index.html#_4","title":"\u5185\u5bb9\u200b\u68c0\u7d22","text":"<ul> <li>\u200b\u56fe\u4e66\u200b\u8d44\u6e90\u200b\uff1a\u200b\u9e20\u200b\u6469\u200b\u641c\u7d22\u200b</li> <li>unicode\uff1a\u200b\u624b\u200b\u5199\u5b57\u200b\u8bc6\u522b\u200b\u3001\u200b\u7b26\u53f7\u5e93\u200b\u3001\u200b\u6c49\u5b57\u7f16\u7801\u200b\u8868\u200b\u3001\u200b\u56fd\u9645\u200b\u7535\u8111\u200b\u6c49\u5b57\u200b\u53ca\u200b\u5f02\u4f53\u5b57\u200b\u77e5\u8bc6\u5e93\u200b\u3001Unicode\u200b\u5927\u5168\u200b</li> <li>emoji\uff1aEmoji XD\u3001Emojipedia</li> </ul>"},{"location":"Resource/Tool/index.html#_5","title":"\u4e13\u4e1a\u200b\u5de5\u5177","text":"<ul> <li>\u200b\u6b63\u5219\u8868\u8fbe\u5f0f\u200b\uff1aRE\u200b\u53ef\u89c6\u5316\u200b</li> </ul>"},{"location":"Resource/Tool/index.html#_6","title":"\u63d2\u4ef6","text":""},{"location":"Resource/Tool/index.html#edge","title":"Edge\u200b\u63d2\u4ef6","text":"<ul> <li>\u200b\u8fdc\u7a0b\u200b\u4ed3\u5e93\u200b\u76ee\u5f55\u200b\u67e5\u770b\u200b\uff1aOctotree - GitHub code tree</li> <li>\u200b\u7f51\u9875\u200b\u97f3\u200b\u3001\u200b\u89c6\u9891\u200b\u500d\u901f\u200b\uff1aGlobal Speed\uff1a\u200b\u89c6\u9891\u200b\u901f\u5ea6\u200b\u63a7\u5236\u200b</li> <li>\u200b\u7f51\u9875\u5185\u5bb9\u200b\u89e3\u7801\u200b\u590d\u5236\u200b\uff1a\u200b\u7f51\u9875\u200b\u4e07\u80fd\u200b\u590d\u5236\u200b</li> <li>\u200b\u57fa\u91d1\u200b\u5b9e\u65f6\u200b\u4f30\u503c\u200b\uff1a\u200b\u81ea\u9009\u200b\u57fa\u91d1\u200b\u52a9\u624b\u200b</li> </ul>"},{"location":"Resource/Tutorial/index.html","title":"\u624b\u518c","text":"<ul> <li>pyplot</li> <li>katex</li> </ul>"},{"location":"Software/Compiler/CUDA/index.html","title":"CUDA","text":""},{"location":"Software/Compiler/Conda/index.html","title":"Conda","text":""},{"location":"Software/Compiler/Maven/index.html","title":"Maven","text":""},{"location":"Software/IDE/IDEA/index.html","title":"IDEA","text":""},{"location":"Software/IDE/PyCharm/index.html","title":"PyCharm","text":""},{"location":"Software/IDE/VSCode/index.html","title":"VSCode","text":""},{"location":"Software/Office/Adobe/index.html","title":"Adboe","text":"<p>Audition  </p> <ol> <li>\u200b\u6253\u5f00\u200b\u6587\u4ef6\u200b</li> <li>\u200b\u65b0\u5efa\u200b\u591a\u8f68\u200b\u4f1a\u8bdd\u200b\u5e76\u200b\u5c06\u200b\u6587\u4ef6\u200b\u62d6\u5165\u200b\u97f3\u8f68\u200b\u4e2d\u200b</li> <li>\u200b\u53f3\u4e0b\u89d2\u200b\u9009\u5b9a\u200b\u65f6\u533a\u200b\u5e76\u200b\u901a\u8fc7\u200b<code>\u200b\u526a\u8f91\u200b \u2192 \u200b\u526a\u5207\u200b</code>\u200b\u65b9\u5f0f\u200b\u5220\u9664\u200b\u9009\u4e2d\u200b\u65f6\u200b\u533a\u200b</li> <li><code>\u200b\u5bfc\u51fa\u200b \u2192 \u200b\u591a\u8f68\u200b\u6df7\u97f3\u200b \u2192 \u200b\u6240\u200b\u9009\u200b\u526a\u8f91\u200b</code>\uff0c\u200b\u5e76\u200b\u53d6\u6d88\u200b\u52fe\u9009\u200b<code>\u200b\u5305\u542b\u200b\u6807\u8bb0\u200b\u548c\u200b\u5176\u4ed6\u200b\u5143\u200b\u6570\u636e\u200b</code>\u200b\u5373\u53ef\u200b\u5b8c\u6210\u200b\u97f3\u9891\u6587\u4ef6\u200b\u7684\u200b\u526a\u8f91\u200b</li> </ol>"},{"location":"Software/Office/Office/index.html","title":"Office","text":""},{"location":"System/Linux/index.html","title":"Linux","text":""},{"location":"System/Virtual_Machine/index.html","title":"\u865a\u62df\u673a","text":""},{"location":"System/Windows/index.html","title":"Windows","text":""},{"location":"blog/index.html","title":"Index","text":""},{"location":"blog/2025/01/31/%E6%88%91%E6%98%AF%E7%BD%97%E6%9F%90.html","title":"\u6211\u200b\u662f\u200b\u7f57\u67d0","text":"<p>hello post</p>"},{"location":"blog/archive/2025-01.html","title":"2025-01","text":""},{"location":"blog/archive/2025-01.html#2025-01","title":"2025-01","text":""},{"location":"blog/category/hello.html","title":"Hello","text":""},{"location":"blog/category/hello.html#hello","title":"Hello","text":""},{"location":"blog/category/world.html","title":"World","text":""},{"location":"blog/category/world.html#world","title":"World","text":""}]}
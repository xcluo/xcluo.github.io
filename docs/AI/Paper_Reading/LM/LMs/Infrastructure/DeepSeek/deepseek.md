## DeepSeekMath
> è®ºæ–‡ï¼šDeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models  
> DeepSeek-AI & Tsinghua University & Peking University, 2024 Feb  

### ä¸»è¦å†…å®¹
- [x] æå‡ºï¼ˆPPOå˜ç§ï¼‰GRPOå¼ºåŒ–å­¦ä¹ æ–¹æ¡ˆæå‡æ¨¡å‹å¯¹é½æ•ˆæœ

#### GRPO

<div class="one-image-container">
    <img src="image/ppo_grpo_diagram.jpg" style="width: 90%;">
</div>

GRPO (Group Relative Policy Optimization)æ˜¯PPOç®—æ³•çš„ä¸€ä¸ªå˜ç§ï¼Œä¸å†éœ€è¦ç»´æŠ¤ä¸€ä¸ªè®¡ç®—é‡éœ€æ±‚å·¨å¤§çš„ä»·å€¼æ¨¡å‹è¾“å‡ºbaselineæ¥è®¡ç®—æ ·æœ¬ä¼˜åŠ¿ï¼Œè€Œæ˜¯
<div class="one-image-container">
    <img src="image/grpo_algorithm.jpg" style="width: 95%;">
</div>
1. ä½¿ç”¨$\pi_{old}$å¯¹åŒä¸€é—®é¢˜é‡‡æ ·ç”Ÿæˆ$G$ä¸ªå›ç­”  
2. æ ¹æ®RMè¾“å‡ºå¯¹åº”çš„å¥–åŠ±åˆ†æ•°  
3. å¯¹å¥–åŠ±åˆ†æ•°ç»“æœ $\mathbb{R}^{G}$ è¿›è¡Œnormæ“ä½œå¾—åˆ°æ ·æœ¬ä¼˜åŠ¿ç»“æœ$A_{i}$  

$$
\begin{aligned}
    \mathcal{J}_{GRPO}&(\theta) = \mathbb{E}\left[q \sim P(Q), \{o_i\}_{i=1}^G \sim \pi_{\theta_{\text{old}}} (O|q)\right] \\
    \frac{1}{G} &\sum_{i=1}^G  \left( \min \left( \frac{\pi_{\theta}(o_i|q)} {\pi_{\theta_{\text{old}}}(o_i|q)} A_i, \operatorname{clip} \left( \frac{\pi_{\theta}(o_i|q)}{\pi_{\theta_{\text{old}}}(o_i|q)}, 1 - \varepsilon, 1 + \varepsilon \right) A_i \right) - \beta \mathbb{D}_{KL} (\pi_{\theta} | \pi_{\text{ref}}) \right) \\
    &\mathbb{D}_{KL} (\pi_{\theta} | \pi_{\text{ref}}) = \frac{\pi_{\text{ref}}(o_i|q)}{\pi_{\theta}(o_i|q)} - \log \frac{\pi_{\text{ref}}(o_i|q)}{\pi_{\theta}(o_i|q)} - 1.
\end{aligned}
$$

## DeepSeek-1
> è®ºæ–‡ï¼šDeepSeek LLM Scaling Open-Source Language Models with Longtermism  
> DeepSeek-AI, 2024 Jan

### ä¸»è¦å†…å®¹
#### Architecture
ä¸»ä½“åŸºäºLLaMAæ¨¡å‹æ¡†æ¶ï¼Œè¿›è¡Œäº†éƒ¨åˆ†æ”¹åŠ¨ï¼š

<div class="one-image-container">
    <img src="image/ds-1_architecture.png" style="width: 100%;">
</div>

- `Pre-RMSNorm`
- `8/3 d_model FFN + SwiGLU` 
- 67B: `GQA â† MHA`  

    > ç›¸åŒå‚æ•°é‡ä¸‹ï¼ŒåŠ æ·±æ¨¡å‹å±‚æ•°è€Œä¸æ˜¯æ‹“å®½$d_\text{ff}$æ›´å®¹æ˜“è·å¾—æ•ˆæœæå‡



#### Pre-Training

1. **Dataset**  
    <div class="one-image-container">
        <img src="image/ds-1_data_deduplication.png" style="width: 100%;">
    </div>
    - ^^å»é‡deduplication^^ï¼šå¯¹Commom Crawl corpusçš„91ä¸ªå…¨ç½‘æ•°æ®çˆ¬å–å­˜æ¡£([CC](https://data.commoncrawl.org/crawl-data/index.html) dump split by month)å»é‡æ¯”å¯¹å•ä¸ªå­˜æ¡£å»é‡ï¼Œå»é‡ç»“æœæ›´ä¼˜  
    - ^^è¿‡æ»¤filtering^^: é›†åˆè¯­æ³•å’Œè¯­ä¹‰ç­‰å±€éƒ¨å’Œå…¨å±€è§†è§’å¯¹æ–‡æ¡£è´¨é‡è¯„ä¼°  
    - ^^æ··åˆremixing^^: å¤„ç†æ•°æ®ä¸å¹³è¡¡é—®é¢˜ï¼Œé‡ç‚¹å¢åŠ ä»£è¡¨æ€§ä¸è¶³çš„é¢†åŸŸæ ·æœ¬
2. **Tokenizer**ï¼ŒByte-level BPE
    - ^^Pre-tokenization^^ ç±»ä¼¼äºGPT-2ï¼Œé˜²æ­¢ä¸åŒç±»åˆ«ç¬¦å·åˆå¹¶ï¼Œå¦‚æ¢è¡Œç¬¦ã€æ ‡ç‚¹ç¬¦å·ä»¥åŠCJKç¬¦å·  
    - ^^Split Number^^ ç±»ä¼¼äºLLaMAï¼Œå°†æ•°å€¼åˆ’åˆ†ä¸ºå•ä¸ªæ•°å­—åºåˆ—
    - ^^Vocab^^: `100000 conventional + 15 special + used for future â†’ 102400`

3. **Hyperparameter**
    - ^^AdamW^^ï¼š$\beta_1 = 0.9, \beta_2 = 0.95$
    - gradient_clip=1.0
    - ^^Multi-step LR scheduler^^
        - ~2000 stepsï¼Œwarmupå‡è‡³max_lr
        - ~80% tokensï¼Œé™è‡³ 0.316*max_lr
        - ~90% tokensï¼Œé™è‡³ 0.1*max_lr
    <div class="one-image-container">
        <img src="image/ds-1_lr_scheduler.png" style="width: 100%;">
    </div>

        !!! info ""
            1. multi-step LRå’Œcos LRæ•ˆæœä¸€è‡´ï¼Œä½†å‰è€…çš„é˜¶æ®µæ€§ç»“æœä¾¿äºä¿å­˜å¤ç”¨ï¼Œå› æ­¤é€‰æ‹©multi-stepæ–¹æ¡ˆ
            2. è°ƒæ•´å„stepçš„tokenå æ¯”å¯èƒ½è·å¾—äº›å¾®æå‡ï¼Œç»¼åˆè€ƒè™‘é€‰æ‹© 80% + 10% + 10% æ–¹æ¡ˆ


- https://152334h.github.io/blog/deepseek-1/


#### Scaling Laws
åŸºäºAttentionæœºåˆ¶çš„Transformeræ¶æ„ä¸­ï¼Œç›´æ¥ä½¿ç”¨$C=6ND$ ä¼°è®¡ç®—åŠ›ä¸è´´åˆå®é™…ï¼Œåº”æ”¹ä¸ºï¼š

$$
\begin{aligned}
    6N_1 =& 72 n_\text{layer} d^2_\text{model} \\
    6N_2 =& 72 n_\text{layer} d^2_\text{model} + 6n_\text{vocab}d_\text{model}\\
    M =& 72 n_\text{layer}d^2_\text{model} + 12 n_\text{layer}d_\text{model} l_\text{seq}
\end{aligned}
$$



- scaling laws  
    - of batch size and learning rate, and found their trends with model size  
    - of the data and model scale  
    - scaling laws derived from different datasets show significant differences  
    - choice of dataset remarkably affects the scaling behavior, indicating that caution should be exercised when generalizing scaling laws across datasets.  

- stages: 2 trillion tokens in Chinese and English for pre-training + 1 million instances for SFT + DPO

- Scaling laws (Henighan et al., 2020; Hoffmann et al., 2022; Kaplan et al., 2020) suggest that model performance can be predictably improved with increases in compute budget ğ¶, model scale ğ‘, and data scale ğ·
    - N: model parameters
    - D: number of tokens
    - C: â‰ˆ6NDï¼Œ6è¡¨ç¤º 1 forward + 2 backward + 3 update

- IsoFLOP profile approach from Chinchilla
- our contributions and findings: 3é¡¹
- FLOPs/tokenï¼Œæ¯å¤„ç†ä¸€ä¸ªtokenæ‰€éœ€çš„**æµ®ç‚¹è¿ç®—**æ¬¡æ•°
    - åµŒå…¥å±‚Embeddingï¼šæ˜ å°„æ“ä½œï¼ŒFLOPs/token=0
    - æ³¨æ„åŠ›å±‚Self-Attentionï¼š1) QKCæŠ•å½±æ“ä½œï¼Œ$3*d_{model}^2$ï¼›2) æ³¨æ„åŠ›æƒé‡çŸ©é˜µï¼Œ`n_head*d_head*seq_len=seq_len*d_model`ï¼›3) softmaxï¼Œåˆ†æ¯éƒ¨åˆ†æ±‚å’Œ $O(d_{model})$ï¼›4) valueåŠ æƒï¼Œ`seq_len*d_model`ï¼›5) Oè¾“å‡ºæŠ•å½±ï¼Œ$d_{model}^2$
    - å‰é¦ˆç½‘ç»œFFNï¼š`d_model â†’ d_ff â†’ d_model, è®¡ç®—é‡ä¸º2*d_model*d_ff`, é€šå¸¸ FLOPs/token=$8*d_{model}^2$
    - LNï¼šå‡å€¼å’Œæ–¹å·® $O(d_{model})$ï¼Œé™¤æ“ä½œæ˜¯bitwise operationï¼ŒFLOPs/token=$2*d_{model}$
    - æ®‹å·®è¿æ¥ï¼šåŠ æ³•æ“ä½œæ˜¯bitwise operationï¼ŒFLOPs/token=0

- $C=MD$ï¼Œ$M$çš„å•ä½ä¸º FLOPs/token
- $\eta_\text{opt}=0.3118\cdot C^{-0.1250}, B_\text{opt} = 0.2920 \cdot C^{0.3271}$
- https://152334h.github.io/blog/deepseek-1/
- optimal Modelï¼š$N_\text{opt} \propto C^{a}$
- optimal Data Scaling (#token)ï¼š$D_\text{opt} \propto C^{b}$
- bits-per-byte on the validation set

- safety evaluation

## DeepSeek-2
> è®ºæ–‡ï¼šDeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model  
> DeepSeek-AI 2024 May

- [x] MLAé€šè¿‡é«˜æ•ˆå‹ç¼©Kã€Vå‘é‡æ–¹å¼å‡å°‘KV cacheä»¥æå‡è®­ç»ƒå’Œé¢„æµ‹æ•ˆç‡ï¼Œå¹¶è·å¾—æ›´å¥½æ•ˆæœè¡¨ç°
- [x] éƒ¨ç½²æ¨¡å‹å‰ï¼Œå¯¹æ¨¡å‹é‡åŒ–ã€å‹ç¼©åï¼Œgeneration throughput è¶…è¿‡ 50K token/sï¼Œprompt throughput è¶…è¿‡ 100K token/s

### ä¸»è¦å†…å®¹
#### MLA
<div class="one-image-container">
    <img src="image/mha_gqa_mqa_mla_diagram.jpg" style="width: 90%;">
    <!-- <p>LoRAåœ¨Attentionå„éƒ¨åˆ†æƒé‡ä¸Šçš„æ¶ˆèå®éªŒæ•ˆæœ</p> -->
    <!-- <figcaption>è¿™æ˜¯å›¾ç‰‡çš„æ ‡é¢˜æˆ–æè¿°ã€‚</figcaption> -->
</div>

MLAï¼ˆ**M**ulti-head **L**atent **A**ttentionï¼‰ä¸MHAæœºåˆ¶ç±»ä¼¼ï¼ŒåŒºåˆ«åœ¨äºå¯¹Qã€Kã€Vå‘é‡è¿›è¡Œäº†å‹ç¼©ï¼Œä¸”å°†ä½ç½®ç¼–ç RoPEä¸å‹ç¼©åçš„Qã€Kã€Vå‘é‡è§£è€¦

1. QKVå‘é‡ä½ç§©å‹ç¼©ï¼Œç±»ä¼¼äºLoRAä¸­$Wx=W^{U}W^{D}x$
    - KVå‘é‡ä½ç§©è”åˆå‹ç¼©

        $$
        \begin{aligned}
            c_{t}^{KV} =& W^{DKV}h_t \\
            k_t^C =& W^{UK}c_t^{KV} \\
            v_t^C =& W^{UV}c_t^{KV} 
        \end{aligned}
        $$

    - Qå‘é‡ä½ç§©å‹ç¼©

        $$
        \begin{aligned}
            c_{t}^{Q} =& W^{DQ}h_t \\
            q_t^C =& W^{UQ}c_t^{Q} 
        \end{aligned}
        $$

    > ä¸Šæ ‡$D$è¡¨ç¤ºé™ç»´ï¼Œ$U$è¡¨ç¤ºå‡ç»´  
    > $W^{UK},W^{UV}\in \mathbb{R}^{d_hn_h\times d_c}$ï¼Œ$W^{UQ}\in \mathbb{R}^{d_hn_h\times d_c^{'}}$ ä¸” $d_c,d_c^{'} \ll d_hn_h$  
    > $c$ è¡¨ç¤ºé™ç»´å‹ç¼©åçš„ç¼“å­˜å‘é‡ï¼Œ$C$è¡¨ç¤ºå‘é‡ç»é™ç»´ã€å‡ç»´æ“ä½œåçš„ç»“æœæ ‡å¿—  

2. ä½ç½®ç¼–ç RoPEè§£è€¦åˆï¼Œç”±äºç›®çš„æ˜¯cacheå‹ç¼©åçš„å‘é‡ $c$ï¼Œå¦‚ä¸‹å¯¹$c$å‡ç»´ååº”ç”¨RoPEï¼Œ
    
    $$
    \begin{aligned}
        \langle \text{RoPE}(W^{UQ}c^Q_t, m), \text{RoPE}(W^{UK}c^{K}_t, n) \rangle =& \big(c_t^Q\big)^T\big(W^{UQ}\big)^Te^{-im\theta} e^{in\theta}W^{UK}c_t^K \\
        = &  g(c_t^Q, c_t^K, n-m)
    \end{aligned}
    $$

    è™½ç„¶ä¾ç„¶èƒ½è·å–ç›¸å¯¹ä½ç½®ä¿¡æ¯ï¼Œä½†ç”±äº$W^{UQ}$ä¸$W^{UK}$è¢«æ—‹è½¬ä½ç½®ç¼–ç çŸ©é˜µé—´éš”ï¼Œæ— æ³•èåˆï¼Œå› æ­¤æ¯æ¬¡è®¡ç®—$\langle q, k \rangle$ä¼šé‡æ–°è®¡ç®—$k=W^{UK}c^K_t$ï¼Œæå¤§åœ°é˜»ç¢äº†é¢„æµ‹æ—¶çš„æ•ˆç‡ã€‚ä¸ºä½¿MLAèƒ½å…¼å®¹RoPEå¹¶æå‡æ•ˆç‡ï¼Œæå‡ºäº†å¯¹å‹ç¼©åçš„Qã€Kã€Vå‘é‡è§£è€¦çš„æ–¹å¼é¢å¤–æ³¨å…¥ä½ç½®ä¿¡æ¯ã€‚

    $$
    \begin{aligned}
        q_t^R \in \mathbb{R}^{d_h^{R}n_h} =& \text{RoPE}(W^{QR}c_t^Q) \\
        k_t^R \in \mathbb{R}^{d_h^R} =& \text{RoPE}(W^{KR}h_t) \\
        q_{t, i} =& [q^C_{t, i}; q^R_{t, i}] \\
        k_{t, i} =& [k^C_{t, i}; k^R_{t}] \\
    \end{aligned}
    $$

    > - è®¡ç®—$k^R_t$æ—¶ä½¿ç”¨$h_t$è€Œä¸æ˜¯ä½¿ç”¨$c_t^{KV}$åªæ˜¯ä¸€ä¸ªç›´è§‚ä¸Šçš„é€‰æ‹©ï¼Œä¸”ç”±äºä¸éœ€è¦å‡ç»´ï¼Œé€‰æ‹©å‰è€…æ•ˆæœæ›´åŠ åˆç†  
    > - æ¯ä¸ªheadå„è‡ªæ‹¥æœ‰ä¸€ä¸ª$q_{t,i}^R$ï¼Œæ‰€æœ‰headå…±äº«ä¸€ä¸ª$k_t^R$  
    > - ç›®æ ‡æ˜¯ç¼“å­˜**éœ€è¦å‡ç»´çš„ä½ç»´å‹ç¼©ç»“æœ**$c^{KV}_t$ï¼Œæ‰€ä»¥è¿›è¡Œè§£è€¦å¹¶é¢å¤–ç¼“å­˜**æ— éœ€å‡ç»´çš„ä½ç»´ä½ç½®ç¼–ç **$k^{R}_t$
   
3. put all togetherï¼Œæœ€ç»ˆMLAçš„Attentionè®¡ç®—è¿‡ç¨‹ä¸º

    $$
    \begin{aligned}
        o_{t} =& \sum_{j=1}^t \text{Softmax}_j \bigg(\frac{q^T_{t}k_{j}}{\sqrt{d_h + d_h^R}}\bigg)v_{j}^C \\
        = & \sum_{j=1}^t \text{Softmax}_j \bigg(\frac{[q^C_{t}; q^R_{t}][k^C_{j}; k^R_{j}]^T}{\sqrt{d_h + d_h^R}}\bigg)v_{j}^C\\
        = & \sum_{j=1}^t \text{Softmax}_j \bigg(\frac{[W^{UQ}c^{Q}_t; \text{RoPE}(W^{QR}c^Q_t)][W^{UK}c^{KV}_j; k^R_t)]^T}{\sqrt{d_h + d_h^R}}\bigg)W^{UV}c^{KV}_j\\
        u_t =& W^Oo_{t}
    \end{aligned}
    $$

    > åœ¨é¢„æµ‹æ—¶ï¼Œå¯è¿›ä¸€æ­¥ç¼©å‡å‘é‡è®¡ç®— $W^{UQ}_{absorb} = (W^{UQ})^TW^{UK}$ä»¥åŠ$W^O_{absorb}=W^{O}W^{UV}$

4. KV cacheå¯¹æ¯”ï¼ŒKV cacheæ¥è¿‘MQAï¼Œæ•ˆæœæœ€å¼º
    <div class="one-image-container">
        <img src="image/mha_gqa_mqa_mla_kv-cache_comparion.jpg" style="width: 90%;">
        <!-- <p>LoRAåœ¨Attentionå„éƒ¨åˆ†æƒé‡ä¸Šçš„æ¶ˆèå®éªŒæ•ˆæœ</p> -->
        <!-- <figcaption>DeepSeekMoE</figcaption> -->
    </div>

5. æ•ˆæœå¯¹æ¯”ï¼Œè¾ƒMHAæ•ˆæœæœ‰æ˜æ˜¾æå‡ï¼Œæ•ˆæœæœ€å¼º
    <div class="one-image-container">
        <img src="image/mha_mqa_gqa_performance_comparion.jpg" style="width: 90%;">
        <!-- <p>LoRAåœ¨Attentionå„éƒ¨åˆ†æƒé‡ä¸Šçš„æ¶ˆèå®éªŒæ•ˆæœ</p> -->
        <!-- <figcaption>DeepSeekMoE</figcaption> -->
    </div>

#### DeepSeekMoE

<div class="one-image-container">
    <img src="image/deepseekmoe.jpg" style="width: 90%;">
    <!-- <p>LoRAåœ¨Attentionå„éƒ¨åˆ†æƒé‡ä¸Šçš„æ¶ˆèå®éªŒæ•ˆæœ</p> -->
    <figcaption>DeepSeekMoE</figcaption>
</div>

DeepSeekMoeåœ¨ä¼ ç»ŸMoEçš„åŸºç¡€ä¸Šå°†ä¸“å®¶ç½‘ç»œåˆ†ä¸ºrouted expertså’Œshared expertsï¼Œå‰è€…å®ç°å¯¹è¾“å…¥tokençš„ä¸“ä¸šåŒ–å¤„ç†ï¼Œåè€…ç”¨äºå‡è½»è·¯ç”±ä¸“å®¶ç½‘ç»œé—´çš„çŸ¥è¯†å†—ä½™ã€‚

$$
\begin{aligned} 
\mathbf{h}_t' =& \mathbf{u}_t + \sum_{i=1}^{N_s} \text{FFN}_i^{(s)} (\mathbf{u}_t) + \sum_{i=1}^{N_r} g_{i,t} \text{FFN}_i^{(r)} (\mathbf{u}_t) \\
g_{i,t} = & 
\begin{cases} 
s_{i,t}, & s_{i,t} \in \text{Topk}(\{s_{j,t}|1 \leq j \leq N_r\}, K_r), \\
0, & \text{otherwise}
\end{cases} \\
s_{i,t} =& \text{Softmax}_i (\mathbf{u}_t^T e_i).
\end{aligned}
$$

> topKæ“ä½œåçš„è·¯ç”±ä¸“å®¶ç½‘ç»œæƒé‡$g_{i, t}$æœªsoftmaxï¼Œåœ¨[v3](#deepseek-v3)ä¸­è¿›è¡Œäº†topKåsoftmax


ç”±äºæ¨¡å‹è®­ç»ƒçš„æ—¶å€™é‡‡ç”¨äº†å¹¶è¡ŒæŠ€æœ¯ï¼Œä¸ºé˜²æ­¢ä¸“å®¶ç½‘ç»œæ¿€æ´»è·¯ç”±åå¡Œï¼Œé‡‡ç”¨äº†ä»¥ä¸‹è¾…åŠ©æŸå¤±å‡½æ•°ï¼š

1. Expert-Levelè´Ÿè½½å‡è¡¡ï¼Œå³åœ¨å¤„ç†æŸä¸€åºåˆ—æ—¶ï¼Œå‡è¡¡å„ä¸“å®¶ç½‘ç»œè¢«æ¿€æ´»çš„åŠ æƒåˆ†æ•°æ€»å’Œ

    $$
    \begin{aligned}
        \mathcal{L}_{\text{ExpBal}} =& \alpha_1\sum_{i=1}^{N_r}f_iP_i \\
        f_i =& \frac{N_r}{K_rT}\sum_{t=1}^T \mathbb{1}\text{ (Token }t\text{ selects Expert }i\text{)} \\
        P_i =& \frac{1}{T}\sum_{t=1}^T s_{i, t}
    \end{aligned}
    $$

2. Device-Levelè´Ÿè½½å‡è¡¡ï¼Œå³åœ¨å¤„ç†æŸä¸€åºåˆ—æ—¶ï¼Œå‡è¡¡å„æœºå™¨ä¸Šå„ä¸“å®¶ç½‘ç»œè¢«æ¿€æ´»çš„åŠ æƒåˆ†æ•°æ€»å’Œ

    $$
    \begin{aligned}
        \mathcal{L}_{\text{DevBal}} =& \alpha_2\sum_{i=1}^{D}f_i^{'}P_i^{'} \\
        f_i^{'} =& \frac{1}{\vert \varepsilon_i \vert}\sum_{j \in \varepsilon_i} f_j \\
        P_i^{'} =& \sum_{j \in \varepsilon_i }P_j
    \end{aligned}
    $$

    > è·¯ç”±ç½‘ç»œè¢«åˆ†æˆ$D$ç»„$\{\varepsilon_1, \varepsilon_2, \dots, \varepsilon_D\}$

3. Communicatingè´Ÿè½½å‡è¡¡ï¼Œå³åœ¨å¤„ç†æŸä¸€åºåˆ—æ—¶ï¼Œå‡è¡¡å„ä¸“å®¶ç½‘ç»œç»„è¢«æ¿€æ´»çš„åŠ æƒåˆ†æ•°æ€»å’Œ

    $$
    \begin{aligned}
        \mathcal{L}_{\text{CommBal}} =& \alpha_3\sum_{i=1}^{D}f_i^{''}P_i^{''} \\
        f_i^{''} =& \frac{D}{MT}\sum_{t=1}^T \mathbb{1}\text{ (Token }t\text{ selects Expert }i\text{)} \\
        P_i^{''} =& \sum_{j \in \varepsilon_i }P_j
    \end{aligned}
    $$

    > ä¸MoEç±»ä¼¼ï¼Œå¹¶è¡Œæ—¶æœ€å¤šæ¿€æ´»$M$ç»„ä¸“å®¶ç½‘ç»œ

è™½ç„¶DeepSeekæ¨¡å‹é‡‡ç”¨äº†è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼Œä½†ä¾ç„¶ä¼šå­˜åœ¨éƒ¨åˆ†ä¸“å®¶ç½‘ç»œè®¡ç®—å¼€é”€é«˜äºå¹³å‡æ°´å¹³ï¼Œå› æ­¤éœ€è¦å¯¹è¶…è´Ÿè½½çš„ç½‘ç»œæ‰§è¡Œtoken-dropping ç­–ç•¥ã€‚

1. è®­ç»ƒæ—¶ä»device-levelæ‰§è¡Œtokenèˆå¼ƒç­–ç•¥ï¼Œå³åœ¨è¶…å‡ºè®¡ç®—è´Ÿè½½çš„æœºå™¨ä¸Šï¼ŒæŒ‰æ‰€æœ‰ç½‘ç»œæ¿€æ´»æƒé‡åˆ†æ•°ä»å°åˆ°å¤§èˆå¼ƒtokenç›´åˆ°æœºå™¨è®¡ç®—é‡å¤„äºè´Ÿè½½èŒƒå›´å†…ã€‚  

    > æ­¤å¤–ï¼Œè¿˜è®¾è®¡æ–¹æ¡ˆç¡®ä¿è‡³å°‘10%çš„è®­ç»ƒæ•°æ®ä¸æ‰§è¡Œtokenèˆå¼ƒç­–ç•¥

2. æµ‹è¯•æ—¶ï¼Œå¯åŸºäºæ•ˆç‡å’Œä¸€è‡´æ€§è€ƒé‡æ˜¯å¦è¦æ‰§è¡Œtokenèˆå¼ƒç­–ç•¥

#### Inference Speedup
1. å°†æ‰€æœ‰å‚æ•°é‡åŒ–ä¸ºFP8ç²¾åº¦ç±»å‹
2. è¿›ä¸€æ­¥å¯¹KV cacheè¿›è¡Œé‡åŒ–ï¼Œå‹ç¼©åå¹³å‡å¤§å°ä¸º 6-bit

è®­ç»ƒï¼š

1. full pre-trained on 8.1T tokens(DeepSeek 67B corpus + Chinese Data + higher quality data)  
2. 1.5M conventional sessions with various domains such math, code, writing, reasoning, safety, and more to SFT DeepSeek-v2 chat  
3. follow DeepSeekMath to employ Group Relative policy Optimization(GRPO) to align model with RLHF


æ¨¡å‹æ¶æ„ï¼š

1. DeepSeek-V2
2. DeepSeek-V2-Lite
3. DeepSeek-V2-Chat_SFT
4. DeepSeek-V2-Chat_RL

ç­–ç•¥ï¼š

2. Token-Dropping Strategy: In this way, we can flexibly decide whether to drop tokens during inference according to the efficiency requirements, and always ensure consistency between training and inference.  
3. R1ä¸­çš„reward modelå’Œv2ä¸­çš„ä¸ç›¸åŒï¼Œå®é™…ä¸Šæ˜¯ä¸€ä¸ªrulee-based system

3. HAI-LLM framework

æ•°æ®å¤„ç†ï¼š
1. Data Construction
2. [BBPE](https://zhuanlan.zhihu.com/p/3329211354?utm_psn=1857473827581349889)ï¼ˆByte-level Byte-Pair Encodingï¼‰

- MTP: ç±»ä¼¼äºskip-gramï¼Œté¢„æµ‹t+1, t+2, ..., t+k

- low-precision training

## DeepSeek-3


### ä¸»è¦å†…å®¹
- å…±äº«ä¸“å®¶ä¸ä¸“ä¸šä¸“å®¶æ•°é‡éƒ½ä¹˜ä»¥äº†må€ï¼Œä¸ºä¿æŒå‚æ•°é‡ä¸å˜ï¼Œintermediate hidden state dimä¹Ÿéœ€è¦1/m

#### MoE Load Balance Loss-free
#### MTP
<div class="one-image-container">
    <img src="image/mtp.jpg" style="width: 95%;">
    <!-- <p>LoRAåœ¨Attentionå„éƒ¨åˆ†æƒé‡ä¸Šçš„æ¶ˆèå®éªŒæ•ˆæœ</p> -->
    <!-- <figcaption>DeepSeekMoE</figcaption> -->
</div>
MTP (Multi-Token Predictoin)ï¼ŒåŸºäºå½“å‰tokenä¸€æ¬¡æ€§é¢„æµ‹æœªæ¥$D$ä¸ªä½ç½®çš„tokenã€‚å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œé€šè¿‡ä¸Šä¸€æ—¶åºçš„éšå±‚ä¿¡æ¯ä¸å½“å‰çŠ¶æ€çš„token_embeddingè¾“å…¥ï¼Œé¢„æµ‹ä¸‹ä¸€æ—¶åˆ»çš„tokenï¼Œå³ï¼š

- $MTP_1$è¾“å…¥ä¿¡æ¯ä¸º$\text{cat}\big([t_1], \text{emb}(t_2)\big)$ï¼Œé¢„æµ‹$t_3$
- $MTP_2$è¾“å…¥ä¿¡æ¯ä¸º$\text{cat}\big([t_1, t_2], \text{emb}(t_3))$ï¼Œé¢„æµ‹$t_4$
- $MTP_k$è¾“å…¥ä¿¡æ¯ä¸º$\text{cat}\big([t_1, t_2, \dots, t_{k-1}], \text{emb}(t_k)\big)$ï¼Œé¢„æµ‹$t_{k+1}$

!!! info ""
    - $[t_1, \dots, t_k]$ è¡¨ç¤ºäº†æ•´åˆäº†$[1, t]$ tokensçš„$MTP_{k-1}$è¾“å‡ºï¼ˆ$MTP_0$ä¸ºmain modelï¼‰ï¼Œæœ¬è´¨ä¸Šä¾ç„¶ä¿ç•™äº†æ—¶åºé“¾  
    - $\mathcal{L} = \mathcal{L}_{main} + \frac{\lambda}{D}\sum_{i=1}^{D}\mathcal{L}_{MTP}^k$
    - åœ¨æµ‹è¯•æ—¶å¯ç›´æ¥ä½¿ç”¨main modelè¿›è¡Œæ­£å¸¸æ–‡æœ¬ç”Ÿæˆï¼Œä¹Ÿå¯åŸºäºæå‡æ–‡æœ¬ç”Ÿæˆæ•ˆç‡è€ƒé‡ï¼Œä½¿ç”¨MTPç½‘ç»œå¿«é€Ÿç”Ÿæˆé‚»è¿‘token
#### FP8 Training